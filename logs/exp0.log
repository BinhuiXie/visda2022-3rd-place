2022-10-03 14:06:30,186 - mmseg - INFO - Environment info:------------------------------------------------------------sys.platform: linuxPython: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]CUDA available: TrueGPU 0: NVIDIA A100-SXM4-80GBCUDA_HOME: /usr/local/cudaNVCC: Build cuda_11.3.r11.3/compiler.29745058_0GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0PyTorch: 1.7.1+cu110PyTorch compiling details: PyTorch built with:  - GCC 7.3  - C++ Version: 201402  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)  - OpenMP 201511 (a.k.a. OpenMP 4.5)  - NNPACK is enabled  - CPU capability usage: AVX2  - CUDA Runtime 11.0  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80  - CuDNN 8.0.5  - Magma 2.5.2  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, TorchVision: 0.8.2+cu110OpenCV: 4.4.0MMCV: 1.3.7MMCV Compiler: GCC 7.3MMCV CUDA Compiler: 11.0MMSegmentation: 0.16.0+b04485f------------------------------------------------------------2022-10-03 14:06:30,188 - mmseg - INFO - Distributed training: False2022-10-03 14:06:30,880 - mmseg - INFO - Config:log_config = dict(    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])dist_params = dict(backend='nccl')log_level = 'INFO'load_from = Noneresume_from = Noneworkflow = [('train', 1)]cudnn_benchmark = Truenorm_cfg = dict(type='BN', requires_grad=True)find_unused_parameters = Truemodel = dict(    type='EncoderDecoder',    pretrained='pretrained/mit_b5.pth',    backbone=dict(type='mit_b5', style='pytorch'),    decode_head=dict(        type='SegFormerHead',        in_channels=[64, 128, 320, 512],        in_index=[0, 1, 2, 3],        channels=128,        dropout_ratio=0.1,        num_classes=5,        norm_cfg=dict(type='BN', requires_grad=True),        align_corners=False,        decoder_params=dict(embed_dim=768, conv_kernel_size=1),        loss_decode=dict(            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),    train_cfg=dict(        work_dir=        'work_dirs_test/local-exp0/221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_24646'    ),    test_cfg=dict(mode='whole'))img_norm_cfg = dict(    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)crop_size = (640, 640)train_pipeline = [    dict(type='LoadImageFromFile'),    dict(type='LoadAnnotations'),    dict(type='Resize', img_scale=(1138, 640)),    dict(type='RandomCrop', crop_size=(640, 640), cat_max_ratio=0.75),    dict(type='RandomFlip', prob=0.5),    dict(type='PhotoMetricDistortion'),    dict(        type='Normalize',        mean=[123.675, 116.28, 103.53],        std=[58.395, 57.12, 57.375],        to_rgb=True),    dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),    dict(type='DefaultFormatBundle'),    dict(type='Collect', keys=['img', 'gt_semantic_seg'])]test_pipeline = [    dict(type='LoadImageFromFile'),    dict(        type='MultiScaleFlipAug',        img_scale=(1138, 640),        flip=False,        transforms=[            dict(type='Resize', keep_ratio=True),            dict(type='RandomFlip'),            dict(                type='Normalize',                mean=[123.675, 116.28, 103.53],                std=[58.395, 57.12, 57.375],                to_rgb=True),            dict(type='ImageToTensor', keys=['img']),            dict(type='Collect', keys=['img'])        ])]data = dict(    samples_per_gpu=2,    workers_per_gpu=4,    train=dict(        type='ZeroWasteDataset',        data_root='data/zerowaste-f/train',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(type='LoadAnnotations'),            dict(type='Resize', img_scale=(1138, 640)),            dict(type='RandomCrop', crop_size=(640, 640), cat_max_ratio=0.75),            dict(type='RandomFlip', prob=0.5),            dict(type='PhotoMetricDistortion'),            dict(                type='Normalize',                mean=[123.675, 116.28, 103.53],                std=[58.395, 57.12, 57.375],                to_rgb=True),            dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),            dict(type='DefaultFormatBundle'),            dict(type='Collect', keys=['img', 'gt_semantic_seg'])        ]),    val=dict(        type='ZeroWasteDataset',        data_root='data/zerowaste-f/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]),    test=dict(        type='ZeroWasteV2Dataset',        data_root='data/zerowaste-v2-splits/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]))optimizer = dict(    type='AdamW',    lr=6e-05,    betas=(0.9, 0.999),    weight_decay=0.01,    paramwise_cfg=dict(        custom_keys=dict(            head=dict(lr_mult=10.0),            pos_block=dict(decay_mult=0.0),            norm=dict(decay_mult=0.0))))optimizer_config = dict()lr_config = dict(    policy='poly',    warmup='linear',    warmup_iters=1500,    warmup_ratio=1e-06,    power=1.0,    min_lr=0.0,    by_epoch=False)n_gpus = 1seed = 0runner = dict(type='IterBasedRunner', max_iters=40000)checkpoint_config = dict(by_epoch=False, interval=40000, max_keep_ckpts=1)evaluation = dict(interval=4000, metric='mIoU')exp = 0name_dataset = 'zerov12zerov2'name_architecture = 'segformer_mitb5'name_encoder = 'mitb5'name_decoder = 'segformer'name_uda = 'source-only'name_opt = 'adamw_6e-05_pmTrue_poly10warm_1x2_40k'name = '221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_24646'work_dir = 'work_dirs_test/local-exp0/221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_24646'git_rev = 'b04485f35bf8bfa11df11b677c6511e302c0dffc'gpu_ids = range(0, 1)2022-10-03 14:06:30,880 - mmseg - INFO - Set random seed to 0, deterministic: False/mnt/data/bit/xbh/_visda2022/visda2022-ours/mmseg/models/backbones/mix_transformer.py:214: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead  warnings.warn('DeprecationWarning: pretrained is a deprecated, '2022-10-03 14:06:31,467 - mmseg - INFO - Load mit checkpoint.2022-10-03 14:06:31,467 - mmseg - INFO - Use load_from_local loader/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/cnn/utils/weight_init.py:118: UserWarning: init_cfg without layer key, if you do not define override key either, this init_cfg will do nothing  warnings.warn(2022-10-03 14:06:31,818 - mmseg - INFO - EncoderDecoder(  (backbone): mit_b5(    (patch_embed1): OverlapPatchEmbed(      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)    )    (patch_embed2): OverlapPatchEmbed(      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)    )    (patch_embed3): OverlapPatchEmbed(      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)    )    (patch_embed4): OverlapPatchEmbed(      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)    )    (block1): ModuleList(      (0): Block(        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=64, out_features=64, bias=True)          (kv): Linear(in_features=64, out_features=128, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=64, out_features=64, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)        )        (drop_path): Identity()        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=64, out_features=256, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)          )          (act): GELU()          (fc2): Linear(in_features=256, out_features=64, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (1): Block(        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=64, out_features=64, bias=True)          (kv): Linear(in_features=64, out_features=128, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=64, out_features=64, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=64, out_features=256, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)          )          (act): GELU()          (fc2): Linear(in_features=256, out_features=64, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (2): Block(        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=64, out_features=64, bias=True)          (kv): Linear(in_features=64, out_features=128, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=64, out_features=64, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=64, out_features=256, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)          )          (act): GELU()          (fc2): Linear(in_features=256, out_features=64, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )    )    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)    (block2): ModuleList(      (0): Block(        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=128, out_features=128, bias=True)          (kv): Linear(in_features=128, out_features=256, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=128, out_features=128, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=128, out_features=512, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)          )          (act): GELU()          (fc2): Linear(in_features=512, out_features=128, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (1): Block(        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=128, out_features=128, bias=True)          (kv): Linear(in_features=128, out_features=256, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=128, out_features=128, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=128, out_features=512, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)          )          (act): GELU()          (fc2): Linear(in_features=512, out_features=128, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (2): Block(        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=128, out_features=128, bias=True)          (kv): Linear(in_features=128, out_features=256, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=128, out_features=128, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=128, out_features=512, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)          )          (act): GELU()          (fc2): Linear(in_features=512, out_features=128, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (3): Block(        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=128, out_features=128, bias=True)          (kv): Linear(in_features=128, out_features=256, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=128, out_features=128, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=128, out_features=512, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)          )          (act): GELU()          (fc2): Linear(in_features=512, out_features=128, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (4): Block(        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=128, out_features=128, bias=True)          (kv): Linear(in_features=128, out_features=256, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=128, out_features=128, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=128, out_features=512, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)          )          (act): GELU()          (fc2): Linear(in_features=512, out_features=128, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (5): Block(        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=128, out_features=128, bias=True)          (kv): Linear(in_features=128, out_features=256, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=128, out_features=128, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=128, out_features=512, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)          )          (act): GELU()          (fc2): Linear(in_features=512, out_features=128, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )    )    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)    (block3): ModuleList(      (0): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (1): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (2): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (3): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (4): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (5): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (6): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (7): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (8): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (9): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (10): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (11): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (12): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (13): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (14): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (15): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (16): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (17): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (18): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (19): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (20): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (21): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (22): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (23): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (24): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (25): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (26): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (27): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (28): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (29): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (30): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (31): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (32): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (33): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (34): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (35): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (36): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (37): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (38): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (39): Block(        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=320, out_features=320, bias=True)          (kv): Linear(in_features=320, out_features=640, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=320, out_features=320, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)        )        (drop_path): DropPath()        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=320, out_features=1280, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)          )          (act): GELU()          (fc2): Linear(in_features=1280, out_features=320, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )    )    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)    (block4): ModuleList(      (0): Block(        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=512, out_features=512, bias=True)          (kv): Linear(in_features=512, out_features=1024, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=512, out_features=512, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)        )        (drop_path): DropPath()        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=512, out_features=2048, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)          )          (act): GELU()          (fc2): Linear(in_features=2048, out_features=512, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (1): Block(        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=512, out_features=512, bias=True)          (kv): Linear(in_features=512, out_features=1024, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=512, out_features=512, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)        )        (drop_path): DropPath()        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=512, out_features=2048, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)          )          (act): GELU()          (fc2): Linear(in_features=2048, out_features=512, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )      (2): Block(        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)        (attn): Attention(          (q): Linear(in_features=512, out_features=512, bias=True)          (kv): Linear(in_features=512, out_features=1024, bias=True)          (attn_drop): Dropout(p=0.0, inplace=False)          (proj): Linear(in_features=512, out_features=512, bias=True)          (proj_drop): Dropout(p=0.0, inplace=False)        )        (drop_path): DropPath()        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)        (mlp): Mlp(          (fc1): Linear(in_features=512, out_features=2048, bias=True)          (dwconv): DWConv(            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)          )          (act): GELU()          (fc2): Linear(in_features=2048, out_features=512, bias=True)          (drop): Dropout(p=0.0, inplace=False)        )      )    )    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)  )  (decode_head): SegFormerHead(    input_transform=multiple_select, ignore_index=255, align_corners=False    (loss_decode): CrossEntropyLoss()    (conv_seg): Conv2d(128, 5, kernel_size=(1, 1), stride=(1, 1))    (dropout): Dropout2d(p=0.1, inplace=False)    (linear_c): ModuleDict(      (0): MLP(        (proj): Linear(in_features=64, out_features=768, bias=True)      )      (1): MLP(        (proj): Linear(in_features=128, out_features=768, bias=True)      )      (2): MLP(        (proj): Linear(in_features=320, out_features=768, bias=True)      )      (3): MLP(        (proj): Linear(in_features=512, out_features=768, bias=True)      )    )    (linear_fuse): ConvModule(      (conv): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (activate): ReLU(inplace=True)    )    (linear_pred): Conv2d(768, 5, kernel_size=(1, 1), stride=(1, 1))  )  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}})2022-10-03 14:06:31,870 - mmseg - INFO - Loaded 3002 images from data/zerowaste-f/train/data2022-10-03 14:06:33,786 - mmseg - INFO - Loaded 929 images from data/zerowaste-f/test/data2022-10-03 14:06:33,786 - mmseg - INFO - Start running, host: root@perception-jupyter, work_dir: /mnt/data/bit/xbh/_visda2022/visda2022-ours/work_dirs_test/local-exp0/221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:06:33,786 - mmseg - INFO - workflow: [('train', 1)], max: 40000 itersRun job 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_24646/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:06:54,840 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 4:36:27, time: 0.415, data_time: 0.015, memory: 11956, decode.loss_seg: 1.6186, decode.acc_seg: 24.8533, loss: 1.6186/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:07:14,392 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 4:28:04, time: 0.391, data_time: 0.007, memory: 11956, decode.loss_seg: 1.1864, decode.acc_seg: 64.2208, loss: 1.1864/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:07:34,331 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 4:26:45, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.7380, decode.acc_seg: 84.1515, loss: 0.7380/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:07:54,093 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 4:25:21, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.5418, decode.acc_seg: 85.0593, loss: 0.5418/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:08:14,117 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 4:25:04, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.4501, decode.acc_seg: 85.9344, loss: 0.4501/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:08:33,963 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 4:24:23, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.4022, decode.acc_seg: 86.9071, loss: 0.4022/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:08:53,745 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 4:23:41, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3791, decode.acc_seg: 86.9744, loss: 0.3791/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:09:13,755 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 4:23:26, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3836, decode.acc_seg: 86.7717, loss: 0.3836/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:09:33,563 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 4:22:53, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3732, decode.acc_seg: 86.5429, loss: 0.3732/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:09:53,276 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 4:22:15, time: 0.394, data_time: 0.006, memory: 11956, decode.loss_seg: 0.3571, decode.acc_seg: 87.2564, loss: 0.3571/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:10:12,965 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 4:21:39, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3588, decode.acc_seg: 87.3427, loss: 0.3588/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:10:32,735 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 4:21:10, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3569, decode.acc_seg: 87.1990, loss: 0.3569/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:10:52,554 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 4:20:46, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3246, decode.acc_seg: 88.5606, loss: 0.3246/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:11:12,601 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 4:20:36, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3270, decode.acc_seg: 89.0181, loss: 0.3270/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:11:32,291 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 4:20:05, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3513, decode.acc_seg: 87.6332, loss: 0.3513/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:11:52,203 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 4:19:47, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3265, decode.acc_seg: 89.0132, loss: 0.3265/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:12:12,133 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 4:19:29, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3180, decode.acc_seg: 88.2775, loss: 0.3180/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:12:32,115 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 4:19:13, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2931, decode.acc_seg: 90.1849, loss: 0.2931/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:12:51,966 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 4:18:52, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2724, decode.acc_seg: 90.0429, loss: 0.2724/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:13:11,770 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:13:11,771 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 4:18:29, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3206, decode.acc_seg: 89.4088, loss: 0.3206/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:13:31,463 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 4:18:02, time: 0.394, data_time: 0.006, memory: 11956, decode.loss_seg: 0.3278, decode.acc_seg: 88.3339, loss: 0.3278/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:13:51,256 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 4:17:39, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3019, decode.acc_seg: 89.3818, loss: 0.3019/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:14:11,001 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 4:17:15, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3525, decode.acc_seg: 87.8388, loss: 0.3525/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:14:30,840 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 4:16:54, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3281, decode.acc_seg: 87.8030, loss: 0.3281/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:14:50,929 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 4:16:41, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3123, decode.acc_seg: 88.5180, loss: 0.3123/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:15:10,677 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 4:16:17, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3010, decode.acc_seg: 89.4306, loss: 0.3010/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:15:30,475 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 4:15:56, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2924, decode.acc_seg: 89.7516, loss: 0.2924/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:15:50,404 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 4:15:37, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3088, decode.acc_seg: 88.9356, loss: 0.3088/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:16:10,280 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 4:15:18, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2745, decode.acc_seg: 90.3960, loss: 0.2745/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:16:30,076 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 4:14:56, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3139, decode.acc_seg: 89.1265, loss: 0.3139/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:16:50,555 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 4:14:51, time: 0.410, data_time: 0.021, memory: 11956, decode.loss_seg: 0.3042, decode.acc_seg: 89.1207, loss: 0.3042/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:17:10,335 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 4:14:29, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2827, decode.acc_seg: 89.4605, loss: 0.2827/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:17:30,323 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 4:14:11, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2841, decode.acc_seg: 89.3791, loss: 0.2841/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:17:50,030 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 4:13:48, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2779, decode.acc_seg: 89.7670, loss: 0.2779/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:18:09,730 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 4:13:24, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2996, decode.acc_seg: 89.5813, loss: 0.2996/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:18:29,523 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 4:13:02, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2675, decode.acc_seg: 90.6175, loss: 0.2675/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:18:49,270 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 4:12:40, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2340, decode.acc_seg: 92.0616, loss: 0.2340/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:19:09,078 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 4:12:19, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2749, decode.acc_seg: 90.0717, loss: 0.2749/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:19:28,760 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 4:11:55, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3084, decode.acc_seg: 88.8116, loss: 0.3084/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:19:48,542 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:19:48,542 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 4:11:34, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2606, decode.acc_seg: 90.1806, loss: 0.2606/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:20:08,190 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 4:11:10, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2472, decode.acc_seg: 91.3455, loss: 0.2472/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:20:28,129 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 4:10:51, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2685, decode.acc_seg: 90.1832, loss: 0.2685/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:20:48,042 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 4:10:33, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2934, decode.acc_seg: 89.9348, loss: 0.2934/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:21:08,058 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 4:10:15, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.3151, decode.acc_seg: 88.9975, loss: 0.3151/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:21:27,722 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 4:09:52, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2902, decode.acc_seg: 89.7193, loss: 0.2902/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:21:47,432 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 4:09:30, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2600, decode.acc_seg: 91.4189, loss: 0.2600/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:22:07,100 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 4:09:07, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2806, decode.acc_seg: 89.7780, loss: 0.2806/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:22:27,094 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 4:08:49, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2712, decode.acc_seg: 90.0108, loss: 0.2712/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:22:47,042 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 4:08:31, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2034, decode.acc_seg: 92.9696, loss: 0.2034/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:23:07,032 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 4:08:13, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2584, decode.acc_seg: 90.5791, loss: 0.2584/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:23:26,965 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 4:07:54, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2413, decode.acc_seg: 91.3104, loss: 0.2413/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:23:46,898 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 4:07:36, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2049, decode.acc_seg: 92.8340, loss: 0.2049/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:24:06,639 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 4:07:14, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2717, decode.acc_seg: 90.5515, loss: 0.2717/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:24:26,499 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 4:06:54, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2458, decode.acc_seg: 91.3931, loss: 0.2458/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:24:46,437 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 4:06:35, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2315, decode.acc_seg: 91.9799, loss: 0.2315/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:25:06,372 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 4:06:17, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2540, decode.acc_seg: 91.2292, loss: 0.2540/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:25:26,342 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 4:05:58, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2292, decode.acc_seg: 92.0727, loss: 0.2292/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:25:46,252 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 4:05:39, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2847, decode.acc_seg: 89.7892, loss: 0.2847/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:26:06,014 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 4:05:18, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2870, decode.acc_seg: 89.7089, loss: 0.2870/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:26:25,844 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:26:25,844 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 4:04:57, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2627, decode.acc_seg: 90.3830, loss: 0.2627/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:26:46,372 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 4:04:46, time: 0.411, data_time: 0.023, memory: 11956, decode.loss_seg: 0.2667, decode.acc_seg: 90.3696, loss: 0.2667/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:27:06,358 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 4:04:27, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2057, decode.acc_seg: 92.9946, loss: 0.2057/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:27:26,460 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 4:04:10, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2069, decode.acc_seg: 92.5826, loss: 0.2069/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:27:46,403 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 4:03:51, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2233, decode.acc_seg: 92.0558, loss: 0.2233/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:28:06,233 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 4:03:30, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2380, decode.acc_seg: 91.2585, loss: 0.2380/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:28:26,161 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 4:03:11, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2075, decode.acc_seg: 92.2916, loss: 0.2075/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:28:46,005 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 4:02:51, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2399, decode.acc_seg: 91.6367, loss: 0.2399/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:29:05,995 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 4:02:32, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2116, decode.acc_seg: 92.4897, loss: 0.2116/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:29:25,800 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 4:02:11, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2063, decode.acc_seg: 92.6438, loss: 0.2063/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:29:45,560 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 4:01:50, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2283, decode.acc_seg: 92.3560, loss: 0.2283/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:30:05,349 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 4:01:29, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1868, decode.acc_seg: 93.4733, loss: 0.1868/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:30:25,217 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 4:01:09, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2050, decode.acc_seg: 92.3665, loss: 0.2050/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:30:45,014 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 4:00:49, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2156, decode.acc_seg: 92.3637, loss: 0.2156/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:31:04,839 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 4:00:28, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2392, decode.acc_seg: 91.5060, loss: 0.2392/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:31:24,792 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 4:00:09, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2358, decode.acc_seg: 91.0440, loss: 0.2358/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:31:44,662 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 3:59:49, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2331, decode.acc_seg: 91.8968, loss: 0.2331/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:32:04,386 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 3:59:28, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1793, decode.acc_seg: 93.9184, loss: 0.1793/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:32:24,308 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 3:59:09, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2328, decode.acc_seg: 91.6580, loss: 0.2328/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:32:44,016 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 3:58:47, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2219, decode.acc_seg: 91.3798, loss: 0.2219[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.2 task/s, elapsed: 1s, ETA:   744s[                                 ] 2/929, 2.2 task/s, elapsed: 1s, ETA:   417s[                                 ] 3/929, 3.0 task/s, elapsed: 1s, ETA:   311s[                                 ] 4/929, 3.6 task/s, elapsed: 1s, ETA:   254s[                                 ] 5/929, 4.2 task/s, elapsed: 1s, ETA:   220s[                                 ] 6/929, 4.7 task/s, elapsed: 1s, ETA:   198s[                                 ] 7/929, 5.1 task/s, elapsed: 1s, ETA:   182s[                                 ] 8/929, 5.4 task/s, elapsed: 1s, ETA:   170s[                                 ] 9/929, 5.7 task/s, elapsed: 2s, ETA:   161s[                                ] 10/929, 6.0 task/s, elapsed: 2s, ETA:   153s[                                ] 11/929, 6.2 task/s, elapsed: 2s, ETA:   148s[                                ] 12/929, 6.4 task/s, elapsed: 2s, ETA:   143s[                                ] 13/929, 6.6 task/s, elapsed: 2s, ETA:   138s[                                ] 14/929, 6.8 task/s, elapsed: 2s, ETA:   134s[                                ] 15/929, 7.0 task/s, elapsed: 2s, ETA:   131s[                                ] 16/929, 7.1 task/s, elapsed: 2s, ETA:   128s[                                ] 17/929, 7.3 task/s, elapsed: 2s, ETA:   125s[                                ] 18/929, 7.4 task/s, elapsed: 2s, ETA:   122s[                                ] 19/929, 7.6 task/s, elapsed: 3s, ETA:   120s[                                ] 20/929, 7.7 task/s, elapsed: 3s, ETA:   118s[                                ] 21/929, 7.8 task/s, elapsed: 3s, ETA:   116s[                                ] 22/929, 7.9 task/s, elapsed: 3s, ETA:   115s[                                ] 23/929, 8.0 task/s, elapsed: 3s, ETA:   113s[                                ] 24/929, 8.1 task/s, elapsed: 3s, ETA:   112s[                                ] 25/929, 8.2 task/s, elapsed: 3s, ETA:   111s[                                ] 26/929, 8.2 task/s, elapsed: 3s, ETA:   110s[                                ] 27/929, 8.3 task/s, elapsed: 3s, ETA:   109s[                                ] 28/929, 8.4 task/s, elapsed: 3s, ETA:   107s[                                ] 29/929, 8.5 task/s, elapsed: 3s, ETA:   106s[>                               ] 30/929, 8.5 task/s, elapsed: 4s, ETA:   105s[>                               ] 31/929, 8.6 task/s, elapsed: 4s, ETA:   104s[>                               ] 32/929, 8.7 task/s, elapsed: 4s, ETA:   103s[>                               ] 33/929, 8.7 task/s, elapsed: 4s, ETA:   103s[>                               ] 34/929, 8.8 task/s, elapsed: 4s, ETA:   102s[>                               ] 35/929, 8.8 task/s, elapsed: 4s, ETA:   101s[>                               ] 36/929, 8.9 task/s, elapsed: 4s, ETA:   101s[>                               ] 37/929, 8.9 task/s, elapsed: 4s, ETA:   101s[>                               ] 38/929, 8.9 task/s, elapsed: 4s, ETA:   100s[>                               ] 39/929, 8.9 task/s, elapsed: 4s, ETA:   100s[>                               ] 40/929, 9.0 task/s, elapsed: 4s, ETA:    99s[>                               ] 41/929, 9.0 task/s, elapsed: 5s, ETA:    98s[>                               ] 42/929, 9.1 task/s, elapsed: 5s, ETA:    98s[>                               ] 43/929, 9.1 task/s, elapsed: 5s, ETA:    97s[>                               ] 44/929, 9.2 task/s, elapsed: 5s, ETA:    97s[>                               ] 45/929, 9.2 task/s, elapsed: 5s, ETA:    96s[>                               ] 46/929, 9.2 task/s, elapsed: 5s, ETA:    96s[>                               ] 47/929, 9.2 task/s, elapsed: 5s, ETA:    95s[>                               ] 48/929, 9.3 task/s, elapsed: 5s, ETA:    95s[>                               ] 49/929, 9.3 task/s, elapsed: 5s, ETA:    95s[>                               ] 50/929, 9.3 task/s, elapsed: 5s, ETA:    94s[>                               ] 51/929, 9.3 task/s, elapsed: 5s, ETA:    94s[>                               ] 52/929, 9.3 task/s, elapsed: 6s, ETA:    94s[>                               ] 53/929, 9.3 task/s, elapsed: 6s, ETA:    94s[>                               ] 54/929, 9.3 task/s, elapsed: 6s, ETA:    94s[>                               ] 55/929, 9.4 task/s, elapsed: 6s, ETA:    93s[>                               ] 56/929, 9.4 task/s, elapsed: 6s, ETA:    93s[>                               ] 57/929, 9.4 task/s, elapsed: 6s, ETA:    93s[>                               ] 58/929, 9.4 task/s, elapsed: 6s, ETA:    92s[>>                              ] 59/929, 9.5 task/s, elapsed: 6s, ETA:    92s[>>                              ] 60/929, 9.5 task/s, elapsed: 6s, ETA:    92s[>>                              ] 61/929, 9.5 task/s, elapsed: 6s, ETA:    91s[>>                              ] 62/929, 9.5 task/s, elapsed: 7s, ETA:    91s[>>                              ] 63/929, 9.6 task/s, elapsed: 7s, ETA:    91s[>>                              ] 64/929, 9.6 task/s, elapsed: 7s, ETA:    90s[>>                              ] 65/929, 9.6 task/s, elapsed: 7s, ETA:    90s[>>                              ] 66/929, 9.6 task/s, elapsed: 7s, ETA:    90s[>>                              ] 67/929, 9.6 task/s, elapsed: 7s, ETA:    89s[>>                              ] 68/929, 9.7 task/s, elapsed: 7s, ETA:    89s[>>                              ] 69/929, 9.7 task/s, elapsed: 7s, ETA:    89s[>>                              ] 70/929, 9.7 task/s, elapsed: 7s, ETA:    89s[>>                              ] 71/929, 9.7 task/s, elapsed: 7s, ETA:    88s[>>                              ] 72/929, 9.7 task/s, elapsed: 7s, ETA:    88s[>>                              ] 73/929, 9.8 task/s, elapsed: 7s, ETA:    88s[>>                              ] 74/929, 9.8 task/s, elapsed: 8s, ETA:    87s[>>                              ] 75/929, 9.8 task/s, elapsed: 8s, ETA:    87s[>>                              ] 76/929, 9.8 task/s, elapsed: 8s, ETA:    87s[>>                              ] 77/929, 9.8 task/s, elapsed: 8s, ETA:    87s[>>                              ] 78/929, 9.8 task/s, elapsed: 8s, ETA:    87s[>>                              ] 79/929, 9.8 task/s, elapsed: 8s, ETA:    86s[>>                              ] 80/929, 9.8 task/s, elapsed: 8s, ETA:    86s[>>                              ] 81/929, 9.8 task/s, elapsed: 8s, ETA:    86s[>>                              ] 82/929, 9.9 task/s, elapsed: 8s, ETA:    86s[>>                              ] 83/929, 9.9 task/s, elapsed: 8s, ETA:    86s[>>                              ] 84/929, 9.9 task/s, elapsed: 8s, ETA:    85s[>>                              ] 85/929, 9.9 task/s, elapsed: 9s, ETA:    85s[>>                              ] 86/929, 9.9 task/s, elapsed: 9s, ETA:    85s[>>                              ] 87/929, 9.9 task/s, elapsed: 9s, ETA:    85s[>>>                             ] 88/929, 9.9 task/s, elapsed: 9s, ETA:    85s[>>                             ] 89/929, 10.0 task/s, elapsed: 9s, ETA:    84s[>>>                            ] 90/929, 10.0 task/s, elapsed: 9s, ETA:    84s[>>>                            ] 91/929, 10.0 task/s, elapsed: 9s, ETA:    84s[>>>                            ] 92/929, 10.0 task/s, elapsed: 9s, ETA:    84s[>>>                            ] 93/929, 10.0 task/s, elapsed: 9s, ETA:    84s[>>>                            ] 94/929, 10.0 task/s, elapsed: 9s, ETA:    84s[>>>                            ] 95/929, 10.0 task/s, elapsed: 9s, ETA:    83s[>>>                           ] 96/929, 10.0 task/s, elapsed: 10s, ETA:    83s[>>>                           ] 97/929, 10.0 task/s, elapsed: 10s, ETA:    83s[>>>                           ] 98/929, 10.0 task/s, elapsed: 10s, ETA:    83s[>>>                           ] 99/929, 10.1 task/s, elapsed: 10s, ETA:    83s[>>>                          ] 100/929, 10.1 task/s, elapsed: 10s, ETA:    82s[>>>                          ] 101/929, 10.1 task/s, elapsed: 10s, ETA:    82s[>>>                          ] 102/929, 10.1 task/s, elapsed: 10s, ETA:    82s[>>>                          ] 103/929, 10.1 task/s, elapsed: 10s, ETA:    82s[>>>                          ] 104/929, 10.1 task/s, elapsed: 10s, ETA:    82s[>>>                          ] 105/929, 10.1 task/s, elapsed: 10s, ETA:    81s[>>>                          ] 106/929, 10.1 task/s, elapsed: 10s, ETA:    81s[>>>                          ] 107/929, 10.1 task/s, elapsed: 11s, ETA:    81s[>>>                          ] 108/929, 10.1 task/s, elapsed: 11s, ETA:    81s[>>>                          ] 109/929, 10.2 task/s, elapsed: 11s, ETA:    81s[>>>                          ] 110/929, 10.2 task/s, elapsed: 11s, ETA:    81s[>>>                          ] 111/929, 10.2 task/s, elapsed: 11s, ETA:    80s[>>>                          ] 112/929, 10.2 task/s, elapsed: 11s, ETA:    80s[>>>                          ] 113/929, 10.2 task/s, elapsed: 11s, ETA:    80s[>>>                          ] 114/929, 10.2 task/s, elapsed: 11s, ETA:    80s[>>>                          ] 115/929, 10.2 task/s, elapsed: 11s, ETA:    80s[>>>                          ] 116/929, 10.2 task/s, elapsed: 11s, ETA:    80s[>>>                          ] 117/929, 10.2 task/s, elapsed: 11s, ETA:    80s[>>>                          ] 118/929, 10.2 task/s, elapsed: 12s, ETA:    79s[>>>                          ] 119/929, 10.2 task/s, elapsed: 12s, ETA:    79s[>>>                          ] 120/929, 10.2 task/s, elapsed: 12s, ETA:    79s[>>>                          ] 121/929, 10.2 task/s, elapsed: 12s, ETA:    79s[>>>                          ] 122/929, 10.2 task/s, elapsed: 12s, ETA:    79s[>>>                          ] 123/929, 10.3 task/s, elapsed: 12s, ETA:    79s[>>>                          ] 124/929, 10.3 task/s, elapsed: 12s, ETA:    78s[>>>                          ] 125/929, 10.3 task/s, elapsed: 12s, ETA:    78s[>>>                          ] 126/929, 10.3 task/s, elapsed: 12s, ETA:    78s[>>>                          ] 127/929, 10.3 task/s, elapsed: 12s, ETA:    78s[>>>                          ] 128/929, 10.3 task/s, elapsed: 12s, ETA:    78s[>>>>                         ] 129/929, 10.3 task/s, elapsed: 13s, ETA:    78s[>>>>                         ] 130/929, 10.3 task/s, elapsed: 13s, ETA:    78s[>>>>                         ] 131/929, 10.3 task/s, elapsed: 13s, ETA:    77s[>>>>                         ] 132/929, 10.3 task/s, elapsed: 13s, ETA:    77s[>>>>                         ] 133/929, 10.3 task/s, elapsed: 13s, ETA:    77s[>>>>                         ] 134/929, 10.3 task/s, elapsed: 13s, ETA:    77s[>>>>                         ] 135/929, 10.3 task/s, elapsed: 13s, ETA:    77s[>>>>                         ] 136/929, 10.3 task/s, elapsed: 13s, ETA:    77s[>>>>                         ] 137/929, 10.3 task/s, elapsed: 13s, ETA:    77s[>>>>                         ] 138/929, 10.3 task/s, elapsed: 13s, ETA:    76s[>>>>                         ] 139/929, 10.3 task/s, elapsed: 13s, ETA:    76s[>>>>                         ] 140/929, 10.3 task/s, elapsed: 14s, ETA:    76s[>>>>                         ] 141/929, 10.3 task/s, elapsed: 14s, ETA:    76s[>>>>                         ] 142/929, 10.3 task/s, elapsed: 14s, ETA:    76s[>>>>                         ] 143/929, 10.3 task/s, elapsed: 14s, ETA:    76s[>>>>                         ] 144/929, 10.4 task/s, elapsed: 14s, ETA:    76s[>>>>                         ] 145/929, 10.4 task/s, elapsed: 14s, ETA:    76s[>>>>                         ] 146/929, 10.4 task/s, elapsed: 14s, ETA:    76s[>>>>                         ] 147/929, 10.4 task/s, elapsed: 14s, ETA:    75s[>>>>                         ] 148/929, 10.4 task/s, elapsed: 14s, ETA:    75s[>>>>                         ] 149/929, 10.4 task/s, elapsed: 14s, ETA:    75s[>>>>                         ] 150/929, 10.4 task/s, elapsed: 14s, ETA:    75s[>>>>                         ] 151/929, 10.4 task/s, elapsed: 15s, ETA:    75s[>>>>                         ] 152/929, 10.4 task/s, elapsed: 15s, ETA:    75s[>>>>                         ] 153/929, 10.4 task/s, elapsed: 15s, ETA:    75s[>>>>                         ] 154/929, 10.4 task/s, elapsed: 15s, ETA:    75s[>>>>                         ] 155/929, 10.4 task/s, elapsed: 15s, ETA:    74s[>>>>                         ] 156/929, 10.4 task/s, elapsed: 15s, ETA:    74s[>>>>                         ] 157/929, 10.4 task/s, elapsed: 15s, ETA:    74s[>>>>                         ] 158/929, 10.4 task/s, elapsed: 15s, ETA:    74s[>>>>                         ] 159/929, 10.4 task/s, elapsed: 15s, ETA:    74s[>>>>                         ] 160/929, 10.4 task/s, elapsed: 15s, ETA:    74s[>>>>>                        ] 161/929, 10.4 task/s, elapsed: 15s, ETA:    74s[>>>>>                        ] 162/929, 10.4 task/s, elapsed: 16s, ETA:    74s[>>>>>                        ] 163/929, 10.4 task/s, elapsed: 16s, ETA:    73s[>>>>>                        ] 164/929, 10.4 task/s, elapsed: 16s, ETA:    73s[>>>>>                        ] 165/929, 10.4 task/s, elapsed: 16s, ETA:    73s[>>>>>                        ] 166/929, 10.5 task/s, elapsed: 16s, ETA:    73s[>>>>>                        ] 167/929, 10.5 task/s, elapsed: 16s, ETA:    73s[>>>>>                        ] 168/929, 10.5 task/s, elapsed: 16s, ETA:    73s[>>>>>                        ] 169/929, 10.5 task/s, elapsed: 16s, ETA:    73s[>>>>>                        ] 170/929, 10.5 task/s, elapsed: 16s, ETA:    72s[>>>>>                        ] 171/929, 10.5 task/s, elapsed: 16s, ETA:    72s[>>>>>                        ] 172/929, 10.5 task/s, elapsed: 16s, ETA:    72s[>>>>>                        ] 173/929, 10.5 task/s, elapsed: 16s, ETA:    72s[>>>>>                        ] 174/929, 10.5 task/s, elapsed: 17s, ETA:    72s[>>>>>                        ] 175/929, 10.5 task/s, elapsed: 17s, ETA:    72s[>>>>>                        ] 176/929, 10.5 task/s, elapsed: 17s, ETA:    72s[>>>>>                        ] 177/929, 10.5 task/s, elapsed: 17s, ETA:    72s[>>>>>                        ] 178/929, 10.5 task/s, elapsed: 17s, ETA:    72s[>>>>>                        ] 179/929, 10.5 task/s, elapsed: 17s, ETA:    71s[>>>>>                        ] 180/929, 10.5 task/s, elapsed: 17s, ETA:    71s[>>>>>                        ] 181/929, 10.5 task/s, elapsed: 17s, ETA:    71s[>>>>>                        ] 182/929, 10.5 task/s, elapsed: 17s, ETA:    71s[>>>>>                        ] 183/929, 10.5 task/s, elapsed: 17s, ETA:    71s[>>>>>                        ] 184/929, 10.5 task/s, elapsed: 17s, ETA:    71s[>>>>>                        ] 185/929, 10.5 task/s, elapsed: 18s, ETA:    71s[>>>>>                        ] 186/929, 10.5 task/s, elapsed: 18s, ETA:    71s[>>>>>                        ] 187/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>                        ] 188/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>                        ] 189/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>                        ] 190/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>                        ] 191/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>                        ] 192/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>>                       ] 193/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>>                       ] 194/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>>                       ] 195/929, 10.5 task/s, elapsed: 18s, ETA:    70s[>>>>>>                       ] 196/929, 10.5 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 197/929, 10.6 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 198/929, 10.6 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 199/929, 10.6 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 200/929, 10.6 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 201/929, 10.6 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 202/929, 10.6 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 203/929, 10.6 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 204/929, 10.5 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 205/929, 10.5 task/s, elapsed: 19s, ETA:    69s[>>>>>>                       ] 206/929, 10.5 task/s, elapsed: 20s, ETA:    69s[>>>>>>                       ] 207/929, 10.5 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 208/929, 10.5 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 209/929, 10.6 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 210/929, 10.6 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 211/929, 10.6 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 212/929, 10.5 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 213/929, 10.5 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 214/929, 10.5 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 215/929, 10.5 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 216/929, 10.5 task/s, elapsed: 20s, ETA:    68s[>>>>>>                       ] 217/929, 10.5 task/s, elapsed: 21s, ETA:    68s[>>>>>>                       ] 218/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>                       ] 219/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>                       ] 220/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>                       ] 221/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>                       ] 222/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>                       ] 223/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>                       ] 224/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>>                      ] 225/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>>                      ] 226/929, 10.5 task/s, elapsed: 21s, ETA:    67s[>>>>>>>                      ] 227/929, 10.6 task/s, elapsed: 22s, ETA:    67s[>>>>>>>                      ] 228/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 229/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 230/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 231/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 232/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 233/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 234/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 235/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 236/929, 10.6 task/s, elapsed: 22s, ETA:    66s[>>>>>>>                      ] 237/929, 10.6 task/s, elapsed: 22s, ETA:    65s[>>>>>>>                      ] 238/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 239/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 240/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 241/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 242/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 243/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 244/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 245/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 246/929, 10.6 task/s, elapsed: 23s, ETA:    65s[>>>>>>>                      ] 247/929, 10.6 task/s, elapsed: 23s, ETA:    64s[>>>>>>>                      ] 248/929, 10.6 task/s, elapsed: 23s, ETA:    64s[>>>>>>>                      ] 249/929, 10.6 task/s, elapsed: 23s, ETA:    64s[>>>>>>>                      ] 250/929, 10.6 task/s, elapsed: 24s, ETA:    64s[>>>>>>>                      ] 251/929, 10.6 task/s, elapsed: 24s, ETA:    64s[>>>>>>>                      ] 252/929, 10.6 task/s, elapsed: 24s, ETA:    64s[>>>>>>>                      ] 253/929, 10.6 task/s, elapsed: 24s, ETA:    64s[>>>>>>>                      ] 254/929, 10.6 task/s, elapsed: 24s, ETA:    64s[>>>>>>>                      ] 255/929, 10.6 task/s, elapsed: 24s, ETA:    64s[>>>>>>>                      ] 256/929, 10.6 task/s, elapsed: 24s, ETA:    63s[>>>>>>>>                     ] 257/929, 10.6 task/s, elapsed: 24s, ETA:    63s[>>>>>>>>                     ] 258/929, 10.6 task/s, elapsed: 24s, ETA:    63s[>>>>>>>>                     ] 259/929, 10.6 task/s, elapsed: 24s, ETA:    63s[>>>>>>>>                     ] 260/929, 10.6 task/s, elapsed: 24s, ETA:    63s[>>>>>>>>                     ] 261/929, 10.6 task/s, elapsed: 25s, ETA:    63s[>>>>>>>>                     ] 262/929, 10.6 task/s, elapsed: 25s, ETA:    63s[>>>>>>>>                     ] 263/929, 10.6 task/s, elapsed: 25s, ETA:    63s[>>>>>>>>                     ] 264/929, 10.6 task/s, elapsed: 25s, ETA:    63s[>>>>>>>>                     ] 265/929, 10.6 task/s, elapsed: 25s, ETA:    62s[>>>>>>>>                     ] 266/929, 10.6 task/s, elapsed: 25s, ETA:    62s[>>>>>>>>                     ] 267/929, 10.6 task/s, elapsed: 25s, ETA:    62s[>>>>>>>>                     ] 268/929, 10.6 task/s, elapsed: 25s, ETA:    62s[>>>>>>>>                     ] 269/929, 10.6 task/s, elapsed: 25s, ETA:    62s[>>>>>>>>                     ] 270/929, 10.6 task/s, elapsed: 25s, ETA:    62s[>>>>>>>>                     ] 271/929, 10.6 task/s, elapsed: 26s, ETA:    62s[>>>>>>>>                     ] 272/929, 10.6 task/s, elapsed: 26s, ETA:    62s[>>>>>>>>                     ] 273/929, 10.6 task/s, elapsed: 26s, ETA:    62s[>>>>>>>>                     ] 274/929, 10.6 task/s, elapsed: 26s, ETA:    62s[>>>>>>>>                     ] 275/929, 10.6 task/s, elapsed: 26s, ETA:    62s[>>>>>>>>                     ] 276/929, 10.6 task/s, elapsed: 26s, ETA:    62s[>>>>>>>>                     ] 277/929, 10.6 task/s, elapsed: 26s, ETA:    61s[>>>>>>>>                     ] 278/929, 10.6 task/s, elapsed: 26s, ETA:    61s[>>>>>>>>                     ] 279/929, 10.6 task/s, elapsed: 26s, ETA:    61s[>>>>>>>>                     ] 280/929, 10.6 task/s, elapsed: 26s, ETA:    61s[>>>>>>>>                     ] 281/929, 10.6 task/s, elapsed: 26s, ETA:    61s[>>>>>>>>                     ] 282/929, 10.6 task/s, elapsed: 27s, ETA:    61s[>>>>>>>>                     ] 283/929, 10.6 task/s, elapsed: 27s, ETA:    61s[>>>>>>>>                     ] 284/929, 10.6 task/s, elapsed: 27s, ETA:    61s[>>>>>>>>                     ] 285/929, 10.6 task/s, elapsed: 27s, ETA:    61s[>>>>>>>>                     ] 286/929, 10.6 task/s, elapsed: 27s, ETA:    61s[>>>>>>>>                     ] 287/929, 10.6 task/s, elapsed: 27s, ETA:    61s[>>>>>>>>                     ] 288/929, 10.6 task/s, elapsed: 27s, ETA:    60s[>>>>>>>>>                    ] 289/929, 10.6 task/s, elapsed: 27s, ETA:    60s[>>>>>>>>>                    ] 290/929, 10.6 task/s, elapsed: 27s, ETA:    60s[>>>>>>>>>                    ] 291/929, 10.6 task/s, elapsed: 27s, ETA:    60s[>>>>>>>>>                    ] 292/929, 10.6 task/s, elapsed: 27s, ETA:    60s[>>>>>>>>>                    ] 293/929, 10.6 task/s, elapsed: 28s, ETA:    60s[>>>>>>>>>                    ] 294/929, 10.6 task/s, elapsed: 28s, ETA:    60s[>>>>>>>>>                    ] 295/929, 10.6 task/s, elapsed: 28s, ETA:    60s[>>>>>>>>>                    ] 296/929, 10.6 task/s, elapsed: 28s, ETA:    60s[>>>>>>>>>                    ] 297/929, 10.6 task/s, elapsed: 28s, ETA:    59s[>>>>>>>>>                    ] 298/929, 10.6 task/s, elapsed: 28s, ETA:    59s[>>>>>>>>>                    ] 299/929, 10.6 task/s, elapsed: 28s, ETA:    59s[>>>>>>>>>                    ] 300/929, 10.6 task/s, elapsed: 28s, ETA:    59s[>>>>>>>>>                    ] 301/929, 10.6 task/s, elapsed: 28s, ETA:    59s[>>>>>>>>>                    ] 302/929, 10.6 task/s, elapsed: 28s, ETA:    59s[>>>>>>>>>                    ] 303/929, 10.6 task/s, elapsed: 28s, ETA:    59s[>>>>>>>>>                    ] 304/929, 10.6 task/s, elapsed: 29s, ETA:    59s[>>>>>>>>>                    ] 305/929, 10.6 task/s, elapsed: 29s, ETA:    59s[>>>>>>>>>                    ] 306/929, 10.6 task/s, elapsed: 29s, ETA:    59s[>>>>>>>>>                    ] 307/929, 10.6 task/s, elapsed: 29s, ETA:    58s[>>>>>>>>>                    ] 308/929, 10.6 task/s, elapsed: 29s, ETA:    58s[>>>>>>>>>                    ] 309/929, 10.6 task/s, elapsed: 29s, ETA:    58s[>>>>>>>>>                    ] 310/929, 10.6 task/s, elapsed: 29s, ETA:    58s[>>>>>>>>>                    ] 311/929, 10.6 task/s, elapsed: 29s, ETA:    58s[>>>>>>>>>                    ] 312/929, 10.6 task/s, elapsed: 29s, ETA:    58s[>>>>>>>>>                    ] 313/929, 10.6 task/s, elapsed: 29s, ETA:    58s[>>>>>>>>>                    ] 314/929, 10.6 task/s, elapsed: 30s, ETA:    58s[>>>>>>>>>                    ] 315/929, 10.6 task/s, elapsed: 30s, ETA:    58s[>>>>>>>>>                    ] 316/929, 10.6 task/s, elapsed: 30s, ETA:    58s[>>>>>>>>>                    ] 317/929, 10.6 task/s, elapsed: 30s, ETA:    58s[>>>>>>>>>                    ] 318/929, 10.6 task/s, elapsed: 30s, ETA:    57s[>>>>>>>>>                    ] 319/929, 10.6 task/s, elapsed: 30s, ETA:    57s[>>>>>>>>>                    ] 320/929, 10.6 task/s, elapsed: 30s, ETA:    57s[>>>>>>>>>>                   ] 321/929, 10.6 task/s, elapsed: 30s, ETA:    57s[>>>>>>>>>>                   ] 322/929, 10.6 task/s, elapsed: 30s, ETA:    57s[>>>>>>>>>>                   ] 323/929, 10.6 task/s, elapsed: 30s, ETA:    57s[>>>>>>>>>>                   ] 324/929, 10.6 task/s, elapsed: 30s, ETA:    57s[>>>>>>>>>>                   ] 325/929, 10.6 task/s, elapsed: 31s, ETA:    57s[>>>>>>>>>>                   ] 326/929, 10.6 task/s, elapsed: 31s, ETA:    57s[>>>>>>>>>>                   ] 327/929, 10.7 task/s, elapsed: 31s, ETA:    57s[>>>>>>>>>>                   ] 328/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 329/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 330/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 331/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 332/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 333/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 334/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 335/929, 10.7 task/s, elapsed: 31s, ETA:    56s[>>>>>>>>>>                   ] 336/929, 10.7 task/s, elapsed: 32s, ETA:    56s[>>>>>>>>>>                   ] 337/929, 10.7 task/s, elapsed: 32s, ETA:    56s[>>>>>>>>>>                   ] 338/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 339/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 340/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 341/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 342/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 343/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 344/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 345/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 346/929, 10.7 task/s, elapsed: 32s, ETA:    55s[>>>>>>>>>>                   ] 347/929, 10.7 task/s, elapsed: 33s, ETA:    55s[>>>>>>>>>>                   ] 348/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>                   ] 349/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>                   ] 350/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>                   ] 351/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>                   ] 352/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>>                  ] 353/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>>                  ] 354/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>>                  ] 355/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>>                  ] 356/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>>                  ] 357/929, 10.7 task/s, elapsed: 33s, ETA:    54s[>>>>>>>>>>>                  ] 358/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 359/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 360/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 361/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 362/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 363/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 364/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 365/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 366/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 367/929, 10.7 task/s, elapsed: 34s, ETA:    53s[>>>>>>>>>>>                  ] 368/929, 10.7 task/s, elapsed: 34s, ETA:    52s[>>>>>>>>>>>                  ] 369/929, 10.7 task/s, elapsed: 34s, ETA:    52s[>>>>>>>>>>>                  ] 370/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 371/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 372/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 373/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 374/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 375/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 376/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 377/929, 10.7 task/s, elapsed: 35s, ETA:    52s[>>>>>>>>>>>                  ] 378/929, 10.7 task/s, elapsed: 35s, ETA:    51s[>>>>>>>>>>>                  ] 379/929, 10.7 task/s, elapsed: 35s, ETA:    51s[>>>>>>>>>>>                  ] 380/929, 10.7 task/s, elapsed: 35s, ETA:    51s[>>>>>>>>>>>                  ] 381/929, 10.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>                  ] 382/929, 10.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>                  ] 383/929, 10.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>                  ] 384/929, 10.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>>                 ] 385/929, 10.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>>                 ] 386/929, 10.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>>                 ] 387/929, 10.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>>                 ] 388/929, 10.7 task/s, elapsed: 36s, ETA:    50s[>>>>>>>>>>>>                 ] 389/929, 10.7 task/s, elapsed: 36s, ETA:    50s[>>>>>>>>>>>>                 ] 390/929, 10.7 task/s, elapsed: 36s, ETA:    50s[>>>>>>>>>>>>                 ] 391/929, 10.7 task/s, elapsed: 36s, ETA:    50s[>>>>>>>>>>>>                 ] 392/929, 10.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                 ] 393/929, 10.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                 ] 394/929, 10.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                 ] 395/929, 10.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                 ] 396/929, 10.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                 ] 397/929, 10.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                 ] 398/929, 10.7 task/s, elapsed: 37s, ETA:    49s[>>>>>>>>>>>>                 ] 399/929, 10.7 task/s, elapsed: 37s, ETA:    49s[>>>>>>>>>>>>                 ] 400/929, 10.7 task/s, elapsed: 37s, ETA:    49s[>>>>>>>>>>>>                 ] 401/929, 10.7 task/s, elapsed: 37s, ETA:    49s[>>>>>>>>>>>>                 ] 402/929, 10.7 task/s, elapsed: 37s, ETA:    49s[>>>>>>>>>>>>                 ] 403/929, 10.7 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>                 ] 404/929, 10.7 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>                 ] 405/929, 10.7 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>                 ] 406/929, 10.7 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>                 ] 407/929, 10.7 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>                 ] 408/929, 10.7 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>                 ] 409/929, 10.7 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>                 ] 410/929, 10.7 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>                 ] 411/929, 10.7 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>                 ] 412/929, 10.7 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>                 ] 413/929, 10.7 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>                 ] 414/929, 10.7 task/s, elapsed: 39s, ETA:    48s[>>>>>>>>>>>>                 ] 415/929, 10.7 task/s, elapsed: 39s, ETA:    48s[>>>>>>>>>>>>                 ] 416/929, 10.7 task/s, elapsed: 39s, ETA:    48s[>>>>>>>>>>>>>                ] 417/929, 10.7 task/s, elapsed: 39s, ETA:    48s[>>>>>>>>>>>>>                ] 418/929, 10.7 task/s, elapsed: 39s, ETA:    48s[>>>>>>>>>>>>>                ] 419/929, 10.7 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                ] 420/929, 10.7 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                ] 421/929, 10.7 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                ] 422/929, 10.7 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                ] 423/929, 10.8 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                ] 424/929, 10.8 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                ] 425/929, 10.8 task/s, elapsed: 40s, ETA:    47s[>>>>>>>>>>>>>                ] 426/929, 10.8 task/s, elapsed: 40s, ETA:    47s[>>>>>>>>>>>>>                ] 427/929, 10.8 task/s, elapsed: 40s, ETA:    47s[>>>>>>>>>>>>>                ] 428/929, 10.8 task/s, elapsed: 40s, ETA:    47s[>>>>>>>>>>>>>                ] 429/929, 10.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>                ] 430/929, 10.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>                ] 431/929, 10.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>                ] 432/929, 10.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>                ] 433/929, 10.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>                ] 434/929, 10.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>                ] 435/929, 10.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>                ] 436/929, 10.8 task/s, elapsed: 41s, ETA:    46s[>>>>>>>>>>>>>                ] 437/929, 10.8 task/s, elapsed: 41s, ETA:    46s[>>>>>>>>>>>>>                ] 438/929, 10.8 task/s, elapsed: 41s, ETA:    46s[>>>>>>>>>>>>>                ] 439/929, 10.8 task/s, elapsed: 41s, ETA:    46s[>>>>>>>>>>>>>                ] 440/929, 10.8 task/s, elapsed: 41s, ETA:    45s[>>>>>>>>>>>>>                ] 441/929, 10.8 task/s, elapsed: 41s, ETA:    45s[>>>>>>>>>>>>>                ] 442/929, 10.8 task/s, elapsed: 41s, ETA:    45s[>>>>>>>>>>>>>                ] 443/929, 10.8 task/s, elapsed: 41s, ETA:    45s[>>>>>>>>>>>>>                ] 444/929, 10.8 task/s, elapsed: 41s, ETA:    45s[>>>>>>>>>>>>>                ] 445/929, 10.8 task/s, elapsed: 41s, ETA:    45s[>>>>>>>>>>>>>                ] 446/929, 10.8 task/s, elapsed: 41s, ETA:    45s[>>>>>>>>>>>>>                ] 447/929, 10.8 task/s, elapsed: 42s, ETA:    45s[>>>>>>>>>>>>>                ] 448/929, 10.8 task/s, elapsed: 42s, ETA:    45s[>>>>>>>>>>>>>>               ] 449/929, 10.8 task/s, elapsed: 42s, ETA:    45s[>>>>>>>>>>>>>>               ] 450/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 451/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 452/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 453/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 454/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 455/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 456/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 457/929, 10.8 task/s, elapsed: 42s, ETA:    44s[>>>>>>>>>>>>>>               ] 458/929, 10.8 task/s, elapsed: 43s, ETA:    44s[>>>>>>>>>>>>>>               ] 459/929, 10.8 task/s, elapsed: 43s, ETA:    44s[>>>>>>>>>>>>>>               ] 460/929, 10.8 task/s, elapsed: 43s, ETA:    44s[>>>>>>>>>>>>>>               ] 461/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 462/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 463/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 464/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 465/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 466/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 467/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 468/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 469/929, 10.8 task/s, elapsed: 43s, ETA:    43s[>>>>>>>>>>>>>>               ] 470/929, 10.8 task/s, elapsed: 44s, ETA:    43s[>>>>>>>>>>>>>>               ] 471/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 472/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 473/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 474/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 475/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 476/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 477/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 478/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 479/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>               ] 480/929, 10.8 task/s, elapsed: 44s, ETA:    42s[>>>>>>>>>>>>>>>              ] 481/929, 10.8 task/s, elapsed: 45s, ETA:    42s[>>>>>>>>>>>>>>>              ] 482/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 483/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 484/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 485/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 486/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 487/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 488/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 489/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 490/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 491/929, 10.8 task/s, elapsed: 45s, ETA:    41s[>>>>>>>>>>>>>>>              ] 492/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 493/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 494/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 495/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 496/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 497/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 498/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 499/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 500/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 501/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 502/929, 10.8 task/s, elapsed: 46s, ETA:    40s[>>>>>>>>>>>>>>>              ] 503/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 504/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 505/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 506/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 507/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 508/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 509/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 510/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 511/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>              ] 512/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 513/929, 10.8 task/s, elapsed: 47s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 514/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 515/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 516/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 517/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 518/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 519/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 520/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 521/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 522/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 523/929, 10.8 task/s, elapsed: 48s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 524/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 525/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 526/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 527/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 528/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 529/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 530/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 531/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 532/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 533/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 534/929, 10.8 task/s, elapsed: 49s, ETA:    37s[>>>>>>>>>>>>>>>>             ] 535/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 536/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 537/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 538/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 539/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 540/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 541/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 542/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 543/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>             ] 544/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.8 task/s, elapsed: 50s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.8 task/s, elapsed: 51s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.8 task/s, elapsed: 51s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.8 task/s, elapsed: 51s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.8 task/s, elapsed: 52s, ETA:    34s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.8 task/s, elapsed: 52s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.8 task/s, elapsed: 52s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.8 task/s, elapsed: 53s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.8 task/s, elapsed: 53s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.8 task/s, elapsed: 53s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.8 task/s, elapsed: 54s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.8 task/s, elapsed: 54s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.8 task/s, elapsed: 54s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.8 task/s, elapsed: 54s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.8 task/s, elapsed: 55s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.8 task/s, elapsed: 55s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.8 task/s, elapsed: 55s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.8 task/s, elapsed: 55s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.8 task/s, elapsed: 56s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.8 task/s, elapsed: 56s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.8 task/s, elapsed: 56s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.8 task/s, elapsed: 56s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.8 task/s, elapsed: 57s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.8 task/s, elapsed: 57s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.8 task/s, elapsed: 57s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.8 task/s, elapsed: 57s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.8 task/s, elapsed: 57s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.8 task/s, elapsed: 57s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.8 task/s, elapsed: 57s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.8 task/s, elapsed: 57s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.8 task/s, elapsed: 57s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.8 task/s, elapsed: 57s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.8 task/s, elapsed: 57s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.8 task/s, elapsed: 58s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.8 task/s, elapsed: 58s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.8 task/s, elapsed: 58s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.8 task/s, elapsed: 58s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.8 task/s, elapsed: 58s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.8 task/s, elapsed: 58s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.8 task/s, elapsed: 58s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.8 task/s, elapsed: 58s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.8 task/s, elapsed: 58s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.8 task/s, elapsed: 58s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.8 task/s, elapsed: 58s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.8 task/s, elapsed: 59s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.8 task/s, elapsed: 59s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.8 task/s, elapsed: 59s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.8 task/s, elapsed: 59s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.8 task/s, elapsed: 59s, ETA:    27s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.8 task/s, elapsed: 59s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.8 task/s, elapsed: 59s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.8 task/s, elapsed: 59s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.8 task/s, elapsed: 59s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.8 task/s, elapsed: 59s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.8 task/s, elapsed: 59s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.8 task/s, elapsed: 60s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.8 task/s, elapsed: 60s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.8 task/s, elapsed: 60s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.8 task/s, elapsed: 60s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.8 task/s, elapsed: 60s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.8 task/s, elapsed: 60s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.8 task/s, elapsed: 60s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.8 task/s, elapsed: 60s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.8 task/s, elapsed: 60s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.8 task/s, elapsed: 60s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.8 task/s, elapsed: 60s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.8 task/s, elapsed: 61s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.8 task/s, elapsed: 61s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.8 task/s, elapsed: 61s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.8 task/s, elapsed: 61s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.9 task/s, elapsed: 61s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.9 task/s, elapsed: 61s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.9 task/s, elapsed: 61s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.9 task/s, elapsed: 61s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.9 task/s, elapsed: 61s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.9 task/s, elapsed: 61s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.9 task/s, elapsed: 61s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.9 task/s, elapsed: 62s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.9 task/s, elapsed: 62s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.9 task/s, elapsed: 62s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.9 task/s, elapsed: 62s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.9 task/s, elapsed: 62s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.9 task/s, elapsed: 62s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.9 task/s, elapsed: 62s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.9 task/s, elapsed: 62s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.9 task/s, elapsed: 62s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.9 task/s, elapsed: 62s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.9 task/s, elapsed: 62s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.9 task/s, elapsed: 63s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.9 task/s, elapsed: 63s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.9 task/s, elapsed: 63s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.9 task/s, elapsed: 63s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.9 task/s, elapsed: 63s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.9 task/s, elapsed: 63s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.9 task/s, elapsed: 63s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.9 task/s, elapsed: 63s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.9 task/s, elapsed: 63s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.9 task/s, elapsed: 63s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.9 task/s, elapsed: 63s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.9 task/s, elapsed: 64s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.9 task/s, elapsed: 64s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.9 task/s, elapsed: 64s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.9 task/s, elapsed: 64s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.9 task/s, elapsed: 64s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.9 task/s, elapsed: 64s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.9 task/s, elapsed: 64s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.9 task/s, elapsed: 64s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.9 task/s, elapsed: 64s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.9 task/s, elapsed: 64s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.9 task/s, elapsed: 64s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.9 task/s, elapsed: 65s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.9 task/s, elapsed: 65s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.9 task/s, elapsed: 65s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.9 task/s, elapsed: 65s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.9 task/s, elapsed: 65s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.9 task/s, elapsed: 65s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.9 task/s, elapsed: 65s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.9 task/s, elapsed: 65s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.9 task/s, elapsed: 65s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.9 task/s, elapsed: 65s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.9 task/s, elapsed: 66s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.9 task/s, elapsed: 66s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.9 task/s, elapsed: 66s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.9 task/s, elapsed: 66s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.9 task/s, elapsed: 66s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.9 task/s, elapsed: 66s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.9 task/s, elapsed: 66s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.9 task/s, elapsed: 66s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.9 task/s, elapsed: 66s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.9 task/s, elapsed: 66s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.9 task/s, elapsed: 66s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.9 task/s, elapsed: 67s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.9 task/s, elapsed: 67s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.9 task/s, elapsed: 67s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.9 task/s, elapsed: 67s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.9 task/s, elapsed: 67s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.9 task/s, elapsed: 67s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.9 task/s, elapsed: 67s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.9 task/s, elapsed: 67s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.9 task/s, elapsed: 67s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.9 task/s, elapsed: 67s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.9 task/s, elapsed: 67s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.9 task/s, elapsed: 68s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.9 task/s, elapsed: 68s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.9 task/s, elapsed: 68s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.9 task/s, elapsed: 68s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.9 task/s, elapsed: 68s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.9 task/s, elapsed: 68s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.9 task/s, elapsed: 68s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.9 task/s, elapsed: 68s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.9 task/s, elapsed: 68s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.9 task/s, elapsed: 68s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.9 task/s, elapsed: 68s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.9 task/s, elapsed: 68s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.9 task/s, elapsed: 69s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.9 task/s, elapsed: 69s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.9 task/s, elapsed: 69s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.9 task/s, elapsed: 69s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.9 task/s, elapsed: 69s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.9 task/s, elapsed: 69s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.9 task/s, elapsed: 69s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.9 task/s, elapsed: 69s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.9 task/s, elapsed: 69s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.9 task/s, elapsed: 69s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.9 task/s, elapsed: 69s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.9 task/s, elapsed: 70s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.9 task/s, elapsed: 70s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.9 task/s, elapsed: 70s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.9 task/s, elapsed: 70s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.9 task/s, elapsed: 70s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.9 task/s, elapsed: 70s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.9 task/s, elapsed: 70s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.9 task/s, elapsed: 70s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.9 task/s, elapsed: 70s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.9 task/s, elapsed: 70s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.9 task/s, elapsed: 70s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.9 task/s, elapsed: 71s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.9 task/s, elapsed: 71s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.9 task/s, elapsed: 71s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.9 task/s, elapsed: 71s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.9 task/s, elapsed: 71s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.9 task/s, elapsed: 71s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.9 task/s, elapsed: 71s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.9 task/s, elapsed: 71s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.9 task/s, elapsed: 71s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.9 task/s, elapsed: 71s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.9 task/s, elapsed: 71s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.9 task/s, elapsed: 72s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.9 task/s, elapsed: 72s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.9 task/s, elapsed: 72s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.9 task/s, elapsed: 72s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.9 task/s, elapsed: 72s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.9 task/s, elapsed: 72s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.9 task/s, elapsed: 72s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.9 task/s, elapsed: 72s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.9 task/s, elapsed: 72s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.9 task/s, elapsed: 72s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.9 task/s, elapsed: 72s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.9 task/s, elapsed: 73s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.9 task/s, elapsed: 73s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.9 task/s, elapsed: 73s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.9 task/s, elapsed: 73s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.9 task/s, elapsed: 73s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.9 task/s, elapsed: 73s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.9 task/s, elapsed: 73s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.9 task/s, elapsed: 73s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.9 task/s, elapsed: 73s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.9 task/s, elapsed: 73s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.9 task/s, elapsed: 73s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.9 task/s, elapsed: 74s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.9 task/s, elapsed: 74s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.9 task/s, elapsed: 74s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.9 task/s, elapsed: 74s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.9 task/s, elapsed: 74s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.9 task/s, elapsed: 74s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.9 task/s, elapsed: 74s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.9 task/s, elapsed: 74s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.9 task/s, elapsed: 74s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.9 task/s, elapsed: 74s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.9 task/s, elapsed: 74s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.9 task/s, elapsed: 75s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.9 task/s, elapsed: 75s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.9 task/s, elapsed: 75s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.9 task/s, elapsed: 75s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.9 task/s, elapsed: 75s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.9 task/s, elapsed: 75s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.9 task/s, elapsed: 75s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.9 task/s, elapsed: 75s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.9 task/s, elapsed: 75s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.9 task/s, elapsed: 75s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.9 task/s, elapsed: 75s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.9 task/s, elapsed: 76s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.9 task/s, elapsed: 76s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.9 task/s, elapsed: 76s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.9 task/s, elapsed: 76s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.9 task/s, elapsed: 76s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.9 task/s, elapsed: 76s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.9 task/s, elapsed: 76s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.9 task/s, elapsed: 76s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.9 task/s, elapsed: 76s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.9 task/s, elapsed: 76s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.9 task/s, elapsed: 77s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.9 task/s, elapsed: 77s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.9 task/s, elapsed: 77s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.9 task/s, elapsed: 77s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.9 task/s, elapsed: 77s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.9 task/s, elapsed: 77s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.9 task/s, elapsed: 77s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.9 task/s, elapsed: 77s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.9 task/s, elapsed: 77s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.9 task/s, elapsed: 77s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.9 task/s, elapsed: 77s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.9 task/s, elapsed: 78s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.9 task/s, elapsed: 78s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.9 task/s, elapsed: 78s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.9 task/s, elapsed: 78s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.9 task/s, elapsed: 78s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.9 task/s, elapsed: 78s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.9 task/s, elapsed: 78s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.9 task/s, elapsed: 78s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.9 task/s, elapsed: 78s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.9 task/s, elapsed: 78s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.9 task/s, elapsed: 78s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.9 task/s, elapsed: 78s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.9 task/s, elapsed: 79s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.9 task/s, elapsed: 79s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.9 task/s, elapsed: 79s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.9 task/s, elapsed: 79s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.9 task/s, elapsed: 79s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.9 task/s, elapsed: 79s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.9 task/s, elapsed: 79s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.9 task/s, elapsed: 79s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.9 task/s, elapsed: 79s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.9 task/s, elapsed: 79s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.9 task/s, elapsed: 79s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.9 task/s, elapsed: 80s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.9 task/s, elapsed: 80s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.9 task/s, elapsed: 80s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.9 task/s, elapsed: 80s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.9 task/s, elapsed: 80s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.9 task/s, elapsed: 80s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.9 task/s, elapsed: 80s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.9 task/s, elapsed: 80s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.9 task/s, elapsed: 80s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.9 task/s, elapsed: 80s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.9 task/s, elapsed: 80s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.9 task/s, elapsed: 81s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.9 task/s, elapsed: 81s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.9 task/s, elapsed: 81s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.9 task/s, elapsed: 81s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.9 task/s, elapsed: 81s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.9 task/s, elapsed: 81s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.9 task/s, elapsed: 81s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.9 task/s, elapsed: 81s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.9 task/s, elapsed: 81s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.9 task/s, elapsed: 81s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.9 task/s, elapsed: 82s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.9 task/s, elapsed: 82s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.9 task/s, elapsed: 82s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.9 task/s, elapsed: 82s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.9 task/s, elapsed: 82s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.9 task/s, elapsed: 82s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.9 task/s, elapsed: 82s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.9 task/s, elapsed: 82s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.9 task/s, elapsed: 82s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.9 task/s, elapsed: 82s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.9 task/s, elapsed: 82s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.9 task/s, elapsed: 83s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.9 task/s, elapsed: 83s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.9 task/s, elapsed: 83s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.9 task/s, elapsed: 83s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.9 task/s, elapsed: 83s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.9 task/s, elapsed: 83s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.9 task/s, elapsed: 83s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.9 task/s, elapsed: 83s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.9 task/s, elapsed: 83s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.9 task/s, elapsed: 83s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.9 task/s, elapsed: 83s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.9 task/s, elapsed: 84s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.9 task/s, elapsed: 84s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.9 task/s, elapsed: 84s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.9 task/s, elapsed: 84s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.9 task/s, elapsed: 84s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.9 task/s, elapsed: 84s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.9 task/s, elapsed: 84s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.9 task/s, elapsed: 84s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.9 task/s, elapsed: 84s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.9 task/s, elapsed: 84s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.9 task/s, elapsed: 84s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.9 task/s, elapsed: 85s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.9 task/s, elapsed: 85s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.9 task/s, elapsed: 85s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.9 task/s, elapsed: 85s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.9 task/s, elapsed: 85s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.9 task/s, elapsed: 85s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.9 task/s, elapsed: 85s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.9 task/s, elapsed: 85s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.9 task/s, elapsed: 85s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.9 task/s, elapsed: 85s, ETA:     0s2022-10-03 14:35:24,594 - mmseg - INFO - per class results:2022-10-03 14:35:24,594 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 89.33 | 97.24 || rigid_plastic |  3.14 |  3.17 ||   cardboard   | 47.91 | 56.76 ||     metal     | 26.16 | 31.58 ||  soft_plastic | 52.28 | 60.35 |+---------------+-------+-------+2022-10-03 14:35:24,594 - mmseg - INFO - Summary:2022-10-03 14:35:24,595 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 89.73 | 43.76 | 49.82 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:35:24,603 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:35:24,603 - mmseg - INFO - Iter [929/40000]	lr: 5.400e-05, eta: 3:58:27, time: 0.396, data_time: 0.008, memory: 11956, aAcc: 0.8973, mIoU: 0.4376, mAcc: 0.4982, IoU.background: 0.8933, IoU.rigid_plastic: 0.0314, IoU.cardboard: 0.4791, IoU.metal: 0.2616, IoU.soft_plastic: 0.5228, Acc.background: 0.9724, Acc.rigid_plastic: 0.0317, Acc.cardboard: 0.5676, Acc.metal: 0.3158, Acc.soft_plastic: 0.6035, decode.loss_seg: 0.2504, decode.acc_seg: 91.6620, loss: 0.2504/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:35:44,672 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 4:18:58, time: 3.217, data_time: 2.822, memory: 11956, decode.loss_seg: 0.1840, decode.acc_seg: 93.2232, loss: 0.1840/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:36:04,586 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 4:18:22, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2069, decode.acc_seg: 92.8765, loss: 0.2069/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:36:24,374 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 4:17:45, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2176, decode.acc_seg: 91.9464, loss: 0.2176/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:36:44,125 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 4:17:07, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2064, decode.acc_seg: 92.7968, loss: 0.2064/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:37:03,858 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 4:16:31, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2240, decode.acc_seg: 92.3177, loss: 0.2240/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:37:23,627 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 4:15:55, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2084, decode.acc_seg: 92.5424, loss: 0.2084/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:37:43,670 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 4:15:21, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2013, decode.acc_seg: 92.3592, loss: 0.2013/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:38:03,669 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 4:14:47, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1951, decode.acc_seg: 93.1922, loss: 0.1951/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:38:23,425 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 4:14:12, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1950, decode.acc_seg: 92.8490, loss: 0.1950/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:38:43,228 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 4:13:38, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1961, decode.acc_seg: 93.0590, loss: 0.1961/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:39:04,771 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 4:13:17, time: 0.431, data_time: 0.040, memory: 11956, decode.loss_seg: 0.2018, decode.acc_seg: 92.5019, loss: 0.2018/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:39:24,454 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 4:12:42, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2204, decode.acc_seg: 91.8304, loss: 0.2204/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:39:44,403 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 4:12:10, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1674, decode.acc_seg: 93.6780, loss: 0.1674/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:40:04,236 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 4:11:37, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1857, decode.acc_seg: 93.1579, loss: 0.1857/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:40:24,048 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 4:11:04, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1959, decode.acc_seg: 92.9759, loss: 0.1959/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:40:43,833 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 4:10:31, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1859, decode.acc_seg: 93.6387, loss: 0.1859/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:41:03,748 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 4:09:59, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2052, decode.acc_seg: 92.6560, loss: 0.2052/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:41:23,520 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 4:09:26, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1782, decode.acc_seg: 93.5758, loss: 0.1782/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:41:43,323 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 4:08:54, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1617, decode.acc_seg: 94.3542, loss: 0.1617/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:42:03,214 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:42:03,215 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 4:08:23, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1774, decode.acc_seg: 93.7116, loss: 0.1774/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:42:22,975 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 4:07:51, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2060, decode.acc_seg: 92.3360, loss: 0.2060/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:42:43,151 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 4:07:22, time: 0.404, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1629, decode.acc_seg: 94.1141, loss: 0.1629/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:43:02,921 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 4:06:51, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1806, decode.acc_seg: 94.2281, loss: 0.1806/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:43:22,874 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 4:06:21, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1378, decode.acc_seg: 95.2303, loss: 0.1378/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:43:42,686 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 4:05:50, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1891, decode.acc_seg: 93.5833, loss: 0.1891/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:44:02,548 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 4:05:20, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2151, decode.acc_seg: 92.4411, loss: 0.2151/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:44:22,240 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 4:04:49, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1972, decode.acc_seg: 92.8217, loss: 0.1972/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:44:42,097 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 4:04:19, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1782, decode.acc_seg: 93.4754, loss: 0.1782/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:45:02,164 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 4:03:51, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2418, decode.acc_seg: 91.2818, loss: 0.2418/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:45:22,123 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 4:03:22, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1728, decode.acc_seg: 93.9578, loss: 0.1728/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:45:42,084 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 4:02:54, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1629, decode.acc_seg: 94.0853, loss: 0.1629/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:46:01,965 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 4:02:25, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1604, decode.acc_seg: 93.8739, loss: 0.1604/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:46:22,031 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 4:01:57, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1810, decode.acc_seg: 93.4918, loss: 0.1810/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:46:41,753 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 4:01:27, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1726, decode.acc_seg: 93.7955, loss: 0.1726/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:47:01,838 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 4:01:00, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2257, decode.acc_seg: 91.7395, loss: 0.2257/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:47:21,568 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 4:00:31, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1743, decode.acc_seg: 93.9290, loss: 0.1743/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:47:41,372 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 4:00:02, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1836, decode.acc_seg: 93.5088, loss: 0.1836/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:48:01,450 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 3:59:35, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.2130, decode.acc_seg: 92.1948, loss: 0.2130/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:48:21,270 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 3:59:07, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1937, decode.acc_seg: 93.2537, loss: 0.1937/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:48:41,309 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:48:41,309 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 3:58:40, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1845, decode.acc_seg: 93.7724, loss: 0.1845/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:49:03,178 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 3:58:24, time: 0.437, data_time: 0.046, memory: 11956, decode.loss_seg: 0.1298, decode.acc_seg: 95.4901, loss: 0.1298/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:49:22,913 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 3:57:55, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1565, decode.acc_seg: 94.2659, loss: 0.1565/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:49:42,894 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 3:57:28, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1464, decode.acc_seg: 94.5094, loss: 0.1464/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:50:02,781 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 3:57:01, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1684, decode.acc_seg: 94.2477, loss: 0.1684/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:50:22,672 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 3:56:33, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1788, decode.acc_seg: 94.0525, loss: 0.1788/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:50:42,733 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 3:56:07, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1819, decode.acc_seg: 93.7187, loss: 0.1819/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:51:02,488 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 3:55:40, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1857, decode.acc_seg: 93.2819, loss: 0.1857/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:51:22,340 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 3:55:12, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1595, decode.acc_seg: 94.3287, loss: 0.1595/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:51:42,281 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 3:54:46, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1545, decode.acc_seg: 94.5380, loss: 0.1545/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:52:02,298 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 3:54:20, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1695, decode.acc_seg: 94.0670, loss: 0.1695/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:52:22,545 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 3:53:55, time: 0.405, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1779, decode.acc_seg: 93.4380, loss: 0.1779/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:52:42,445 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 3:53:29, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.2010, decode.acc_seg: 92.6634, loss: 0.2010/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:53:02,285 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 3:53:02, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1664, decode.acc_seg: 94.1668, loss: 0.1664/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:53:22,215 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 3:52:36, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1597, decode.acc_seg: 94.0133, loss: 0.1597/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:53:42,318 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 3:52:11, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1645, decode.acc_seg: 94.1819, loss: 0.1645/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:54:02,090 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 3:51:44, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1381, decode.acc_seg: 95.0022, loss: 0.1381/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:54:21,930 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 3:51:18, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1509, decode.acc_seg: 94.6135, loss: 0.1509/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:54:41,762 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 3:50:52, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1422, decode.acc_seg: 94.6433, loss: 0.1422/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:55:01,605 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 3:50:26, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1827, decode.acc_seg: 93.2017, loss: 0.1827/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:55:21,480 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 14:55:21,481 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 3:50:00, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1525, decode.acc_seg: 94.2161, loss: 0.1525/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:55:41,326 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 3:49:34, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1650, decode.acc_seg: 94.1395, loss: 0.1650/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:56:01,356 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 3:49:09, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1650, decode.acc_seg: 94.2898, loss: 0.1650/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:56:21,513 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 3:48:45, time: 0.403, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1396, decode.acc_seg: 94.7615, loss: 0.1396/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:56:41,320 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 3:48:19, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1398, decode.acc_seg: 95.1070, loss: 0.1398/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:57:01,176 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 3:47:53, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1740, decode.acc_seg: 93.6718, loss: 0.1740/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:57:21,031 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 3:47:28, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1609, decode.acc_seg: 93.9919, loss: 0.1609/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:57:41,254 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 3:47:04, time: 0.404, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1529, decode.acc_seg: 94.5307, loss: 0.1529/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:58:01,285 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 3:46:39, time: 0.401, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1195, decode.acc_seg: 95.8345, loss: 0.1195/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:58:21,087 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 3:46:14, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1291, decode.acc_seg: 95.3163, loss: 0.1291/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:58:41,198 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 3:45:50, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1529, decode.acc_seg: 94.7193, loss: 0.1529/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:59:02,791 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 3:45:32, time: 0.432, data_time: 0.041, memory: 11956, decode.loss_seg: 0.1569, decode.acc_seg: 94.4695, loss: 0.1569/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:59:22,808 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 3:45:08, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1093, decode.acc_seg: 96.2158, loss: 0.1093/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 14:59:42,552 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 3:44:42, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1561, decode.acc_seg: 94.5334, loss: 0.1561/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:00:02,402 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 3:44:17, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1373, decode.acc_seg: 95.0245, loss: 0.1373/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:00:22,402 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 3:43:53, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1560, decode.acc_seg: 94.5450, loss: 0.1560/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:00:42,174 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 3:43:28, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1575, decode.acc_seg: 94.1891, loss: 0.1575/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:01:02,090 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 3:43:03, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1406, decode.acc_seg: 94.8947, loss: 0.1406/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:01:21,963 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 3:42:39, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1371, decode.acc_seg: 94.6675, loss: 0.1371/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:01:41,878 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 3:42:14, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1630, decode.acc_seg: 93.9094, loss: 0.1630[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.7 task/s, elapsed: 1s, ETA:  1312s[                                 ] 2/929, 1.3 task/s, elapsed: 2s, ETA:   699s[                                 ] 3/929, 1.9 task/s, elapsed: 2s, ETA:   495s[                                 ] 4/929, 2.4 task/s, elapsed: 2s, ETA:   393s[                                 ] 5/929, 2.8 task/s, elapsed: 2s, ETA:   333s[                                 ] 6/929, 3.2 task/s, elapsed: 2s, ETA:   292s[                                 ] 7/929, 3.5 task/s, elapsed: 2s, ETA:   263s[                                 ] 8/929, 3.8 task/s, elapsed: 2s, ETA:   241s[                                 ] 9/929, 4.1 task/s, elapsed: 2s, ETA:   224s[                                ] 10/929, 4.4 task/s, elapsed: 2s, ETA:   210s[                                ] 11/929, 4.6 task/s, elapsed: 2s, ETA:   199s[                                ] 12/929, 4.8 task/s, elapsed: 2s, ETA:   189s[                                ] 13/929, 5.1 task/s, elapsed: 3s, ETA:   181s[                                ] 14/929, 5.2 task/s, elapsed: 3s, ETA:   175s[                                ] 15/929, 5.4 task/s, elapsed: 3s, ETA:   169s[                                ] 16/929, 5.6 task/s, elapsed: 3s, ETA:   163s[                                ] 17/929, 5.7 task/s, elapsed: 3s, ETA:   159s[                                ] 18/929, 5.9 task/s, elapsed: 3s, ETA:   155s[                                ] 19/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 20/929, 6.2 task/s, elapsed: 3s, ETA:   147s[                                ] 21/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 22/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 23/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 24/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 25/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 26/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 27/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 28/929, 7.0 task/s, elapsed: 4s, ETA:   129s[                                ] 29/929, 7.1 task/s, elapsed: 4s, ETA:   128s[>                               ] 30/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 31/929, 7.2 task/s, elapsed: 4s, ETA:   124s[>                               ] 32/929, 7.3 task/s, elapsed: 4s, ETA:   123s[>                               ] 33/929, 7.4 task/s, elapsed: 4s, ETA:   122s[>                               ] 34/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 35/929, 7.5 task/s, elapsed: 5s, ETA:   120s[>                               ] 36/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 37/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 38/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 39/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 40/929, 7.8 task/s, elapsed: 5s, ETA:   115s[>                               ] 41/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 42/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 43/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 44/929, 8.0 task/s, elapsed: 6s, ETA:   111s[>                               ] 45/929, 8.0 task/s, elapsed: 6s, ETA:   111s[>                               ] 46/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 47/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 48/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 49/929, 8.1 task/s, elapsed: 6s, ETA:   108s[>                               ] 50/929, 8.2 task/s, elapsed: 6s, ETA:   108s[>                               ] 51/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 52/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 53/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 54/929, 8.3 task/s, elapsed: 6s, ETA:   105s[>                               ] 55/929, 8.4 task/s, elapsed: 7s, ETA:   105s[>                               ] 56/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>                               ] 57/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>                               ] 58/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 59/929, 8.5 task/s, elapsed: 7s, ETA:   103s[>>                              ] 60/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 61/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 62/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 63/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 64/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 65/929, 8.6 task/s, elapsed: 8s, ETA:   101s[>>                              ] 66/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 67/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 68/929, 8.7 task/s, elapsed: 8s, ETA:   100s[>>                              ] 69/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 70/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 71/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 72/929, 8.7 task/s, elapsed: 8s, ETA:    98s[>>                              ] 73/929, 8.7 task/s, elapsed: 8s, ETA:    98s[>>                              ] 74/929, 8.7 task/s, elapsed: 8s, ETA:    98s[>>                              ] 75/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 76/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 77/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 78/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 79/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                              ] 80/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                              ] 81/929, 8.9 task/s, elapsed: 9s, ETA:    96s[>>                              ] 82/929, 8.9 task/s, elapsed: 9s, ETA:    95s[>>                              ] 83/929, 8.9 task/s, elapsed: 9s, ETA:    95s[>>                              ] 84/929, 8.9 task/s, elapsed: 9s, ETA:    95s[>>                             ] 85/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 86/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 87/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 88/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>                             ] 89/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 90/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 91/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 92/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 93/929, 9.0 task/s, elapsed: 10s, ETA:    93s[>>>                            ] 94/929, 9.0 task/s, elapsed: 10s, ETA:    93s[>>>                            ] 95/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 96/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 97/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 98/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 99/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                           ] 100/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 101/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 102/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 103/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 104/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 105/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 106/929, 9.1 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 107/929, 9.1 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 108/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 109/929, 9.1 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 110/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 111/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 112/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 113/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 114/929, 9.1 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 115/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 116/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 117/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 118/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 119/929, 9.2 task/s, elapsed: 13s, ETA:    88s[>>>                           ] 120/929, 9.2 task/s, elapsed: 13s, ETA:    88s[>>>                           ] 121/929, 9.2 task/s, elapsed: 13s, ETA:    88s[>>>                           ] 122/929, 9.2 task/s, elapsed: 13s, ETA:    88s[>>>                           ] 123/929, 9.2 task/s, elapsed: 13s, ETA:    88s[>>>>                          ] 124/929, 9.2 task/s, elapsed: 13s, ETA:    88s[>>>>                          ] 125/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 126/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 127/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 128/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 129/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 130/929, 9.3 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 131/929, 9.3 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 132/929, 9.3 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 133/929, 9.3 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 134/929, 9.3 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 135/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 136/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 137/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 138/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 139/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 140/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 141/929, 9.3 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 142/929, 9.3 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 143/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 144/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 145/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 146/929, 9.4 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 147/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 148/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 149/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 150/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 151/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 152/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 153/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>                          ] 154/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>>                         ] 155/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>>                         ] 156/929, 9.4 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 157/929, 9.4 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 158/929, 9.4 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 159/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 160/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 161/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 162/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 163/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 164/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 165/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 166/929, 9.5 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 167/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 168/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 169/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 170/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 171/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 172/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 173/929, 9.5 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 174/929, 9.5 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 175/929, 9.5 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 176/929, 9.5 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 177/929, 9.5 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 178/929, 9.5 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 179/929, 9.6 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 180/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 181/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 182/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 183/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 184/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 185/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>>                        ] 186/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>>                        ] 187/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 188/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 189/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 190/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 191/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 192/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 193/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 194/929, 9.6 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 195/929, 9.6 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 196/929, 9.6 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 197/929, 9.6 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 198/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 199/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 200/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 201/929, 9.6 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 202/929, 9.6 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 203/929, 9.7 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 204/929, 9.7 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 205/929, 9.7 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 206/929, 9.7 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 207/929, 9.7 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 208/929, 9.7 task/s, elapsed: 22s, ETA:    75s[>>>>>>                        ] 209/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 210/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 211/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 212/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 213/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 214/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 215/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 216/929, 9.7 task/s, elapsed: 22s, ETA:    74s[>>>>>>>                       ] 217/929, 9.7 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 218/929, 9.7 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 219/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 220/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 221/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 222/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 223/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 224/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 225/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 226/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 227/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 228/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 229/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 230/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 231/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 232/929, 9.7 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 233/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 234/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 235/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 236/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 237/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 238/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 239/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 240/929, 9.8 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 241/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 242/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 243/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 244/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 245/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 246/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 247/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>>                      ] 248/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>>                      ] 249/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>>                      ] 250/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 251/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 252/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 253/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 254/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 255/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 256/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 257/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 258/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 259/929, 9.8 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 260/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 261/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 262/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 263/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 264/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 265/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 266/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 267/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 268/929, 9.8 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 269/929, 9.8 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 270/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 271/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 272/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 273/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 274/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 275/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 276/929, 9.8 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 277/929, 9.8 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 278/929, 9.8 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 279/929, 9.8 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 280/929, 9.8 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 281/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 282/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 283/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 284/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 285/929, 9.8 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 286/929, 9.8 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 287/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 288/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 289/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 290/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 291/929, 9.9 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 292/929, 9.9 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 293/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 294/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 295/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 296/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 297/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 298/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 299/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 300/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 301/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 302/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 303/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 304/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 305/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 306/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 307/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 308/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 309/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>>                    ] 310/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>>                    ] 311/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 312/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 313/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 314/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 315/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 316/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 317/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 318/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 319/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 320/929, 9.9 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 321/929, 9.9 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 322/929, 9.9 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 323/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 324/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 325/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 326/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 327/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 328/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 329/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 330/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 331/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 332/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 333/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 334/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 335/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 336/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 337/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 338/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 339/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                    ] 340/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>>                   ] 341/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>>                   ] 342/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>>                   ] 343/929, 9.9 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 344/929, 9.9 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 345/929, 9.9 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 346/929, 9.9 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 347/929, 9.9 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 348/929, 9.9 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 349/929, 9.9 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 350/929, 9.9 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 351/929, 9.9 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 352/929, 9.9 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 353/929, 9.9 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 354/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                  ] 355/929, 10.0 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                  ] 356/929, 10.0 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                  ] 357/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 358/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 359/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 360/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 361/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 362/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 363/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 364/929, 10.0 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                  ] 365/929, 10.0 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                  ] 366/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 367/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 368/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 369/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 370/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 371/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 372/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 373/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 374/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 375/929, 10.0 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>                  ] 376/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 377/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 378/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 379/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 380/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 381/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 382/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 383/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 384/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>>                 ] 385/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 387/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 388/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 389/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 390/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 391/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 392/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 393/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 394/929, 10.0 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.0 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 397/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 398/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 399/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 400/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 401/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 402/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 403/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 404/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 407/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 408/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 409/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 410/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 411/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 412/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 413/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 414/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 417/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 418/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 419/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 420/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 421/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 422/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 423/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 427/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 428/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 429/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 430/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 431/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 432/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 433/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 437/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 438/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 439/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 440/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 441/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 442/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 443/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 445/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 447/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>                ] 448/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 449/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 450/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 451/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 452/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 453/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 455/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 457/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 458/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 459/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 460/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 461/929, 10.1 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 462/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 466/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 467/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 468/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 469/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 470/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 471/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 472/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 477/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 478/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 479/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 480/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 481/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 482/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 487/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 488/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 489/929, 10.1 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 490/929, 10.1 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 491/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 492/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 496/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 497/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 498/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 499/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 500/929, 10.1 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 501/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 506/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 507/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 508/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 509/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 510/929, 10.1 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 511/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 516/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 517/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 518/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 519/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 520/929, 10.1 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 521/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 526/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 527/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 528/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 529/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 530/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 531/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 537/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 538/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 539/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 540/929, 10.1 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 541/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.1 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.1 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.1 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.1 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.1 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.1 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.1 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.1 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.1 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.1 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.1 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.1 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.1 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.1 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.1 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.2 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.2 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.2 task/s, elapsed: 91s, ETA:     0s2022-10-03 15:04:27,251 - mmseg - INFO - per class results:2022-10-03 15:04:27,252 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 89.54 | 94.28 || rigid_plastic | 21.45 | 23.24 ||   cardboard   | 55.34 |  66.8 ||     metal     |  25.1 | 27.06 ||  soft_plastic | 53.13 |  83.6 |+---------------+-------+-------+2022-10-03 15:04:27,252 - mmseg - INFO - Summary:2022-10-03 15:04:27,252 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 89.94 | 48.91 | 58.99 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:04:27,326 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:04:27,326 - mmseg - INFO - Iter [929/40000]	lr: 4.800e-05, eta: 3:41:50, time: 0.401, data_time: 0.009, memory: 11956, aAcc: 0.8994, mIoU: 0.4891, mAcc: 0.5899, IoU.background: 0.8954, IoU.rigid_plastic: 0.2145, IoU.cardboard: 0.5534, IoU.metal: 0.2510, IoU.soft_plastic: 0.5313, Acc.background: 0.9428, Acc.rigid_plastic: 0.2324, Acc.cardboard: 0.6680, Acc.metal: 0.2706, Acc.soft_plastic: 0.8360, decode.loss_seg: 0.1341, decode.acc_seg: 95.1338, loss: 0.1341/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:04:47,118 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 3:51:03, time: 3.304, data_time: 2.917, memory: 11956, decode.loss_seg: 0.1407, decode.acc_seg: 94.8825, loss: 0.1407/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:05:07,053 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 3:50:34, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1359, decode.acc_seg: 94.6849, loss: 0.1359/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:05:26,894 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 3:50:05, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1443, decode.acc_seg: 94.6916, loss: 0.1443/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:05:46,780 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 3:49:37, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1437, decode.acc_seg: 94.8954, loss: 0.1437/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:06:06,921 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 3:49:09, time: 0.403, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1386, decode.acc_seg: 95.1544, loss: 0.1386/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:06:26,782 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 3:48:41, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1284, decode.acc_seg: 95.2206, loss: 0.1284/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:06:46,834 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 3:48:13, time: 0.401, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1430, decode.acc_seg: 95.0494, loss: 0.1430/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:07:06,863 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 3:47:45, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1258, decode.acc_seg: 95.4265, loss: 0.1258/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:07:26,683 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 3:47:17, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1385, decode.acc_seg: 95.0936, loss: 0.1385/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:07:46,575 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 3:46:49, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1318, decode.acc_seg: 95.3396, loss: 0.1318/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:08:06,422 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 3:46:21, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1388, decode.acc_seg: 95.0482, loss: 0.1388/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:08:26,213 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 3:45:53, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1147, decode.acc_seg: 95.9943, loss: 0.1147/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:08:45,989 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 3:45:25, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1450, decode.acc_seg: 95.0927, loss: 0.1450/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:09:05,575 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 3:44:56, time: 0.392, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1128, decode.acc_seg: 95.8590, loss: 0.1128/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:09:25,472 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 3:44:28, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1256, decode.acc_seg: 95.3760, loss: 0.1256/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:09:45,223 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 3:44:00, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1447, decode.acc_seg: 94.5764, loss: 0.1447/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:10:05,183 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 3:43:33, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1465, decode.acc_seg: 94.7446, loss: 0.1465/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:10:25,011 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 3:43:06, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1334, decode.acc_seg: 95.5040, loss: 0.1334/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:10:44,951 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 3:42:39, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1515, decode.acc_seg: 94.0817, loss: 0.1515/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:11:04,869 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:11:04,869 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 3:42:12, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1282, decode.acc_seg: 95.7103, loss: 0.1282/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:11:26,782 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 3:41:52, time: 0.438, data_time: 0.051, memory: 11956, decode.loss_seg: 0.1098, decode.acc_seg: 95.9587, loss: 0.1098/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:11:46,786 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 3:41:25, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1212, decode.acc_seg: 95.3596, loss: 0.1212/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:12:06,748 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 3:40:58, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1431, decode.acc_seg: 94.7126, loss: 0.1431/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:12:26,702 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 3:40:32, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1422, decode.acc_seg: 94.8374, loss: 0.1422/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:12:46,572 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 3:40:05, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1270, decode.acc_seg: 95.1578, loss: 0.1270/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:13:06,420 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 3:39:38, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1405, decode.acc_seg: 95.2295, loss: 0.1405/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:13:26,263 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 3:39:11, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1100, decode.acc_seg: 95.9162, loss: 0.1100/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:13:46,208 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 3:38:45, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1162, decode.acc_seg: 95.6254, loss: 0.1162/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:14:06,117 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 3:38:19, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1113, decode.acc_seg: 96.1110, loss: 0.1113/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:14:26,038 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 3:37:52, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1085, decode.acc_seg: 96.0648, loss: 0.1085/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:14:46,212 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 3:37:27, time: 0.403, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1231, decode.acc_seg: 95.5062, loss: 0.1231/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:15:05,873 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 3:37:00, time: 0.393, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1148, decode.acc_seg: 95.7321, loss: 0.1148/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:15:25,606 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 3:36:33, time: 0.395, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0994, decode.acc_seg: 96.4270, loss: 0.0994/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:15:45,621 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 3:36:07, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1129, decode.acc_seg: 96.0141, loss: 0.1129/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:16:05,699 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 3:35:42, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1103, decode.acc_seg: 96.0685, loss: 0.1103/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:16:25,374 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 3:35:15, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1311, decode.acc_seg: 95.3700, loss: 0.1311/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:16:45,224 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 3:34:49, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1319, decode.acc_seg: 95.2613, loss: 0.1319/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:17:05,048 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 3:34:23, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1183, decode.acc_seg: 95.8643, loss: 0.1183/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:17:24,847 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 3:33:57, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1145, decode.acc_seg: 95.8743, loss: 0.1145/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:17:44,710 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:17:44,710 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 3:33:31, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1168, decode.acc_seg: 95.8412, loss: 0.1168/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:18:04,508 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 3:33:05, time: 0.396, data_time: 0.006, memory: 11956, decode.loss_seg: 0.1306, decode.acc_seg: 95.5204, loss: 0.1306/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:18:24,399 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 3:32:39, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1391, decode.acc_seg: 95.1650, loss: 0.1391/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:18:44,041 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 3:32:13, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1265, decode.acc_seg: 95.4977, loss: 0.1265/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:19:04,572 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 3:31:49, time: 0.411, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1375, decode.acc_seg: 94.7765, loss: 0.1375/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:19:25,433 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 3:31:27, time: 0.417, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1198, decode.acc_seg: 95.8248, loss: 0.1198/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:19:45,953 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 3:31:03, time: 0.410, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1224, decode.acc_seg: 95.6349, loss: 0.1224/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:20:05,699 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 3:30:37, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1261, decode.acc_seg: 95.4394, loss: 0.1261/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:20:25,592 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 3:30:12, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1186, decode.acc_seg: 95.6087, loss: 0.1186/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:20:46,115 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 3:29:48, time: 0.410, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1343, decode.acc_seg: 95.2539, loss: 0.1343/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:21:06,914 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 3:29:26, time: 0.416, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1366, decode.acc_seg: 94.8213, loss: 0.1366/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:21:28,864 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 3:29:06, time: 0.439, data_time: 0.043, memory: 11956, decode.loss_seg: 0.1134, decode.acc_seg: 95.9985, loss: 0.1134/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:21:48,690 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 3:28:41, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1053, decode.acc_seg: 96.1672, loss: 0.1053/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:22:08,491 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 3:28:15, time: 0.396, data_time: 0.006, memory: 11956, decode.loss_seg: 0.1071, decode.acc_seg: 96.1606, loss: 0.1071/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:22:28,341 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 3:27:50, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1020, decode.acc_seg: 96.3143, loss: 0.1020/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:22:48,184 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 3:27:25, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1141, decode.acc_seg: 95.9667, loss: 0.1141/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:23:07,972 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 3:27:00, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1100, decode.acc_seg: 95.8793, loss: 0.1100/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:23:27,754 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 3:26:34, time: 0.396, data_time: 0.006, memory: 11956, decode.loss_seg: 0.1119, decode.acc_seg: 96.1047, loss: 0.1119/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:23:47,645 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 3:26:10, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0999, decode.acc_seg: 96.4537, loss: 0.0999/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:24:07,446 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 3:25:44, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1132, decode.acc_seg: 95.6687, loss: 0.1132/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:24:27,141 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:24:27,141 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 3:25:19, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1209, decode.acc_seg: 95.5069, loss: 0.1209/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:24:46,963 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 3:24:54, time: 0.396, data_time: 0.006, memory: 11956, decode.loss_seg: 0.1186, decode.acc_seg: 95.9630, loss: 0.1186/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:25:06,792 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 3:24:29, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0735, decode.acc_seg: 97.3222, loss: 0.0735/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:25:26,731 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 3:24:05, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1079, decode.acc_seg: 96.1473, loss: 0.1079/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:25:46,372 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 3:23:39, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1222, decode.acc_seg: 95.8496, loss: 0.1222/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:26:06,182 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 3:23:15, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1060, decode.acc_seg: 96.0736, loss: 0.1060/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:26:26,070 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 3:22:50, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0999, decode.acc_seg: 96.2784, loss: 0.0999/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:26:45,858 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 3:22:25, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1296, decode.acc_seg: 95.1370, loss: 0.1296/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:27:05,747 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 3:22:01, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1080, decode.acc_seg: 95.9514, loss: 0.1080/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:27:25,564 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 3:21:36, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1281, decode.acc_seg: 95.8163, loss: 0.1281/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:27:45,268 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 3:21:11, time: 0.394, data_time: 0.006, memory: 11956, decode.loss_seg: 0.1066, decode.acc_seg: 96.2261, loss: 0.1066/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:28:05,143 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 3:20:47, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0981, decode.acc_seg: 96.4513, loss: 0.0981/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:28:24,786 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 3:20:22, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1069, decode.acc_seg: 96.1095, loss: 0.1069/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:28:44,492 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 3:19:57, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1152, decode.acc_seg: 95.8843, loss: 0.1152/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:29:04,330 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 3:19:33, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1198, decode.acc_seg: 96.0220, loss: 0.1198/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:29:24,178 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 3:19:09, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0920, decode.acc_seg: 96.6992, loss: 0.0920/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:29:43,838 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 3:18:44, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1206, decode.acc_seg: 95.5417, loss: 0.1206/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:30:03,560 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 3:18:19, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1022, decode.acc_seg: 96.3860, loss: 0.1022/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:30:23,324 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 3:17:55, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0934, decode.acc_seg: 96.6882, loss: 0.0934/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:30:42,982 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 3:17:30, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1138, decode.acc_seg: 96.2087, loss: 0.1138[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1041s[                                 ] 2/929, 1.6 task/s, elapsed: 1s, ETA:   566s[                                 ] 3/929, 2.3 task/s, elapsed: 1s, ETA:   406s[                                 ] 4/929, 2.8 task/s, elapsed: 1s, ETA:   327s[                                 ] 5/929, 3.3 task/s, elapsed: 2s, ETA:   280s[                                 ] 6/929, 3.7 task/s, elapsed: 2s, ETA:   248s[                                 ] 7/929, 4.1 task/s, elapsed: 2s, ETA:   225s[                                 ] 8/929, 4.4 task/s, elapsed: 2s, ETA:   208s[                                 ] 9/929, 4.7 task/s, elapsed: 2s, ETA:   194s[                                ] 10/929, 5.0 task/s, elapsed: 2s, ETA:   183s[                                ] 11/929, 5.3 task/s, elapsed: 2s, ETA:   174s[                                ] 12/929, 5.5 task/s, elapsed: 2s, ETA:   167s[                                ] 13/929, 5.7 task/s, elapsed: 2s, ETA:   160s[                                ] 14/929, 5.9 task/s, elapsed: 2s, ETA:   155s[                                ] 15/929, 6.1 task/s, elapsed: 2s, ETA:   150s[                                ] 16/929, 6.3 task/s, elapsed: 3s, ETA:   146s[                                ] 17/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 18/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 19/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 20/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 21/929, 6.9 task/s, elapsed: 3s, ETA:   131s[                                ] 22/929, 7.0 task/s, elapsed: 3s, ETA:   129s[                                ] 23/929, 7.1 task/s, elapsed: 3s, ETA:   127s[                                ] 24/929, 7.2 task/s, elapsed: 3s, ETA:   125s[                                ] 25/929, 7.3 task/s, elapsed: 3s, ETA:   123s[                                ] 26/929, 7.4 task/s, elapsed: 4s, ETA:   122s[                                ] 27/929, 7.5 task/s, elapsed: 4s, ETA:   121s[                                ] 28/929, 7.6 task/s, elapsed: 4s, ETA:   119s[                                ] 29/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 30/929, 7.7 task/s, elapsed: 4s, ETA:   117s[>                               ] 31/929, 7.8 task/s, elapsed: 4s, ETA:   116s[>                               ] 32/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 33/929, 7.9 task/s, elapsed: 4s, ETA:   114s[>                               ] 34/929, 7.9 task/s, elapsed: 4s, ETA:   113s[>                               ] 35/929, 8.0 task/s, elapsed: 4s, ETA:   112s[>                               ] 36/929, 8.0 task/s, elapsed: 4s, ETA:   111s[>                               ] 37/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 38/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 39/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 40/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 41/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 42/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 43/929, 8.4 task/s, elapsed: 5s, ETA:   106s[>                               ] 44/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 45/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 46/929, 8.5 task/s, elapsed: 5s, ETA:   104s[>                               ] 47/929, 8.5 task/s, elapsed: 6s, ETA:   104s[>                               ] 48/929, 8.6 task/s, elapsed: 6s, ETA:   103s[>                               ] 49/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 50/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 51/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 52/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 53/929, 8.7 task/s, elapsed: 6s, ETA:   100s[>                               ] 54/929, 8.7 task/s, elapsed: 6s, ETA:   100s[>                               ] 55/929, 8.8 task/s, elapsed: 6s, ETA:   100s[>                               ] 56/929, 8.8 task/s, elapsed: 6s, ETA:    99s[>                               ] 57/929, 8.8 task/s, elapsed: 6s, ETA:    99s[>                               ] 58/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 59/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 60/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 61/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 62/929, 9.0 task/s, elapsed: 7s, ETA:    97s[>>                              ] 63/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 64/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 65/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 66/929, 9.0 task/s, elapsed: 7s, ETA:    95s[>>                              ] 67/929, 9.1 task/s, elapsed: 7s, ETA:    95s[>>                              ] 68/929, 9.1 task/s, elapsed: 7s, ETA:    95s[>>                              ] 69/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 70/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 71/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 72/929, 9.2 task/s, elapsed: 8s, ETA:    94s[>>                              ] 73/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 74/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 75/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 76/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 77/929, 9.2 task/s, elapsed: 8s, ETA:    92s[>>                              ] 78/929, 9.2 task/s, elapsed: 8s, ETA:    92s[>>                              ] 79/929, 9.3 task/s, elapsed: 9s, ETA:    92s[>>                              ] 80/929, 9.3 task/s, elapsed: 9s, ETA:    92s[>>                              ] 81/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 82/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 83/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 84/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 85/929, 9.3 task/s, elapsed: 9s, ETA:    90s[>>                              ] 86/929, 9.3 task/s, elapsed: 9s, ETA:    90s[>>                              ] 87/929, 9.4 task/s, elapsed: 9s, ETA:    90s[>>>                             ] 88/929, 9.4 task/s, elapsed: 9s, ETA:    90s[>>>                             ] 89/929, 9.4 task/s, elapsed: 9s, ETA:    90s[>>>                            ] 90/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 91/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 92/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 93/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 94/929, 9.4 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 95/929, 9.4 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 96/929, 9.5 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 97/929, 9.5 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 98/929, 9.5 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 99/929, 9.5 task/s, elapsed: 10s, ETA:    88s[>>>                           ] 100/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 101/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 102/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 103/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 104/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 105/929, 9.5 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 106/929, 9.5 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 107/929, 9.5 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 108/929, 9.6 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 109/929, 9.6 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 110/929, 9.6 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 111/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 112/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 113/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 114/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 115/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 116/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 117/929, 9.6 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 118/929, 9.6 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 119/929, 9.6 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 120/929, 9.6 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 121/929, 9.7 task/s, elapsed: 13s, ETA:    84s[>>>                           ] 122/929, 9.7 task/s, elapsed: 13s, ETA:    84s[>>>                           ] 123/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 124/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 125/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 126/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 127/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 128/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 129/929, 9.7 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 130/929, 9.7 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 131/929, 9.7 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 132/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 133/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 134/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 135/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 136/929, 9.7 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 137/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 138/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 139/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 140/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 141/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 142/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 143/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 144/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 145/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 146/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 147/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 148/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 149/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 150/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 151/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 152/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 153/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>                          ] 154/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 155/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 156/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 157/929, 9.8 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 158/929, 9.8 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 159/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 160/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 161/929, 9.8 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 162/929, 9.8 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 163/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 164/929, 9.9 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 165/929, 9.9 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 166/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 167/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 168/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 169/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 170/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 171/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 172/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 173/929, 9.9 task/s, elapsed: 17s, ETA:    76s[>>>>>                         ] 174/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 175/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 176/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 177/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 178/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 179/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 180/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 181/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 182/929, 9.9 task/s, elapsed: 18s, ETA:    75s[>>>>>                         ] 183/929, 9.9 task/s, elapsed: 18s, ETA:    75s[>>>>>                         ] 184/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>                         ] 185/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 186/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 187/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 188/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 189/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 190/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 191/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 192/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 193/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 194/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 195/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 196/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 197/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 198/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 199/929, 10.0 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 200/929, 10.0 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 201/929, 10.0 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 202/929, 10.0 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 203/929, 10.0 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 204/929, 10.0 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 205/929, 10.0 task/s, elapsed: 21s, ETA:    73s[>>>>>>                       ] 206/929, 10.0 task/s, elapsed: 21s, ETA:    73s[>>>>>>                       ] 207/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 208/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 209/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 210/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 211/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 212/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 213/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 214/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 215/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 216/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 217/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 218/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 219/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 220/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 221/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 222/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 223/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 224/929, 10.0 task/s, elapsed: 22s, ETA:    70s[>>>>>>>                      ] 225/929, 10.0 task/s, elapsed: 22s, ETA:    70s[>>>>>>>                      ] 226/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 227/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 228/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 229/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 230/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 231/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 232/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 233/929, 10.0 task/s, elapsed: 23s, ETA:    69s[>>>>>>>                      ] 234/929, 10.0 task/s, elapsed: 23s, ETA:    69s[>>>>>>>                      ] 235/929, 10.0 task/s, elapsed: 23s, ETA:    69s[>>>>>>>                      ] 236/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 237/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 238/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 239/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 240/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 241/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 242/929, 10.0 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 243/929, 10.0 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 244/929, 10.0 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 245/929, 10.0 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 246/929, 10.1 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 247/929, 10.1 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 248/929, 10.1 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 249/929, 10.1 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 250/929, 10.1 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 251/929, 10.1 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 252/929, 10.1 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 253/929, 10.1 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 254/929, 10.1 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 255/929, 10.1 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 256/929, 10.1 task/s, elapsed: 25s, ETA:    67s[>>>>>>>>                     ] 257/929, 10.1 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 258/929, 10.1 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 259/929, 10.1 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 260/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 261/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 262/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 263/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 264/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 265/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 266/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 267/929, 10.1 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 268/929, 10.1 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 269/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 270/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 271/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 272/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 273/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 274/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 275/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 276/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 277/929, 10.1 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 278/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 279/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 280/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 281/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 282/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 283/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 284/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 285/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 286/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 287/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 288/929, 10.1 task/s, elapsed: 28s, ETA:    63s[>>>>>>>>>                    ] 289/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 290/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 291/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 292/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 293/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 294/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 295/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 296/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 297/929, 10.1 task/s, elapsed: 29s, ETA:    62s[>>>>>>>>>                    ] 298/929, 10.1 task/s, elapsed: 29s, ETA:    62s[>>>>>>>>>                    ] 299/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 300/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 301/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 302/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 303/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 304/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 305/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 306/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 307/929, 10.1 task/s, elapsed: 30s, ETA:    61s[>>>>>>>>>                    ] 308/929, 10.1 task/s, elapsed: 30s, ETA:    61s[>>>>>>>>>                    ] 309/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 310/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 311/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 312/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 313/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 314/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 315/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 316/929, 10.1 task/s, elapsed: 31s, ETA:    60s[>>>>>>>>>                    ] 317/929, 10.1 task/s, elapsed: 31s, ETA:    60s[>>>>>>>>>                    ] 318/929, 10.1 task/s, elapsed: 31s, ETA:    60s[>>>>>>>>>                    ] 319/929, 10.1 task/s, elapsed: 31s, ETA:    60s[>>>>>>>>>                    ] 320/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 321/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 322/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 323/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 324/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 325/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 326/929, 10.1 task/s, elapsed: 32s, ETA:    59s[>>>>>>>>>>                   ] 327/929, 10.1 task/s, elapsed: 32s, ETA:    59s[>>>>>>>>>>                   ] 328/929, 10.1 task/s, elapsed: 32s, ETA:    59s[>>>>>>>>>>                   ] 329/929, 10.1 task/s, elapsed: 32s, ETA:    59s[>>>>>>>>>>                   ] 330/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 331/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 332/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 333/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 334/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 335/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 336/929, 10.1 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                   ] 337/929, 10.1 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                   ] 338/929, 10.1 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                   ] 339/929, 10.1 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                   ] 340/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 341/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 342/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 343/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 344/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 345/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 346/929, 10.1 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 347/929, 10.2 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 348/929, 10.2 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 349/929, 10.2 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 350/929, 10.1 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 351/929, 10.2 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 352/929, 10.2 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 353/929, 10.2 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 354/929, 10.2 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 355/929, 10.2 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 356/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 357/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 358/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 359/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 360/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 361/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 362/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 363/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 364/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 365/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 366/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 367/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 368/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 369/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 370/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 371/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 372/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 373/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 374/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 375/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 376/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 377/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 378/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 379/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 380/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 381/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 382/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 383/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 384/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 385/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 387/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 388/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 389/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 390/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 391/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 392/929, 10.2 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 393/929, 10.2 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 394/929, 10.2 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.2 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 397/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 398/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 399/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 400/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 401/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 402/929, 10.2 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 403/929, 10.2 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 404/929, 10.2 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.2 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 407/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 408/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 409/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 410/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 411/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 412/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 413/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 414/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 417/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 418/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 419/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 420/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 421/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 422/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 423/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 427/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 428/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 429/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 430/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 431/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 432/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 433/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 437/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 438/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 439/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 440/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 441/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 442/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 443/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.2 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 445/929, 10.2 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 447/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 448/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 449/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 450/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 451/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 452/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 453/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 455/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 457/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 458/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 459/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 460/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 461/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 462/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 466/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 467/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 468/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 469/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 470/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 471/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 472/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 477/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 478/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 479/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 480/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 481/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 482/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 487/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 488/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 489/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 490/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 491/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 492/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 496/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 497/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 498/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 499/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 500/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 501/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.2 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.2 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 506/929, 10.2 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 507/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 508/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 509/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 510/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 511/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.2 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 516/929, 10.2 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 517/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 518/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 519/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 520/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 521/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.2 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 526/929, 10.2 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 527/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 528/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 529/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 530/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 531/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.2 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.2 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 537/929, 10.2 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 538/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 539/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 540/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 541/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.2 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.2 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.2 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.2 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.2 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.2 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.2 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.2 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.2 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.2 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.2 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.2 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.2 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.2 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.2 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.2 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.2 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.2 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.2 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.2 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.2 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.2 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.2 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.2 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.2 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.2 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.2 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.2 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.2 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.2 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.2 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.2 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.2 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.2 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.2 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.2 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.2 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.2 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.2 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.2 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.2 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.2 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.2 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.2 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.2 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.2 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.2 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.2 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.2 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.2 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.2 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.2 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.2 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.2 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.2 task/s, elapsed: 91s, ETA:     0s2022-10-03 15:33:35,089 - mmseg - INFO - per class results:2022-10-03 15:33:35,091 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  |  90.6 | 96.17 || rigid_plastic | 28.18 |  33.2 ||   cardboard   | 54.99 | 68.34 ||     metal     | 30.34 |  32.8 ||  soft_plastic | 61.97 | 72.28 |+---------------+-------+-------+2022-10-03 15:33:35,091 - mmseg - INFO - Summary:2022-10-03 15:33:35,091 - mmseg - INFO - +------+-------+-------+| aAcc |  mIoU |  mAcc |+------+-------+-------+| 91.1 | 53.21 | 60.56 |+------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:33:35,097 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:33:35,097 - mmseg - INFO - Iter [929/40000]	lr: 4.200e-05, eta: 3:17:07, time: 0.401, data_time: 0.007, memory: 11956, aAcc: 0.9110, mIoU: 0.5321, mAcc: 0.6056, IoU.background: 0.9060, IoU.rigid_plastic: 0.2818, IoU.cardboard: 0.5499, IoU.metal: 0.3034, IoU.soft_plastic: 0.6197, Acc.background: 0.9617, Acc.rigid_plastic: 0.3320, Acc.cardboard: 0.6834, Acc.metal: 0.3280, Acc.soft_plastic: 0.7228, decode.loss_seg: 0.1287, decode.acc_seg: 95.4783, loss: 0.1287/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:34:00,495 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 3:22:48, time: 3.549, data_time: 3.095, memory: 11956, decode.loss_seg: 0.0997, decode.acc_seg: 96.4652, loss: 0.0997/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:34:24,361 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 3:22:31, time: 0.477, data_time: 0.009, memory: 11956, decode.loss_seg: 0.1070, decode.acc_seg: 96.0792, loss: 0.1070/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:34:50,022 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 3:22:18, time: 0.513, data_time: 0.011, memory: 11956, decode.loss_seg: 0.1248, decode.acc_seg: 95.6719, loss: 0.1248/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:35:16,099 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 3:22:06, time: 0.522, data_time: 0.011, memory: 11956, decode.loss_seg: 0.0975, decode.acc_seg: 96.5230, loss: 0.0975/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:35:42,612 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 3:21:55, time: 0.530, data_time: 0.011, memory: 11956, decode.loss_seg: 0.1019, decode.acc_seg: 96.3479, loss: 0.1019/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:36:10,118 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 3:21:46, time: 0.550, data_time: 0.011, memory: 11956, decode.loss_seg: 0.1035, decode.acc_seg: 96.4132, loss: 0.1035/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:36:34,887 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 3:21:31, time: 0.495, data_time: 0.011, memory: 11956, decode.loss_seg: 0.1009, decode.acc_seg: 96.5475, loss: 0.1009/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:36:57,162 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 3:21:10, time: 0.446, data_time: 0.010, memory: 11956, decode.loss_seg: 0.1013, decode.acc_seg: 96.2948, loss: 0.1013/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:37:17,343 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 3:20:44, time: 0.404, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1023, decode.acc_seg: 96.2442, loss: 0.1023/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:37:37,159 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 3:20:18, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1185, decode.acc_seg: 95.9702, loss: 0.1185/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:37:56,878 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 3:19:51, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0968, decode.acc_seg: 96.6649, loss: 0.0968/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:38:16,627 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 3:19:25, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1009, decode.acc_seg: 96.1604, loss: 0.1009/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:38:36,517 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 3:18:59, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1155, decode.acc_seg: 96.0352, loss: 0.1155/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:38:56,417 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 3:18:33, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1034, decode.acc_seg: 96.3529, loss: 0.1034/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:39:16,061 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 3:18:07, time: 0.393, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1169, decode.acc_seg: 95.7428, loss: 0.1169/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:39:35,794 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 3:17:40, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0979, decode.acc_seg: 96.4450, loss: 0.0979/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:39:55,779 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 3:17:15, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0850, decode.acc_seg: 96.7331, loss: 0.0850/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:40:15,602 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 3:16:49, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0965, decode.acc_seg: 96.8000, loss: 0.0965/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:40:35,505 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 3:16:23, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1018, decode.acc_seg: 96.2038, loss: 0.1018/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:40:55,393 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:40:55,393 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 3:15:57, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0935, decode.acc_seg: 96.5714, loss: 0.0935/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:41:15,011 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 3:15:31, time: 0.392, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1027, decode.acc_seg: 96.2747, loss: 0.1027/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:41:35,027 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 3:15:06, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0947, decode.acc_seg: 96.5800, loss: 0.0947/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:41:54,814 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 3:14:40, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0802, decode.acc_seg: 97.0909, loss: 0.0802/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:42:14,768 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 3:14:15, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0831, decode.acc_seg: 97.0009, loss: 0.0831/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:42:34,518 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 3:13:49, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1256, decode.acc_seg: 95.5367, loss: 0.1256/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:42:54,238 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 3:13:23, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1107, decode.acc_seg: 96.2195, loss: 0.1107/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:43:14,123 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 3:12:58, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1058, decode.acc_seg: 96.0268, loss: 0.1058/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:43:34,138 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 3:12:32, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0979, decode.acc_seg: 96.7379, loss: 0.0979/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:43:53,966 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 3:12:07, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0928, decode.acc_seg: 96.5949, loss: 0.0928/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:44:13,862 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 3:11:42, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0797, decode.acc_seg: 97.0559, loss: 0.0797/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:44:35,309 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 3:11:20, time: 0.429, data_time: 0.041, memory: 11956, decode.loss_seg: 0.0662, decode.acc_seg: 97.5183, loss: 0.0662/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:44:55,061 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 3:10:54, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0928, decode.acc_seg: 96.5141, loss: 0.0928/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:45:14,984 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 3:10:29, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0807, decode.acc_seg: 97.1171, loss: 0.0807/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:45:34,618 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 3:10:03, time: 0.393, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1127, decode.acc_seg: 95.8567, loss: 0.1127/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:45:54,254 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 3:09:38, time: 0.393, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1084, decode.acc_seg: 96.2029, loss: 0.1084/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:46:14,041 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 3:09:12, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0928, decode.acc_seg: 96.5812, loss: 0.0928/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:46:33,853 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 3:08:47, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0948, decode.acc_seg: 96.5086, loss: 0.0948/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:46:53,480 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 3:08:22, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0848, decode.acc_seg: 96.9646, loss: 0.0848/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:47:13,429 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 3:07:57, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0970, decode.acc_seg: 96.4562, loss: 0.0970/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:47:33,465 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:47:33,465 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 3:07:32, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0837, decode.acc_seg: 96.7900, loss: 0.0837/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:47:53,308 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 3:07:07, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1002, decode.acc_seg: 96.3850, loss: 0.1002/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:48:12,874 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 3:06:42, time: 0.391, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0936, decode.acc_seg: 96.8919, loss: 0.0936/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:48:32,676 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 3:06:17, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0992, decode.acc_seg: 96.3713, loss: 0.0992/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:48:52,753 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 3:05:53, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0747, decode.acc_seg: 97.2559, loss: 0.0747/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:49:12,522 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 3:05:28, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0806, decode.acc_seg: 97.1886, loss: 0.0806/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:49:32,258 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 3:05:03, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0860, decode.acc_seg: 97.0001, loss: 0.0860/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:49:52,183 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 3:04:38, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0951, decode.acc_seg: 96.5563, loss: 0.0951/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:50:11,825 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 3:04:13, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0670, decode.acc_seg: 97.5878, loss: 0.0670/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:50:31,640 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 3:03:48, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0815, decode.acc_seg: 97.0464, loss: 0.0815/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:50:51,544 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 3:03:24, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0878, decode.acc_seg: 96.9064, loss: 0.0878/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:51:11,449 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 3:02:59, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0777, decode.acc_seg: 97.1556, loss: 0.0777/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:51:31,240 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 3:02:35, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0885, decode.acc_seg: 96.7989, loss: 0.0885/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:51:51,104 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 3:02:10, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0873, decode.acc_seg: 96.8549, loss: 0.0873/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:52:10,798 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 3:01:45, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1106, decode.acc_seg: 96.1108, loss: 0.1106/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:52:30,724 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 3:01:21, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0829, decode.acc_seg: 97.1924, loss: 0.0829/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:52:50,535 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 3:00:56, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0932, decode.acc_seg: 96.6849, loss: 0.0932/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:53:10,534 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 3:00:32, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0907, decode.acc_seg: 96.7369, loss: 0.0907/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:53:30,203 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 3:00:08, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0879, decode.acc_seg: 96.9590, loss: 0.0879/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:53:49,974 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 2:59:43, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.1004, decode.acc_seg: 96.5809, loss: 0.1004/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:54:09,763 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 15:54:09,763 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 2:59:19, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0777, decode.acc_seg: 97.2088, loss: 0.0777/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:54:31,292 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 2:58:57, time: 0.431, data_time: 0.040, memory: 11956, decode.loss_seg: 0.0815, decode.acc_seg: 97.1772, loss: 0.0815/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:54:51,114 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 2:58:33, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0813, decode.acc_seg: 97.1895, loss: 0.0813/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:55:11,001 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 2:58:09, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0726, decode.acc_seg: 97.4109, loss: 0.0726/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:55:30,895 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 2:57:45, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1117, decode.acc_seg: 95.8807, loss: 0.1117/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:55:50,569 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 2:57:20, time: 0.393, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0776, decode.acc_seg: 97.1308, loss: 0.0776/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:56:10,721 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 2:56:56, time: 0.403, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0699, decode.acc_seg: 97.4281, loss: 0.0699/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:56:30,827 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 2:56:33, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0844, decode.acc_seg: 96.8451, loss: 0.0844/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:56:50,449 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 2:56:08, time: 0.392, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0843, decode.acc_seg: 96.9002, loss: 0.0843/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:57:10,119 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 2:55:44, time: 0.393, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0899, decode.acc_seg: 96.7044, loss: 0.0899/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:57:30,089 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 2:55:20, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0784, decode.acc_seg: 97.2466, loss: 0.0784/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:57:49,964 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 2:54:56, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0798, decode.acc_seg: 97.0224, loss: 0.0798/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:58:09,803 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 2:54:32, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0648, decode.acc_seg: 97.6259, loss: 0.0648/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:58:29,623 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 2:54:08, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0766, decode.acc_seg: 97.3069, loss: 0.0766/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:58:49,471 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 2:53:44, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0925, decode.acc_seg: 96.8029, loss: 0.0925/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:59:09,440 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 2:53:20, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0771, decode.acc_seg: 97.2957, loss: 0.0771/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:59:29,435 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 2:52:57, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0802, decode.acc_seg: 97.0711, loss: 0.0802/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 15:59:49,277 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 2:52:33, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0953, decode.acc_seg: 96.5483, loss: 0.0953/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:00:09,018 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 2:52:09, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0865, decode.acc_seg: 96.7662, loss: 0.0865/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:00:29,024 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 2:51:45, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0864, decode.acc_seg: 96.9407, loss: 0.0864[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.0 task/s, elapsed: 1s, ETA:   960s[                                 ] 2/929, 1.8 task/s, elapsed: 1s, ETA:   527s[                                 ] 3/929, 2.4 task/s, elapsed: 1s, ETA:   380s[                                 ] 4/929, 3.0 task/s, elapsed: 1s, ETA:   307s[                                 ] 5/929, 3.5 task/s, elapsed: 1s, ETA:   264s[                                 ] 6/929, 3.9 task/s, elapsed: 2s, ETA:   235s[                                 ] 7/929, 4.3 task/s, elapsed: 2s, ETA:   214s[                                 ] 8/929, 4.7 task/s, elapsed: 2s, ETA:   198s[                                 ] 9/929, 5.0 task/s, elapsed: 2s, ETA:   186s[                                ] 10/929, 5.2 task/s, elapsed: 2s, ETA:   176s[                                ] 11/929, 5.5 task/s, elapsed: 2s, ETA:   167s[                                ] 12/929, 5.7 task/s, elapsed: 2s, ETA:   160s[                                ] 13/929, 5.9 task/s, elapsed: 2s, ETA:   155s[                                ] 14/929, 6.1 task/s, elapsed: 2s, ETA:   150s[                                ] 15/929, 6.2 task/s, elapsed: 2s, ETA:   146s[                                ] 16/929, 6.4 task/s, elapsed: 2s, ETA:   143s[                                ] 17/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 18/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 19/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 20/929, 6.9 task/s, elapsed: 3s, ETA:   131s[                                ] 21/929, 7.0 task/s, elapsed: 3s, ETA:   129s[                                ] 22/929, 7.1 task/s, elapsed: 3s, ETA:   127s[                                ] 23/929, 7.2 task/s, elapsed: 3s, ETA:   125s[                                ] 24/929, 7.3 task/s, elapsed: 3s, ETA:   124s[                                ] 25/929, 7.4 task/s, elapsed: 3s, ETA:   122s[                                ] 26/929, 7.5 task/s, elapsed: 3s, ETA:   121s[                                ] 27/929, 7.5 task/s, elapsed: 4s, ETA:   119s[                                ] 28/929, 7.6 task/s, elapsed: 4s, ETA:   118s[                                ] 29/929, 7.7 task/s, elapsed: 4s, ETA:   117s[>                               ] 30/929, 7.8 task/s, elapsed: 4s, ETA:   116s[>                               ] 31/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 32/929, 7.9 task/s, elapsed: 4s, ETA:   114s[>                               ] 33/929, 8.0 task/s, elapsed: 4s, ETA:   113s[>                               ] 34/929, 8.0 task/s, elapsed: 4s, ETA:   112s[>                               ] 35/929, 8.1 task/s, elapsed: 4s, ETA:   111s[>                               ] 36/929, 8.1 task/s, elapsed: 4s, ETA:   110s[>                               ] 37/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 38/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 39/929, 8.3 task/s, elapsed: 5s, ETA:   108s[>                               ] 40/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 41/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 42/929, 8.4 task/s, elapsed: 5s, ETA:   106s[>                               ] 43/929, 8.4 task/s, elapsed: 5s, ETA:   106s[>                               ] 44/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 45/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 46/929, 8.5 task/s, elapsed: 5s, ETA:   104s[>                               ] 47/929, 8.5 task/s, elapsed: 6s, ETA:   104s[>                               ] 48/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 49/929, 8.6 task/s, elapsed: 6s, ETA:   103s[>                               ] 50/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 51/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 52/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 53/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 54/929, 8.7 task/s, elapsed: 6s, ETA:   100s[>                               ] 55/929, 8.7 task/s, elapsed: 6s, ETA:   100s[>                               ] 56/929, 8.8 task/s, elapsed: 6s, ETA:   100s[>                               ] 57/929, 8.8 task/s, elapsed: 6s, ETA:    99s[>                               ] 58/929, 8.8 task/s, elapsed: 7s, ETA:    99s[>>                              ] 59/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 60/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 61/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 62/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 63/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 64/929, 9.0 task/s, elapsed: 7s, ETA:    97s[>>                              ] 65/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 66/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 67/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 68/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 69/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 70/929, 9.1 task/s, elapsed: 8s, ETA:    95s[>>                              ] 71/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 72/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 73/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 74/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 75/929, 9.1 task/s, elapsed: 8s, ETA:    93s[>>                              ] 76/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 77/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 78/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 79/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 80/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 81/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 82/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 83/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 84/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 85/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 86/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 87/929, 9.3 task/s, elapsed: 9s, ETA:    90s[>>>                             ] 88/929, 9.3 task/s, elapsed: 9s, ETA:    90s[>>                             ] 89/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 90/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 91/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 92/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 93/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 94/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 95/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 96/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 97/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 98/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 99/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 100/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 101/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 102/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 103/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 104/929, 9.4 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 105/929, 9.4 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 106/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 107/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 108/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 109/929, 9.5 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 110/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 111/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 112/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 113/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 114/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 115/929, 9.5 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 116/929, 9.5 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 117/929, 9.5 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 118/929, 9.5 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 119/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 120/929, 9.6 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 121/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>                           ] 122/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>                           ] 123/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 124/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 125/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 126/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 127/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 128/929, 9.6 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 129/929, 9.6 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 130/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 131/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 132/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 133/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 134/929, 9.6 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 135/929, 9.6 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 136/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 137/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 138/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 139/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 140/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 141/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 142/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 143/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 144/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 145/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 146/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 147/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 148/929, 9.7 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 149/929, 9.7 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 150/929, 9.7 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 151/929, 9.7 task/s, elapsed: 16s, ETA:    80s[>>>>                          ] 152/929, 9.7 task/s, elapsed: 16s, ETA:    80s[>>>>                          ] 153/929, 9.7 task/s, elapsed: 16s, ETA:    80s[>>>>                          ] 154/929, 9.7 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 155/929, 9.7 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 156/929, 9.7 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 157/929, 9.7 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 158/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 159/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 160/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 161/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 162/929, 9.8 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 163/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 164/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 165/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 166/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 167/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 168/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 169/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 170/929, 9.8 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 171/929, 9.8 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 172/929, 9.8 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 173/929, 9.8 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 174/929, 9.8 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 175/929, 9.8 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 176/929, 9.8 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 177/929, 9.8 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 178/929, 9.8 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 179/929, 9.8 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 180/929, 9.8 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 181/929, 9.8 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 182/929, 9.8 task/s, elapsed: 19s, ETA:    76s[>>>>>                         ] 183/929, 9.8 task/s, elapsed: 19s, ETA:    76s[>>>>>                         ] 184/929, 9.8 task/s, elapsed: 19s, ETA:    76s[>>>>>                         ] 185/929, 9.8 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 186/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 187/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 188/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 189/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 190/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 191/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 192/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 193/929, 9.9 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 194/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 195/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 196/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 197/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 198/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 199/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 200/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 201/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 202/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 203/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 204/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 205/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 206/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 207/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 208/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 209/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 210/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 211/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 212/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 213/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 214/929, 9.9 task/s, elapsed: 22s, ETA:    72s[>>>>>>                        ] 215/929, 9.9 task/s, elapsed: 22s, ETA:    72s[>>>>>>                        ] 216/929, 9.9 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 217/929, 9.9 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 218/929, 9.9 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                       ] 219/929, 9.9 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                       ] 220/929, 9.9 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                       ] 221/929, 9.9 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                       ] 222/929, 9.9 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                       ] 223/929, 9.9 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                       ] 224/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 225/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 226/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                      ] 227/929, 10.0 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                      ] 228/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 229/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 230/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 231/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 232/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 233/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 234/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 235/929, 10.0 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                      ] 236/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 237/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 238/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 239/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 240/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 241/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 242/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 243/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 244/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 245/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 246/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 247/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 248/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 249/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 250/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 251/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 252/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 253/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 254/929, 10.0 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 255/929, 10.0 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 256/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 257/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 258/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 259/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 260/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 261/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 262/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 263/929, 10.0 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 264/929, 10.0 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 265/929, 10.0 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 266/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 267/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 268/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 269/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 270/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 271/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 272/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 273/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 274/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 275/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 276/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 277/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 278/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 279/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 280/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 281/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 282/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 283/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 284/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 285/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 286/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 287/929, 10.1 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 288/929, 10.1 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 289/929, 10.1 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 290/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 291/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 292/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 293/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 294/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 295/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 296/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 297/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 298/929, 10.1 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 299/929, 10.1 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 300/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 301/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 302/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 303/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 304/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 305/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 306/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 307/929, 10.1 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 308/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 309/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 310/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 311/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 312/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 313/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 314/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 315/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 316/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 317/929, 10.1 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 318/929, 10.1 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 319/929, 10.1 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 320/929, 10.1 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 321/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 322/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 323/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 324/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 325/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 326/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 327/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 328/929, 10.1 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 329/929, 10.1 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 330/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 331/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 332/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 333/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 334/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 335/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 336/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 337/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 338/929, 10.1 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 339/929, 10.1 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 340/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 341/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 342/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 343/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 344/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 345/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 346/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 347/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 348/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 349/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 350/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 351/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 352/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 353/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 354/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 355/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 356/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 357/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 358/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 359/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 360/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 361/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 362/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 363/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 364/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 365/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 366/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 367/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 368/929, 10.1 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 369/929, 10.1 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 370/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 371/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 372/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 373/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 374/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 375/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 376/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 377/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 378/929, 10.1 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 379/929, 10.1 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 380/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 381/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 382/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 383/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 384/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 385/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 387/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 388/929, 10.1 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 389/929, 10.1 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 390/929, 10.1 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 391/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 392/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 393/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 394/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 397/929, 10.1 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 398/929, 10.1 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 399/929, 10.1 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 400/929, 10.1 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 401/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 402/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 403/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 404/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 407/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 408/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 409/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 410/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 411/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 412/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 413/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 414/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>>                ] 417/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 418/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 419/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 420/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 421/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 422/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 423/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 427/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 428/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 429/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 430/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 431/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 432/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 433/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 437/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 438/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 439/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 440/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 441/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 442/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 443/929, 10.2 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.2 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 445/929, 10.2 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 447/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 448/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 449/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 450/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 451/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 452/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 453/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 455/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 457/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 458/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 459/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 460/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 461/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 462/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 466/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 467/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 468/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 469/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 470/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 471/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 472/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 477/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 478/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 479/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 480/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 481/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 482/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 487/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 488/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 489/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 490/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 491/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 492/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.2 task/s, elapsed: 48s, ETA:    42s[>>>>>>>>>>>>>>>              ] 496/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 497/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 498/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 499/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 500/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 501/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.2 task/s, elapsed: 49s, ETA:    41s[>>>>>>>>>>>>>>>              ] 506/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 507/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 508/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 509/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 510/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 511/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.2 task/s, elapsed: 50s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 516/929, 10.2 task/s, elapsed: 50s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 517/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 518/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 519/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 520/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 521/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.2 task/s, elapsed: 51s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 526/929, 10.2 task/s, elapsed: 51s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 527/929, 10.2 task/s, elapsed: 51s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 528/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 529/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 530/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 531/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.2 task/s, elapsed: 52s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 536/929, 10.2 task/s, elapsed: 52s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 537/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 538/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 539/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 540/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 541/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.2 task/s, elapsed: 53s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.2 task/s, elapsed: 53s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.2 task/s, elapsed: 55s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.2 task/s, elapsed: 55s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.2 task/s, elapsed: 55s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.3 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.3 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.3 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.2 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.2 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.3 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.3 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.3 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.3 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.3 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.3 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.3 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.3 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.3 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.3 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.3 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.3 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.3 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.3 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.3 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.3 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.3 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.3 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.3 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.3 task/s, elapsed: 90s, ETA:     0s2022-10-03 16:03:12,693 - mmseg - INFO - per class results:2022-10-03 16:03:12,694 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.77 | 96.11 || rigid_plastic | 21.56 | 25.98 ||   cardboard   |  55.5 | 68.79 ||     metal     | 30.43 | 44.14 ||  soft_plastic | 61.96 |  73.9 |+---------------+-------+-------+2022-10-03 16:03:12,694 - mmseg - INFO - Summary:2022-10-03 16:03:12,695 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.14 | 52.04 | 61.79 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:03:12,699 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:03:12,699 - mmseg - INFO - Iter [929/40000]	lr: 3.600e-05, eta: 2:51:21, time: 0.398, data_time: 0.008, memory: 11956, aAcc: 0.9114, mIoU: 0.5204, mAcc: 0.6179, IoU.background: 0.9077, IoU.rigid_plastic: 0.2156, IoU.cardboard: 0.5550, IoU.metal: 0.3043, IoU.soft_plastic: 0.6196, Acc.background: 0.9611, Acc.rigid_plastic: 0.2598, Acc.cardboard: 0.6879, Acc.metal: 0.4414, Acc.soft_plastic: 0.7390, decode.loss_seg: 0.0864, decode.acc_seg: 96.7300, loss: 0.0864/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:03:32,628 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 2:54:32, time: 3.274, data_time: 2.884, memory: 11956, decode.loss_seg: 0.0975, decode.acc_seg: 96.4046, loss: 0.0975/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:03:52,371 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 2:54:07, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0774, decode.acc_seg: 97.2275, loss: 0.0774/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:04:12,344 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 2:53:43, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0982, decode.acc_seg: 96.5477, loss: 0.0982/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:04:32,271 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 2:53:18, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0815, decode.acc_seg: 96.9784, loss: 0.0815/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:04:52,071 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 2:52:53, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0625, decode.acc_seg: 97.7443, loss: 0.0625/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:05:11,866 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 2:52:28, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0829, decode.acc_seg: 97.1651, loss: 0.0829/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:05:31,538 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 2:52:03, time: 0.393, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0998, decode.acc_seg: 96.6053, loss: 0.0998/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:05:51,358 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 2:51:39, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0783, decode.acc_seg: 97.1905, loss: 0.0783/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:06:11,259 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 2:51:14, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0823, decode.acc_seg: 97.2492, loss: 0.0823/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:06:31,065 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 2:50:49, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.1070, decode.acc_seg: 96.2440, loss: 0.1070/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:06:52,788 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 2:50:28, time: 0.434, data_time: 0.045, memory: 11956, decode.loss_seg: 0.0784, decode.acc_seg: 97.1871, loss: 0.0784/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:07:12,536 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 2:50:03, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0657, decode.acc_seg: 97.5279, loss: 0.0657/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:07:32,425 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 2:49:38, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0674, decode.acc_seg: 97.4430, loss: 0.0674/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:07:52,221 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 2:49:14, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0724, decode.acc_seg: 97.4219, loss: 0.0724/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:08:11,953 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 2:48:49, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0724, decode.acc_seg: 97.2765, loss: 0.0724/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:08:31,828 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 2:48:25, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0698, decode.acc_seg: 97.4642, loss: 0.0698/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:08:51,675 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 2:48:00, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0845, decode.acc_seg: 96.8988, loss: 0.0845/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:09:11,472 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 2:47:36, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0731, decode.acc_seg: 97.3381, loss: 0.0731/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:09:31,180 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 2:47:11, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0692, decode.acc_seg: 97.3805, loss: 0.0692/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:09:51,146 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:09:51,146 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 2:46:47, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0865, decode.acc_seg: 96.8866, loss: 0.0865/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:10:11,066 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 2:46:23, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0765, decode.acc_seg: 97.0886, loss: 0.0765/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:10:30,919 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 2:45:59, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0621, decode.acc_seg: 97.7768, loss: 0.0621/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:10:51,041 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 2:45:35, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0747, decode.acc_seg: 97.3183, loss: 0.0747/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:11:10,734 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 2:45:10, time: 0.394, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0695, decode.acc_seg: 97.6071, loss: 0.0695/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:11:30,610 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 2:44:46, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0743, decode.acc_seg: 97.4623, loss: 0.0743/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:11:50,386 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 2:44:22, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0803, decode.acc_seg: 96.9307, loss: 0.0803/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:12:10,121 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 2:43:57, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0590, decode.acc_seg: 97.8178, loss: 0.0590/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:12:29,963 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 2:43:33, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0621, decode.acc_seg: 97.7673, loss: 0.0621/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:12:49,751 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 2:43:09, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0805, decode.acc_seg: 97.0240, loss: 0.0805/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:13:09,514 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 2:42:45, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0601, decode.acc_seg: 97.8043, loss: 0.0601/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:13:29,547 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 2:42:21, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0746, decode.acc_seg: 97.2678, loss: 0.0746/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:13:49,439 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 2:41:57, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0801, decode.acc_seg: 97.0654, loss: 0.0801/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:14:09,189 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 2:41:33, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0861, decode.acc_seg: 97.0050, loss: 0.0861/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:14:29,169 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 2:41:09, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0673, decode.acc_seg: 97.5659, loss: 0.0673/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:14:48,965 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 2:40:45, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0830, decode.acc_seg: 97.0796, loss: 0.0830/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:15:08,748 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 2:40:21, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0778, decode.acc_seg: 97.1471, loss: 0.0778/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:15:28,574 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 2:39:57, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0929, decode.acc_seg: 96.6987, loss: 0.0929/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:15:48,504 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 2:39:33, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0846, decode.acc_seg: 96.8861, loss: 0.0846/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:16:08,542 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 2:39:10, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0741, decode.acc_seg: 97.3158, loss: 0.0741/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:16:28,394 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:16:28,394 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 2:38:46, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0752, decode.acc_seg: 97.2444, loss: 0.0752/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:16:50,193 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 2:38:24, time: 0.436, data_time: 0.041, memory: 11956, decode.loss_seg: 0.0709, decode.acc_seg: 97.4755, loss: 0.0709/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:17:10,134 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 2:38:00, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0702, decode.acc_seg: 97.5977, loss: 0.0702/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:17:29,845 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 2:37:36, time: 0.394, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0654, decode.acc_seg: 97.6767, loss: 0.0654/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:17:49,792 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 2:37:13, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0665, decode.acc_seg: 97.6498, loss: 0.0665/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:18:09,843 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 2:36:49, time: 0.401, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0667, decode.acc_seg: 97.4223, loss: 0.0667/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:18:29,733 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 2:36:26, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0662, decode.acc_seg: 97.5185, loss: 0.0662/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:18:49,737 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 2:36:02, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0785, decode.acc_seg: 96.9969, loss: 0.0785/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:19:09,530 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 2:35:38, time: 0.396, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0656, decode.acc_seg: 97.7127, loss: 0.0656/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:19:29,490 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 2:35:15, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0667, decode.acc_seg: 97.5242, loss: 0.0667/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:19:49,366 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 2:34:51, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0747, decode.acc_seg: 97.2746, loss: 0.0747/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:20:09,424 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 2:34:28, time: 0.401, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0777, decode.acc_seg: 97.0538, loss: 0.0777/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:20:29,371 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 2:34:04, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0695, decode.acc_seg: 97.4441, loss: 0.0695/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:20:49,234 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 2:33:41, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0704, decode.acc_seg: 97.5093, loss: 0.0704/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:21:09,072 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 2:33:17, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0704, decode.acc_seg: 97.6291, loss: 0.0704/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:21:29,021 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 2:32:54, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0754, decode.acc_seg: 97.1635, loss: 0.0754/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:21:48,919 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 2:32:30, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0747, decode.acc_seg: 97.4183, loss: 0.0747/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:22:08,936 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 2:32:07, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0679, decode.acc_seg: 97.5998, loss: 0.0679/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:22:28,732 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 2:31:43, time: 0.396, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0591, decode.acc_seg: 97.9306, loss: 0.0591/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:22:48,732 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 2:31:20, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0650, decode.acc_seg: 97.5284, loss: 0.0650/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:23:08,738 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:23:08,739 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 2:30:57, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0714, decode.acc_seg: 97.5296, loss: 0.0714/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:23:28,702 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 2:30:33, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0814, decode.acc_seg: 96.9599, loss: 0.0814/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:23:48,622 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 2:30:10, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0688, decode.acc_seg: 97.4903, loss: 0.0688/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:24:08,539 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 2:29:47, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0860, decode.acc_seg: 96.8100, loss: 0.0860/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:24:28,482 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 2:29:23, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0716, decode.acc_seg: 97.2465, loss: 0.0716/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:24:48,514 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 2:29:00, time: 0.401, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0635, decode.acc_seg: 97.6520, loss: 0.0635/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:25:08,477 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 2:28:37, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0650, decode.acc_seg: 97.7165, loss: 0.0650/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:25:28,341 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 2:28:13, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0608, decode.acc_seg: 97.6859, loss: 0.0608/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:25:48,107 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 2:27:50, time: 0.395, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0565, decode.acc_seg: 97.8661, loss: 0.0565/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:26:08,062 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 2:27:27, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0736, decode.acc_seg: 97.3485, loss: 0.0736/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:26:27,882 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 2:27:04, time: 0.396, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0661, decode.acc_seg: 97.5209, loss: 0.0661/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:26:49,246 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 2:26:42, time: 0.427, data_time: 0.038, memory: 11956, decode.loss_seg: 0.0657, decode.acc_seg: 97.6223, loss: 0.0657/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:27:09,176 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 2:26:19, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0662, decode.acc_seg: 97.6914, loss: 0.0662/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:27:29,012 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 2:25:55, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0640, decode.acc_seg: 97.6728, loss: 0.0640/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:27:48,903 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 2:25:32, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0688, decode.acc_seg: 97.5916, loss: 0.0688/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:28:08,764 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 2:25:09, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0555, decode.acc_seg: 97.9442, loss: 0.0555/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:28:28,720 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 2:24:46, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0655, decode.acc_seg: 97.6757, loss: 0.0655/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:28:48,628 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 2:24:23, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0655, decode.acc_seg: 97.5982, loss: 0.0655/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:29:08,758 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 2:24:00, time: 0.403, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0550, decode.acc_seg: 97.9928, loss: 0.0550/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:29:29,051 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 2:23:37, time: 0.406, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0646, decode.acc_seg: 97.6004, loss: 0.0646[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:   997s[                                 ] 2/929, 1.7 task/s, elapsed: 1s, ETA:   544s[                                 ] 3/929, 2.4 task/s, elapsed: 1s, ETA:   390s[                                 ] 4/929, 2.9 task/s, elapsed: 1s, ETA:   314s[                                 ] 5/929, 3.4 task/s, elapsed: 1s, ETA:   268s[                                 ] 6/929, 3.9 task/s, elapsed: 2s, ETA:   238s[                                 ] 7/929, 4.3 task/s, elapsed: 2s, ETA:   216s[                                 ] 8/929, 4.6 task/s, elapsed: 2s, ETA:   200s[                                 ] 9/929, 4.9 task/s, elapsed: 2s, ETA:   187s[                                ] 10/929, 5.2 task/s, elapsed: 2s, ETA:   178s[                                ] 11/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 12/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 13/929, 5.8 task/s, elapsed: 2s, ETA:   157s[                                ] 14/929, 6.0 task/s, elapsed: 2s, ETA:   152s[                                ] 15/929, 6.2 task/s, elapsed: 2s, ETA:   147s[                                ] 16/929, 6.4 task/s, elapsed: 3s, ETA:   143s[                                ] 17/929, 6.5 task/s, elapsed: 3s, ETA:   140s[                                ] 18/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 19/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 20/929, 6.9 task/s, elapsed: 3s, ETA:   131s[                                ] 21/929, 7.1 task/s, elapsed: 3s, ETA:   129s[                                ] 22/929, 7.2 task/s, elapsed: 3s, ETA:   127s[                                ] 23/929, 7.3 task/s, elapsed: 3s, ETA:   125s[                                ] 24/929, 7.3 task/s, elapsed: 3s, ETA:   123s[                                ] 25/929, 7.4 task/s, elapsed: 3s, ETA:   122s[                                ] 26/929, 7.5 task/s, elapsed: 3s, ETA:   120s[                                ] 27/929, 7.6 task/s, elapsed: 4s, ETA:   119s[                                ] 28/929, 7.6 task/s, elapsed: 4s, ETA:   118s[                                ] 29/929, 7.7 task/s, elapsed: 4s, ETA:   117s[>                               ] 30/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 31/929, 7.9 task/s, elapsed: 4s, ETA:   114s[>                               ] 32/929, 7.9 task/s, elapsed: 4s, ETA:   113s[>                               ] 33/929, 8.0 task/s, elapsed: 4s, ETA:   112s[>                               ] 34/929, 8.1 task/s, elapsed: 4s, ETA:   111s[>                               ] 35/929, 8.1 task/s, elapsed: 4s, ETA:   110s[>                               ] 36/929, 8.2 task/s, elapsed: 4s, ETA:   110s[>                               ] 37/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 38/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 39/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 40/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 41/929, 8.4 task/s, elapsed: 5s, ETA:   106s[>                               ] 42/929, 8.4 task/s, elapsed: 5s, ETA:   106s[>                               ] 43/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 44/929, 8.5 task/s, elapsed: 5s, ETA:   104s[>                               ] 45/929, 8.5 task/s, elapsed: 5s, ETA:   104s[>                               ] 46/929, 8.6 task/s, elapsed: 5s, ETA:   103s[>                               ] 47/929, 8.6 task/s, elapsed: 5s, ETA:   103s[>                               ] 48/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 49/929, 8.7 task/s, elapsed: 6s, ETA:   102s[>                               ] 50/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 51/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 52/929, 8.8 task/s, elapsed: 6s, ETA:   100s[>                               ] 53/929, 8.8 task/s, elapsed: 6s, ETA:   100s[>                               ] 54/929, 8.8 task/s, elapsed: 6s, ETA:    99s[>                               ] 55/929, 8.8 task/s, elapsed: 6s, ETA:    99s[>                               ] 56/929, 8.9 task/s, elapsed: 6s, ETA:    99s[>                               ] 57/929, 8.9 task/s, elapsed: 6s, ETA:    98s[>                               ] 58/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 59/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 60/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 61/929, 9.0 task/s, elapsed: 7s, ETA:    97s[>>                              ] 62/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 63/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 64/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 65/929, 9.1 task/s, elapsed: 7s, ETA:    95s[>>                              ] 66/929, 9.1 task/s, elapsed: 7s, ETA:    95s[>>                              ] 67/929, 9.1 task/s, elapsed: 7s, ETA:    95s[>>                              ] 68/929, 9.1 task/s, elapsed: 7s, ETA:    94s[>>                              ] 69/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 70/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 71/929, 9.2 task/s, elapsed: 8s, ETA:    94s[>>                              ] 72/929, 9.2 task/s, elapsed: 8s, ETA:    94s[>>                              ] 73/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 74/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 75/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 76/929, 9.2 task/s, elapsed: 8s, ETA:    92s[>>                              ] 77/929, 9.2 task/s, elapsed: 8s, ETA:    92s[>>                              ] 78/929, 9.2 task/s, elapsed: 8s, ETA:    92s[>>                              ] 79/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 80/929, 9.3 task/s, elapsed: 9s, ETA:    92s[>>                              ] 81/929, 9.3 task/s, elapsed: 9s, ETA:    92s[>>                              ] 82/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 83/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 84/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 85/929, 9.3 task/s, elapsed: 9s, ETA:    91s[>>                              ] 86/929, 9.3 task/s, elapsed: 9s, ETA:    90s[>>                              ] 87/929, 9.3 task/s, elapsed: 9s, ETA:    90s[>>>                             ] 88/929, 9.3 task/s, elapsed: 9s, ETA:    90s[>>                             ] 89/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 90/929, 9.4 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 91/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 92/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 93/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 94/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 95/929, 9.4 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 96/929, 9.4 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 97/929, 9.5 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 98/929, 9.5 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 99/929, 9.5 task/s, elapsed: 10s, ETA:    88s[>>>                           ] 100/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 101/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 102/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 103/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 104/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 105/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 106/929, 9.5 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 107/929, 9.5 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 108/929, 9.5 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 109/929, 9.5 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 110/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 111/929, 9.6 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 112/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 113/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 114/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 115/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 116/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 117/929, 9.5 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 118/929, 9.5 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 119/929, 9.6 task/s, elapsed: 12s, ETA:    85s[>>>                           ] 120/929, 9.6 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 121/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>                           ] 122/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>                           ] 123/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 124/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 125/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 126/929, 9.6 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 127/929, 9.6 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 128/929, 9.6 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 129/929, 9.6 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 130/929, 9.6 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 131/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 132/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 133/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 134/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 135/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 136/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 137/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 138/929, 9.7 task/s, elapsed: 14s, ETA:    82s[>>>>                          ] 139/929, 9.7 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 140/929, 9.7 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 141/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 142/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 143/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 144/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 145/929, 9.7 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 146/929, 9.7 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 147/929, 9.7 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 148/929, 9.7 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 149/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 150/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 151/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 152/929, 9.8 task/s, elapsed: 16s, ETA:    80s[>>>>                          ] 153/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>                          ] 154/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 155/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 156/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 157/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 158/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 159/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 160/929, 9.8 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 161/929, 9.8 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 162/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 163/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 164/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 165/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 166/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 167/929, 9.8 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 168/929, 9.8 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 169/929, 9.8 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 170/929, 9.8 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 171/929, 9.8 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 172/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 173/929, 9.9 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 174/929, 9.9 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 175/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 176/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 177/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 178/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 179/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 180/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 181/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 182/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 183/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>                         ] 184/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>                         ] 185/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 186/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 187/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 188/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 189/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 190/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 191/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 192/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 193/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 194/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 195/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 196/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 197/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 198/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 199/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 200/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 201/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 202/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 203/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 204/929, 10.0 task/s, elapsed: 20s, ETA:    73s[>>>>>>                       ] 205/929, 10.0 task/s, elapsed: 21s, ETA:    73s[>>>>>>                       ] 206/929, 10.0 task/s, elapsed: 21s, ETA:    73s[>>>>>>                       ] 207/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 208/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 209/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 210/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 211/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 212/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 213/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 214/929, 10.0 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 215/929, 10.0 task/s, elapsed: 22s, ETA:    72s[>>>>>>                       ] 216/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 217/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 218/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 219/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 220/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 221/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 222/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 223/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 224/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                      ] 225/929, 10.0 task/s, elapsed: 22s, ETA:    70s[>>>>>>>                      ] 226/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 227/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 228/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 229/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 230/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 231/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 232/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 233/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 234/929, 10.0 task/s, elapsed: 23s, ETA:    69s[>>>>>>>                      ] 235/929, 10.0 task/s, elapsed: 23s, ETA:    69s[>>>>>>>                      ] 236/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 237/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 238/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 239/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 240/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 241/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 242/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 243/929, 10.0 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 244/929, 10.0 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 245/929, 10.0 task/s, elapsed: 24s, ETA:    68s[>>>>>>>                      ] 246/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 247/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 248/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 249/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 250/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 251/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 252/929, 10.0 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 253/929, 10.0 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 254/929, 10.0 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 255/929, 10.0 task/s, elapsed: 25s, ETA:    67s[>>>>>>>                      ] 256/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 257/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 258/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 259/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 260/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 261/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 262/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 263/929, 10.0 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 264/929, 10.0 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 265/929, 10.0 task/s, elapsed: 26s, ETA:    66s[>>>>>>>>                     ] 266/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 267/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 268/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 269/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 270/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 271/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 272/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 273/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 274/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 275/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 276/929, 10.0 task/s, elapsed: 27s, ETA:    65s[>>>>>>>>                     ] 277/929, 10.1 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 278/929, 10.1 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 279/929, 10.1 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 280/929, 10.1 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 281/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 282/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 283/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 284/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 285/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 286/929, 10.1 task/s, elapsed: 28s, ETA:    64s[>>>>>>>>                     ] 287/929, 10.1 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 288/929, 10.1 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 289/929, 10.1 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 290/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 291/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 292/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 293/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 294/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 295/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 296/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 297/929, 10.1 task/s, elapsed: 29s, ETA:    63s[>>>>>>>>>                    ] 298/929, 10.1 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 299/929, 10.1 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 300/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 301/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 302/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 303/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 304/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 305/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 306/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 307/929, 10.1 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 308/929, 10.1 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 309/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 310/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 311/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 312/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 313/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 314/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 315/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 316/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 317/929, 10.1 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 318/929, 10.1 task/s, elapsed: 31s, ETA:    60s[>>>>>>>>>                    ] 319/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>                    ] 320/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 321/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 322/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 323/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 324/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 325/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 326/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 327/929, 10.1 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 328/929, 10.1 task/s, elapsed: 32s, ETA:    59s[>>>>>>>>>>                   ] 329/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 330/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 331/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 332/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 333/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 334/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 335/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 336/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 337/929, 10.1 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                   ] 338/929, 10.1 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                   ] 339/929, 10.1 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                   ] 340/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 341/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 342/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 343/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 344/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 345/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 346/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 347/929, 10.1 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 348/929, 10.1 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 349/929, 10.1 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>                   ] 350/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 351/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 352/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 353/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 354/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 355/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 356/929, 10.1 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 357/929, 10.1 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 358/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 359/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 360/929, 10.2 task/s, elapsed: 35s, ETA:    56s[>>>>>>>>>>>                  ] 361/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 362/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 363/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 364/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 365/929, 10.2 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 366/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 367/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 368/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 369/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 370/929, 10.2 task/s, elapsed: 36s, ETA:    55s[>>>>>>>>>>>                  ] 371/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 372/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 373/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 374/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 375/929, 10.2 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 376/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 377/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 378/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 379/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 380/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 381/929, 10.2 task/s, elapsed: 37s, ETA:    54s[>>>>>>>>>>>                  ] 382/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 383/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 384/929, 10.2 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 385/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 386/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 387/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 388/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 389/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 390/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 391/929, 10.2 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 392/929, 10.2 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 393/929, 10.2 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 394/929, 10.2 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 396/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 397/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 398/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 399/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 400/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 401/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 402/929, 10.2 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 403/929, 10.2 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 404/929, 10.2 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 406/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 407/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 408/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 409/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 410/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 411/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 412/929, 10.2 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 413/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 414/929, 10.2 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>                 ] 416/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 417/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 418/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 419/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 420/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 421/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 422/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 423/929, 10.2 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.2 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 426/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 427/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 428/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 429/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 430/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 431/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 432/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 433/929, 10.2 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.2 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 436/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 437/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 438/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 439/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 440/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 441/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 442/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 443/929, 10.2 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.2 task/s, elapsed: 43s, ETA:    47s[>>>>>>>>>>>>>                ] 445/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 446/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 447/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 448/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 449/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 450/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 451/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 452/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 453/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.2 task/s, elapsed: 44s, ETA:    46s[>>>>>>>>>>>>>>               ] 455/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 456/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 457/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 458/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 459/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 460/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 461/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 462/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 466/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 467/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 468/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 469/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 470/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 471/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 472/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 476/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 477/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 478/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 479/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 480/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 481/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 482/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.2 task/s, elapsed: 47s, ETA:    43s[>>>>>>>>>>>>>>>              ] 486/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 487/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 488/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 489/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 490/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 491/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 492/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.2 task/s, elapsed: 48s, ETA:    42s[>>>>>>>>>>>>>>>              ] 496/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 497/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 498/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 499/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 500/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 501/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.2 task/s, elapsed: 49s, ETA:    41s[>>>>>>>>>>>>>>>              ] 506/929, 10.2 task/s, elapsed: 49s, ETA:    41s[>>>>>>>>>>>>>>>              ] 507/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 508/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 509/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 510/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 511/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.2 task/s, elapsed: 50s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 516/929, 10.2 task/s, elapsed: 50s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 517/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 518/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 519/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 520/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 521/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.2 task/s, elapsed: 51s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 526/929, 10.2 task/s, elapsed: 51s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 527/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 528/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 529/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 530/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 531/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.2 task/s, elapsed: 52s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 537/929, 10.2 task/s, elapsed: 52s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 538/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 539/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 540/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 541/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.2 task/s, elapsed: 53s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.2 task/s, elapsed: 53s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.2 task/s, elapsed: 55s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.2 task/s, elapsed: 55s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.2 task/s, elapsed: 55s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.2 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.2 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.2 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.2 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.2 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.2 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.2 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.2 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.2 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.2 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.2 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.3 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.3 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.3 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.3 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.3 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.3 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.3 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.3 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.3 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.3 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.3 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.3 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.3 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.3 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.3 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.3 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.2 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.2 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.2 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.2 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.2 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.2 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.2 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.3 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.3 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.3 task/s, elapsed: 90s, ETA:     0s2022-10-03 16:32:13,209 - mmseg - INFO - per class results:2022-10-03 16:32:13,209 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.79 | 95.72 || rigid_plastic |  24.9 | 29.13 ||   cardboard   | 57.16 | 72.77 ||     metal     | 34.58 | 43.03 ||  soft_plastic | 62.83 | 73.72 |+---------------+-------+-------+2022-10-03 16:32:13,209 - mmseg - INFO - Summary:2022-10-03 16:32:13,210 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.29 | 54.05 | 62.87 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:32:13,213 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:32:13,214 - mmseg - INFO - Iter [929/40000]	lr: 3.000e-05, eta: 2:23:14, time: 0.397, data_time: 0.008, memory: 11956, aAcc: 0.9129, mIoU: 0.5405, mAcc: 0.6287, IoU.background: 0.9079, IoU.rigid_plastic: 0.2490, IoU.cardboard: 0.5716, IoU.metal: 0.3458, IoU.soft_plastic: 0.6283, Acc.background: 0.9572, Acc.rigid_plastic: 0.2913, Acc.cardboard: 0.7277, Acc.metal: 0.4303, Acc.soft_plastic: 0.7372, decode.loss_seg: 0.0697, decode.acc_seg: 97.4848, loss: 0.0697/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:32:34,014 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 2:25:16, time: 3.303, data_time: 2.895, memory: 11956, decode.loss_seg: 0.0656, decode.acc_seg: 97.9361, loss: 0.0656/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:32:54,890 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 2:24:53, time: 0.418, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0622, decode.acc_seg: 97.6340, loss: 0.0622/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:33:15,207 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 2:24:29, time: 0.406, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0547, decode.acc_seg: 97.9458, loss: 0.0547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:33:35,075 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 2:24:06, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0640, decode.acc_seg: 97.6662, loss: 0.0640/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:33:54,901 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 2:23:42, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0590, decode.acc_seg: 97.9432, loss: 0.0590/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:34:14,852 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 2:23:18, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0612, decode.acc_seg: 97.7829, loss: 0.0612/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:34:34,688 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 2:22:54, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0731, decode.acc_seg: 97.3336, loss: 0.0731/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:34:54,510 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 2:22:31, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0647, decode.acc_seg: 97.6493, loss: 0.0647/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:35:14,339 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 2:22:07, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0561, decode.acc_seg: 97.9271, loss: 0.0561/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:35:34,404 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 2:21:44, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0631, decode.acc_seg: 97.7701, loss: 0.0631/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:35:54,195 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 2:21:20, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0723, decode.acc_seg: 97.4598, loss: 0.0723/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:36:13,932 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 2:20:56, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0751, decode.acc_seg: 97.1796, loss: 0.0751/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:36:33,712 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 2:20:32, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0651, decode.acc_seg: 97.5315, loss: 0.0651/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:36:53,374 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 2:20:09, time: 0.393, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0726, decode.acc_seg: 97.1712, loss: 0.0726/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:37:13,145 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 2:19:45, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0550, decode.acc_seg: 98.0319, loss: 0.0550/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:37:33,072 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 2:19:21, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0657, decode.acc_seg: 97.7403, loss: 0.0657/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:37:52,978 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 2:18:58, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0782, decode.acc_seg: 97.1379, loss: 0.0782/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:38:12,768 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 2:18:34, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0762, decode.acc_seg: 97.3076, loss: 0.0762/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:38:32,604 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 2:18:11, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0546, decode.acc_seg: 97.9492, loss: 0.0546/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:38:52,534 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:38:52,535 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 2:17:47, time: 0.399, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0684, decode.acc_seg: 97.6273, loss: 0.0684/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:39:14,330 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 2:17:26, time: 0.436, data_time: 0.044, memory: 11956, decode.loss_seg: 0.0629, decode.acc_seg: 97.7085, loss: 0.0629/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:39:34,378 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 2:17:02, time: 0.401, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0606, decode.acc_seg: 97.8780, loss: 0.0606/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:39:54,274 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 2:16:39, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0673, decode.acc_seg: 97.6521, loss: 0.0673/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:40:14,236 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 2:16:16, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0751, decode.acc_seg: 97.2476, loss: 0.0751/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:40:34,062 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 2:15:52, time: 0.397, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0627, decode.acc_seg: 97.7161, loss: 0.0627/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:40:53,996 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 2:15:29, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0540, decode.acc_seg: 98.0246, loss: 0.0540/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:41:13,783 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 2:15:05, time: 0.396, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0665, decode.acc_seg: 97.6310, loss: 0.0665/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:41:33,932 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 2:14:42, time: 0.403, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0636, decode.acc_seg: 97.5764, loss: 0.0636/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:41:53,776 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 2:14:19, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0632, decode.acc_seg: 97.7002, loss: 0.0632/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:42:13,571 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 2:13:56, time: 0.396, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0652, decode.acc_seg: 97.5078, loss: 0.0652/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:42:33,638 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 2:13:32, time: 0.401, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0672, decode.acc_seg: 97.7171, loss: 0.0672/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:42:53,410 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 2:13:09, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0682, decode.acc_seg: 97.5350, loss: 0.0682/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:43:13,515 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 2:12:46, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0651, decode.acc_seg: 97.5737, loss: 0.0651/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:43:33,532 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 2:12:23, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0636, decode.acc_seg: 97.8302, loss: 0.0636/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:43:53,435 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 2:12:00, time: 0.398, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0669, decode.acc_seg: 97.6523, loss: 0.0669/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:44:13,348 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 2:11:36, time: 0.398, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0537, decode.acc_seg: 97.9931, loss: 0.0537/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:44:33,350 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 2:11:13, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0538, decode.acc_seg: 98.0367, loss: 0.0538/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:44:53,080 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 2:10:50, time: 0.395, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0603, decode.acc_seg: 97.7835, loss: 0.0603/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:45:13,071 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 2:10:27, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0578, decode.acc_seg: 97.8898, loss: 0.0578/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:45:33,035 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:45:33,035 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 2:10:04, time: 0.399, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0731, decode.acc_seg: 97.3256, loss: 0.0731/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:45:53,024 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 2:09:41, time: 0.400, data_time: 0.009, memory: 11956, decode.loss_seg: 0.0581, decode.acc_seg: 98.0050, loss: 0.0581/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:46:12,887 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 2:09:18, time: 0.397, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0591, decode.acc_seg: 97.8165, loss: 0.0591/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:46:32,983 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 2:08:55, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0651, decode.acc_seg: 97.5740, loss: 0.0651/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:46:52,967 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 2:08:32, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0592, decode.acc_seg: 97.7612, loss: 0.0592/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:47:13,079 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 2:08:09, time: 0.402, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0585, decode.acc_seg: 97.8517, loss: 0.0585/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:47:33,392 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 2:07:46, time: 0.406, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0556, decode.acc_seg: 98.0582, loss: 0.0556/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:47:54,139 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 2:07:24, time: 0.415, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0596, decode.acc_seg: 97.7513, loss: 0.0596/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:48:14,611 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 2:07:01, time: 0.409, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0646, decode.acc_seg: 97.5610, loss: 0.0646/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:48:34,514 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 2:06:38, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0670, decode.acc_seg: 97.6602, loss: 0.0670/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:48:54,265 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 2:06:15, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0615, decode.acc_seg: 97.6588, loss: 0.0615/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:49:15,792 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 2:05:53, time: 0.431, data_time: 0.041, memory: 11956, decode.loss_seg: 0.0687, decode.acc_seg: 97.4924, loss: 0.0687/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:49:35,425 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 2:05:30, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0678, decode.acc_seg: 97.5475, loss: 0.0678/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:49:55,450 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 2:05:07, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0458, decode.acc_seg: 98.2895, loss: 0.0458/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:50:15,242 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 2:04:44, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0564, decode.acc_seg: 97.8885, loss: 0.0564/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:50:35,025 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 2:04:21, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0546, decode.acc_seg: 97.9065, loss: 0.0546/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:50:54,760 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 2:03:58, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0457, decode.acc_seg: 98.2616, loss: 0.0457/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:51:14,469 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 2:03:35, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0476, decode.acc_seg: 98.2421, loss: 0.0476/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:51:34,299 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 2:03:12, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0689, decode.acc_seg: 97.5767, loss: 0.0689/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:51:54,225 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 2:02:49, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0564, decode.acc_seg: 97.8450, loss: 0.0564/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:52:13,902 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 16:52:13,902 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 2:02:26, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0811, decode.acc_seg: 97.4419, loss: 0.0811/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:52:33,799 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 2:02:03, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0564, decode.acc_seg: 98.0284, loss: 0.0564/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:52:53,643 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 2:01:40, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0655, decode.acc_seg: 97.5274, loss: 0.0655/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:53:13,337 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 2:01:17, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0735, decode.acc_seg: 97.3744, loss: 0.0735/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:53:33,258 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 2:00:55, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0595, decode.acc_seg: 97.8380, loss: 0.0595/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:53:53,167 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 2:00:32, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0486, decode.acc_seg: 98.2014, loss: 0.0486/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:54:12,842 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 2:00:09, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0545, decode.acc_seg: 97.9614, loss: 0.0545/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:54:32,576 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 1:59:46, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0546, decode.acc_seg: 97.9861, loss: 0.0546/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:54:52,366 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 1:59:23, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0721, decode.acc_seg: 97.5157, loss: 0.0721/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:55:12,150 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 1:59:00, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0521, decode.acc_seg: 98.1085, loss: 0.0521/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:55:31,803 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 1:58:37, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0572, decode.acc_seg: 97.8896, loss: 0.0572/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:55:51,520 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 1:58:14, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0502, decode.acc_seg: 98.0554, loss: 0.0502/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:56:11,262 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 1:57:52, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0609, decode.acc_seg: 97.8431, loss: 0.0609/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:56:31,149 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 1:57:29, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0628, decode.acc_seg: 97.7217, loss: 0.0628/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:56:50,812 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 1:57:06, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0591, decode.acc_seg: 97.8165, loss: 0.0591/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:57:10,676 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 1:56:43, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0626, decode.acc_seg: 97.6339, loss: 0.0626/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:57:30,535 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 1:56:21, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0605, decode.acc_seg: 97.8794, loss: 0.0605/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:57:50,347 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 1:55:58, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0557, decode.acc_seg: 97.9062, loss: 0.0557/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:58:10,275 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 1:55:35, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0519, decode.acc_seg: 98.0186, loss: 0.0519/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 16:58:30,132 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 1:55:13, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0495, decode.acc_seg: 98.2318, loss: 0.0495[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1013s[                                 ] 2/929, 1.7 task/s, elapsed: 1s, ETA:   551s[                                 ] 3/929, 2.3 task/s, elapsed: 1s, ETA:   395s[                                 ] 4/929, 2.9 task/s, elapsed: 1s, ETA:   318s[                                 ] 5/929, 3.4 task/s, elapsed: 1s, ETA:   273s[                                 ] 6/929, 3.8 task/s, elapsed: 2s, ETA:   245s[                                 ] 7/929, 4.1 task/s, elapsed: 2s, ETA:   222s[                                 ] 8/929, 4.5 task/s, elapsed: 2s, ETA:   206s[                                 ] 9/929, 4.7 task/s, elapsed: 2s, ETA:   195s[                                ] 10/929, 4.9 task/s, elapsed: 2s, ETA:   187s[                                ] 11/929, 5.2 task/s, elapsed: 2s, ETA:   177s[                                ] 12/929, 5.4 task/s, elapsed: 2s, ETA:   169s[                                ] 13/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 14/929, 5.8 task/s, elapsed: 2s, ETA:   157s[                                ] 15/929, 6.0 task/s, elapsed: 2s, ETA:   152s[                                ] 16/929, 6.2 task/s, elapsed: 3s, ETA:   148s[                                ] 17/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 18/929, 6.5 task/s, elapsed: 3s, ETA:   141s[                                ] 19/929, 6.6 task/s, elapsed: 3s, ETA:   138s[                                ] 20/929, 6.7 task/s, elapsed: 3s, ETA:   135s[                                ] 21/929, 6.8 task/s, elapsed: 3s, ETA:   133s[                                ] 22/929, 6.9 task/s, elapsed: 3s, ETA:   131s[                                ] 23/929, 7.0 task/s, elapsed: 3s, ETA:   129s[                                ] 24/929, 7.1 task/s, elapsed: 3s, ETA:   127s[                                ] 25/929, 7.2 task/s, elapsed: 3s, ETA:   125s[                                ] 26/929, 7.3 task/s, elapsed: 4s, ETA:   124s[                                ] 27/929, 7.4 task/s, elapsed: 4s, ETA:   122s[                                ] 28/929, 7.5 task/s, elapsed: 4s, ETA:   121s[                                ] 29/929, 7.5 task/s, elapsed: 4s, ETA:   119s[>                               ] 30/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 31/929, 7.7 task/s, elapsed: 4s, ETA:   117s[>                               ] 32/929, 7.8 task/s, elapsed: 4s, ETA:   116s[>                               ] 33/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 34/929, 7.9 task/s, elapsed: 4s, ETA:   114s[>                               ] 35/929, 7.9 task/s, elapsed: 4s, ETA:   113s[>                               ] 36/929, 8.0 task/s, elapsed: 5s, ETA:   112s[>                               ] 37/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 38/929, 8.1 task/s, elapsed: 5s, ETA:   111s[>                               ] 39/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 40/929, 8.1 task/s, elapsed: 5s, ETA:   109s[>                               ] 41/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 42/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 43/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 44/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 45/929, 8.3 task/s, elapsed: 5s, ETA:   106s[>                               ] 46/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 47/929, 8.4 task/s, elapsed: 6s, ETA:   105s[>                               ] 48/929, 8.5 task/s, elapsed: 6s, ETA:   104s[>                               ] 49/929, 8.5 task/s, elapsed: 6s, ETA:   104s[>                               ] 50/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 51/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 52/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 53/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 54/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 55/929, 8.6 task/s, elapsed: 6s, ETA:   101s[>                               ] 56/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 57/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>                               ] 58/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>>                              ] 59/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>>                              ] 60/929, 8.8 task/s, elapsed: 7s, ETA:    99s[>>                              ] 61/929, 8.8 task/s, elapsed: 7s, ETA:    99s[>>                              ] 62/929, 8.8 task/s, elapsed: 7s, ETA:    99s[>>                              ] 63/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 64/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 65/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 66/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 67/929, 8.9 task/s, elapsed: 8s, ETA:    97s[>>                              ] 68/929, 8.9 task/s, elapsed: 8s, ETA:    97s[>>                              ] 69/929, 8.9 task/s, elapsed: 8s, ETA:    97s[>>                              ] 70/929, 8.9 task/s, elapsed: 8s, ETA:    96s[>>                              ] 71/929, 8.9 task/s, elapsed: 8s, ETA:    96s[>>                              ] 72/929, 9.0 task/s, elapsed: 8s, ETA:    96s[>>                              ] 73/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 74/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 75/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 76/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 77/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                              ] 78/929, 9.1 task/s, elapsed: 9s, ETA:    94s[>>                              ] 79/929, 9.1 task/s, elapsed: 9s, ETA:    94s[>>                              ] 80/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 81/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 82/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 83/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 84/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 85/929, 9.1 task/s, elapsed: 9s, ETA:    92s[>>                              ] 86/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 87/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                             ] 88/929, 9.2 task/s, elapsed: 10s, ETA:    92s[>>                             ] 89/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 90/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 91/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 92/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 93/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 94/929, 9.2 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 95/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 96/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 97/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 98/929, 9.3 task/s, elapsed: 11s, ETA:    90s[>>>                            ] 99/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 100/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 101/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 102/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 103/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 104/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 105/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 106/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 107/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 108/929, 9.4 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 109/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 110/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 111/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 112/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 113/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 114/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 115/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 116/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 117/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 118/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 119/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 120/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 121/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 122/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 123/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 124/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 125/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 126/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 127/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 128/929, 9.5 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 129/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 130/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 131/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 132/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 133/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 134/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 135/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 136/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 137/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 138/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 139/929, 9.6 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 140/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 141/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 142/929, 9.5 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 143/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 144/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 145/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 146/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 147/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 148/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 149/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 150/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 151/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 152/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 153/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 154/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>>                         ] 155/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 156/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 157/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 158/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 159/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 160/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 161/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 162/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 163/929, 9.6 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 164/929, 9.6 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 165/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 166/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 167/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 168/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 169/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 170/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 171/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 172/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 173/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 174/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 175/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 176/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 177/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 178/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 179/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 180/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 181/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 182/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 183/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 184/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>                         ] 185/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 186/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 187/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 188/929, 9.8 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 189/929, 9.8 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 190/929, 9.8 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 191/929, 9.8 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 192/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 193/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 194/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 195/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 196/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 197/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 198/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 199/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 200/929, 9.8 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 201/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 202/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 203/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 204/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 205/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 206/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 207/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 208/929, 9.8 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 209/929, 9.8 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 210/929, 9.8 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 211/929, 9.8 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 212/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 213/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 214/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 215/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 216/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 217/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 218/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 219/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 220/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 221/929, 9.9 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 222/929, 9.9 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 223/929, 9.9 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 224/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 225/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 226/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 227/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 228/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 229/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 230/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 231/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 232/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 233/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 234/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 235/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 236/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 237/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 238/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 239/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 240/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 241/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 242/929, 9.9 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                       ] 243/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 244/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 245/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 246/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 247/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 248/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 249/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 250/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 251/929, 9.9 task/s, elapsed: 25s, ETA:    68s[>>>>>>>>                      ] 252/929, 9.9 task/s, elapsed: 25s, ETA:    68s[>>>>>>>>                      ] 253/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 254/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 255/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 256/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 257/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 258/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 259/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 260/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 261/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 262/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 263/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 264/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 265/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 266/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 267/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 268/929, 9.9 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                      ] 269/929, 9.9 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                      ] 270/929, 9.9 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 271/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 272/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 273/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 274/929, 10.0 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                     ] 275/929, 10.0 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                     ] 276/929, 10.0 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                     ] 277/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 278/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 279/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 280/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 281/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 282/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 283/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 284/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 285/929, 10.0 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>                     ] 286/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 287/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 288/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 289/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 290/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 291/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 292/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 293/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 294/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 295/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 296/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 297/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 298/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 299/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 300/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 301/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 302/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 303/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 304/929, 10.0 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 305/929, 10.0 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 306/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 307/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 308/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 309/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 310/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 311/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 312/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 313/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 314/929, 10.0 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 315/929, 10.0 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 316/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 317/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 318/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 319/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 320/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 321/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 322/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 323/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 324/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 325/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 326/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 327/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 328/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 329/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 330/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 331/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 332/929, 10.0 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 333/929, 10.0 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 334/929, 10.0 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 335/929, 10.0 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 336/929, 10.0 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 337/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 338/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 339/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 340/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 341/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 342/929, 10.0 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 343/929, 10.0 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 344/929, 10.0 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 345/929, 10.0 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 346/929, 10.0 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 347/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 348/929, 10.1 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 349/929, 10.1 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 350/929, 10.1 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 351/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 352/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 353/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 354/929, 10.0 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 355/929, 10.0 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 356/929, 10.0 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 357/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 358/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 359/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 360/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 361/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 362/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 363/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 364/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 365/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 366/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 367/929, 10.1 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 368/929, 10.1 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 369/929, 10.1 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 370/929, 10.1 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 371/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 372/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 373/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 374/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 375/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 376/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 377/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 378/929, 10.1 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 379/929, 10.1 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 380/929, 10.1 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 381/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 382/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 383/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 384/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 385/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 387/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 388/929, 10.1 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 389/929, 10.1 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 390/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 391/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 392/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 393/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 394/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 397/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 398/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 399/929, 10.1 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 400/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 401/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 402/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 403/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 404/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 407/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 408/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 409/929, 10.1 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 410/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 411/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 412/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 413/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 414/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>>                ] 417/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>>                ] 418/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>>                ] 419/929, 10.1 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 420/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 421/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 422/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 423/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 427/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 428/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 429/929, 10.1 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 430/929, 10.1 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 431/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 432/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 433/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 437/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 438/929, 10.1 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 439/929, 10.1 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 440/929, 10.1 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 441/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 442/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 443/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 445/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 447/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 448/929, 10.1 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 449/929, 10.1 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 450/929, 10.1 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 451/929, 10.1 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 452/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 453/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 455/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 457/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 458/929, 10.1 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 459/929, 10.1 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 460/929, 10.1 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 461/929, 10.1 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 462/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 466/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 467/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 468/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 469/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 470/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 471/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 472/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 477/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 478/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 479/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 480/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 481/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 482/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 487/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 488/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 489/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 490/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 491/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 492/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 496/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 497/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 498/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 499/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 500/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 501/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.2 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 506/929, 10.2 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 507/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 508/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 509/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 510/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 511/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.2 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 516/929, 10.2 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 517/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 518/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 519/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 520/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 521/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.2 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 526/929, 10.2 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 527/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 528/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 529/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 530/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 531/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.2 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.2 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 537/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 538/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 539/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 540/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 541/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.2 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.2 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.2 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.2 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.2 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.2 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.2 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.2 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.2 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.2 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.2 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.2 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.2 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.2 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.2 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.2 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.2 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.2 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.2 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.2 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.2 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.2 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.2 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.2 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.2 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.2 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.2 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.2 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.3 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.3 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.3 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.3 task/s, elapsed: 90s, ETA:     0s2022-10-03 17:01:13,160 - mmseg - INFO - per class results:2022-10-03 17:01:13,161 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  |  90.9 | 96.05 || rigid_plastic | 28.52 | 31.79 ||   cardboard   | 56.81 | 71.51 ||     metal     | 29.42 | 40.24 ||  soft_plastic | 63.09 | 72.98 |+---------------+-------+-------+2022-10-03 17:01:13,161 - mmseg - INFO - Summary:2022-10-03 17:01:13,161 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.39 | 53.75 | 62.52 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:01:13,165 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:01:13,165 - mmseg - INFO - Iter [929/40000]	lr: 2.400e-05, eta: 1:54:50, time: 0.394, data_time: 0.007, memory: 11956, aAcc: 0.9139, mIoU: 0.5375, mAcc: 0.6252, IoU.background: 0.9090, IoU.rigid_plastic: 0.2852, IoU.cardboard: 0.5681, IoU.metal: 0.2942, IoU.soft_plastic: 0.6309, Acc.background: 0.9605, Acc.rigid_plastic: 0.3179, Acc.cardboard: 0.7151, Acc.metal: 0.4024, Acc.soft_plastic: 0.7298, decode.loss_seg: 0.0495, decode.acc_seg: 98.1447, loss: 0.0495/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:01:35,075 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 1:56:04, time: 3.305, data_time: 2.914, memory: 11956, decode.loss_seg: 0.0535, decode.acc_seg: 97.9965, loss: 0.0535/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:01:54,984 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 1:55:41, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0514, decode.acc_seg: 98.1108, loss: 0.0514/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:02:14,775 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 1:55:17, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0587, decode.acc_seg: 97.9504, loss: 0.0587/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:02:34,652 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 1:54:54, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0620, decode.acc_seg: 97.8418, loss: 0.0620/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:02:54,670 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 1:54:31, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0559, decode.acc_seg: 97.9470, loss: 0.0559/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:03:14,392 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 1:54:08, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0651, decode.acc_seg: 97.5357, loss: 0.0651/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:03:34,298 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 1:53:45, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0588, decode.acc_seg: 97.8693, loss: 0.0588/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:03:54,232 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 1:53:22, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0532, decode.acc_seg: 98.0499, loss: 0.0532/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:04:14,200 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 1:52:59, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0517, decode.acc_seg: 98.0495, loss: 0.0517/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:04:33,998 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 1:52:36, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0540, decode.acc_seg: 98.0887, loss: 0.0540/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:04:53,840 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 1:52:13, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0525, decode.acc_seg: 98.1168, loss: 0.0525/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:05:13,787 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 1:51:50, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0531, decode.acc_seg: 98.0906, loss: 0.0531/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:05:33,468 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 1:51:27, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0462, decode.acc_seg: 98.3794, loss: 0.0462/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:05:53,257 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 1:51:04, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0510, decode.acc_seg: 98.1934, loss: 0.0510/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:06:13,147 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 1:50:41, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0553, decode.acc_seg: 98.0881, loss: 0.0553/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:06:32,971 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 1:50:18, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0583, decode.acc_seg: 97.7750, loss: 0.0583/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:06:52,742 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 1:49:55, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0689, decode.acc_seg: 97.5198, loss: 0.0689/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:07:12,624 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 1:49:32, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0483, decode.acc_seg: 98.2122, loss: 0.0483/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:07:32,501 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 1:49:09, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0556, decode.acc_seg: 97.9631, loss: 0.0556/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:07:52,408 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:07:52,408 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 1:48:46, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0491, decode.acc_seg: 98.2502, loss: 0.0491/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:08:12,283 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 1:48:23, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0454, decode.acc_seg: 98.3367, loss: 0.0454/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:08:32,094 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 1:48:01, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0491, decode.acc_seg: 98.1544, loss: 0.0491/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:08:51,872 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 1:47:38, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0540, decode.acc_seg: 97.9778, loss: 0.0540/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:09:11,644 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 1:47:15, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0612, decode.acc_seg: 97.7313, loss: 0.0612/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:09:31,342 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 1:46:52, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0458, decode.acc_seg: 98.2708, loss: 0.0458/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:09:51,606 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 1:46:29, time: 0.405, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0547, decode.acc_seg: 98.0168, loss: 0.0547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:10:11,443 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 1:46:06, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0452, decode.acc_seg: 98.3258, loss: 0.0452/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:10:31,269 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 1:45:44, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0570, decode.acc_seg: 97.8521, loss: 0.0570/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:10:51,303 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 1:45:21, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0475, decode.acc_seg: 98.1826, loss: 0.0475/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:11:11,207 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 1:44:58, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0577, decode.acc_seg: 97.8421, loss: 0.0577/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:11:32,755 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 1:44:36, time: 0.431, data_time: 0.039, memory: 11956, decode.loss_seg: 0.0578, decode.acc_seg: 97.8265, loss: 0.0578/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:11:52,491 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 1:44:13, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0480, decode.acc_seg: 98.2225, loss: 0.0480/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:12:12,518 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 1:43:51, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0411, decode.acc_seg: 98.4394, loss: 0.0411/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:12:32,296 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 1:43:28, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0606, decode.acc_seg: 97.6938, loss: 0.0606/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:12:52,154 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 1:43:05, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0648, decode.acc_seg: 97.6424, loss: 0.0648/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:13:12,016 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 1:42:43, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0493, decode.acc_seg: 98.1775, loss: 0.0493/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:13:32,032 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 1:42:20, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0518, decode.acc_seg: 98.0577, loss: 0.0518/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:13:51,891 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 1:41:57, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0491, decode.acc_seg: 98.1387, loss: 0.0491/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:14:11,819 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 1:41:35, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0535, decode.acc_seg: 98.0035, loss: 0.0535/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:14:32,641 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:14:32,641 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 1:41:12, time: 0.416, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0436, decode.acc_seg: 98.3384, loss: 0.0436/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:14:53,298 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 1:40:50, time: 0.413, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0421, decode.acc_seg: 98.4227, loss: 0.0421/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:15:14,804 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 1:40:28, time: 0.430, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0430, decode.acc_seg: 98.3263, loss: 0.0430/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:15:35,571 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 1:40:06, time: 0.415, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0594, decode.acc_seg: 97.8278, loss: 0.0594/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:15:56,028 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 1:39:44, time: 0.409, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0590, decode.acc_seg: 97.8603, loss: 0.0590/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:16:16,828 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 1:39:22, time: 0.416, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0602, decode.acc_seg: 97.8597, loss: 0.0602/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:16:37,663 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 1:39:00, time: 0.417, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0529, decode.acc_seg: 98.1606, loss: 0.0529/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:16:58,522 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 1:38:38, time: 0.417, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0540, decode.acc_seg: 98.0469, loss: 0.0540/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:17:19,557 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 1:38:16, time: 0.421, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0547, decode.acc_seg: 97.9383, loss: 0.0547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:17:39,939 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 1:37:53, time: 0.408, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0513, decode.acc_seg: 98.1282, loss: 0.0513/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:17:59,837 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 1:37:31, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0412, decode.acc_seg: 98.5235, loss: 0.0412/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:18:20,692 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 1:37:09, time: 0.417, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0522, decode.acc_seg: 98.0416, loss: 0.0522/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:18:41,571 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 1:36:46, time: 0.418, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0436, decode.acc_seg: 98.3758, loss: 0.0436/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:19:01,923 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 1:36:24, time: 0.407, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0494, decode.acc_seg: 98.1804, loss: 0.0494/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:19:21,599 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 1:36:01, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0444, decode.acc_seg: 98.3656, loss: 0.0444/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:19:41,478 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 1:35:39, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0656, decode.acc_seg: 97.7783, loss: 0.0656/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:20:01,235 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 1:35:16, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0551, decode.acc_seg: 97.9933, loss: 0.0551/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:20:21,204 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 1:34:54, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0580, decode.acc_seg: 97.7544, loss: 0.0580/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:20:40,949 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 1:34:31, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0634, decode.acc_seg: 97.8222, loss: 0.0634/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:21:00,855 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 1:34:09, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0656, decode.acc_seg: 97.7202, loss: 0.0656/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:21:20,767 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:21:20,767 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 1:33:46, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0497, decode.acc_seg: 98.2327, loss: 0.0497/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:21:42,324 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 1:33:25, time: 0.431, data_time: 0.041, memory: 11956, decode.loss_seg: 0.0493, decode.acc_seg: 98.2552, loss: 0.0493/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:22:02,309 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 1:33:02, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0531, decode.acc_seg: 98.0585, loss: 0.0531/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:22:22,317 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 1:32:40, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0487, decode.acc_seg: 98.1797, loss: 0.0487/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:22:42,201 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 1:32:17, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0539, decode.acc_seg: 97.9084, loss: 0.0539/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:23:02,161 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 1:31:55, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0491, decode.acc_seg: 98.1986, loss: 0.0491/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:23:21,923 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 1:31:32, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0499, decode.acc_seg: 98.1244, loss: 0.0499/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:23:41,842 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 1:31:10, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0481, decode.acc_seg: 98.1953, loss: 0.0481/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:24:01,718 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 1:30:48, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0480, decode.acc_seg: 98.2485, loss: 0.0480/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:24:21,520 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 1:30:25, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0473, decode.acc_seg: 98.1983, loss: 0.0473/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:24:41,348 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 1:30:03, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0497, decode.acc_seg: 98.2210, loss: 0.0497/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:25:01,208 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 1:29:40, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0476, decode.acc_seg: 98.1675, loss: 0.0476/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:25:20,995 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 1:29:18, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0573, decode.acc_seg: 98.0736, loss: 0.0573/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:25:40,743 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 1:28:55, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0527, decode.acc_seg: 98.1518, loss: 0.0527/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:26:00,502 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 1:28:33, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0515, decode.acc_seg: 98.0404, loss: 0.0515/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:26:20,242 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 1:28:11, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0442, decode.acc_seg: 98.4005, loss: 0.0442/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:26:40,352 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 1:27:48, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0470, decode.acc_seg: 98.2188, loss: 0.0470/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:27:00,164 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 1:27:26, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0424, decode.acc_seg: 98.4564, loss: 0.0424/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:27:20,041 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 1:27:04, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0492, decode.acc_seg: 98.1665, loss: 0.0492/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:27:39,860 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 1:26:41, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0508, decode.acc_seg: 98.1595, loss: 0.0508[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1137s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   615s[                                 ] 3/929, 2.1 task/s, elapsed: 1s, ETA:   440s[                                 ] 4/929, 2.6 task/s, elapsed: 2s, ETA:   352s[                                 ] 5/929, 3.1 task/s, elapsed: 2s, ETA:   299s[                                 ] 6/929, 3.5 task/s, elapsed: 2s, ETA:   264s[                                 ] 7/929, 3.9 task/s, elapsed: 2s, ETA:   239s[                                 ] 8/929, 4.2 task/s, elapsed: 2s, ETA:   220s[                                 ] 9/929, 4.5 task/s, elapsed: 2s, ETA:   205s[                                ] 10/929, 4.8 task/s, elapsed: 2s, ETA:   193s[                                ] 11/929, 5.0 task/s, elapsed: 2s, ETA:   183s[                                ] 12/929, 5.2 task/s, elapsed: 2s, ETA:   175s[                                ] 13/929, 5.4 task/s, elapsed: 2s, ETA:   168s[                                ] 14/929, 5.6 task/s, elapsed: 2s, ETA:   162s[                                ] 15/929, 5.8 task/s, elapsed: 3s, ETA:   157s[                                ] 16/929, 6.0 task/s, elapsed: 3s, ETA:   153s[                                ] 17/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 18/929, 6.3 task/s, elapsed: 3s, ETA:   145s[                                ] 19/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 20/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 21/929, 6.7 task/s, elapsed: 3s, ETA:   137s[                                ] 22/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 23/929, 6.9 task/s, elapsed: 3s, ETA:   132s[                                ] 24/929, 7.0 task/s, elapsed: 3s, ETA:   130s[                                ] 25/929, 7.1 task/s, elapsed: 4s, ETA:   128s[                                ] 26/929, 7.1 task/s, elapsed: 4s, ETA:   126s[                                ] 27/929, 7.2 task/s, elapsed: 4s, ETA:   125s[                                ] 28/929, 7.3 task/s, elapsed: 4s, ETA:   123s[                                ] 29/929, 7.4 task/s, elapsed: 4s, ETA:   122s[>                               ] 30/929, 7.5 task/s, elapsed: 4s, ETA:   121s[>                               ] 31/929, 7.5 task/s, elapsed: 4s, ETA:   119s[>                               ] 32/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 33/929, 7.7 task/s, elapsed: 4s, ETA:   117s[>                               ] 34/929, 7.7 task/s, elapsed: 4s, ETA:   116s[>                               ] 35/929, 7.8 task/s, elapsed: 5s, ETA:   115s[>                               ] 36/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 37/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 38/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 39/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 40/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 41/929, 8.0 task/s, elapsed: 5s, ETA:   110s[>                               ] 42/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 43/929, 8.1 task/s, elapsed: 5s, ETA:   109s[>                               ] 44/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 45/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 46/929, 8.3 task/s, elapsed: 6s, ETA:   107s[>                               ] 47/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 48/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 49/929, 8.4 task/s, elapsed: 6s, ETA:   105s[>                               ] 50/929, 8.4 task/s, elapsed: 6s, ETA:   105s[>                               ] 51/929, 8.4 task/s, elapsed: 6s, ETA:   104s[>                               ] 52/929, 8.4 task/s, elapsed: 6s, ETA:   104s[>                               ] 53/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 54/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 55/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 56/929, 8.6 task/s, elapsed: 7s, ETA:   102s[>                               ] 57/929, 8.6 task/s, elapsed: 7s, ETA:   102s[>                               ] 58/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 59/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 60/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>>                              ] 61/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>>                              ] 62/929, 8.7 task/s, elapsed: 7s, ETA:    99s[>>                              ] 63/929, 8.7 task/s, elapsed: 7s, ETA:    99s[>>                              ] 64/929, 8.8 task/s, elapsed: 7s, ETA:    99s[>>                              ] 65/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 66/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 67/929, 8.8 task/s, elapsed: 8s, ETA:    98s[>>                              ] 68/929, 8.8 task/s, elapsed: 8s, ETA:    97s[>>                              ] 69/929, 8.9 task/s, elapsed: 8s, ETA:    97s[>>                              ] 70/929, 8.9 task/s, elapsed: 8s, ETA:    97s[>>                              ] 71/929, 8.9 task/s, elapsed: 8s, ETA:    96s[>>                              ] 72/929, 8.9 task/s, elapsed: 8s, ETA:    96s[>>                              ] 73/929, 8.9 task/s, elapsed: 8s, ETA:    96s[>>                              ] 74/929, 9.0 task/s, elapsed: 8s, ETA:    96s[>>                              ] 75/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 76/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 77/929, 9.0 task/s, elapsed: 9s, ETA:    95s[>>                              ] 78/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                              ] 79/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                              ] 80/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                              ] 81/929, 9.1 task/s, elapsed: 9s, ETA:    94s[>>                              ] 82/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 83/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 84/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 85/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 86/929, 9.1 task/s, elapsed: 9s, ETA:    92s[>>                             ] 87/929, 9.1 task/s, elapsed: 10s, ETA:    92s[>>                             ] 88/929, 9.2 task/s, elapsed: 10s, ETA:    92s[>>                             ] 89/929, 9.2 task/s, elapsed: 10s, ETA:    92s[>>>                            ] 90/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 91/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 92/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 93/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 94/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 95/929, 9.2 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 96/929, 9.2 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 97/929, 9.2 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 98/929, 9.3 task/s, elapsed: 11s, ETA:    90s[>>>                            ] 99/929, 9.3 task/s, elapsed: 11s, ETA:    90s[>>>                           ] 100/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 101/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 102/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 103/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 104/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 105/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 106/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 107/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 108/929, 9.3 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 109/929, 9.4 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 110/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 111/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 112/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 113/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 114/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 115/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 116/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 117/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 118/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 119/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 120/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 121/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 122/929, 9.4 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 123/929, 9.4 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 124/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 125/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 126/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 127/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 128/929, 9.5 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 129/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 130/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 131/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 132/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 133/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 134/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 135/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 136/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 137/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 138/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 139/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 140/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 141/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 142/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 143/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 144/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 145/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 146/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 147/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 148/929, 9.6 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 149/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 150/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 151/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 152/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 153/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 154/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>>                         ] 155/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 156/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 157/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 158/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 159/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 160/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 161/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 162/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 163/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 164/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 165/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 166/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 167/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 168/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 169/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 170/929, 9.7 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 171/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 172/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 173/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 174/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 175/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 176/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 177/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 178/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 179/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 180/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 181/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 182/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 183/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 184/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 185/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>>                        ] 186/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 187/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 188/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 189/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 190/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 191/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 192/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 193/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 194/929, 9.7 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 195/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 196/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 197/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 198/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 199/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 200/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 201/929, 9.8 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 202/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 203/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 204/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 205/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 206/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 207/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 208/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 209/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 210/929, 9.8 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 211/929, 9.8 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 212/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 213/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 214/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 215/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 216/929, 9.7 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 217/929, 9.7 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 218/929, 9.7 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 219/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 220/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 221/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 222/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 223/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 224/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 225/929, 9.7 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 226/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 227/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 228/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 229/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 230/929, 9.8 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 231/929, 9.8 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 232/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 233/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 234/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 235/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 236/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 237/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 238/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 239/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 240/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 241/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 242/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 243/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 244/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 245/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 246/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 247/929, 9.8 task/s, elapsed: 25s, ETA:    70s[>>>>>>>>                      ] 248/929, 9.8 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 249/929, 9.8 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 250/929, 9.8 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 251/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 252/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 253/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 254/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 255/929, 9.8 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 256/929, 9.8 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 257/929, 9.8 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 258/929, 9.8 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 259/929, 9.8 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 260/929, 9.8 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 261/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 262/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 263/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 264/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 265/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 266/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 267/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 268/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 269/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 270/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 271/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 272/929, 9.9 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 273/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 274/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 275/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 276/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 277/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 278/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 279/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 280/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 281/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 282/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 283/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 284/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 285/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 286/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 287/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 288/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 289/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 290/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 291/929, 9.9 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                     ] 292/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 293/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 294/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 295/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 296/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 297/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 298/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 299/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 300/929, 9.9 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                     ] 301/929, 9.9 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                     ] 302/929, 9.9 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                     ] 303/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 304/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 305/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 306/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 307/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 308/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 309/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>>                    ] 310/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 311/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 312/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 313/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 314/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 315/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 316/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 317/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 318/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 319/929, 9.9 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 320/929, 9.9 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 321/929, 9.9 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 322/929, 9.9 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 323/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 324/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 325/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 326/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 327/929, 9.9 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 328/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 329/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 330/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 331/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 332/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 333/929, 9.9 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 334/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 335/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 336/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 337/929, 9.9 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 338/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                    ] 339/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                    ] 340/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>>                   ] 341/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>>                   ] 342/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>>                   ] 343/929, 9.9 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 344/929, 10.0 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>                   ] 345/929, 10.0 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>                   ] 346/929, 10.0 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>                   ] 347/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 348/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 349/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 350/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 351/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 352/929, 9.9 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                   ] 353/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 354/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 355/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 356/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                  ] 357/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 358/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 359/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 360/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 361/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 362/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 363/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 364/929, 10.0 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                  ] 365/929, 10.0 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                  ] 366/929, 10.0 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                  ] 367/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 368/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 369/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 370/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 371/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 372/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 373/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 374/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 375/929, 10.0 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>                  ] 376/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 377/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 378/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 379/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 380/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 381/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 382/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 383/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 384/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>>                 ] 385/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 387/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 388/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 389/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 390/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 391/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 392/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 393/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 394/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 395/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 397/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 398/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 399/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 400/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 401/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 402/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 403/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 404/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 407/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 408/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 409/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 410/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 411/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 412/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 413/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 414/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 417/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 418/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 419/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 420/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 421/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 422/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 423/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 427/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 428/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 429/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 430/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 431/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 432/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 433/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 437/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 438/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 439/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 440/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 441/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 442/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 443/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 445/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 447/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 448/929, 10.1 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 449/929, 10.1 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 450/929, 10.1 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 451/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 452/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 453/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 455/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 457/929, 10.0 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 458/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 459/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 460/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 461/929, 10.1 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 462/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 466/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 467/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 468/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 469/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 470/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 471/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 472/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 477/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 478/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 479/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 480/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 481/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 482/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 487/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 488/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 489/929, 10.1 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 490/929, 10.1 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 491/929, 10.1 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 492/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 496/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 497/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 498/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 499/929, 10.1 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 500/929, 10.1 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 501/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 506/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 507/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 508/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 509/929, 10.1 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 510/929, 10.1 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 511/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 516/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 517/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 518/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 519/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 520/929, 10.1 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 521/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 526/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 527/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 528/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 529/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 530/929, 10.1 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 531/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 537/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 538/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 539/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 540/929, 10.1 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 541/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.1 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.1 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.1 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.1 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.1 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.1 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.1 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.1 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.1 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.1 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.2 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.2 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.2 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.2 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.2 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.2 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.2 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.2 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.2 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.2 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.2 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.2 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.2 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.2 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.2 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.2 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.2 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.2 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.2 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.2 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.2 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.2 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.2 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.2 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.2 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.2 task/s, elapsed: 91s, ETA:     0s2022-10-03 17:30:23,929 - mmseg - INFO - per class results:2022-10-03 17:30:23,930 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  |  91.1 | 95.43 || rigid_plastic | 32.42 | 40.17 ||   cardboard   | 58.81 | 76.51 ||     metal     | 28.39 | 33.69 ||  soft_plastic | 64.08 | 74.12 |+---------------+-------+-------+2022-10-03 17:30:23,930 - mmseg - INFO - Summary:2022-10-03 17:30:23,931 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.58 | 54.96 | 63.98 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:30:23,936 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:30:23,937 - mmseg - INFO - Iter [929/40000]	lr: 1.800e-05, eta: 1:26:19, time: 0.395, data_time: 0.007, memory: 11956, aAcc: 0.9158, mIoU: 0.5496, mAcc: 0.6398, IoU.background: 0.9110, IoU.rigid_plastic: 0.3242, IoU.cardboard: 0.5881, IoU.metal: 0.2839, IoU.soft_plastic: 0.6408, Acc.background: 0.9543, Acc.rigid_plastic: 0.4017, Acc.cardboard: 0.7651, Acc.metal: 0.3369, Acc.soft_plastic: 0.7412, decode.loss_seg: 0.0461, decode.acc_seg: 98.3230, loss: 0.0461/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:30:43,717 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 1:26:58, time: 3.282, data_time: 2.893, memory: 11956, decode.loss_seg: 0.0497, decode.acc_seg: 98.1788, loss: 0.0497/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:31:03,477 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 1:26:35, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0538, decode.acc_seg: 98.1938, loss: 0.0538/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:31:23,362 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 1:26:13, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0472, decode.acc_seg: 98.2458, loss: 0.0472/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:31:43,182 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 1:25:50, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0496, decode.acc_seg: 98.2288, loss: 0.0496/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:32:02,850 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 1:25:27, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0485, decode.acc_seg: 98.1478, loss: 0.0485/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:32:22,525 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 1:25:05, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0478, decode.acc_seg: 98.2141, loss: 0.0478/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:32:42,435 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 1:24:42, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0547, decode.acc_seg: 97.9708, loss: 0.0547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:33:02,210 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 1:24:19, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0510, decode.acc_seg: 98.1831, loss: 0.0510/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:33:22,040 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 1:23:57, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0435, decode.acc_seg: 98.3199, loss: 0.0435/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:33:41,831 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 1:23:34, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0484, decode.acc_seg: 98.1482, loss: 0.0484/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:34:03,573 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 1:23:12, time: 0.435, data_time: 0.044, memory: 11956, decode.loss_seg: 0.0472, decode.acc_seg: 98.2824, loss: 0.0472/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:34:23,367 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 1:22:50, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0493, decode.acc_seg: 98.1026, loss: 0.0493/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:34:43,106 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 1:22:27, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0393, decode.acc_seg: 98.5298, loss: 0.0393/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:35:03,064 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 1:22:05, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0542, decode.acc_seg: 98.1179, loss: 0.0542/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:35:22,802 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 1:21:42, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0462, decode.acc_seg: 98.2417, loss: 0.0462/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:35:42,839 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 1:21:19, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0484, decode.acc_seg: 98.2607, loss: 0.0484/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:36:02,563 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 1:20:57, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0521, decode.acc_seg: 98.0719, loss: 0.0521/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:36:22,410 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 1:20:34, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0457, decode.acc_seg: 98.2469, loss: 0.0457/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:36:42,105 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 1:20:12, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0428, decode.acc_seg: 98.4078, loss: 0.0428/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:37:01,931 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:37:01,931 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 1:19:49, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0448, decode.acc_seg: 98.3038, loss: 0.0448/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:37:21,666 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 1:19:27, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0547, decode.acc_seg: 98.1488, loss: 0.0547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:37:41,309 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 1:19:04, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0435, decode.acc_seg: 98.3562, loss: 0.0435/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:38:01,126 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 1:18:42, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0465, decode.acc_seg: 98.2420, loss: 0.0465/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:38:21,053 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 1:18:19, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0503, decode.acc_seg: 98.0697, loss: 0.0503/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:38:40,745 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 1:17:57, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0372, decode.acc_seg: 98.5956, loss: 0.0372/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:39:00,600 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 1:17:34, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0571, decode.acc_seg: 97.9162, loss: 0.0571/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:39:20,463 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 1:17:12, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0467, decode.acc_seg: 98.2039, loss: 0.0467/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:39:40,359 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 1:16:49, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0423, decode.acc_seg: 98.4698, loss: 0.0423/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:40:00,296 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 1:16:27, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0432, decode.acc_seg: 98.3668, loss: 0.0432/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:40:20,179 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 1:16:05, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0428, decode.acc_seg: 98.3772, loss: 0.0428/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:40:40,004 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 1:15:42, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0417, decode.acc_seg: 98.3978, loss: 0.0417/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:40:59,718 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 1:15:20, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0443, decode.acc_seg: 98.3499, loss: 0.0443/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:41:19,671 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 1:14:57, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0500, decode.acc_seg: 98.3394, loss: 0.0500/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:41:39,480 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 1:14:35, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0619, decode.acc_seg: 97.7999, loss: 0.0619/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:41:59,275 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 1:14:13, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0554, decode.acc_seg: 98.0749, loss: 0.0554/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:42:19,165 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 1:13:50, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0370, decode.acc_seg: 98.6429, loss: 0.0370/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:42:38,925 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 1:13:28, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0439, decode.acc_seg: 98.3748, loss: 0.0439/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:42:58,735 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 1:13:06, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0496, decode.acc_seg: 98.1409, loss: 0.0496/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:43:18,523 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 1:12:43, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0444, decode.acc_seg: 98.3575, loss: 0.0444/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:43:38,478 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:43:38,478 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 1:12:21, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0428, decode.acc_seg: 98.3681, loss: 0.0428/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:44:00,253 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 1:11:59, time: 0.435, data_time: 0.041, memory: 11956, decode.loss_seg: 0.0534, decode.acc_seg: 98.1144, loss: 0.0534/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:44:20,050 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 1:11:37, time: 0.396, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0453, decode.acc_seg: 98.3110, loss: 0.0453/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:44:39,906 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 1:11:15, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0581, decode.acc_seg: 97.9995, loss: 0.0581/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:44:59,757 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 1:10:52, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0460, decode.acc_seg: 98.2585, loss: 0.0460/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:45:20,081 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 1:10:30, time: 0.406, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0417, decode.acc_seg: 98.4427, loss: 0.0417/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:45:40,843 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 1:10:08, time: 0.415, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0442, decode.acc_seg: 98.4546, loss: 0.0442/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:46:01,276 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 1:09:46, time: 0.409, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0438, decode.acc_seg: 98.3323, loss: 0.0438/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:46:21,150 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 1:09:24, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0450, decode.acc_seg: 98.3077, loss: 0.0450/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:46:41,039 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 1:09:01, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0461, decode.acc_seg: 98.3709, loss: 0.0461/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:47:00,927 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 1:08:39, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0391, decode.acc_seg: 98.5060, loss: 0.0391/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:47:20,637 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 1:08:17, time: 0.394, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0489, decode.acc_seg: 98.2468, loss: 0.0489/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:47:40,395 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 1:07:55, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0469, decode.acc_seg: 98.2541, loss: 0.0469/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:48:00,273 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 1:07:32, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0453, decode.acc_seg: 98.3223, loss: 0.0453/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:48:20,185 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 1:07:10, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0435, decode.acc_seg: 98.3412, loss: 0.0435/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:48:40,203 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 1:06:48, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0468, decode.acc_seg: 98.2634, loss: 0.0468/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:49:00,034 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 1:06:26, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0534, decode.acc_seg: 98.1251, loss: 0.0534/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:49:19,867 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 1:06:04, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0511, decode.acc_seg: 98.1691, loss: 0.0511/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:49:39,670 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 1:05:41, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0436, decode.acc_seg: 98.3825, loss: 0.0436/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:49:59,514 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 1:05:19, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0444, decode.acc_seg: 98.2821, loss: 0.0444/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:50:19,511 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:50:19,511 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 1:04:57, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0451, decode.acc_seg: 98.3658, loss: 0.0451/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:50:39,213 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 1:04:35, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0457, decode.acc_seg: 98.3560, loss: 0.0457/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:50:58,792 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 1:04:13, time: 0.392, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0457, decode.acc_seg: 98.3263, loss: 0.0457/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:51:18,562 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 1:03:50, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0551, decode.acc_seg: 97.9246, loss: 0.0551/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:51:38,344 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 1:03:28, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0444, decode.acc_seg: 98.3576, loss: 0.0444/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:51:58,056 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 1:03:06, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0389, decode.acc_seg: 98.5340, loss: 0.0389/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:52:17,742 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 1:02:44, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0486, decode.acc_seg: 98.2215, loss: 0.0486/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:52:37,473 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 1:02:22, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0487, decode.acc_seg: 98.1400, loss: 0.0487/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:52:57,264 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 1:02:00, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0453, decode.acc_seg: 98.4194, loss: 0.0453/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:53:17,070 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 1:01:38, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0444, decode.acc_seg: 98.3209, loss: 0.0444/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:53:36,809 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 1:01:15, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0435, decode.acc_seg: 98.4427, loss: 0.0435/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:53:58,184 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 1:00:54, time: 0.427, data_time: 0.039, memory: 11956, decode.loss_seg: 0.0527, decode.acc_seg: 98.0850, loss: 0.0527/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:54:17,891 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 1:00:32, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0518, decode.acc_seg: 98.0592, loss: 0.0518/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:54:37,743 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 1:00:09, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0520, decode.acc_seg: 98.0799, loss: 0.0520/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:54:57,595 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 0:59:47, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0461, decode.acc_seg: 98.3285, loss: 0.0461/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:55:17,245 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 0:59:25, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0408, decode.acc_seg: 98.4926, loss: 0.0408/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:55:37,060 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 0:59:03, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0444, decode.acc_seg: 98.3083, loss: 0.0444/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:55:56,846 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 0:58:41, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0424, decode.acc_seg: 98.4077, loss: 0.0424/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:56:16,648 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 0:58:19, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0404, decode.acc_seg: 98.4652, loss: 0.0404/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:56:36,343 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 0:57:57, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0355, decode.acc_seg: 98.6296, loss: 0.0355[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1178s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   634s[                                 ] 3/929, 2.1 task/s, elapsed: 1s, ETA:   451s[                                 ] 4/929, 2.6 task/s, elapsed: 2s, ETA:   360s[                                 ] 5/929, 3.0 task/s, elapsed: 2s, ETA:   306s[                                 ] 6/929, 3.4 task/s, elapsed: 2s, ETA:   270s[                                 ] 7/929, 3.8 task/s, elapsed: 2s, ETA:   244s[                                 ] 8/929, 4.1 task/s, elapsed: 2s, ETA:   224s[                                 ] 9/929, 4.4 task/s, elapsed: 2s, ETA:   208s[                                ] 10/929, 4.7 task/s, elapsed: 2s, ETA:   196s[                                ] 11/929, 4.9 task/s, elapsed: 2s, ETA:   186s[                                ] 12/929, 5.2 task/s, elapsed: 2s, ETA:   177s[                                ] 13/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 14/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 15/929, 5.8 task/s, elapsed: 3s, ETA:   159s[                                ] 16/929, 5.9 task/s, elapsed: 3s, ETA:   154s[                                ] 17/929, 6.1 task/s, elapsed: 3s, ETA:   150s[                                ] 18/929, 6.2 task/s, elapsed: 3s, ETA:   146s[                                ] 19/929, 6.4 task/s, elapsed: 3s, ETA:   143s[                                ] 20/929, 6.5 task/s, elapsed: 3s, ETA:   140s[                                ] 21/929, 6.5 task/s, elapsed: 3s, ETA:   140s[                                ] 22/929, 6.6 task/s, elapsed: 3s, ETA:   137s[                                ] 23/929, 6.7 task/s, elapsed: 3s, ETA:   135s[                                ] 24/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 25/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 26/929, 7.0 task/s, elapsed: 4s, ETA:   130s[                                ] 27/929, 7.1 task/s, elapsed: 4s, ETA:   128s[                                ] 28/929, 7.1 task/s, elapsed: 4s, ETA:   126s[                                ] 29/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 30/929, 7.3 task/s, elapsed: 4s, ETA:   123s[>                               ] 31/929, 7.4 task/s, elapsed: 4s, ETA:   122s[>                               ] 32/929, 7.4 task/s, elapsed: 4s, ETA:   121s[>                               ] 33/929, 7.5 task/s, elapsed: 4s, ETA:   120s[>                               ] 34/929, 7.6 task/s, elapsed: 5s, ETA:   118s[>                               ] 35/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 36/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 37/929, 7.7 task/s, elapsed: 5s, ETA:   115s[>                               ] 38/929, 7.8 task/s, elapsed: 5s, ETA:   115s[>                               ] 39/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 40/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 41/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 42/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 43/929, 8.0 task/s, elapsed: 5s, ETA:   110s[>                               ] 44/929, 8.0 task/s, elapsed: 5s, ETA:   110s[>                               ] 45/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 46/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 47/929, 8.2 task/s, elapsed: 6s, ETA:   108s[>                               ] 48/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 49/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 50/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 51/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 52/929, 8.4 task/s, elapsed: 6s, ETA:   105s[>                               ] 53/929, 8.4 task/s, elapsed: 6s, ETA:   104s[>                               ] 54/929, 8.4 task/s, elapsed: 6s, ETA:   104s[>                               ] 55/929, 8.5 task/s, elapsed: 7s, ETA:   103s[>                               ] 56/929, 8.5 task/s, elapsed: 7s, ETA:   103s[>                               ] 57/929, 8.5 task/s, elapsed: 7s, ETA:   103s[>                               ] 58/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 59/929, 8.6 task/s, elapsed: 7s, ETA:   102s[>>                              ] 60/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 61/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 62/929, 8.6 task/s, elapsed: 7s, ETA:   100s[>>                              ] 63/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>>                              ] 64/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>>                              ] 65/929, 8.7 task/s, elapsed: 7s, ETA:    99s[>>                              ] 66/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 67/929, 8.8 task/s, elapsed: 8s, ETA:    98s[>>                              ] 68/929, 8.8 task/s, elapsed: 8s, ETA:    98s[>>                              ] 69/929, 8.8 task/s, elapsed: 8s, ETA:    98s[>>                              ] 70/929, 8.8 task/s, elapsed: 8s, ETA:    97s[>>                              ] 71/929, 8.8 task/s, elapsed: 8s, ETA:    97s[>>                              ] 72/929, 8.9 task/s, elapsed: 8s, ETA:    97s[>>                              ] 73/929, 8.9 task/s, elapsed: 8s, ETA:    96s[>>                              ] 74/929, 8.8 task/s, elapsed: 8s, ETA:    97s[>>                              ] 75/929, 8.9 task/s, elapsed: 8s, ETA:    96s[>>                              ] 76/929, 8.9 task/s, elapsed: 9s, ETA:    96s[>>                              ] 77/929, 8.9 task/s, elapsed: 9s, ETA:    96s[>>                              ] 78/929, 8.9 task/s, elapsed: 9s, ETA:    95s[>>                              ] 79/929, 8.9 task/s, elapsed: 9s, ETA:    95s[>>                              ] 80/929, 9.0 task/s, elapsed: 9s, ETA:    95s[>>                              ] 81/929, 9.0 task/s, elapsed: 9s, ETA:    95s[>>                              ] 82/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                              ] 83/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                              ] 84/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                              ] 85/929, 9.0 task/s, elapsed: 9s, ETA:    94s[>>                             ] 86/929, 9.0 task/s, elapsed: 10s, ETA:    93s[>>                             ] 87/929, 9.1 task/s, elapsed: 10s, ETA:    93s[>>                             ] 88/929, 9.1 task/s, elapsed: 10s, ETA:    93s[>>                             ] 89/929, 9.1 task/s, elapsed: 10s, ETA:    92s[>>>                            ] 90/929, 9.1 task/s, elapsed: 10s, ETA:    92s[>>>                            ] 91/929, 9.1 task/s, elapsed: 10s, ETA:    92s[>>>                            ] 92/929, 9.1 task/s, elapsed: 10s, ETA:    92s[>>>                            ] 93/929, 9.1 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 94/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 95/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 96/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 97/929, 9.2 task/s, elapsed: 11s, ETA:    91s[>>>                            ] 98/929, 9.2 task/s, elapsed: 11s, ETA:    90s[>>>                            ] 99/929, 9.2 task/s, elapsed: 11s, ETA:    90s[>>>                           ] 100/929, 9.2 task/s, elapsed: 11s, ETA:    90s[>>>                           ] 101/929, 9.2 task/s, elapsed: 11s, ETA:    90s[>>>                           ] 102/929, 9.2 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 103/929, 9.2 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 104/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 105/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 106/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 107/929, 9.3 task/s, elapsed: 12s, ETA:    89s[>>>                           ] 108/929, 9.3 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 109/929, 9.3 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 110/929, 9.3 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 111/929, 9.3 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 112/929, 9.3 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 113/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 114/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 115/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 116/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 117/929, 9.3 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 118/929, 9.3 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 119/929, 9.4 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 120/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 121/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 122/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 123/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>>                          ] 124/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>>                          ] 125/929, 9.4 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 126/929, 9.4 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 127/929, 9.4 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 128/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 129/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 130/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 131/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 132/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 133/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 134/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 135/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 136/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 137/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 138/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 139/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 140/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 141/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 142/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 143/929, 9.5 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 144/929, 9.5 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 145/929, 9.5 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 146/929, 9.5 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 147/929, 9.5 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 148/929, 9.5 task/s, elapsed: 16s, ETA:    82s[>>>>                          ] 149/929, 9.5 task/s, elapsed: 16s, ETA:    82s[>>>>                          ] 150/929, 9.5 task/s, elapsed: 16s, ETA:    82s[>>>>                          ] 151/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 152/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 153/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 154/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>>                         ] 155/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>>                         ] 156/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>>                         ] 157/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 158/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 159/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 160/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 161/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 162/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 163/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 164/929, 9.6 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 165/929, 9.6 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 166/929, 9.6 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 167/929, 9.6 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 168/929, 9.6 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 169/929, 9.7 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 170/929, 9.7 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 171/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 172/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 173/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 174/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 175/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 176/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 177/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 178/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 179/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 180/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 181/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 182/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 183/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 184/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 185/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>>                        ] 186/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 187/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 188/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 189/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 190/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 191/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 192/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 193/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 194/929, 9.7 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 195/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 196/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 197/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 198/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 199/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 200/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 201/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 202/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 203/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 204/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 205/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 206/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 207/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 208/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 209/929, 9.8 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 210/929, 9.8 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 211/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 212/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 213/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 214/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 215/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 216/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 217/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 218/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 219/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 220/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 221/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 222/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 223/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 224/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 225/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 226/929, 9.8 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 227/929, 9.8 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 228/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 229/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 230/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 231/929, 9.9 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 232/929, 9.9 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 233/929, 9.9 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 234/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 235/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 236/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 237/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 238/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 239/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 240/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 241/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 242/929, 9.9 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                       ] 243/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 244/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 245/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 246/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 247/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 248/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 249/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 250/929, 9.9 task/s, elapsed: 25s, ETA:    68s[>>>>>>>>                      ] 251/929, 9.9 task/s, elapsed: 25s, ETA:    68s[>>>>>>>>                      ] 252/929, 9.9 task/s, elapsed: 25s, ETA:    68s[>>>>>>>>                      ] 253/929, 9.9 task/s, elapsed: 25s, ETA:    68s[>>>>>>>>                      ] 254/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 255/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 256/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 257/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 258/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 259/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 260/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 261/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 262/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 263/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 264/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 265/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 266/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 267/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 268/929, 9.9 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 269/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 270/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 271/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 272/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 273/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 274/929, 10.0 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                     ] 275/929, 10.0 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                     ] 276/929, 10.0 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                     ] 277/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 278/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 279/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 280/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 281/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 282/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 283/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 284/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 285/929, 10.0 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>                     ] 286/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 287/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 288/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 289/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 290/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 291/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 292/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 293/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 294/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 295/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 296/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 297/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 298/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 299/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 300/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 301/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 302/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 303/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 304/929, 10.0 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 305/929, 10.0 task/s, elapsed: 30s, ETA:    62s[>>>>>>>>>                    ] 306/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 307/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 308/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 309/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 310/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 311/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 312/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 313/929, 10.0 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 314/929, 10.0 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 315/929, 10.0 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 316/929, 10.0 task/s, elapsed: 31s, ETA:    61s[>>>>>>>>>                    ] 317/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 318/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 319/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 320/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 321/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 322/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 323/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 324/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 325/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 326/929, 10.0 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                   ] 327/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 328/929, 10.1 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 329/929, 10.1 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 330/929, 10.1 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 331/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 332/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 333/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 334/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 335/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 336/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 337/929, 10.1 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 338/929, 10.1 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 339/929, 10.1 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 340/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 341/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 342/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 343/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 344/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 345/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 346/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 347/929, 10.1 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 348/929, 10.1 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 349/929, 10.1 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 350/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 351/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>                   ] 352/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 353/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 354/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 355/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 356/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 357/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 358/929, 10.1 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 359/929, 10.1 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 360/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 361/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 362/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 363/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 364/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 365/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 366/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 367/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 368/929, 10.1 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 369/929, 10.1 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 370/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 371/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 372/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 373/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 374/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 375/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 376/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 377/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 378/929, 10.1 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 379/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 380/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 381/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 382/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 383/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>                  ] 384/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 385/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 387/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 388/929, 10.1 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 389/929, 10.1 task/s, elapsed: 38s, ETA:    53s[>>>>>>>>>>>>                 ] 390/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 391/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 392/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 393/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 394/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 397/929, 10.1 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 398/929, 10.1 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 399/929, 10.1 task/s, elapsed: 39s, ETA:    52s[>>>>>>>>>>>>                 ] 400/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 401/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 402/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 403/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 404/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 407/929, 10.1 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 408/929, 10.1 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 409/929, 10.1 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 410/929, 10.1 task/s, elapsed: 40s, ETA:    51s[>>>>>>>>>>>>                 ] 411/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 412/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 413/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 414/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.1 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>>                ] 417/929, 10.1 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 418/929, 10.1 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 419/929, 10.1 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 420/929, 10.1 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 421/929, 10.1 task/s, elapsed: 41s, ETA:    50s[>>>>>>>>>>>>>                ] 422/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 423/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.1 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 427/929, 10.1 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 428/929, 10.1 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 429/929, 10.1 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 430/929, 10.1 task/s, elapsed: 42s, ETA:    49s[>>>>>>>>>>>>>                ] 431/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 432/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 433/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 437/929, 10.1 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 438/929, 10.1 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 439/929, 10.1 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 440/929, 10.1 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 441/929, 10.1 task/s, elapsed: 43s, ETA:    48s[>>>>>>>>>>>>>                ] 442/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 443/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.1 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 445/929, 10.2 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.2 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 447/929, 10.1 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>                ] 448/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 449/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 450/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 451/929, 10.2 task/s, elapsed: 44s, ETA:    47s[>>>>>>>>>>>>>>               ] 452/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 453/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 455/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.2 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 457/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 458/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 459/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 460/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 461/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 462/929, 10.2 task/s, elapsed: 45s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 466/929, 10.2 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 467/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 468/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 469/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 470/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 471/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 472/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.2 task/s, elapsed: 46s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.2 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 477/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 478/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 479/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>               ] 480/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 481/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 482/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.2 task/s, elapsed: 47s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.2 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 487/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 488/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 489/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 490/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 491/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 492/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.2 task/s, elapsed: 48s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 496/929, 10.2 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 497/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 498/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 499/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 500/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 501/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.2 task/s, elapsed: 49s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.2 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 506/929, 10.2 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 507/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 508/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 509/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 510/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 511/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.2 task/s, elapsed: 50s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.2 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 516/929, 10.2 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 517/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 518/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 519/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 520/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 521/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.2 task/s, elapsed: 51s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 526/929, 10.2 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 527/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 528/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 529/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 530/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 531/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.2 task/s, elapsed: 52s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.2 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 537/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 538/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 539/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 540/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 541/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.2 task/s, elapsed: 53s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.2 task/s, elapsed: 54s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.2 task/s, elapsed: 54s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.2 task/s, elapsed: 55s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.2 task/s, elapsed: 55s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.2 task/s, elapsed: 56s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.2 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.2 task/s, elapsed: 56s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.2 task/s, elapsed: 57s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.2 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.2 task/s, elapsed: 57s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.2 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.2 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.2 task/s, elapsed: 58s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.2 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.2 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.2 task/s, elapsed: 59s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.2 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.2 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.2 task/s, elapsed: 60s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.2 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.2 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.2 task/s, elapsed: 61s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.2 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.2 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.2 task/s, elapsed: 62s, ETA:    28s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.2 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.2 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.2 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.2 task/s, elapsed: 63s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.2 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.2 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.2 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.2 task/s, elapsed: 64s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.2 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.2 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.2 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.2 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.2 task/s, elapsed: 65s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.2 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.2 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.2 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.2 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.2 task/s, elapsed: 66s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.3 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.3 task/s, elapsed: 67s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.3 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.2 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.2 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.2 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.2 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.3 task/s, elapsed: 68s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.3 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.3 task/s, elapsed: 69s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.3 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.3 task/s, elapsed: 70s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.3 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.3 task/s, elapsed: 71s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.3 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.3 task/s, elapsed: 72s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.3 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.3 task/s, elapsed: 73s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.3 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.3 task/s, elapsed: 74s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.3 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.3 task/s, elapsed: 75s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.3 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.3 task/s, elapsed: 76s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.3 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.3 task/s, elapsed: 77s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.3 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.3 task/s, elapsed: 78s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.3 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.3 task/s, elapsed: 79s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.3 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.3 task/s, elapsed: 80s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.3 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.3 task/s, elapsed: 81s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.3 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.3 task/s, elapsed: 82s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.3 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.3 task/s, elapsed: 83s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.3 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.3 task/s, elapsed: 84s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.3 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.3 task/s, elapsed: 85s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.3 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.3 task/s, elapsed: 86s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.3 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.3 task/s, elapsed: 87s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.3 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.3 task/s, elapsed: 88s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.3 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.3 task/s, elapsed: 89s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.3 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.3 task/s, elapsed: 90s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.3 task/s, elapsed: 90s, ETA:     0s2022-10-03 17:59:19,335 - mmseg - INFO - per class results:2022-10-03 17:59:19,336 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.11 | 95.79 || rigid_plastic | 31.42 | 36.68 ||   cardboard   | 58.69 | 75.88 ||     metal     |  28.4 | 36.79 ||  soft_plastic | 62.87 | 70.79 |+---------------+-------+-------+2022-10-03 17:59:19,336 - mmseg - INFO - Summary:2022-10-03 17:59:19,336 - mmseg - INFO - +-------+------+-------+|  aAcc | mIoU |  mAcc |+-------+------+-------+| 91.58 | 54.5 | 63.19 |+-------+------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:59:19,343 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 17:59:19,343 - mmseg - INFO - Iter [929/40000]	lr: 1.200e-05, eta: 0:57:35, time: 0.398, data_time: 0.007, memory: 11956, aAcc: 0.9158, mIoU: 0.5450, mAcc: 0.6319, IoU.background: 0.9111, IoU.rigid_plastic: 0.3142, IoU.cardboard: 0.5869, IoU.metal: 0.2840, IoU.soft_plastic: 0.6287, Acc.background: 0.9579, Acc.rigid_plastic: 0.3668, Acc.cardboard: 0.7588, Acc.metal: 0.3679, Acc.soft_plastic: 0.7079, decode.loss_seg: 0.0419, decode.acc_seg: 98.4430, loss: 0.0419/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:59:39,007 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 0:57:48, time: 3.256, data_time: 2.869, memory: 11956, decode.loss_seg: 0.0430, decode.acc_seg: 98.3735, loss: 0.0430/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 17:59:58,674 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 0:57:26, time: 0.393, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0381, decode.acc_seg: 98.5795, loss: 0.0381/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:00:18,608 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 0:57:04, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0417, decode.acc_seg: 98.3623, loss: 0.0417/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:00:38,234 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 0:56:41, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0350, decode.acc_seg: 98.6760, loss: 0.0350/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:00:57,939 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 0:56:19, time: 0.394, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0416, decode.acc_seg: 98.4473, loss: 0.0416/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:01:17,835 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 0:55:57, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0383, decode.acc_seg: 98.4943, loss: 0.0383/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:01:37,569 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 0:55:35, time: 0.395, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0409, decode.acc_seg: 98.4541, loss: 0.0409/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:01:57,214 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 0:55:12, time: 0.393, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0504, decode.acc_seg: 98.2504, loss: 0.0504/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:02:16,918 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 0:54:50, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0348, decode.acc_seg: 98.7043, loss: 0.0348/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:02:36,659 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 0:54:28, time: 0.395, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0359, decode.acc_seg: 98.7284, loss: 0.0359/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:02:56,268 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 0:54:05, time: 0.392, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0425, decode.acc_seg: 98.3407, loss: 0.0425/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:03:15,870 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 0:53:43, time: 0.392, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0376, decode.acc_seg: 98.5507, loss: 0.0376/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:03:35,627 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 0:53:21, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0473, decode.acc_seg: 98.2548, loss: 0.0473/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:03:55,322 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 0:52:59, time: 0.394, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0430, decode.acc_seg: 98.4114, loss: 0.0430/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:04:15,029 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 0:52:36, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0454, decode.acc_seg: 98.2831, loss: 0.0454/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:04:34,914 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 0:52:14, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0407, decode.acc_seg: 98.4472, loss: 0.0407/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:04:54,730 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 0:51:52, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0465, decode.acc_seg: 98.4039, loss: 0.0465/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:05:14,609 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 0:51:30, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0391, decode.acc_seg: 98.5192, loss: 0.0391/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:05:34,700 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 0:51:08, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0402, decode.acc_seg: 98.4217, loss: 0.0402/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:05:54,564 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 18:05:54,565 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 0:50:46, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0421, decode.acc_seg: 98.4539, loss: 0.0421/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:06:16,398 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 0:50:24, time: 0.437, data_time: 0.042, memory: 11956, decode.loss_seg: 0.0411, decode.acc_seg: 98.4924, loss: 0.0411/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:06:36,306 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 0:50:02, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0413, decode.acc_seg: 98.4902, loss: 0.0413/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:06:56,175 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 0:49:40, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0438, decode.acc_seg: 98.3450, loss: 0.0438/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:07:15,990 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 0:49:17, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0382, decode.acc_seg: 98.5924, loss: 0.0382/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:07:35,905 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 0:48:55, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0399, decode.acc_seg: 98.4956, loss: 0.0399/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:07:55,802 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 0:48:33, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0469, decode.acc_seg: 98.2079, loss: 0.0469/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:08:15,650 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 0:48:11, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0362, decode.acc_seg: 98.6843, loss: 0.0362/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:08:35,518 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 0:47:49, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0474, decode.acc_seg: 98.2132, loss: 0.0474/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:08:55,348 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 0:47:27, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0462, decode.acc_seg: 98.3689, loss: 0.0462/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:09:15,428 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 0:47:05, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0374, decode.acc_seg: 98.5816, loss: 0.0374/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:09:35,301 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 0:46:43, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0397, decode.acc_seg: 98.4731, loss: 0.0397/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:09:55,224 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 0:46:21, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0414, decode.acc_seg: 98.4961, loss: 0.0414/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:10:15,267 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 0:45:59, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0450, decode.acc_seg: 98.3240, loss: 0.0450/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:10:35,111 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 0:45:36, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0413, decode.acc_seg: 98.4160, loss: 0.0413/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:10:54,859 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 0:45:14, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0455, decode.acc_seg: 98.2454, loss: 0.0455/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:11:14,834 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 0:44:52, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0412, decode.acc_seg: 98.4405, loss: 0.0412/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:11:34,604 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 0:44:30, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0424, decode.acc_seg: 98.4225, loss: 0.0424/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:11:54,513 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 0:44:08, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0354, decode.acc_seg: 98.6639, loss: 0.0354/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:12:14,337 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 0:43:46, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0437, decode.acc_seg: 98.4265, loss: 0.0437/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:12:34,102 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 18:12:34,102 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 0:43:24, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0406, decode.acc_seg: 98.4130, loss: 0.0406/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:12:53,875 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 0:43:02, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0365, decode.acc_seg: 98.5909, loss: 0.0365/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:13:13,611 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 0:42:40, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0395, decode.acc_seg: 98.5191, loss: 0.0395/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:13:33,333 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 0:42:18, time: 0.394, data_time: 0.006, memory: 11956, decode.loss_seg: 0.0352, decode.acc_seg: 98.6472, loss: 0.0352/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:13:53,175 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 0:41:56, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0392, decode.acc_seg: 98.5450, loss: 0.0392/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:14:13,589 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 0:41:34, time: 0.408, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0371, decode.acc_seg: 98.5231, loss: 0.0371/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:14:34,279 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 0:41:12, time: 0.414, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0451, decode.acc_seg: 98.2945, loss: 0.0451/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:14:54,895 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 0:40:50, time: 0.412, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0361, decode.acc_seg: 98.6449, loss: 0.0361/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:15:14,833 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 0:40:28, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0392, decode.acc_seg: 98.4350, loss: 0.0392/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:15:34,708 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 0:40:06, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0451, decode.acc_seg: 98.2965, loss: 0.0451/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:15:54,538 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 0:39:44, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0475, decode.acc_seg: 98.2750, loss: 0.0475/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:16:15,761 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 0:39:23, time: 0.424, data_time: 0.036, memory: 11956, decode.loss_seg: 0.0433, decode.acc_seg: 98.3732, loss: 0.0433/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:16:35,601 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 0:39:01, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0388, decode.acc_seg: 98.5639, loss: 0.0388/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:16:55,380 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 0:38:39, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0335, decode.acc_seg: 98.7196, loss: 0.0335/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:17:15,208 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 0:38:17, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0373, decode.acc_seg: 98.5983, loss: 0.0373/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:17:35,191 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 0:37:55, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0422, decode.acc_seg: 98.4029, loss: 0.0422/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:17:55,062 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 0:37:33, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0395, decode.acc_seg: 98.5114, loss: 0.0395/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:18:14,985 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 0:37:11, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0389, decode.acc_seg: 98.5578, loss: 0.0389/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:18:34,795 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 0:36:49, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0387, decode.acc_seg: 98.5454, loss: 0.0387/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:18:54,617 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 0:36:27, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0391, decode.acc_seg: 98.6001, loss: 0.0391/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:19:14,365 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 18:19:14,365 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 0:36:05, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0536, decode.acc_seg: 97.9984, loss: 0.0536/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:19:34,219 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 0:35:43, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0408, decode.acc_seg: 98.4345, loss: 0.0408/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:19:54,131 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 0:35:21, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0366, decode.acc_seg: 98.5816, loss: 0.0366/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:20:13,851 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 0:34:59, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0388, decode.acc_seg: 98.4623, loss: 0.0388/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:20:33,598 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 0:34:38, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0408, decode.acc_seg: 98.4138, loss: 0.0408/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:20:53,290 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 0:34:16, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0353, decode.acc_seg: 98.6084, loss: 0.0353/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:21:13,280 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 0:33:54, time: 0.400, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0414, decode.acc_seg: 98.4599, loss: 0.0414/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:21:32,985 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 0:33:32, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0455, decode.acc_seg: 98.2904, loss: 0.0455/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:21:52,820 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 0:33:10, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0459, decode.acc_seg: 98.3664, loss: 0.0459/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:22:12,699 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 0:32:48, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0380, decode.acc_seg: 98.5891, loss: 0.0380/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:22:32,437 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 0:32:26, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0413, decode.acc_seg: 98.4975, loss: 0.0413/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:22:52,374 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 0:32:04, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0355, decode.acc_seg: 98.6507, loss: 0.0355/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:23:12,233 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 0:31:43, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0454, decode.acc_seg: 98.3552, loss: 0.0454/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:23:32,016 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 0:31:21, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0406, decode.acc_seg: 98.4729, loss: 0.0406/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:23:51,984 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 0:30:59, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0408, decode.acc_seg: 98.4491, loss: 0.0408/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:24:11,734 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 0:30:37, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0415, decode.acc_seg: 98.4339, loss: 0.0415/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:24:31,679 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 0:30:15, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0401, decode.acc_seg: 98.4213, loss: 0.0401/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:24:51,494 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 0:29:53, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0378, decode.acc_seg: 98.6003, loss: 0.0378/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:25:11,449 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 0:29:32, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0346, decode.acc_seg: 98.6649, loss: 0.0346/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:25:31,272 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 0:29:10, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0418, decode.acc_seg: 98.4996, loss: 0.0418[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.0 task/s, elapsed: 1s, ETA:   916s[                                 ] 2/929, 1.8 task/s, elapsed: 1s, ETA:   504s[                                 ] 3/929, 2.5 task/s, elapsed: 1s, ETA:   365s[                                 ] 4/929, 3.1 task/s, elapsed: 1s, ETA:   296s[                                 ] 5/929, 3.6 task/s, elapsed: 1s, ETA:   254s[                                 ] 6/929, 4.1 task/s, elapsed: 1s, ETA:   226s[                                 ] 7/929, 4.5 task/s, elapsed: 2s, ETA:   206s[                                 ] 8/929, 4.8 task/s, elapsed: 2s, ETA:   191s[                                 ] 9/929, 5.1 task/s, elapsed: 2s, ETA:   180s[                                ] 10/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 11/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 12/929, 5.9 task/s, elapsed: 2s, ETA:   156s[                                ] 13/929, 6.1 task/s, elapsed: 2s, ETA:   151s[                                ] 14/929, 6.2 task/s, elapsed: 2s, ETA:   146s[                                ] 15/929, 6.4 task/s, elapsed: 2s, ETA:   142s[                                ] 16/929, 6.6 task/s, elapsed: 2s, ETA:   139s[                                ] 17/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 18/929, 6.9 task/s, elapsed: 3s, ETA:   133s[                                ] 19/929, 7.0 task/s, elapsed: 3s, ETA:   130s[                                ] 20/929, 7.1 task/s, elapsed: 3s, ETA:   128s[                                ] 21/929, 7.2 task/s, elapsed: 3s, ETA:   126s[                                ] 22/929, 7.3 task/s, elapsed: 3s, ETA:   124s[                                ] 23/929, 7.4 task/s, elapsed: 3s, ETA:   122s[                                ] 24/929, 7.5 task/s, elapsed: 3s, ETA:   120s[                                ] 25/929, 7.6 task/s, elapsed: 3s, ETA:   119s[                                ] 26/929, 7.6 task/s, elapsed: 3s, ETA:   119s[                                ] 27/929, 7.6 task/s, elapsed: 4s, ETA:   118s[                                ] 28/929, 7.6 task/s, elapsed: 4s, ETA:   118s[                                ] 29/929, 7.7 task/s, elapsed: 4s, ETA:   117s[>                               ] 30/929, 7.7 task/s, elapsed: 4s, ETA:   116s[>                               ] 31/929, 7.7 task/s, elapsed: 4s, ETA:   116s[>                               ] 32/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 33/929, 7.8 task/s, elapsed: 4s, ETA:   114s[>                               ] 34/929, 7.9 task/s, elapsed: 4s, ETA:   113s[>                               ] 35/929, 8.0 task/s, elapsed: 4s, ETA:   112s[>                               ] 36/929, 8.0 task/s, elapsed: 4s, ETA:   112s[>                               ] 37/929, 8.1 task/s, elapsed: 5s, ETA:   111s[>                               ] 38/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 39/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 40/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 41/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 42/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 43/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 44/929, 8.4 task/s, elapsed: 5s, ETA:   106s[>                               ] 45/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 46/929, 8.4 task/s, elapsed: 5s, ETA:   105s[>                               ] 47/929, 8.5 task/s, elapsed: 6s, ETA:   104s[>                               ] 48/929, 8.5 task/s, elapsed: 6s, ETA:   104s[>                               ] 49/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 50/929, 8.6 task/s, elapsed: 6s, ETA:   103s[>                               ] 51/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 52/929, 8.6 task/s, elapsed: 6s, ETA:   102s[>                               ] 53/929, 8.6 task/s, elapsed: 6s, ETA:   101s[>                               ] 54/929, 8.7 task/s, elapsed: 6s, ETA:   101s[>                               ] 55/929, 8.7 task/s, elapsed: 6s, ETA:   100s[>                               ] 56/929, 8.7 task/s, elapsed: 6s, ETA:   100s[>                               ] 57/929, 8.7 task/s, elapsed: 7s, ETA:   100s[>                               ] 58/929, 8.8 task/s, elapsed: 7s, ETA:    99s[>>                              ] 59/929, 8.8 task/s, elapsed: 7s, ETA:    99s[>>                              ] 60/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 61/929, 8.8 task/s, elapsed: 7s, ETA:    98s[>>                              ] 62/929, 8.9 task/s, elapsed: 7s, ETA:    98s[>>                              ] 63/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 64/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 65/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 66/929, 8.9 task/s, elapsed: 7s, ETA:    96s[>>                              ] 67/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 68/929, 9.0 task/s, elapsed: 8s, ETA:    96s[>>                              ] 69/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 70/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 71/929, 9.0 task/s, elapsed: 8s, ETA:    95s[>>                              ] 72/929, 9.1 task/s, elapsed: 8s, ETA:    95s[>>                              ] 73/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 74/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 75/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 76/929, 9.1 task/s, elapsed: 8s, ETA:    93s[>>                              ] 77/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 78/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 79/929, 9.1 task/s, elapsed: 9s, ETA:    93s[>>                              ] 80/929, 9.2 task/s, elapsed: 9s, ETA:    93s[>>                              ] 81/929, 9.2 task/s, elapsed: 9s, ETA:    93s[>>                              ] 82/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 83/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 84/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 85/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 86/929, 9.2 task/s, elapsed: 9s, ETA:    91s[>>                              ] 87/929, 9.2 task/s, elapsed: 9s, ETA:    91s[>>                             ] 88/929, 9.3 task/s, elapsed: 10s, ETA:    91s[>>                             ] 89/929, 9.3 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 90/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 91/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 92/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 93/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 94/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 95/929, 9.3 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 96/929, 9.3 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 97/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 98/929, 9.4 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 99/929, 9.4 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 100/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 101/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 102/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 103/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 104/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 105/929, 9.4 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 106/929, 9.4 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 107/929, 9.4 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 108/929, 9.4 task/s, elapsed: 11s, ETA:    87s[>>>                           ] 109/929, 9.5 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 110/929, 9.5 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 111/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 112/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 113/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 114/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 115/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 116/929, 9.4 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 117/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 118/929, 9.5 task/s, elapsed: 12s, ETA:    86s[>>>                           ] 119/929, 9.5 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 120/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 121/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 122/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>                           ] 123/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 124/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 125/929, 9.5 task/s, elapsed: 13s, ETA:    85s[>>>>                          ] 126/929, 9.5 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 127/929, 9.5 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 128/929, 9.5 task/s, elapsed: 13s, ETA:    84s[>>>>                          ] 129/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 130/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 131/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 132/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 133/929, 9.5 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 134/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 135/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 136/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 137/929, 9.5 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 138/929, 9.6 task/s, elapsed: 14s, ETA:    83s[>>>>                          ] 139/929, 9.6 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 140/929, 9.6 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 141/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 142/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 143/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 144/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 145/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 146/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 147/929, 9.6 task/s, elapsed: 15s, ETA:    82s[>>>>                          ] 148/929, 9.6 task/s, elapsed: 15s, ETA:    81s[>>>>                          ] 149/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 150/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 151/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 152/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 153/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>                          ] 154/929, 9.6 task/s, elapsed: 16s, ETA:    81s[>>>>>                         ] 155/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 156/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 157/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 158/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 159/929, 9.6 task/s, elapsed: 16s, ETA:    80s[>>>>>                         ] 160/929, 9.6 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 161/929, 9.7 task/s, elapsed: 17s, ETA:    80s[>>>>>                         ] 162/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 163/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 164/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 165/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 166/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 167/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 168/929, 9.7 task/s, elapsed: 17s, ETA:    79s[>>>>>                         ] 169/929, 9.7 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 170/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 171/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 172/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 173/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 174/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 175/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 176/929, 9.7 task/s, elapsed: 18s, ETA:    78s[>>>>>                         ] 177/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 178/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 179/929, 9.7 task/s, elapsed: 18s, ETA:    77s[>>>>>                         ] 180/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 181/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 182/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 183/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 184/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>                         ] 185/929, 9.7 task/s, elapsed: 19s, ETA:    77s[>>>>>>                        ] 186/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 187/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 188/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 189/929, 9.7 task/s, elapsed: 19s, ETA:    76s[>>>>>>                        ] 190/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 191/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 192/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 193/929, 9.7 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 194/929, 9.7 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 195/929, 9.7 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 196/929, 9.7 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 197/929, 9.7 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 198/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 199/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 200/929, 9.8 task/s, elapsed: 20s, ETA:    75s[>>>>>>                        ] 201/929, 9.8 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 202/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 203/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 204/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 205/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 206/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 207/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 208/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 209/929, 9.8 task/s, elapsed: 21s, ETA:    74s[>>>>>>                        ] 210/929, 9.8 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 211/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 212/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 213/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 214/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 215/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>                        ] 216/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 217/929, 9.8 task/s, elapsed: 22s, ETA:    73s[>>>>>>>                       ] 218/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 219/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 220/929, 9.8 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 221/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 222/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 223/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 224/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 225/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 226/929, 9.8 task/s, elapsed: 23s, ETA:    72s[>>>>>>>                       ] 227/929, 9.8 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 228/929, 9.8 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 229/929, 9.8 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 230/929, 9.8 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 231/929, 9.8 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                       ] 232/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 233/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 234/929, 9.8 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 235/929, 9.8 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 236/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 237/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 238/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 239/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 240/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 241/929, 9.9 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                       ] 242/929, 9.9 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 243/929, 9.9 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 244/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 245/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 246/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>                       ] 247/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 248/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 249/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 250/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 251/929, 9.9 task/s, elapsed: 25s, ETA:    69s[>>>>>>>>                      ] 252/929, 9.9 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 253/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 254/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 255/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 256/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 257/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 258/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 259/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 260/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 261/929, 9.9 task/s, elapsed: 26s, ETA:    68s[>>>>>>>>                      ] 262/929, 9.9 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                      ] 263/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 264/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 265/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 266/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 267/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 268/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 269/929, 9.9 task/s, elapsed: 27s, ETA:    67s[>>>>>>>>                      ] 270/929, 9.9 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                      ] 271/929, 9.9 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                      ] 272/929, 9.9 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                      ] 273/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 274/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 275/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 276/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 277/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                      ] 278/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 279/929, 9.9 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>>                     ] 280/929, 9.9 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>>                     ] 281/929, 9.9 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>>                     ] 282/929, 9.9 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>>                     ] 283/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 284/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 285/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 286/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 287/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 288/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 289/929, 9.9 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>>                     ] 290/929, 9.9 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                     ] 291/929, 9.9 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                     ] 292/929, 9.9 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                     ] 293/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 294/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 295/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 296/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 297/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 298/929, 9.9 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 299/929, 9.9 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                     ] 300/929, 9.9 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                     ] 301/929, 9.9 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                     ] 302/929, 9.9 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                     ] 303/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 304/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 305/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 306/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 307/929, 9.9 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 308/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                     ] 309/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 310/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 311/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 312/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 313/929, 9.9 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 314/929, 9.9 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>                    ] 315/929, 10.0 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>                    ] 316/929, 10.0 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>                    ] 317/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 318/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 319/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 320/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 321/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 322/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 323/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 324/929, 10.0 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                   ] 325/929, 10.0 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                   ] 326/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 327/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 328/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 329/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 330/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 331/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 332/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 333/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 334/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 335/929, 10.0 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                   ] 336/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 337/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 338/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 339/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 340/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 341/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 342/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 343/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 344/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 345/929, 10.0 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>                   ] 346/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 347/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 348/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 349/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 350/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 351/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 352/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                  ] 353/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                  ] 354/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                  ] 355/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 356/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 357/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 358/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 359/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 360/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 361/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 362/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 363/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 364/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 365/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 366/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 367/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 368/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 369/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 370/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 371/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 372/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 373/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 374/929, 10.0 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 375/929, 10.0 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 376/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 377/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 378/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 379/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 380/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 381/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 382/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 383/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 384/929, 10.0 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 385/929, 10.0 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 387/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 388/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 389/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 390/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 391/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 392/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 393/929, 10.0 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 394/929, 10.0 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.0 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 397/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 398/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 399/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 400/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 401/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 402/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 403/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 404/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 407/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 408/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 409/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 410/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 411/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 412/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 413/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 414/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 415/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.0 task/s, elapsed: 41s, ETA:    51s[>>>>>>>>>>>>>                ] 417/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 418/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 419/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 420/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 421/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 422/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 423/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 424/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 425/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.0 task/s, elapsed: 42s, ETA:    50s[>>>>>>>>>>>>>                ] 427/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 428/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 429/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 430/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 431/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 432/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 433/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 434/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 435/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.0 task/s, elapsed: 43s, ETA:    49s[>>>>>>>>>>>>>                ] 437/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 438/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 439/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 440/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 441/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 442/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 443/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 444/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 445/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 447/929, 10.0 task/s, elapsed: 44s, ETA:    48s[>>>>>>>>>>>>>                ] 448/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 449/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 450/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 451/929, 10.1 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 452/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 453/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 454/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 455/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 457/929, 10.1 task/s, elapsed: 45s, ETA:    47s[>>>>>>>>>>>>>>               ] 458/929, 10.1 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 459/929, 10.1 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 460/929, 10.1 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 461/929, 10.1 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 462/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 463/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 464/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 465/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 466/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 467/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 468/929, 10.1 task/s, elapsed: 46s, ETA:    46s[>>>>>>>>>>>>>>               ] 469/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 470/929, 10.1 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 471/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 472/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 473/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 474/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 475/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 477/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 478/929, 10.1 task/s, elapsed: 47s, ETA:    45s[>>>>>>>>>>>>>>               ] 479/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 480/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 481/929, 10.1 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 482/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 483/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 484/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 485/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 487/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 488/929, 10.1 task/s, elapsed: 48s, ETA:    44s[>>>>>>>>>>>>>>>              ] 489/929, 10.1 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 490/929, 10.1 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 491/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 492/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 493/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 494/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 495/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 496/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 497/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 498/929, 10.1 task/s, elapsed: 49s, ETA:    43s[>>>>>>>>>>>>>>>              ] 499/929, 10.1 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 500/929, 10.1 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 501/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 502/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 503/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 504/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 505/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 506/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 507/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 508/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 509/929, 10.1 task/s, elapsed: 50s, ETA:    42s[>>>>>>>>>>>>>>>              ] 510/929, 10.1 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 511/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>              ] 512/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 513/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 514/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 515/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 516/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 517/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 518/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 519/929, 10.1 task/s, elapsed: 51s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 520/929, 10.1 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 521/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 522/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 523/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 524/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 525/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 526/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 527/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 528/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 529/929, 10.1 task/s, elapsed: 52s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 530/929, 10.1 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 531/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 532/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 533/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 534/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 535/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 537/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 538/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 539/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 540/929, 10.1 task/s, elapsed: 53s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 541/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 542/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 543/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>             ] 544/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.1 task/s, elapsed: 54s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.1 task/s, elapsed: 55s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.1 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.1 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.1 task/s, elapsed: 58s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.1 task/s, elapsed: 58s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.1 task/s, elapsed: 59s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.1 task/s, elapsed: 59s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.1 task/s, elapsed: 60s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.1 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.1 task/s, elapsed: 60s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.1 task/s, elapsed: 61s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.1 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.1 task/s, elapsed: 61s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.1 task/s, elapsed: 62s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.1 task/s, elapsed: 62s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.1 task/s, elapsed: 63s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.1 task/s, elapsed: 63s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.1 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.1 task/s, elapsed: 64s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.1 task/s, elapsed: 65s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.1 task/s, elapsed: 65s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.1 task/s, elapsed: 66s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.1 task/s, elapsed: 66s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.1 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.1 task/s, elapsed: 67s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.1 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.1 task/s, elapsed: 68s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.1 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.1 task/s, elapsed: 69s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.1 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.1 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.1 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.1 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.1 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.1 task/s, elapsed: 70s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.1 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.1 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.1 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.1 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.1 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.1 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.1 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.2 task/s, elapsed: 71s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.2 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.2 task/s, elapsed: 72s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.2 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.2 task/s, elapsed: 73s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.2 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.2 task/s, elapsed: 74s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.2 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.2 task/s, elapsed: 75s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.2 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.2 task/s, elapsed: 76s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.2 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.2 task/s, elapsed: 77s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.2 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.2 task/s, elapsed: 78s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.2 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.2 task/s, elapsed: 79s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.2 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.2 task/s, elapsed: 80s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.2 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.2 task/s, elapsed: 81s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.2 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.2 task/s, elapsed: 82s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.2 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.2 task/s, elapsed: 83s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.2 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.2 task/s, elapsed: 84s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.2 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.2 task/s, elapsed: 85s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.2 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.2 task/s, elapsed: 86s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.2 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.2 task/s, elapsed: 87s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.2 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.2 task/s, elapsed: 88s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.2 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.2 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.2 task/s, elapsed: 89s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.2 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.2 task/s, elapsed: 90s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.2 task/s, elapsed: 91s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.2 task/s, elapsed: 91s, ETA:     0s2022-10-03 18:28:14,687 - mmseg - INFO - per class results:2022-10-03 18:28:14,688 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  |  91.2 | 96.06 || rigid_plastic | 30.72 | 34.67 ||   cardboard   | 58.73 | 74.01 ||     metal     | 29.31 | 35.33 ||  soft_plastic | 63.85 | 73.15 |+---------------+-------+-------+2022-10-03 18:28:14,688 - mmseg - INFO - Summary:2022-10-03 18:28:14,688 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.72 | 54.76 | 62.65 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:28:14,692 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 18:28:14,692 - mmseg - INFO - Iter [929/40000]	lr: 6.002e-06, eta: 0:28:48, time: 0.399, data_time: 0.007, memory: 11956, aAcc: 0.9172, mIoU: 0.5476, mAcc: 0.6265, IoU.background: 0.9120, IoU.rigid_plastic: 0.3072, IoU.cardboard: 0.5873, IoU.metal: 0.2931, IoU.soft_plastic: 0.6385, Acc.background: 0.9606, Acc.rigid_plastic: 0.3467, Acc.cardboard: 0.7401, Acc.metal: 0.3533, Acc.soft_plastic: 0.7315, decode.loss_seg: 0.0386, decode.acc_seg: 98.6005, loss: 0.0386/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:28:36,377 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 0:28:42, time: 3.303, data_time: 2.913, memory: 11956, decode.loss_seg: 0.0362, decode.acc_seg: 98.5898, loss: 0.0362/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:28:56,133 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 0:28:20, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0423, decode.acc_seg: 98.5120, loss: 0.0423/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:29:15,889 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 0:27:58, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0369, decode.acc_seg: 98.5744, loss: 0.0369/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:29:35,549 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 0:27:36, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0371, decode.acc_seg: 98.6065, loss: 0.0371/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:29:55,245 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 0:27:14, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0387, decode.acc_seg: 98.5236, loss: 0.0387/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:30:15,049 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 0:26:52, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0369, decode.acc_seg: 98.6060, loss: 0.0369/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:30:34,782 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 0:26:30, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0402, decode.acc_seg: 98.4965, loss: 0.0402/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:30:54,580 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 0:26:08, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0347, decode.acc_seg: 98.6520, loss: 0.0347/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:31:14,421 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 0:25:46, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0370, decode.acc_seg: 98.6135, loss: 0.0370/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:31:34,264 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 0:25:24, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0438, decode.acc_seg: 98.3784, loss: 0.0438/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:31:54,294 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 0:25:02, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0394, decode.acc_seg: 98.5831, loss: 0.0394/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:32:13,959 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 0:24:40, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0363, decode.acc_seg: 98.6189, loss: 0.0363/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:32:33,750 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 0:24:18, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0344, decode.acc_seg: 98.6812, loss: 0.0344/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:32:53,518 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 0:23:56, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0344, decode.acc_seg: 98.6554, loss: 0.0344/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:33:13,330 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 0:23:34, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0365, decode.acc_seg: 98.6639, loss: 0.0365/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:33:33,093 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 0:23:12, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0407, decode.acc_seg: 98.4163, loss: 0.0407/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:33:52,815 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 0:22:50, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0404, decode.acc_seg: 98.4666, loss: 0.0404/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:34:12,560 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 0:22:29, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0401, decode.acc_seg: 98.4885, loss: 0.0401/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:34:32,439 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 0:22:07, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0429, decode.acc_seg: 98.4195, loss: 0.0429/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:34:52,219 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 18:34:52,220 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 0:21:45, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0376, decode.acc_seg: 98.6255, loss: 0.0376/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:35:12,005 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 0:21:23, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0364, decode.acc_seg: 98.6050, loss: 0.0364/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:35:31,901 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 0:21:01, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0336, decode.acc_seg: 98.7185, loss: 0.0336/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:35:51,718 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 0:20:39, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0394, decode.acc_seg: 98.4446, loss: 0.0394/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:36:11,376 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 0:20:17, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0349, decode.acc_seg: 98.6529, loss: 0.0349/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:36:31,261 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:19:55, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0368, decode.acc_seg: 98.6011, loss: 0.0368/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:36:51,004 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:19:33, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0357, decode.acc_seg: 98.5794, loss: 0.0357/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:37:10,880 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:19:11, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0414, decode.acc_seg: 98.4783, loss: 0.0414/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:37:30,619 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:18:50, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0317, decode.acc_seg: 98.7942, loss: 0.0317/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:37:50,417 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:18:28, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0435, decode.acc_seg: 98.4272, loss: 0.0435/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:38:10,185 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:18:06, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0360, decode.acc_seg: 98.5979, loss: 0.0360/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:38:32,278 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:17:44, time: 0.442, data_time: 0.049, memory: 11956, decode.loss_seg: 0.0401, decode.acc_seg: 98.5017, loss: 0.0401/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:38:52,089 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:17:22, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0401, decode.acc_seg: 98.5249, loss: 0.0401/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:39:11,941 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:17:00, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0365, decode.acc_seg: 98.6378, loss: 0.0365/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:39:31,856 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:16:39, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0382, decode.acc_seg: 98.5240, loss: 0.0382/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:39:51,753 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:16:17, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0355, decode.acc_seg: 98.6754, loss: 0.0355/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:40:11,440 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:15:55, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0359, decode.acc_seg: 98.6650, loss: 0.0359/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:40:31,331 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:15:33, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0403, decode.acc_seg: 98.4541, loss: 0.0403/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:40:51,168 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:15:11, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0373, decode.acc_seg: 98.5446, loss: 0.0373/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:41:10,950 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:14:50, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0386, decode.acc_seg: 98.4886, loss: 0.0386/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:41:30,768 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 18:41:30,768 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:14:28, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0376, decode.acc_seg: 98.5834, loss: 0.0376/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:41:50,566 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:14:06, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0397, decode.acc_seg: 98.5730, loss: 0.0397/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:42:10,486 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:13:44, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0366, decode.acc_seg: 98.6273, loss: 0.0366/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:42:30,353 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:13:22, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0390, decode.acc_seg: 98.5366, loss: 0.0390/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:42:50,163 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:13:01, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0362, decode.acc_seg: 98.6252, loss: 0.0362/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:43:09,803 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:12:39, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0422, decode.acc_seg: 98.4416, loss: 0.0422/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:43:29,881 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:12:17, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0389, decode.acc_seg: 98.5522, loss: 0.0389/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:43:49,612 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:11:55, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0325, decode.acc_seg: 98.7433, loss: 0.0325/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:44:09,487 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:11:33, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0444, decode.acc_seg: 98.3469, loss: 0.0444/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:44:29,502 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:11:12, time: 0.400, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0364, decode.acc_seg: 98.6028, loss: 0.0364/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:44:49,206 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:10:50, time: 0.394, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0344, decode.acc_seg: 98.6963, loss: 0.0344/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:45:08,992 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:10:28, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0386, decode.acc_seg: 98.5213, loss: 0.0386/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:45:28,841 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:10:06, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0375, decode.acc_seg: 98.5869, loss: 0.0375/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:45:48,504 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:09:45, time: 0.393, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0345, decode.acc_seg: 98.6071, loss: 0.0345/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:46:08,399 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:09:23, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0369, decode.acc_seg: 98.6305, loss: 0.0369/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:46:28,124 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:09:01, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0439, decode.acc_seg: 98.3027, loss: 0.0439/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:46:48,209 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:08:40, time: 0.402, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0414, decode.acc_seg: 98.4106, loss: 0.0414/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:47:08,022 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:08:18, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0376, decode.acc_seg: 98.5920, loss: 0.0376/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:47:27,942 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:07:56, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0394, decode.acc_seg: 98.4903, loss: 0.0394/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:47:47,722 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:07:34, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0319, decode.acc_seg: 98.7762, loss: 0.0319/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:48:07,525 - mmseg - INFO - Exp name: 221003_1406_segformer_mitb5_source-only_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed0_246462022-10-03 18:48:07,525 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:07:13, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0387, decode.acc_seg: 98.4785, loss: 0.0387/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:48:29,089 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:06:51, time: 0.431, data_time: 0.041, memory: 11956, decode.loss_seg: 0.0383, decode.acc_seg: 98.5824, loss: 0.0383/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:48:49,012 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:06:29, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0390, decode.acc_seg: 98.4629, loss: 0.0390/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:49:08,907 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:06:08, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0411, decode.acc_seg: 98.4036, loss: 0.0411/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:49:28,817 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:05:46, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0379, decode.acc_seg: 98.5237, loss: 0.0379/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:49:48,706 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:05:24, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0318, decode.acc_seg: 98.8060, loss: 0.0318/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:50:08,753 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:05:03, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0363, decode.acc_seg: 98.6682, loss: 0.0363/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:50:28,511 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:04:41, time: 0.395, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0362, decode.acc_seg: 98.6208, loss: 0.0362/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:50:48,327 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:04:19, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0343, decode.acc_seg: 98.6738, loss: 0.0343/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:51:08,120 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:03:58, time: 0.396, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0374, decode.acc_seg: 98.5963, loss: 0.0374/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:51:28,069 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:03:36, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0328, decode.acc_seg: 98.7588, loss: 0.0328/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:51:47,952 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:03:14, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0372, decode.acc_seg: 98.5386, loss: 0.0372/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:52:07,824 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:02:53, time: 0.397, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0390, decode.acc_seg: 98.4934, loss: 0.0390/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:52:27,774 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:02:31, time: 0.399, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0369, decode.acc_seg: 98.5861, loss: 0.0369/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:52:47,684 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:02:09, time: 0.398, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0339, decode.acc_seg: 98.6594, loss: 0.0339/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:53:07,717 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:01:48, time: 0.401, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0418, decode.acc_seg: 98.4637, loss: 0.0418/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:53:28,285 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:01:26, time: 0.411, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0379, decode.acc_seg: 98.5427, loss: 0.0379/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:53:49,127 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:01:04, time: 0.417, data_time: 0.008, memory: 11956, decode.loss_seg: 0.0359, decode.acc_seg: 98.6343, loss: 0.0359/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:54:09,762 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:00:43, time: 0.413, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0375, decode.acc_seg: 98.5956, loss: 0.0375/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-03 18:54:30,002 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:00:21, time: 0.405, data_time: 0.007, memory: 11956, decode.loss_seg: 0.0325, decode.acc_seg: 98.7318, loss: 0.0325[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.6 task/s, elapsed: 2s, ETA:  1558s[                                 ] 2/929, 1.1 task/s, elapsed: 2s, ETA:   827s[                                 ] 3/929, 1.6 task/s, elapsed: 2s, ETA:   584s[                                 ] 4/929, 2.0 task/s, elapsed: 2s, ETA:   462s[                                 ] 5/929, 2.4 task/s, elapsed: 2s, ETA:   387s[                                 ] 6/929, 2.7 task/s, elapsed: 2s, ETA:   337s[                                 ] 7/929, 3.1 task/s, elapsed: 2s, ETA:   302s[                                 ] 8/929, 3.3 task/s, elapsed: 2s, ETA:   275s[                                 ] 9/929, 3.6 task/s, elapsed: 3s, ETA:   256s[                                ] 10/929, 3.8 task/s, elapsed: 3s, ETA:   239s[                                ] 11/929, 4.1 task/s, elapsed: 3s, ETA:   225s[                                ] 12/929, 4.3 task/s, elapsed: 3s, ETA:   214s[                                ] 13/929, 4.5 task/s, elapsed: 3s, ETA:   205s[                                ] 14/929, 4.6 task/s, elapsed: 3s, ETA:   197s[                                ] 15/929, 4.8 task/s, elapsed: 3s, ETA:   190s[                                ] 16/929, 5.0 task/s, elapsed: 3s, ETA:   184s[                                ] 17/929, 5.1 task/s, elapsed: 3s, ETA:   178s[                                ] 18/929, 5.3 task/s, elapsed: 3s, ETA:   173s[                                ] 19/929, 5.4 task/s, elapsed: 4s, ETA:   169s[                                ] 20/929, 5.5 task/s, elapsed: 4s, ETA:   165s[                                ] 21/929, 5.6 task/s, elapsed: 4s, ETA:   161s[                                ] 22/929, 5.7 task/s, elapsed: 4s, ETA:   158s[                                ] 23/929, 5.8 task/s, elapsed: 4s, ETA:   155s[                                ] 24/929, 5.9 task/s, elapsed: 4s, ETA:   152s[                                ] 25/929, 6.0 task/s, elapsed: 4s, ETA:   150s[                                ] 26/929, 6.1 task/s, elapsed: 4s, ETA:   147s[                                ] 27/929, 6.2 task/s, elapsed: 4s, ETA:   145s[                                ] 28/929, 6.3 task/s, elapsed: 4s, ETA:   143s[                                ] 29/929, 6.4 task/s, elapsed: 5s, ETA:   142s[>                               ] 30/929, 6.4 task/s, elapsed: 5s, ETA:   140s[>                               ] 31/929, 6.5 task/s, elapsed: 5s, ETA:   138s[>                               ] 32/929, 6.6 task/s, elapsed: 5s, ETA:   137s[>                               ] 33/929, 6.6 task/s, elapsed: 5s, ETA:   135s[>                               ] 34/929, 6.7 task/s, elapsed: 5s, ETA:   134s[>                               ] 35/929, 6.7 task/s, elapsed: 5s, ETA:   132s[>                               ] 36/929, 6.8 task/s, elapsed: 5s, ETA:   131s[>                               ] 37/929, 6.9 task/s, elapsed: 5s, ETA:   130s[>                               ] 38/929, 6.9 task/s, elapsed: 5s, ETA:   129s[>                               ] 39/929, 7.0 task/s, elapsed: 6s, ETA:   128s[>                               ] 40/929, 7.0 task/s, elapsed: 6s, ETA:   126s[>                               ] 41/929, 7.1 task/s, elapsed: 6s, ETA:   125s[>                               ] 42/929, 7.1 task/s, elapsed: 6s, ETA:   125s[>                               ] 43/929, 7.2 task/s, elapsed: 6s, ETA:   124s[>                               ] 44/929, 7.2 task/s, elapsed: 6s, ETA:   123s[>                               ] 45/929, 7.3 task/s, elapsed: 6s, ETA:   122s[>                               ] 46/929, 7.3 task/s, elapsed: 6s, ETA:   121s[>                               ] 47/929, 7.3 task/s, elapsed: 6s, ETA:   120s[>                               ] 48/929, 7.4 task/s, elapsed: 7s, ETA:   120s[>                               ] 49/929, 7.4 task/s, elapsed: 7s, ETA:   119s[>                               ] 50/929, 7.4 task/s, elapsed: 7s, ETA:   118s[>                               ] 51/929, 7.5 task/s, elapsed: 7s, ETA:   118s[>                               ] 52/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 53/929, 7.5 task/s, elapsed: 7s, ETA:   116s[>                               ] 54/929, 7.6 task/s, elapsed: 7s, ETA:   116s[>                               ] 55/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 56/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 57/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 58/929, 7.7 task/s, elapsed: 8s, ETA:   114s[>>                              ] 59/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 60/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 61/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 62/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 63/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 64/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 65/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 66/929, 7.8 task/s, elapsed: 8s, ETA:   110s[>>                              ] 67/929, 7.8 task/s, elapsed: 9s, ETA:   110s[>>                              ] 68/929, 7.9 task/s, elapsed: 9s, ETA:   110s[>>                              ] 69/929, 7.9 task/s, elapsed: 9s, ETA:   109s[>>                              ] 70/929, 7.9 task/s, elapsed: 9s, ETA:   109s[>>                              ] 71/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 72/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 73/929, 8.0 task/s, elapsed: 9s, ETA:   108s[>>                              ] 74/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 75/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 76/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                             ] 77/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 78/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 79/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 80/929, 8.1 task/s, elapsed: 10s, ETA:   105s[>>                             ] 81/929, 8.1 task/s, elapsed: 10s, ETA:   105s[>>                             ] 82/929, 8.1 task/s, elapsed: 10s, ETA:   104s[>>                             ] 83/929, 8.1 task/s, elapsed: 10s, ETA:   104s[>>                             ] 84/929, 8.1 task/s, elapsed: 10s, ETA:   104s[>>                             ] 85/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 86/929, 8.2 task/s, elapsed: 11s, ETA:   103s[>>                             ] 87/929, 8.2 task/s, elapsed: 11s, ETA:   103s[>>                             ] 88/929, 8.2 task/s, elapsed: 11s, ETA:   103s[>>                             ] 89/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 90/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 91/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 92/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 93/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 94/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 95/929, 8.3 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 96/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                            ] 97/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                            ] 98/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                            ] 99/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 100/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 101/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 102/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 103/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 104/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 105/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 106/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 107/929, 8.4 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 108/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 109/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 110/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 111/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 112/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 113/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 114/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 115/929, 8.5 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 116/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 117/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 118/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 119/929, 8.6 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 120/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 121/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 122/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 123/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>>                          ] 124/929, 8.6 task/s, elapsed: 14s, ETA:    93s[>>>>                          ] 125/929, 8.6 task/s, elapsed: 14s, ETA:    93s[>>>>                          ] 126/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 127/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 128/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 129/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 130/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 131/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 132/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 133/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 134/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 135/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 136/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 137/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 138/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 139/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 140/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 141/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 142/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 143/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 144/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 145/929, 8.8 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 146/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 147/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 148/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 149/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 150/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 151/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 152/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 153/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 154/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>>                         ] 155/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 156/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 157/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 158/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 159/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 160/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 161/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 162/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 163/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 164/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 165/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 166/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 167/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 168/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 169/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 170/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 171/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 172/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 173/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 174/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 175/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 176/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 177/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 178/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 179/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 180/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 181/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 183/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 184/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>                         ] 185/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 186/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 187/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 188/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 191/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 192/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 193/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 194/929, 9.0 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 195/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 196/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 198/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 199/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 200/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.2 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.2 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 221/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 222/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 223/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 224/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 225/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 226/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 227/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 228/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 229/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 230/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 231/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 232/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.2 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 234/929, 9.2 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 235/929, 9.2 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 236/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 237/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 238/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 239/929, 9.3 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 240/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 241/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 242/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 243/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 244/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 245/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 246/929, 9.3 task/s, elapsed: 27s, ETA:    74s[>>>>>>>                       ] 247/929, 9.3 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 248/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 249/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 250/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 251/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 252/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 253/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 254/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 255/929, 9.3 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 256/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 257/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 258/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 259/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 260/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 261/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 262/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 263/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 264/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 265/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 266/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 267/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 268/929, 9.4 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 269/929, 9.4 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 270/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 271/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 272/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 273/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 274/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 275/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 276/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 277/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>                      ] 278/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 279/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 280/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 281/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 282/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 283/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 284/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 285/929, 9.4 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 286/929, 9.4 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 287/929, 9.4 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 288/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 289/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 290/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 291/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 292/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 293/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 294/929, 9.4 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 295/929, 9.4 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 296/929, 9.4 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 297/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 298/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 299/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 300/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 301/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 302/929, 9.4 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 303/929, 9.4 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 304/929, 9.4 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 305/929, 9.5 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 306/929, 9.5 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 307/929, 9.5 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 308/929, 9.5 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 309/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 310/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 311/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 312/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 313/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 314/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 315/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 316/929, 9.5 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 317/929, 9.5 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 318/929, 9.5 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 319/929, 9.5 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 320/929, 9.5 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 321/929, 9.5 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 322/929, 9.5 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 323/929, 9.5 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 324/929, 9.5 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 325/929, 9.5 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 326/929, 9.5 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 327/929, 9.5 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 328/929, 9.5 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 329/929, 9.5 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 330/929, 9.5 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 331/929, 9.5 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 332/929, 9.5 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 333/929, 9.5 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 334/929, 9.5 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 335/929, 9.5 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 336/929, 9.5 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 337/929, 9.5 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 338/929, 9.5 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 339/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>                    ] 340/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 341/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 342/929, 9.5 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 343/929, 9.5 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 344/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 345/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 346/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 347/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 348/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 349/929, 9.6 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 350/929, 9.6 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 351/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 352/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 353/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 354/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 355/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 356/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 357/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 358/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 359/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 360/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 361/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 362/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 363/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 364/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 365/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 366/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 367/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 368/929, 9.6 task/s, elapsed: 38s, ETA:    58s[>>>>>>>>>>>                   ] 369/929, 9.6 task/s, elapsed: 38s, ETA:    58s[>>>>>>>>>>>                   ] 370/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>                   ] 371/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 372/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 373/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 374/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 375/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 376/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 377/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 378/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 379/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 380/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 381/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 382/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 383/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 384/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 385/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 386/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 387/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 388/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 389/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 390/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 391/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 392/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 393/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 394/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 395/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 396/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 397/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 398/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 399/929, 9.7 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 400/929, 9.7 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 401/929, 9.7 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>                  ] 402/929, 9.7 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>>                 ] 403/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 404/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 405/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 406/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 407/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 408/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 409/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 410/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 411/929, 9.7 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 412/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 413/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 414/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 415/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 416/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 417/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 418/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 419/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 420/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 421/929, 9.7 task/s, elapsed: 43s, ETA:    52s[>>>>>>>>>>>>>                 ] 422/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 423/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 424/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 425/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 426/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 427/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 428/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 429/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 430/929, 9.7 task/s, elapsed: 44s, ETA:    51s[>>>>>>>>>>>>>                 ] 431/929, 9.7 task/s, elapsed: 44s, ETA:    51s[>>>>>>>>>>>>>                 ] 432/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>                 ] 433/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 434/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 435/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 436/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 437/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 438/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 439/929, 9.7 task/s, elapsed: 45s, ETA:    50s[>>>>>>>>>>>>>>                ] 440/929, 9.7 task/s, elapsed: 45s, ETA:    50s[>>>>>>>>>>>>>>                ] 441/929, 9.7 task/s, elapsed: 45s, ETA:    50s[>>>>>>>>>>>>>>                ] 442/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 443/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 444/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 445/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 446/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 447/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 448/929, 9.7 task/s, elapsed: 46s, ETA:    49s[>>>>>>>>>>>>>>                ] 449/929, 9.7 task/s, elapsed: 46s, ETA:    49s[>>>>>>>>>>>>>>                ] 450/929, 9.7 task/s, elapsed: 46s, ETA:    49s[>>>>>>>>>>>>>>                ] 451/929, 9.7 task/s, elapsed: 46s, ETA:    49s[>>>>>>>>>>>>>>                ] 452/929, 9.7 task/s, elapsed: 46s, ETA:    49s[>>>>>>>>>>>>>>                ] 453/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 454/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 455/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 456/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 457/929, 9.7 task/s, elapsed: 47s, ETA:    48s[>>>>>>>>>>>>>>                ] 458/929, 9.7 task/s, elapsed: 47s, ETA:    48s[>>>>>>>>>>>>>>                ] 459/929, 9.7 task/s, elapsed: 47s, ETA:    48s[>>>>>>>>>>>>>>                ] 460/929, 9.7 task/s, elapsed: 47s, ETA:    48s[>>>>>>>>>>>>>>                ] 461/929, 9.7 task/s, elapsed: 47s, ETA:    48s[>>>>>>>>>>>>>>                ] 462/929, 9.7 task/s, elapsed: 47s, ETA:    48s[>>>>>>>>>>>>>>                ] 463/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>                ] 464/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>>               ] 465/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>>               ] 466/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>>               ] 467/929, 9.7 task/s, elapsed: 48s, ETA:    47s[>>>>>>>>>>>>>>>               ] 468/929, 9.7 task/s, elapsed: 48s, ETA:    47s[>>>>>>>>>>>>>>>               ] 469/929, 9.7 task/s, elapsed: 48s, ETA:    47s[>>>>>>>>>>>>>>>               ] 470/929, 9.7 task/s, elapsed: 48s, ETA:    47s[>>>>>>>>>>>>>>>               ] 471/929, 9.7 task/s, elapsed: 48s, ETA:    47s[>>>>>>>>>>>>>>>               ] 472/929, 9.7 task/s, elapsed: 48s, ETA:    47s[>>>>>>>>>>>>>>>               ] 473/929, 9.8 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 474/929, 9.8 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 475/929, 9.8 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 476/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 477/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 478/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 479/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 480/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 481/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 482/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 483/929, 9.8 task/s, elapsed: 49s, ETA:    46s[>>>>>>>>>>>>>>>               ] 484/929, 9.8 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 485/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 486/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 487/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 488/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 489/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 490/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 491/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 492/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 493/929, 9.8 task/s, elapsed: 50s, ETA:    45s[>>>>>>>>>>>>>>>               ] 494/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>               ] 495/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 496/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 497/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 498/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 499/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 500/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 501/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 502/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 503/929, 9.8 task/s, elapsed: 51s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 504/929, 9.8 task/s, elapsed: 51s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 505/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 506/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 507/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 508/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 509/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 510/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 511/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 512/929, 9.8 task/s, elapsed: 52s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 513/929, 9.8 task/s, elapsed: 52s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 514/929, 9.8 task/s, elapsed: 52s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 515/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 516/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 517/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 518/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 519/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 520/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 521/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 522/929, 9.8 task/s, elapsed: 53s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 523/929, 9.8 task/s, elapsed: 53s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 524/929, 9.8 task/s, elapsed: 53s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 525/929, 9.8 task/s, elapsed: 54s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 526/929, 9.8 task/s, elapsed: 54s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.8 task/s, elapsed: 54s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.8 task/s, elapsed: 54s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.8 task/s, elapsed: 54s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.8 task/s, elapsed: 54s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.8 task/s, elapsed: 54s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.8 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.8 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.8 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.8 task/s, elapsed: 55s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.8 task/s, elapsed: 55s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.8 task/s, elapsed: 55s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.8 task/s, elapsed: 55s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.8 task/s, elapsed: 55s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.8 task/s, elapsed: 55s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.8 task/s, elapsed: 55s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.8 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.8 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.8 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.8 task/s, elapsed: 56s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.8 task/s, elapsed: 56s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.8 task/s, elapsed: 56s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.8 task/s, elapsed: 56s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.8 task/s, elapsed: 56s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.8 task/s, elapsed: 56s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.8 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.8 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.8 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.8 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.8 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.8 task/s, elapsed: 57s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.8 task/s, elapsed: 57s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.8 task/s, elapsed: 57s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.8 task/s, elapsed: 57s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.8 task/s, elapsed: 57s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.8 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.8 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.8 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.8 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.8 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.8 task/s, elapsed: 58s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.8 task/s, elapsed: 58s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.8 task/s, elapsed: 58s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.8 task/s, elapsed: 58s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.8 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.8 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.8 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.8 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.8 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.8 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.8 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.8 task/s, elapsed: 59s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.8 task/s, elapsed: 59s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.8 task/s, elapsed: 59s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.9 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.9 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.9 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.9 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.9 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.9 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.9 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.9 task/s, elapsed: 60s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.9 task/s, elapsed: 60s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.9 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.9 task/s, elapsed: 61s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.9 task/s, elapsed: 61s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.9 task/s, elapsed: 62s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.9 task/s, elapsed: 63s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.9 task/s, elapsed: 63s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.9 task/s, elapsed: 64s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.9 task/s, elapsed: 64s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.9 task/s, elapsed: 64s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.9 task/s, elapsed: 65s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.9 task/s, elapsed: 65s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.9 task/s, elapsed: 65s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.9 task/s, elapsed: 66s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.9 task/s, elapsed: 66s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.9 task/s, elapsed: 66s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.9 task/s, elapsed: 67s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.9 task/s, elapsed: 67s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.9 task/s, elapsed: 68s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.9 task/s, elapsed: 68s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.9 task/s, elapsed: 69s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.9 task/s, elapsed: 69s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.9 task/s, elapsed: 69s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.8 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.8 task/s, elapsed: 70s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.8 task/s, elapsed: 70s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.9 task/s, elapsed: 70s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.8 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.8 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.8 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.8 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.8 task/s, elapsed: 71s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.8 task/s, elapsed: 71s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.8 task/s, elapsed: 71s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.8 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.8 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.8 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.8 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.8 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.8 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.8 task/s, elapsed: 72s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.8 task/s, elapsed: 72s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.8 task/s, elapsed: 72s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.8 task/s, elapsed: 72s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.8 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.8 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.8 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.8 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.8 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.8 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.8 task/s, elapsed: 73s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.8 task/s, elapsed: 73s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.8 task/s, elapsed: 73s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.8 task/s, elapsed: 73s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.8 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.8 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.8 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.8 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.8 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.8 task/s, elapsed: 74s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.8 task/s, elapsed: 74s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.8 task/s, elapsed: 74s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.8 task/s, elapsed: 74s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.8 task/s, elapsed: 74s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.8 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.8 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.8 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.8 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.8 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.8 task/s, elapsed: 75s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.8 task/s, elapsed: 75s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.8 task/s, elapsed: 75s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.8 task/s, elapsed: 75s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.8 task/s, elapsed: 75s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.8 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.8 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.8 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.8 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.8 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.8 task/s, elapsed: 76s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.8 task/s, elapsed: 76s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.8 task/s, elapsed: 76s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.8 task/s, elapsed: 76s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.8 task/s, elapsed: 76s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.8 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.8 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.8 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.8 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.8 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.8 task/s, elapsed: 77s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.8 task/s, elapsed: 77s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.8 task/s, elapsed: 77s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.8 task/s, elapsed: 77s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.8 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.8 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.8 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.8 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.8 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.8 task/s, elapsed: 78s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.8 task/s, elapsed: 78s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.8 task/s, elapsed: 78s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.8 task/s, elapsed: 78s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.8 task/s, elapsed: 78s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.8 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.8 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.8 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.8 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.8 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.8 task/s, elapsed: 79s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.8 task/s, elapsed: 79s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.8 task/s, elapsed: 79s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.8 task/s, elapsed: 79s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.8 task/s, elapsed: 79s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.8 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.8 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.8 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.8 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.8 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.8 task/s, elapsed: 80s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.8 task/s, elapsed: 80s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.8 task/s, elapsed: 80s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.8 task/s, elapsed: 80s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.8 task/s, elapsed: 80s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.8 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.8 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.8 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.8 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.8 task/s, elapsed: 81s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.8 task/s, elapsed: 81s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.8 task/s, elapsed: 81s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.8 task/s, elapsed: 81s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.8 task/s, elapsed: 81s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.8 task/s, elapsed: 81s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.8 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.8 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.8 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.8 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.8 task/s, elapsed: 82s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.8 task/s, elapsed: 82s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.8 task/s, elapsed: 82s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.8 task/s, elapsed: 82s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.8 task/s, elapsed: 82s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.8 task/s, elapsed: 82s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.8 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.8 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.8 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.8 task/s, elapsed: 83s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.8 task/s, elapsed: 83s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.8 task/s, elapsed: 83s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.8 task/s, elapsed: 83s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.8 task/s, elapsed: 83s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.8 task/s, elapsed: 83s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.8 task/s, elapsed: 83s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.8 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.8 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.8 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.8 task/s, elapsed: 84s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.8 task/s, elapsed: 84s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.8 task/s, elapsed: 84s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.8 task/s, elapsed: 84s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.8 task/s, elapsed: 84s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.8 task/s, elapsed: 84s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.8 task/s, elapsed: 84s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.8 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.8 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.8 task/s, elapsed: 85s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.8 task/s, elapsed: 85s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.8 task/s, elapsed: 85s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.8 task/s, elapsed: 85s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.8 task/s, elapsed: 85s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.8 task/s, elapsed: 85s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.8 task/s, elapsed: 85s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.8 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.8 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.8 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.8 task/s, elapsed: 86s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.8 task/s, elapsed: 86s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.8 task/s, elapsed: 86s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.8 task/s, elapsed: 86s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.8 task/s, elapsed: 86s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.8 task/s, elapsed: 86s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.8 task/s, elapsed: 86s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.8 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.8 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.8 task/s, elapsed: 87s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.8 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.8 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.8 task/s, elapsed: 88s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.8 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.8 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.8 task/s, elapsed: 89s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.8 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.8 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.8 task/s, elapsed: 90s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.8 task/s, elapsed: 90s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.8 task/s, elapsed: 90s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.8 task/s, elapsed: 90s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.8 task/s, elapsed: 90s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.8 task/s, elapsed: 90s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.8 task/s, elapsed: 90s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.8 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.8 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.8 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.8 task/s, elapsed: 91s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.8 task/s, elapsed: 91s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.8 task/s, elapsed: 91s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.8 task/s, elapsed: 91s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.8 task/s, elapsed: 91s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.8 task/s, elapsed: 91s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.8 task/s, elapsed: 91s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.8 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.8 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.8 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.8 task/s, elapsed: 92s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.8 task/s, elapsed: 92s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.8 task/s, elapsed: 92s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.8 task/s, elapsed: 92s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.8 task/s, elapsed: 92s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.8 task/s, elapsed: 92s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.8 task/s, elapsed: 92s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.8 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.8 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.8 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.8 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.8 task/s, elapsed: 93s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.8 task/s, elapsed: 93s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.8 task/s, elapsed: 93s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.8 task/s, elapsed: 93s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.8 task/s, elapsed: 93s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.8 task/s, elapsed: 93s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.8 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.8 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.8 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.8 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.8 task/s, elapsed: 94s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.8 task/s, elapsed: 94s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.8 task/s, elapsed: 94s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.8 task/s, elapsed: 94s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.8 task/s, elapsed: 94s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.8 task/s, elapsed: 94s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.8 task/s, elapsed: 94s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.8 task/s, elapsed: 94s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.8 task/s, elapsed: 94s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.8 task/s, elapsed: 94s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.8 task/s, elapsed: 95s, ETA:     0s2022-10-03 18:57:23,023 - mmseg - INFO - per class results:2022-10-03 18:57:23,024 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.19 | 96.17 || rigid_plastic | 29.98 | 34.17 ||   cardboard   | 58.48 | 73.21 ||     metal     | 28.23 | 33.42 ||  soft_plastic | 64.28 | 73.36 |+---------------+-------+-------+2022-10-03 18:57:23,024 - mmseg - INFO - Summary:2022-10-03 18:57:23,024 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.72 | 54.43 | 62.07 |+-------+-------+-------+2022-10-03 18:57:23,027 - mmseg - INFO - Saving checkpoint at 40000 iterations