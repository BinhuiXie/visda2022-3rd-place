2022-10-10 08:51:01,146 - mmseg - INFO - Environment info:------------------------------------------------------------sys.platform: linuxPython: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]CUDA available: TrueGPU 0: NVIDIA A100-SXM4-80GBCUDA_HOME: /usr/local/cudaNVCC: Build cuda_11.3.r11.3/compiler.29745058_0GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0PyTorch: 1.7.1+cu110PyTorch compiling details: PyTorch built with:  - GCC 7.3  - C++ Version: 201402  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)  - OpenMP 201511 (a.k.a. OpenMP 4.5)  - NNPACK is enabled  - CPU capability usage: AVX2  - CUDA Runtime 11.0  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80  - CuDNN 8.0.5  - Magma 2.5.2  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, TorchVision: 0.8.2+cu110OpenCV: 4.4.0MMCV: 1.3.7MMCV Compiler: GCC 7.3MMCV CUDA Compiler: 11.0MMSegmentation: 0.16.0+e6a2fe4------------------------------------------------------------2022-10-10 08:51:01,146 - mmseg - INFO - Distributed training: False2022-10-10 08:51:01,913 - mmseg - INFO - Config:log_config = dict(    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])dist_params = dict(backend='nccl')log_level = 'INFO'load_from = Noneresume_from = Noneworkflow = [('train', 1)]cudnn_benchmark = Truenorm_cfg = dict(type='BN', requires_grad=True)find_unused_parameters = Truemodel = dict(    type='EncoderDecoderProjector',    pretrained='pretrained/mit_b5.pth',    backbone=dict(type='mit_b5', style='pytorch'),    decode_head=dict(        type='DAFormerHead',        in_channels=[64, 128, 320, 512],        in_index=[0, 1, 2, 3],        channels=256,        dropout_ratio=0.1,        num_classes=5,        norm_cfg=dict(type='BN', requires_grad=True),        align_corners=False,        decoder_params=dict(            embed_dims=256,            embed_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),            embed_neck_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),            fusion_cfg=dict(                type='aspp',                sep=True,                dilations=(1, 6, 12, 18),                pool=False,                act_cfg=dict(type='ReLU'),                norm_cfg=dict(type='BN', requires_grad=True))),        loss_decode=dict(            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),    auxiliary_head=dict(        type='ProjHead',        in_channels=[64, 128, 320, 512],        in_index=[0, 1, 2, 3],        input_transform='resize_concat',        channels=512,        num_convs=2,        dropout_ratio=0.1,        num_classes=5,        norm_cfg=dict(type='BN', requires_grad=True),        align_corners=False,        loss_decode=dict(            type='ContrastiveLoss',            use_dist=True,            use_bank=False,            use_reg=True,            use_avg_pool=True,            scale_min_ratio=0.75,            num_classes=5,            contrast_temp=100.0,            loss_weight=0.01,            reg_relative_weight=0.001)),    train_cfg=dict(        work_dir=        'work_dirs_test/local-exp8/221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c'    ),    test_cfg=dict(mode='whole'))img_norm_cfg = dict(    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)crop_size = (640, 640)source_train_pipeline = [    dict(type='LoadImageFromFile'),    dict(type='LoadAnnotations'),    dict(type='Resize', img_scale=(1138, 640)),    dict(type='RandomCrop', crop_size=(640, 640), cat_max_ratio=0.75),    dict(type='RandomFlip', prob=0.5),    dict(        type='Normalize',        mean=[123.675, 116.28, 103.53],        std=[58.395, 57.12, 57.375],        to_rgb=True),    dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),    dict(type='DefaultFormatBundle'),    dict(type='Collect', keys=['img', 'gt_semantic_seg'])]target_train_pipeline = [    dict(type='LoadImageFromFile'),    dict(type='LoadAnnotations'),    dict(type='Resize', img_scale=(1138, 640)),    dict(type='RandomCrop', crop_size=(640, 640)),    dict(type='RandomFlip', prob=0.5),    dict(        type='Normalize',        mean=[123.675, 116.28, 103.53],        std=[58.395, 57.12, 57.375],        to_rgb=True),    dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),    dict(type='DefaultFormatBundle'),    dict(type='Collect', keys=['img', 'gt_semantic_seg'])]test_pipeline = [    dict(type='LoadImageFromFile'),    dict(        type='MultiScaleFlipAug',        img_scale=(1138, 640),        flip=False,        transforms=[            dict(type='Resize', keep_ratio=True),            dict(type='RandomFlip'),            dict(                type='Normalize',                mean=[123.675, 116.28, 103.53],                std=[58.395, 57.12, 57.375],                to_rgb=True),            dict(type='ImageToTensor', keys=['img']),            dict(type='Collect', keys=['img'])        ])]data = dict(    samples_per_gpu=2,    workers_per_gpu=4,    train=dict(        type='UDADataset',        source=dict(            type='ZeroWasteDataset',            data_root='data/zerowaste-f/train',            img_dir='data',            ann_dir='sem_seg',            pipeline=[                dict(type='LoadImageFromFile'),                dict(type='LoadAnnotations'),                dict(type='Resize', img_scale=(1138, 640)),                dict(                    type='RandomCrop',                    crop_size=(640, 640),                    cat_max_ratio=0.75),                dict(type='RandomFlip', prob=0.5),                dict(                    type='Normalize',                    mean=[123.675, 116.28, 103.53],                    std=[58.395, 57.12, 57.375],                    to_rgb=True),                dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),                dict(type='DefaultFormatBundle'),                dict(type='Collect', keys=['img', 'gt_semantic_seg'])            ]),        target=dict(            type='ZeroWasteV2Dataset',            data_root='data/zerowaste-v2-splits/train',            img_dir='data',            ann_dir='sem_seg',            pipeline=[                dict(type='LoadImageFromFile'),                dict(type='LoadAnnotations'),                dict(type='Resize', img_scale=(1138, 640)),                dict(type='RandomCrop', crop_size=(640, 640)),                dict(type='RandomFlip', prob=0.5),                dict(                    type='Normalize',                    mean=[123.675, 116.28, 103.53],                    std=[58.395, 57.12, 57.375],                    to_rgb=True),                dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),                dict(type='DefaultFormatBundle'),                dict(type='Collect', keys=['img', 'gt_semantic_seg'])            ])),    val=dict(        type='ZeroWasteDataset',        data_root='data/zerowaste-f/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]),    test=dict(        type='ZeroWasteV2Dataset',        data_root='data/zerowaste-v2-splits/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]))uda = dict(    type='SePiCo',    alpha=0.999,    pseudo_threshold=0.968,    pseudo_weight_ignore_top=15,    pseudo_weight_ignore_bottom=120,    imnet_feature_dist_lambda=0,    imnet_feature_dist_classes=None,    imnet_feature_dist_scale_min_ratio=None,    mix='class',    blur=True,    color_jitter_strength=0.2,    color_jitter_probability=0.2,    debug_img_interval=1000,    print_grad_magnitude=False,    enable_self_training=True,    enable_strong_aug=True,    start_distribution_iter=3000)use_ddp_wrapper = Trueoptimizer = dict(    type='AdamW',    lr=6e-05,    betas=(0.9, 0.999),    weight_decay=0.01,    paramwise_cfg=dict(        custom_keys=dict(            head=dict(lr_mult=10.0),            pos_block=dict(decay_mult=0.0),            norm=dict(decay_mult=0.0))))optimizer_config = Nonelr_config = dict(    policy='poly',    warmup='linear',    warmup_iters=1500,    warmup_ratio=1e-06,    power=1.0,    min_lr=0.0,    by_epoch=False)n_gpus = 1seed = 42runner = dict(type='IterBasedRunner', max_iters=40000)checkpoint_config = dict(by_epoch=False, interval=40000, max_keep_ckpts=1)evaluation = dict(interval=4000, metric='mIoU')exp = 8name_dataset = 'zerov12zerov2'name_architecture = 'daformer_sepaspp_proj_mitb5'name_encoder = 'mitb5'name_decoder = 'daformer_sepaspp_proj'name_uda = 'dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self'name_opt = 'adamw_6e-05_pmTrue_poly10warm_1x2_40k'name = '221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c'work_dir = 'work_dirs_test/local-exp8/221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c'git_rev = 'e6a2fe470f8338b6aa4778416c9ec54b3fdf2542'gpu_ids = range(0, 1)2022-10-10 08:51:01,913 - mmseg - INFO - Set random seed to 42, deterministic: False/mnt/data/bit/xbh/_visda2022/visda2022-ours/mmseg/models/backbones/mix_transformer.py:214: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead  warnings.warn('DeprecationWarning: pretrained is a deprecated, '2022-10-10 08:51:03,369 - mmseg - INFO - Load mit checkpoint.2022-10-10 08:51:03,369 - mmseg - INFO - Use load_from_local loader/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/cnn/utils/weight_init.py:118: UserWarning: init_cfg without layer key, if you do not define override key either, this init_cfg will do nothing  warnings.warn(2022-10-10 08:51:03,774 - mmseg - INFO - Load mit checkpoint.2022-10-10 08:51:03,774 - mmseg - INFO - Use load_from_local loader2022-10-10 08:51:03,993 - mmseg - INFO - SePiCo(  (model): EncoderDecoderProjector(    (backbone): mit_b5(      (patch_embed1): OverlapPatchEmbed(        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)      )      (patch_embed2): OverlapPatchEmbed(        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)      )      (patch_embed3): OverlapPatchEmbed(        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)      )      (patch_embed4): OverlapPatchEmbed(        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)      )      (block1): ModuleList(        (0): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): Identity()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)      (block2): ModuleList(        (0): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)      (block3): ModuleList(        (0): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (6): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (7): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (8): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (9): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (10): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (11): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (12): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (13): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (14): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (15): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (16): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (17): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (18): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (19): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (20): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (21): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (22): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (23): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (24): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (25): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (26): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (27): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (28): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (29): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (30): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (31): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (32): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (33): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (34): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (35): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (36): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (37): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (38): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (39): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)      (block4): ModuleList(        (0): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)    )    (decode_head): DAFormerHead(      input_transform=multiple_select, ignore_index=255, align_corners=False      (loss_decode): CrossEntropyLoss()      (conv_seg): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))      (dropout): Dropout2d(p=0.1, inplace=False)      (embed_layers): ModuleDict(        (0): MLP(          (proj): Linear(in_features=64, out_features=256, bias=True)        )        (1): MLP(          (proj): Linear(in_features=128, out_features=256, bias=True)        )        (2): MLP(          (proj): Linear(in_features=320, out_features=256, bias=True)        )        (3): MLP(          (proj): Linear(in_features=512, out_features=256, bias=True)        )      )      (fuse_layer): ASPPWrapper(        (aspp_modules): DepthwiseSeparableASPPModule(          (0): ConvModule(            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)            (activate): ReLU(inplace=True)          )          (1): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (2): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (3): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )        )        (bottleneck): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}    (auxiliary_head): ProjHead(      input_transform=resize_concat, ignore_index=255, align_corners=False      (loss_decode): ContrastiveLoss()      (dropout): Dropout2d(p=0.1, inplace=False)      (convs): Sequential(        (0): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )        (1): ConvModule(          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )  )  (ema_model): EncoderDecoderProjector(    (backbone): mit_b5(      (patch_embed1): OverlapPatchEmbed(        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)      )      (patch_embed2): OverlapPatchEmbed(        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)      )      (patch_embed3): OverlapPatchEmbed(        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)      )      (patch_embed4): OverlapPatchEmbed(        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)      )      (block1): ModuleList(        (0): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): Identity()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)      (block2): ModuleList(        (0): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)      (block3): ModuleList(        (0): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (6): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (7): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (8): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (9): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (10): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (11): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (12): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (13): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (14): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (15): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (16): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (17): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (18): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (19): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (20): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (21): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (22): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (23): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (24): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (25): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (26): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (27): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (28): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (29): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (30): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (31): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (32): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (33): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (34): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (35): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (36): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (37): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (38): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (39): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)      (block4): ModuleList(        (0): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)    )    (decode_head): DAFormerHead(      input_transform=multiple_select, ignore_index=255, align_corners=False      (loss_decode): CrossEntropyLoss()      (conv_seg): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))      (dropout): Dropout2d(p=0.1, inplace=False)      (embed_layers): ModuleDict(        (0): MLP(          (proj): Linear(in_features=64, out_features=256, bias=True)        )        (1): MLP(          (proj): Linear(in_features=128, out_features=256, bias=True)        )        (2): MLP(          (proj): Linear(in_features=320, out_features=256, bias=True)        )        (3): MLP(          (proj): Linear(in_features=512, out_features=256, bias=True)        )      )      (fuse_layer): ASPPWrapper(        (aspp_modules): DepthwiseSeparableASPPModule(          (0): ConvModule(            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)            (activate): ReLU(inplace=True)          )          (1): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (2): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (3): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )        )        (bottleneck): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}    (auxiliary_head): ProjHead(      input_transform=resize_concat, ignore_index=255, align_corners=False      (loss_decode): ContrastiveLoss()      (dropout): Dropout2d(p=0.1, inplace=False)      (convs): Sequential(        (0): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )        (1): ConvModule(          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )  ))2022-10-10 08:51:04,055 - mmseg - INFO - Loaded 3002 images from data/zerowaste-f/train/data2022-10-10 08:51:04,149 - mmseg - INFO - Loaded 6216 images from data/zerowaste-v2-splits/train/data2022-10-10 08:51:09,857 - mmseg - INFO - Loaded 929 images from data/zerowaste-f/test/data2022-10-10 08:51:09,858 - mmseg - INFO - Start running, host: root@perception-jupyter, work_dir: /mnt/data/bit/xbh/_visda2022/visda2022-ours/work_dirs_test/local-exp8/221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 08:51:09,858 - mmseg - INFO - workflow: [('train', 1)], max: 40000 itersRun job 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:52:02,632 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 11:27:35, time: 1.033, data_time: 0.021, memory: 67493, src.decode.loss_seg: 1.5307, src.decode.acc_seg: 49.4066, src.loss: 1.5307, mix.decode.loss_seg: 0.9283, mix.decode.acc_seg: 50.1814, mix.loss: 0.9283/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:52:52,605 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 11:15:42, time: 1.000, data_time: 0.013, memory: 67493, src.decode.loss_seg: 1.3951, src.decode.acc_seg: 71.3924, src.loss: 1.3951, mix.decode.loss_seg: 0.7631, mix.decode.acc_seg: 71.2969, mix.loss: 0.7631/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:53:42,416 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 11:10:26, time: 0.996, data_time: 0.012, memory: 67493, src.decode.loss_seg: 1.1376, src.decode.acc_seg: 79.5388, src.loss: 1.1376, mix.decode.loss_seg: 0.6273, mix.decode.acc_seg: 81.3117, mix.loss: 0.6273/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:54:31,934 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 11:06:26, time: 0.990, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.9143, src.decode.acc_seg: 82.7197, src.loss: 0.9143, mix.decode.loss_seg: 0.5414, mix.decode.acc_seg: 84.6617, mix.loss: 0.5414/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:55:22,114 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 11:05:27, time: 1.004, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.7366, src.decode.acc_seg: 83.9912, src.loss: 0.7366, mix.decode.loss_seg: 0.3617, mix.decode.acc_seg: 84.9443, mix.loss: 0.3617/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:56:11,480 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 11:02:44, time: 0.987, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.5957, src.decode.acc_seg: 85.9865, src.loss: 0.5957, mix.decode.loss_seg: 0.2917, mix.decode.acc_seg: 87.7667, mix.loss: 0.2917/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:57:00,971 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 11:00:47, time: 0.990, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.5018, src.decode.acc_seg: 86.7453, src.loss: 0.5018, mix.decode.loss_seg: 0.2548, mix.decode.acc_seg: 89.6457, mix.loss: 0.2548/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:57:50,803 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 10:59:40, time: 0.997, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.4616, src.decode.acc_seg: 86.1473, src.loss: 0.4616, mix.decode.loss_seg: 0.2471, mix.decode.acc_seg: 88.4065, mix.loss: 0.2471/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:58:40,213 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 10:58:01, time: 0.988, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3758, src.decode.acc_seg: 89.0796, src.loss: 0.3758, mix.decode.loss_seg: 0.1828, mix.decode.acc_seg: 91.3079, mix.loss: 0.1828/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:59:29,406 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 10:56:14, time: 0.984, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3669, src.decode.acc_seg: 88.2635, src.loss: 0.3669, mix.decode.loss_seg: 0.1953, mix.decode.acc_seg: 90.2786, mix.loss: 0.1953/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:00:18,805 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 10:54:52, time: 0.988, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3790, src.decode.acc_seg: 87.0064, src.loss: 0.3790, mix.decode.loss_seg: 0.1873, mix.decode.acc_seg: 89.9699, mix.loss: 0.1873/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:01:09,085 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 10:54:34, time: 1.006, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3373, src.decode.acc_seg: 89.1417, src.loss: 0.3373, mix.decode.loss_seg: 0.1877, mix.decode.acc_seg: 90.4797, mix.loss: 0.1877/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:01:58,918 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 10:53:44, time: 0.997, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.3587, src.decode.acc_seg: 88.0783, src.loss: 0.3587, mix.decode.loss_seg: 0.1691, mix.decode.acc_seg: 91.3456, mix.loss: 0.1691/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:02:49,633 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 10:53:43, time: 1.014, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.3057, src.decode.acc_seg: 89.9241, src.loss: 0.3057, mix.decode.loss_seg: 0.1566, mix.decode.acc_seg: 90.9095, mix.loss: 0.1566/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:03:39,115 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 10:52:31, time: 0.990, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3102, src.decode.acc_seg: 89.4982, src.loss: 0.3102, mix.decode.loss_seg: 0.1666, mix.decode.acc_seg: 89.7801, mix.loss: 0.1666/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:04:29,136 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 10:51:48, time: 1.000, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3667, src.decode.acc_seg: 87.3075, src.loss: 0.3667, mix.decode.loss_seg: 0.1863, mix.decode.acc_seg: 89.4254, mix.loss: 0.1863/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:05:18,823 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 10:50:49, time: 0.994, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3276, src.decode.acc_seg: 88.0993, src.loss: 0.3276, mix.decode.loss_seg: 0.1650, mix.decode.acc_seg: 90.5851, mix.loss: 0.1650/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:06:08,491 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 10:49:51, time: 0.993, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2689, src.decode.acc_seg: 91.1859, src.loss: 0.2689, mix.decode.loss_seg: 0.1220, mix.decode.acc_seg: 92.6748, mix.loss: 0.1220/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:06:58,247 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 10:48:56, time: 0.995, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3326, src.decode.acc_seg: 87.9831, src.loss: 0.3326, mix.decode.loss_seg: 0.1436, mix.decode.acc_seg: 91.1168, mix.loss: 0.1436/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:07:48,067 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 09:07:48,067 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 10:48:05, time: 0.996, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3264, src.decode.acc_seg: 88.6528, src.loss: 0.3264, mix.decode.loss_seg: 0.1668, mix.decode.acc_seg: 90.1813, mix.loss: 0.1668/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:08:38,128 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 10:47:23, time: 1.001, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3196, src.decode.acc_seg: 88.3419, src.loss: 0.3196, mix.decode.loss_seg: 0.1621, mix.decode.acc_seg: 90.3823, mix.loss: 0.1621/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:09:28,469 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 10:46:50, time: 1.007, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3111, src.decode.acc_seg: 88.8316, src.loss: 0.3111, mix.decode.loss_seg: 0.1610, mix.decode.acc_seg: 91.6380, mix.loss: 0.1610/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:10:18,010 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 10:45:48, time: 0.991, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3383, src.decode.acc_seg: 87.6557, src.loss: 0.3383, mix.decode.loss_seg: 0.1854, mix.decode.acc_seg: 90.2326, mix.loss: 0.1854/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:11:07,286 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 10:44:39, time: 0.986, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3202, src.decode.acc_seg: 88.5898, src.loss: 0.3202, mix.decode.loss_seg: 0.1664, mix.decode.acc_seg: 91.0017, mix.loss: 0.1664/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:11:56,266 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 10:43:23, time: 0.980, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2810, src.decode.acc_seg: 90.3101, src.loss: 0.2810, mix.decode.loss_seg: 0.1504, mix.decode.acc_seg: 91.8490, mix.loss: 0.1504/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:12:45,924 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 10:42:28, time: 0.993, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3044, src.decode.acc_seg: 89.1649, src.loss: 0.3044, mix.decode.loss_seg: 0.1544, mix.decode.acc_seg: 91.5676, mix.loss: 0.1544/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:13:35,113 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 10:41:21, time: 0.984, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3074, src.decode.acc_seg: 88.1180, src.loss: 0.3074, mix.decode.loss_seg: 0.1686, mix.decode.acc_seg: 91.3658, mix.loss: 0.1686/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:14:24,820 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 10:40:29, time: 0.994, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3045, src.decode.acc_seg: 89.1424, src.loss: 0.3045, mix.decode.loss_seg: 0.1617, mix.decode.acc_seg: 91.6422, mix.loss: 0.1617/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:15:13,891 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 10:39:20, time: 0.981, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2771, src.decode.acc_seg: 89.8873, src.loss: 0.2771, mix.decode.loss_seg: 0.1376, mix.decode.acc_seg: 92.2026, mix.loss: 0.1376/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:16:03,368 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 10:38:24, time: 0.990, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3019, src.decode.acc_seg: 89.6639, src.loss: 0.3019, mix.decode.loss_seg: 0.1872, mix.decode.acc_seg: 91.2085, mix.loss: 0.1872/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:16:52,987 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 10:37:31, time: 0.992, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3144, src.decode.acc_seg: 89.1759, src.loss: 0.3144, mix.decode.loss_seg: 0.1547, mix.decode.acc_seg: 92.5252, mix.loss: 0.1547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:17:42,848 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 10:36:44, time: 0.997, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2938, src.decode.acc_seg: 89.2495, src.loss: 0.2938, mix.decode.loss_seg: 0.1615, mix.decode.acc_seg: 92.2033, mix.loss: 0.1615/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:18:32,651 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 10:35:55, time: 0.996, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3042, src.decode.acc_seg: 89.1475, src.loss: 0.3042, mix.decode.loss_seg: 0.1594, mix.decode.acc_seg: 91.6508, mix.loss: 0.1594/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:19:21,943 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 10:34:55, time: 0.986, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2629, src.decode.acc_seg: 90.5620, src.loss: 0.2629, mix.decode.loss_seg: 0.1435, mix.decode.acc_seg: 92.7277, mix.loss: 0.1435/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:20:11,450 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 10:34:01, time: 0.990, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2748, src.decode.acc_seg: 90.2558, src.loss: 0.2748, mix.decode.loss_seg: 0.1582, mix.decode.acc_seg: 92.2598, mix.loss: 0.1582/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:21:01,042 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 10:33:08, time: 0.992, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2943, src.decode.acc_seg: 89.9683, src.loss: 0.2943, mix.decode.loss_seg: 0.1378, mix.decode.acc_seg: 93.4396, mix.loss: 0.1378/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:21:50,912 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 10:32:21, time: 0.997, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2659, src.decode.acc_seg: 90.6094, src.loss: 0.2659, mix.decode.loss_seg: 0.1381, mix.decode.acc_seg: 92.9191, mix.loss: 0.1381/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:22:41,040 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 10:31:40, time: 1.003, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2559, src.decode.acc_seg: 91.1548, src.loss: 0.2559, mix.decode.loss_seg: 0.1282, mix.decode.acc_seg: 93.9460, mix.loss: 0.1282/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:23:31,105 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 10:30:56, time: 1.001, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2842, src.decode.acc_seg: 90.1297, src.loss: 0.2842, mix.decode.loss_seg: 0.1267, mix.decode.acc_seg: 93.8980, mix.loss: 0.1267/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:24:20,823 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 09:24:20,824 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 10:30:06, time: 0.994, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2761, src.decode.acc_seg: 89.5085, src.loss: 0.2761, mix.decode.loss_seg: 0.1528, mix.decode.acc_seg: 92.6388, mix.loss: 0.1528/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:25:10,267 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 10:29:11, time: 0.989, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2592, src.decode.acc_seg: 90.9376, src.loss: 0.2592, mix.decode.loss_seg: 0.1240, mix.decode.acc_seg: 94.0085, mix.loss: 0.1240/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:25:59,805 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 10:28:17, time: 0.991, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2753, src.decode.acc_seg: 89.3254, src.loss: 0.2753, mix.decode.loss_seg: 0.1651, mix.decode.acc_seg: 91.9710, mix.loss: 0.1651/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:26:49,812 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 10:27:32, time: 1.000, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2503, src.decode.acc_seg: 90.8839, src.loss: 0.2503, mix.decode.loss_seg: 0.1299, mix.decode.acc_seg: 93.8644, mix.loss: 0.1299/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:27:39,638 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 10:26:44, time: 0.997, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2315, src.decode.acc_seg: 91.8529, src.loss: 0.2315, mix.decode.loss_seg: 0.1342, mix.decode.acc_seg: 93.9260, mix.loss: 0.1342/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:28:29,437 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 10:25:55, time: 0.996, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2611, src.decode.acc_seg: 91.2888, src.loss: 0.2611, mix.decode.loss_seg: 0.1291, mix.decode.acc_seg: 93.9625, mix.loss: 0.1291/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:29:18,545 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 10:24:55, time: 0.982, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2315, src.decode.acc_seg: 92.0783, src.loss: 0.2315, mix.decode.loss_seg: 0.1286, mix.decode.acc_seg: 94.3931, mix.loss: 0.1286/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:30:08,204 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 10:24:04, time: 0.993, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2566, src.decode.acc_seg: 90.4083, src.loss: 0.2566, mix.decode.loss_seg: 0.1375, mix.decode.acc_seg: 93.5979, mix.loss: 0.1375/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:30:57,137 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 10:23:02, time: 0.979, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2483, src.decode.acc_seg: 91.0516, src.loss: 0.2483, mix.decode.loss_seg: 0.1293, mix.decode.acc_seg: 94.2706, mix.loss: 0.1293/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:31:46,855 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 10:22:13, time: 0.994, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2633, src.decode.acc_seg: 90.6752, src.loss: 0.2633, mix.decode.loss_seg: 0.1339, mix.decode.acc_seg: 94.3552, mix.loss: 0.1339/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:32:36,047 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 10:21:15, time: 0.984, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2700, src.decode.acc_seg: 90.2049, src.loss: 0.2700, mix.decode.loss_seg: 0.1437, mix.decode.acc_seg: 93.6393, mix.loss: 0.1437/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:33:25,850 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 10:20:27, time: 0.996, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2649, src.decode.acc_seg: 91.0150, src.loss: 0.2649, mix.decode.loss_seg: 0.1310, mix.decode.acc_seg: 94.1131, mix.loss: 0.1310/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:34:15,672 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 10:19:39, time: 0.996, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2391, src.decode.acc_seg: 91.2062, src.loss: 0.2391, mix.decode.loss_seg: 0.1425, mix.decode.acc_seg: 93.7780, mix.loss: 0.1425/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:35:05,311 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 10:18:48, time: 0.993, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2260, src.decode.acc_seg: 91.7940, src.loss: 0.2260, mix.decode.loss_seg: 0.1158, mix.decode.acc_seg: 94.5597, mix.loss: 0.1158/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:35:54,525 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 10:17:52, time: 0.984, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2341, src.decode.acc_seg: 91.2994, src.loss: 0.2341, mix.decode.loss_seg: 0.1360, mix.decode.acc_seg: 94.0526, mix.loss: 0.1360/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:36:44,735 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 10:17:09, time: 1.004, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2305, src.decode.acc_seg: 91.7047, src.loss: 0.2305, mix.decode.loss_seg: 0.1227, mix.decode.acc_seg: 94.3918, mix.loss: 0.1227/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:37:33,901 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 10:16:12, time: 0.983, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2420, src.decode.acc_seg: 91.4106, src.loss: 0.2420, mix.decode.loss_seg: 0.1543, mix.decode.acc_seg: 93.6522, mix.loss: 0.1543/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:38:23,486 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 10:15:21, time: 0.992, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2635, src.decode.acc_seg: 90.8639, src.loss: 0.2635, mix.decode.loss_seg: 0.1588, mix.decode.acc_seg: 93.5864, mix.loss: 0.1588/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:39:12,561 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 10:14:24, time: 0.981, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2378, src.decode.acc_seg: 91.3774, src.loss: 0.2378, mix.decode.loss_seg: 0.1260, mix.decode.acc_seg: 94.3298, mix.loss: 0.1260/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:40:02,112 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 10:13:32, time: 0.991, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2452, src.decode.acc_seg: 90.7723, src.loss: 0.2452, mix.decode.loss_seg: 0.1367, mix.decode.acc_seg: 93.7726, mix.loss: 0.1367/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:40:51,588 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 09:40:51,588 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 10:12:40, time: 0.989, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2103, src.decode.acc_seg: 92.3903, src.loss: 0.2103, mix.decode.loss_seg: 0.1141, mix.decode.acc_seg: 95.1548, mix.loss: 0.1141/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:41:53,375 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 10:14:17, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2236, src.decode.acc_seg: 92.3588, src.loss: 0.2397, mix.decode.loss_seg: 0.1186, mix.decode.acc_seg: 94.8509, mix.loss: 0.1186, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:42:54,919 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 10:15:46, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2304, src.decode.acc_seg: 91.7209, src.loss: 0.2465, mix.decode.loss_seg: 0.1253, mix.decode.acc_seg: 95.0627, mix.loss: 0.1253, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:43:56,326 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 10:17:09, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2535, src.decode.acc_seg: 91.1234, src.loss: 0.2696, mix.decode.loss_seg: 0.1155, mix.decode.acc_seg: 94.9298, mix.loss: 0.1155, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:44:57,751 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 10:18:27, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2179, src.decode.acc_seg: 92.5351, src.loss: 0.2340, mix.decode.loss_seg: 0.1208, mix.decode.acc_seg: 95.0682, mix.loss: 0.1208, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:45:59,876 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 10:19:49, time: 1.243, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2349, src.decode.acc_seg: 91.9154, src.loss: 0.2509, mix.decode.loss_seg: 0.1300, mix.decode.acc_seg: 94.4871, mix.loss: 0.1300, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:47:01,360 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 10:20:59, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2152, src.decode.acc_seg: 92.2684, src.loss: 0.2313, mix.decode.loss_seg: 0.1165, mix.decode.acc_seg: 94.9717, mix.loss: 0.1165, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:48:02,759 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 10:22:05, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2143, src.decode.acc_seg: 92.2282, src.loss: 0.2304, mix.decode.loss_seg: 0.1174, mix.decode.acc_seg: 94.7073, mix.loss: 0.1174, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:49:04,421 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 10:23:10, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2448, src.decode.acc_seg: 90.8861, src.loss: 0.2609, mix.decode.loss_seg: 0.1584, mix.decode.acc_seg: 93.1362, mix.loss: 0.1584, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:50:05,986 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 10:24:10, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2262, src.decode.acc_seg: 92.0639, src.loss: 0.2423, mix.decode.loss_seg: 0.1176, mix.decode.acc_seg: 95.5242, mix.loss: 0.1176, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:51:07,784 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 10:25:09, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1900, src.decode.acc_seg: 93.0245, src.loss: 0.2061, mix.decode.loss_seg: 0.1073, mix.decode.acc_seg: 95.3828, mix.loss: 0.1073, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:52:09,661 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 10:26:05, time: 1.238, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2259, src.decode.acc_seg: 91.7183, src.loss: 0.2419, mix.decode.loss_seg: 0.1201, mix.decode.acc_seg: 94.7153, mix.loss: 0.1201, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:53:11,151 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 10:26:54, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2323, src.decode.acc_seg: 91.9635, src.loss: 0.2484, mix.decode.loss_seg: 0.1263, mix.decode.acc_seg: 94.6190, mix.loss: 0.1263, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:54:14,003 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 10:27:54, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2152, src.decode.acc_seg: 92.4281, src.loss: 0.2313, mix.decode.loss_seg: 0.1256, mix.decode.acc_seg: 94.7753, mix.loss: 0.1256, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:55:15,496 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 10:28:37, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2351, src.decode.acc_seg: 91.6583, src.loss: 0.2512, mix.decode.loss_seg: 0.1340, mix.decode.acc_seg: 94.6079, mix.loss: 0.1340, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:56:17,431 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 10:29:22, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2003, src.decode.acc_seg: 92.3932, src.loss: 0.2164, mix.decode.loss_seg: 0.1051, mix.decode.acc_seg: 95.6275, mix.loss: 0.1051, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:57:18,804 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 10:29:58, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2101, src.decode.acc_seg: 92.7085, src.loss: 0.2261, mix.decode.loss_seg: 0.0982, mix.decode.acc_seg: 95.9233, mix.loss: 0.0982, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:58:21,206 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 10:30:41, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1958, src.decode.acc_seg: 92.7646, src.loss: 0.2119, mix.decode.loss_seg: 0.1067, mix.decode.acc_seg: 95.6345, mix.loss: 0.1067, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:59:22,503 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 10:31:12, time: 1.226, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1756, src.decode.acc_seg: 93.3221, src.loss: 0.1917, mix.decode.loss_seg: 0.0989, mix.decode.acc_seg: 95.8443, mix.loss: 0.0989, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:00:24,576 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 10:31:47, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2183, src.decode.acc_seg: 92.1825, src.loss: 0.2344, mix.decode.loss_seg: 0.1271, mix.decode.acc_seg: 95.0208, mix.loss: 0.1271, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.5 task/s, elapsed: 1s, ETA:   639s[                                 ] 2/929, 2.5 task/s, elapsed: 1s, ETA:   364s[                                 ] 3/929, 3.4 task/s, elapsed: 1s, ETA:   274s[                                 ] 4/929, 4.0 task/s, elapsed: 1s, ETA:   230s[                                 ] 5/929, 4.5 task/s, elapsed: 1s, ETA:   206s[                                 ] 6/929, 4.7 task/s, elapsed: 1s, ETA:   197s[                                 ] 7/929, 5.1 task/s, elapsed: 1s, ETA:   182s[                                 ] 8/929, 5.4 task/s, elapsed: 1s, ETA:   171s[                                 ] 9/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 10/929, 5.9 task/s, elapsed: 2s, ETA:   156s[                                ] 11/929, 6.1 task/s, elapsed: 2s, ETA:   150s[                                ] 12/929, 6.3 task/s, elapsed: 2s, ETA:   146s[                                ] 13/929, 6.4 task/s, elapsed: 2s, ETA:   142s[                                ] 14/929, 6.6 task/s, elapsed: 2s, ETA:   139s[                                ] 15/929, 6.7 task/s, elapsed: 2s, ETA:   136s[                                ] 16/929, 6.9 task/s, elapsed: 2s, ETA:   133s[                                ] 17/929, 7.0 task/s, elapsed: 2s, ETA:   131s[                                ] 18/929, 7.1 task/s, elapsed: 3s, ETA:   128s[                                ] 19/929, 7.2 task/s, elapsed: 3s, ETA:   126s[                                ] 20/929, 7.3 task/s, elapsed: 3s, ETA:   125s[                                ] 21/929, 7.4 task/s, elapsed: 3s, ETA:   123s[                                ] 22/929, 7.5 task/s, elapsed: 3s, ETA:   121s[                                ] 23/929, 7.6 task/s, elapsed: 3s, ETA:   119s[                                ] 24/929, 7.7 task/s, elapsed: 3s, ETA:   118s[                                ] 25/929, 7.8 task/s, elapsed: 3s, ETA:   116s[                                ] 26/929, 7.9 task/s, elapsed: 3s, ETA:   115s[                                ] 27/929, 8.0 task/s, elapsed: 3s, ETA:   113s[                                ] 28/929, 8.0 task/s, elapsed: 3s, ETA:   112s[                                ] 29/929, 8.1 task/s, elapsed: 4s, ETA:   111s[>                               ] 30/929, 8.2 task/s, elapsed: 4s, ETA:   110s[>                               ] 31/929, 8.3 task/s, elapsed: 4s, ETA:   109s[>                               ] 32/929, 8.3 task/s, elapsed: 4s, ETA:   108s[>                               ] 33/929, 8.3 task/s, elapsed: 4s, ETA:   108s[>                               ] 34/929, 8.3 task/s, elapsed: 4s, ETA:   107s[>                               ] 35/929, 8.4 task/s, elapsed: 4s, ETA:   107s[>                               ] 36/929, 8.4 task/s, elapsed: 4s, ETA:   106s[>                               ] 37/929, 8.4 task/s, elapsed: 4s, ETA:   106s[>                               ] 38/929, 8.5 task/s, elapsed: 4s, ETA:   105s[>                               ] 39/929, 8.5 task/s, elapsed: 5s, ETA:   105s[>                               ] 40/929, 8.5 task/s, elapsed: 5s, ETA:   104s[>                               ] 41/929, 8.6 task/s, elapsed: 5s, ETA:   104s[>                               ] 42/929, 8.6 task/s, elapsed: 5s, ETA:   103s[>                               ] 43/929, 8.6 task/s, elapsed: 5s, ETA:   103s[>                               ] 44/929, 8.7 task/s, elapsed: 5s, ETA:   102s[>                               ] 45/929, 8.7 task/s, elapsed: 5s, ETA:   102s[>                               ] 46/929, 8.7 task/s, elapsed: 5s, ETA:   101s[>                               ] 47/929, 8.7 task/s, elapsed: 5s, ETA:   101s[>                               ] 48/929, 8.8 task/s, elapsed: 5s, ETA:   100s[>                               ] 49/929, 8.8 task/s, elapsed: 6s, ETA:   100s[>                               ] 50/929, 8.8 task/s, elapsed: 6s, ETA:   100s[>                               ] 51/929, 8.8 task/s, elapsed: 6s, ETA:   100s[>                               ] 52/929, 8.8 task/s, elapsed: 6s, ETA:    99s[>                               ] 53/929, 8.8 task/s, elapsed: 6s, ETA:    99s[>                               ] 54/929, 8.9 task/s, elapsed: 6s, ETA:    99s[>                               ] 55/929, 8.9 task/s, elapsed: 6s, ETA:    98s[>                               ] 56/929, 8.9 task/s, elapsed: 6s, ETA:    98s[>                               ] 57/929, 8.9 task/s, elapsed: 6s, ETA:    98s[>                               ] 58/929, 8.9 task/s, elapsed: 6s, ETA:    98s[>>                              ] 59/929, 8.9 task/s, elapsed: 7s, ETA:    97s[>>                              ] 60/929, 9.0 task/s, elapsed: 7s, ETA:    97s[>>                              ] 61/929, 9.0 task/s, elapsed: 7s, ETA:    97s[>>                              ] 62/929, 9.0 task/s, elapsed: 7s, ETA:    97s[>>                              ] 63/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 64/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 65/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 66/929, 9.0 task/s, elapsed: 7s, ETA:    96s[>>                              ] 67/929, 9.0 task/s, elapsed: 7s, ETA:    95s[>>                              ] 68/929, 9.1 task/s, elapsed: 8s, ETA:    95s[>>                              ] 69/929, 9.1 task/s, elapsed: 8s, ETA:    95s[>>                              ] 70/929, 9.1 task/s, elapsed: 8s, ETA:    95s[>>                              ] 71/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 72/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 73/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 74/929, 9.1 task/s, elapsed: 8s, ETA:    94s[>>                              ] 75/929, 9.1 task/s, elapsed: 8s, ETA:    93s[>>                              ] 76/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 77/929, 9.2 task/s, elapsed: 8s, ETA:    93s[>>                              ] 78/929, 9.2 task/s, elapsed: 9s, ETA:    93s[>>                              ] 79/929, 9.2 task/s, elapsed: 9s, ETA:    93s[>>                              ] 80/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 81/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 82/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 83/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 84/929, 9.2 task/s, elapsed: 9s, ETA:    92s[>>                              ] 85/929, 9.2 task/s, elapsed: 9s, ETA:    91s[>>                              ] 86/929, 9.2 task/s, elapsed: 9s, ETA:    91s[>>                              ] 87/929, 9.2 task/s, elapsed: 9s, ETA:    91s[>>                             ] 88/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>                             ] 89/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 90/929, 9.2 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 91/929, 9.3 task/s, elapsed: 10s, ETA:    91s[>>>                            ] 92/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 93/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 94/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 95/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 96/929, 9.3 task/s, elapsed: 10s, ETA:    90s[>>>                            ] 97/929, 9.3 task/s, elapsed: 10s, ETA:    89s[>>>                            ] 98/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                            ] 99/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 100/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 101/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 102/929, 9.3 task/s, elapsed: 11s, ETA:    89s[>>>                           ] 103/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 104/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 105/929, 9.3 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 106/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 107/929, 9.4 task/s, elapsed: 11s, ETA:    88s[>>>                           ] 108/929, 9.4 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 109/929, 9.4 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 110/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 111/929, 9.4 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 112/929, 9.3 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 113/929, 9.3 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 114/929, 9.3 task/s, elapsed: 12s, ETA:    88s[>>>                           ] 115/929, 9.3 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 116/929, 9.3 task/s, elapsed: 12s, ETA:    87s[>>>                           ] 117/929, 9.3 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 118/929, 9.3 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 119/929, 9.3 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 120/929, 9.3 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 121/929, 9.3 task/s, elapsed: 13s, ETA:    87s[>>>                           ] 122/929, 9.3 task/s, elapsed: 13s, ETA:    86s[>>>                           ] 123/929, 9.3 task/s, elapsed: 13s, ETA:    86s[>>>>                          ] 124/929, 9.3 task/s, elapsed: 13s, ETA:    86s[>>>>                          ] 125/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>>                          ] 126/929, 9.4 task/s, elapsed: 13s, ETA:    86s[>>>>                          ] 127/929, 9.4 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 128/929, 9.4 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 129/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 130/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 131/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 132/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 133/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 134/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 135/929, 9.4 task/s, elapsed: 14s, ETA:    85s[>>>>                          ] 136/929, 9.4 task/s, elapsed: 14s, ETA:    84s[>>>>                          ] 137/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 138/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 139/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 140/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 141/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 142/929, 9.4 task/s, elapsed: 15s, ETA:    84s[>>>>                          ] 143/929, 9.4 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 144/929, 9.4 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 145/929, 9.4 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 146/929, 9.4 task/s, elapsed: 15s, ETA:    83s[>>>>                          ] 147/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 148/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 149/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 150/929, 9.4 task/s, elapsed: 16s, ETA:    83s[>>>>                          ] 151/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>                          ] 152/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>                          ] 153/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>                          ] 154/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>>                         ] 155/929, 9.4 task/s, elapsed: 16s, ETA:    82s[>>>>>                         ] 156/929, 9.4 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 157/929, 9.4 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 158/929, 9.5 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 159/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 160/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 161/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 162/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 163/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 164/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 165/929, 9.5 task/s, elapsed: 17s, ETA:    81s[>>>>>                         ] 166/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 167/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 168/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 169/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 170/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 171/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 172/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 173/929, 9.5 task/s, elapsed: 18s, ETA:    80s[>>>>>                         ] 174/929, 9.5 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 175/929, 9.5 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 176/929, 9.5 task/s, elapsed: 18s, ETA:    79s[>>>>>                         ] 177/929, 9.5 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 178/929, 9.5 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 179/929, 9.5 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 180/929, 9.5 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 181/929, 9.5 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 182/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 183/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 184/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>                         ] 185/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>>                        ] 186/929, 9.6 task/s, elapsed: 19s, ETA:    78s[>>>>>>                        ] 187/929, 9.6 task/s, elapsed: 20s, ETA:    78s[>>>>>>                        ] 188/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 189/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 190/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 191/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 192/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 193/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 194/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 195/929, 9.6 task/s, elapsed: 20s, ETA:    77s[>>>>>>                        ] 196/929, 9.6 task/s, elapsed: 20s, ETA:    76s[>>>>>>                        ] 197/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 198/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 199/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 200/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 201/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 202/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 203/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 204/929, 9.6 task/s, elapsed: 21s, ETA:    76s[>>>>>>                        ] 205/929, 9.6 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 206/929, 9.6 task/s, elapsed: 21s, ETA:    75s[>>>>>>                        ] 207/929, 9.6 task/s, elapsed: 22s, ETA:    75s[>>>>>>                        ] 208/929, 9.6 task/s, elapsed: 22s, ETA:    75s[>>>>>>                        ] 209/929, 9.6 task/s, elapsed: 22s, ETA:    75s[>>>>>>                        ] 210/929, 9.6 task/s, elapsed: 22s, ETA:    75s[>>>>>>                        ] 211/929, 9.6 task/s, elapsed: 22s, ETA:    75s[>>>>>>                        ] 212/929, 9.6 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 213/929, 9.6 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 214/929, 9.6 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 215/929, 9.6 task/s, elapsed: 22s, ETA:    74s[>>>>>>                        ] 216/929, 9.6 task/s, elapsed: 22s, ETA:    74s[>>>>>>>                       ] 217/929, 9.6 task/s, elapsed: 22s, ETA:    74s[>>>>>>>                       ] 218/929, 9.7 task/s, elapsed: 23s, ETA:    74s[>>>>>>>                       ] 219/929, 9.7 task/s, elapsed: 23s, ETA:    74s[>>>>>>>                       ] 220/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 221/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 222/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 223/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 224/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 225/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 226/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 227/929, 9.7 task/s, elapsed: 23s, ETA:    73s[>>>>>>>                       ] 228/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 229/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 230/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 231/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 232/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 233/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 234/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 235/929, 9.7 task/s, elapsed: 24s, ETA:    72s[>>>>>>>                       ] 236/929, 9.7 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 237/929, 9.7 task/s, elapsed: 24s, ETA:    71s[>>>>>>>                       ] 238/929, 9.7 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 239/929, 9.7 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 240/929, 9.7 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 241/929, 9.7 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 242/929, 9.7 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 243/929, 9.7 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 244/929, 9.7 task/s, elapsed: 25s, ETA:    71s[>>>>>>>                       ] 245/929, 9.7 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 246/929, 9.7 task/s, elapsed: 25s, ETA:    70s[>>>>>>>                       ] 247/929, 9.7 task/s, elapsed: 25s, ETA:    70s[>>>>>>>>                      ] 248/929, 9.7 task/s, elapsed: 26s, ETA:    70s[>>>>>>>>                      ] 249/929, 9.7 task/s, elapsed: 26s, ETA:    70s[>>>>>>>>                      ] 250/929, 9.7 task/s, elapsed: 26s, ETA:    70s[>>>>>>>>                      ] 251/929, 9.7 task/s, elapsed: 26s, ETA:    70s[>>>>>>>>                      ] 252/929, 9.7 task/s, elapsed: 26s, ETA:    70s[>>>>>>>>                      ] 253/929, 9.7 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 254/929, 9.7 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 255/929, 9.7 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 256/929, 9.7 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 257/929, 9.7 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 258/929, 9.7 task/s, elapsed: 26s, ETA:    69s[>>>>>>>>                      ] 259/929, 9.7 task/s, elapsed: 27s, ETA:    69s[>>>>>>>>                      ] 260/929, 9.7 task/s, elapsed: 27s, ETA:    69s[>>>>>>>>                      ] 261/929, 9.7 task/s, elapsed: 27s, ETA:    69s[>>>>>>>>                      ] 262/929, 9.7 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 263/929, 9.7 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 264/929, 9.7 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 265/929, 9.7 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 266/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 267/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 268/929, 9.8 task/s, elapsed: 27s, ETA:    68s[>>>>>>>>                      ] 269/929, 9.8 task/s, elapsed: 28s, ETA:    68s[>>>>>>>>                      ] 270/929, 9.8 task/s, elapsed: 28s, ETA:    68s[>>>>>>>>                      ] 271/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 272/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 273/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 274/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 275/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 276/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 277/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>                      ] 278/929, 9.8 task/s, elapsed: 28s, ETA:    67s[>>>>>>>>>                     ] 279/929, 9.8 task/s, elapsed: 29s, ETA:    67s[>>>>>>>>>                     ] 280/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 281/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 282/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 283/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 284/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 285/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 286/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 287/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 288/929, 9.8 task/s, elapsed: 29s, ETA:    66s[>>>>>>>>>                     ] 289/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 290/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 291/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 292/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 293/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 294/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 295/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 296/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 297/929, 9.8 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 298/929, 9.8 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                     ] 299/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 300/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 301/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 302/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 303/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 304/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 305/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 306/929, 9.8 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 307/929, 9.8 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 308/929, 9.8 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 309/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 310/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 311/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 312/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 313/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 314/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 315/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 316/929, 9.8 task/s, elapsed: 32s, ETA:    63s[>>>>>>>>>>                    ] 317/929, 9.8 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 318/929, 9.8 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 319/929, 9.8 task/s, elapsed: 33s, ETA:    62s[>>>>>>>>>>                    ] 320/929, 9.8 task/s, elapsed: 33s, ETA:    62s[>>>>>>>>>>                    ] 321/929, 9.8 task/s, elapsed: 33s, ETA:    62s[>>>>>>>>>>                    ] 322/929, 9.8 task/s, elapsed: 33s, ETA:    62s[>>>>>>>>>>                    ] 323/929, 9.8 task/s, elapsed: 33s, ETA:    62s[>>>>>>>>>>                    ] 324/929, 9.8 task/s, elapsed: 33s, ETA:    62s[>>>>>>>>>>                    ] 325/929, 9.8 task/s, elapsed: 33s, ETA:    62s[>>>>>>>>>>                    ] 326/929, 9.8 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 327/929, 9.8 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 328/929, 9.8 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 329/929, 9.8 task/s, elapsed: 33s, ETA:    61s[>>>>>>>>>>                    ] 330/929, 9.8 task/s, elapsed: 34s, ETA:    61s[>>>>>>>>>>                    ] 331/929, 9.8 task/s, elapsed: 34s, ETA:    61s[>>>>>>>>>>                    ] 332/929, 9.8 task/s, elapsed: 34s, ETA:    61s[>>>>>>>>>>                    ] 333/929, 9.8 task/s, elapsed: 34s, ETA:    61s[>>>>>>>>>>                    ] 334/929, 9.8 task/s, elapsed: 34s, ETA:    61s[>>>>>>>>>>                    ] 335/929, 9.8 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 336/929, 9.8 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 337/929, 9.8 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 338/929, 9.8 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 339/929, 9.8 task/s, elapsed: 34s, ETA:    60s[>>>>>>>>>>                    ] 340/929, 9.8 task/s, elapsed: 35s, ETA:    60s[>>>>>>>>>>>                   ] 341/929, 9.8 task/s, elapsed: 35s, ETA:    60s[>>>>>>>>>>>                   ] 342/929, 9.8 task/s, elapsed: 35s, ETA:    60s[>>>>>>>>>>>                   ] 343/929, 9.8 task/s, elapsed: 35s, ETA:    60s[>>>>>>>>>>>                   ] 344/929, 9.8 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 345/929, 9.8 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 346/929, 9.8 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 347/929, 9.8 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 348/929, 9.8 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 349/929, 9.8 task/s, elapsed: 35s, ETA:    59s[>>>>>>>>>>>                   ] 350/929, 9.8 task/s, elapsed: 36s, ETA:    59s[>>>>>>>>>>>                   ] 351/929, 9.8 task/s, elapsed: 36s, ETA:    59s[>>>>>>>>>>>                   ] 352/929, 9.8 task/s, elapsed: 36s, ETA:    59s[>>>>>>>>>>>                   ] 353/929, 9.8 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 354/929, 9.8 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 355/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 356/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 357/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 358/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 359/929, 9.9 task/s, elapsed: 36s, ETA:    58s[>>>>>>>>>>>                   ] 360/929, 9.9 task/s, elapsed: 37s, ETA:    58s[>>>>>>>>>>>                   ] 361/929, 9.9 task/s, elapsed: 37s, ETA:    58s[>>>>>>>>>>>                   ] 362/929, 9.9 task/s, elapsed: 37s, ETA:    58s[>>>>>>>>>>>                   ] 363/929, 9.9 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                   ] 364/929, 9.8 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                   ] 365/929, 9.8 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                   ] 366/929, 9.8 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                   ] 367/929, 9.8 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                   ] 368/929, 9.8 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                   ] 369/929, 9.9 task/s, elapsed: 37s, ETA:    57s[>>>>>>>>>>>                   ] 370/929, 9.9 task/s, elapsed: 38s, ETA:    57s[>>>>>>>>>>>                   ] 371/929, 9.9 task/s, elapsed: 38s, ETA:    57s[>>>>>>>>>>>>                  ] 372/929, 9.9 task/s, elapsed: 38s, ETA:    57s[>>>>>>>>>>>>                  ] 373/929, 9.9 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>>                  ] 374/929, 9.9 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>>                  ] 375/929, 9.8 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>>                  ] 376/929, 9.8 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>>                  ] 377/929, 9.8 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>>                  ] 378/929, 9.8 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>>                  ] 379/929, 9.8 task/s, elapsed: 38s, ETA:    56s[>>>>>>>>>>>>                  ] 380/929, 9.8 task/s, elapsed: 39s, ETA:    56s[>>>>>>>>>>>>                  ] 381/929, 9.8 task/s, elapsed: 39s, ETA:    56s[>>>>>>>>>>>>                  ] 382/929, 9.8 task/s, elapsed: 39s, ETA:    56s[>>>>>>>>>>>>                  ] 383/929, 9.9 task/s, elapsed: 39s, ETA:    55s[>>>>>>>>>>>>                  ] 384/929, 9.9 task/s, elapsed: 39s, ETA:    55s[>>>>>>>>>>>>                  ] 385/929, 9.9 task/s, elapsed: 39s, ETA:    55s[>>>>>>>>>>>>                  ] 386/929, 9.9 task/s, elapsed: 39s, ETA:    55s[>>>>>>>>>>>>                  ] 387/929, 9.9 task/s, elapsed: 39s, ETA:    55s[>>>>>>>>>>>>                  ] 388/929, 9.9 task/s, elapsed: 39s, ETA:    55s[>>>>>>>>>>>>                  ] 389/929, 9.9 task/s, elapsed: 39s, ETA:    55s[>>>>>>>>>>>>                  ] 390/929, 9.8 task/s, elapsed: 40s, ETA:    55s[>>>>>>>>>>>>                  ] 391/929, 9.8 task/s, elapsed: 40s, ETA:    55s[>>>>>>>>>>>>                  ] 392/929, 9.8 task/s, elapsed: 40s, ETA:    55s[>>>>>>>>>>>>                  ] 393/929, 9.8 task/s, elapsed: 40s, ETA:    54s[>>>>>>>>>>>>                  ] 394/929, 9.8 task/s, elapsed: 40s, ETA:    54s[>>>>>>>>>>>>                  ] 395/929, 9.8 task/s, elapsed: 40s, ETA:    54s[>>>>>>>>>>>>                  ] 396/929, 9.8 task/s, elapsed: 40s, ETA:    54s[>>>>>>>>>>>>                  ] 397/929, 9.8 task/s, elapsed: 40s, ETA:    54s[>>>>>>>>>>>>                  ] 398/929, 9.8 task/s, elapsed: 40s, ETA:    54s[>>>>>>>>>>>>                  ] 399/929, 9.8 task/s, elapsed: 41s, ETA:    54s[>>>>>>>>>>>>                  ] 400/929, 9.8 task/s, elapsed: 41s, ETA:    54s[>>>>>>>>>>>>                  ] 401/929, 9.8 task/s, elapsed: 41s, ETA:    54s[>>>>>>>>>>>>                  ] 402/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 403/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 404/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 405/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 406/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 407/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 408/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 409/929, 9.9 task/s, elapsed: 41s, ETA:    53s[>>>>>>>>>>>>>                 ] 410/929, 9.9 task/s, elapsed: 42s, ETA:    53s[>>>>>>>>>>>>>                 ] 411/929, 9.9 task/s, elapsed: 42s, ETA:    53s[>>>>>>>>>>>>>                 ] 412/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 413/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 414/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 415/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 416/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 417/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 418/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 419/929, 9.9 task/s, elapsed: 42s, ETA:    52s[>>>>>>>>>>>>>                 ] 420/929, 9.9 task/s, elapsed: 43s, ETA:    52s[>>>>>>>>>>>>>                 ] 421/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 422/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 423/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 424/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 425/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 426/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 427/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 428/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 429/929, 9.9 task/s, elapsed: 43s, ETA:    51s[>>>>>>>>>>>>>                 ] 430/929, 9.9 task/s, elapsed: 44s, ETA:    51s[>>>>>>>>>>>>>                 ] 431/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>                 ] 432/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>                 ] 433/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>>                ] 434/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>>                ] 435/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>>                ] 436/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>>                ] 437/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>>                ] 438/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>>                ] 439/929, 9.9 task/s, elapsed: 44s, ETA:    50s[>>>>>>>>>>>>>>                ] 440/929, 9.9 task/s, elapsed: 45s, ETA:    50s[>>>>>>>>>>>>>>                ] 441/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 442/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 443/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 444/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 445/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 446/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 447/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 448/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 449/929, 9.9 task/s, elapsed: 45s, ETA:    49s[>>>>>>>>>>>>>>                ] 450/929, 9.9 task/s, elapsed: 46s, ETA:    49s[>>>>>>>>>>>>>>                ] 451/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 452/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 453/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 454/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 455/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 456/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 457/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 458/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 459/929, 9.9 task/s, elapsed: 46s, ETA:    48s[>>>>>>>>>>>>>>                ] 460/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>                ] 461/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>                ] 462/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>                ] 463/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>                ] 464/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>>               ] 465/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>>               ] 466/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>>               ] 467/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>>               ] 468/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>>               ] 469/929, 9.9 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>>               ] 470/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 471/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 472/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 473/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 474/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 475/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 476/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 477/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 478/929, 9.9 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>>               ] 479/929, 9.9 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>               ] 480/929, 9.9 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>               ] 481/929, 9.9 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>               ] 482/929, 9.9 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>               ] 483/929, 9.9 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>               ] 484/929, 9.9 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>               ] 485/929, 9.9 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>               ] 486/929, 9.9 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>               ] 487/929, 9.9 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>               ] 488/929, 9.9 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>               ] 489/929, 9.9 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>               ] 490/929, 9.9 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>               ] 491/929, 9.9 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>               ] 492/929, 9.9 task/s, elapsed: 50s, ETA:    44s[>>>>>>>>>>>>>>>               ] 493/929, 9.9 task/s, elapsed: 50s, ETA:    44s[>>>>>>>>>>>>>>>               ] 494/929, 9.9 task/s, elapsed: 50s, ETA:    44s[>>>>>>>>>>>>>>>               ] 495/929, 9.9 task/s, elapsed: 50s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 496/929, 9.9 task/s, elapsed: 50s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 497/929, 9.9 task/s, elapsed: 50s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 498/929, 9.9 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 499/929, 9.9 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 500/929, 9.9 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 501/929, 9.9 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 502/929, 9.9 task/s, elapsed: 51s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 503/929, 9.9 task/s, elapsed: 51s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 504/929, 9.9 task/s, elapsed: 51s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 505/929, 9.9 task/s, elapsed: 51s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 506/929, 9.9 task/s, elapsed: 51s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 507/929, 9.9 task/s, elapsed: 51s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 508/929, 9.9 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 509/929, 9.9 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 510/929, 9.9 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 511/929, 9.9 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 512/929, 9.9 task/s, elapsed: 52s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 513/929, 9.9 task/s, elapsed: 52s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 514/929, 9.9 task/s, elapsed: 52s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 515/929, 9.9 task/s, elapsed: 52s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 516/929, 9.9 task/s, elapsed: 52s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 517/929, 9.9 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 518/929, 9.9 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 519/929, 9.9 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 520/929, 9.9 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 521/929, 9.9 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 522/929, 9.9 task/s, elapsed: 53s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 523/929, 9.9 task/s, elapsed: 53s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 524/929, 9.9 task/s, elapsed: 53s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 525/929, 9.9 task/s, elapsed: 53s, ETA:    41s[>>>>>>>>>>>>>>>>              ] 526/929, 9.9 task/s, elapsed: 53s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.9 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.9 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.9 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.9 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.9 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.9 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.9 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.9 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.9 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.9 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.9 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.9 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.9 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.9 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.9 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.9 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.9 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.9 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.9 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.9 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.9 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.9 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.9 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.9 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.9 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.9 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.9 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.9 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.9 task/s, elapsed: 56s, ETA:    38s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.9 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.9 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.9 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.9 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.9 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.0 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.0 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.0 task/s, elapsed: 57s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.0 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.0 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.0 task/s, elapsed: 58s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.0 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.0 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.0 task/s, elapsed: 59s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.0 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.0 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.0 task/s, elapsed: 60s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.9 task/s, elapsed: 61s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.9 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.9 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.9 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.9 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.9 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.9 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.9 task/s, elapsed: 62s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.9 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.9 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.9 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.9 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.9 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.9 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.9 task/s, elapsed: 63s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.9 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.9 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.9 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.9 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.9 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.9 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.9 task/s, elapsed: 64s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.9 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.9 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.9 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.9 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.9 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.9 task/s, elapsed: 65s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.9 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.9 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.9 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.9 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.9 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.9 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.9 task/s, elapsed: 66s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.9 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.9 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.9 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.9 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.9 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.9 task/s, elapsed: 67s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.9 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.9 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.9 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.9 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.9 task/s, elapsed: 68s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.9 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.9 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.9 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.9 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.9 task/s, elapsed: 69s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.9 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.9 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.9 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.9 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.9 task/s, elapsed: 70s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.9 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.9 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.9 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.9 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.9 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.9 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.9 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.9 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.9 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.9 task/s, elapsed: 71s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.9 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.9 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.9 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.9 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.9 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.9 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.9 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.9 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.9 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.9 task/s, elapsed: 72s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.9 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.9 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.9 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.9 task/s, elapsed: 73s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.9 task/s, elapsed: 73s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.9 task/s, elapsed: 74s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.9 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.9 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.9 task/s, elapsed: 75s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.9 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.9 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.9 task/s, elapsed: 76s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.9 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.9 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.9 task/s, elapsed: 77s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.9 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.9 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.9 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.9 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.9 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.9 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.9 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.9 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.9 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.9 task/s, elapsed: 78s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.9 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.9 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.9 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.9 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.9 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.9 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.9 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.9 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.9 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.9 task/s, elapsed: 79s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.9 task/s, elapsed: 79s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.9 task/s, elapsed: 79s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.9 task/s, elapsed: 79s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.9 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.9 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.9 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.9 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.9 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.9 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.9 task/s, elapsed: 80s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.9 task/s, elapsed: 80s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.9 task/s, elapsed: 80s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.9 task/s, elapsed: 80s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.9 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.9 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.9 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.9 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.9 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.9 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.9 task/s, elapsed: 81s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.9 task/s, elapsed: 81s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.9 task/s, elapsed: 81s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.9 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.9 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.9 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.9 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.9 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.9 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.9 task/s, elapsed: 82s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.9 task/s, elapsed: 82s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.9 task/s, elapsed: 82s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.9 task/s, elapsed: 82s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.9 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.9 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.9 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.9 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.9 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.9 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.9 task/s, elapsed: 83s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.9 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.9 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.9 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.9 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.9 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.9 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.9 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.9 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.9 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.9 task/s, elapsed: 84s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.9 task/s, elapsed: 84s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.9 task/s, elapsed: 84s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.9 task/s, elapsed: 84s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.9 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.9 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.9 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.9 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.9 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.9 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.9 task/s, elapsed: 85s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.9 task/s, elapsed: 85s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.9 task/s, elapsed: 85s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.9 task/s, elapsed: 85s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.9 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.9 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.9 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.9 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.9 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.9 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.9 task/s, elapsed: 86s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.9 task/s, elapsed: 86s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.9 task/s, elapsed: 86s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.9 task/s, elapsed: 86s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.9 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.9 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.9 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.9 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.9 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.9 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.9 task/s, elapsed: 87s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.9 task/s, elapsed: 87s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.9 task/s, elapsed: 87s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.9 task/s, elapsed: 88s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.9 task/s, elapsed: 88s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.9 task/s, elapsed: 88s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.9 task/s, elapsed: 89s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.9 task/s, elapsed: 89s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.9 task/s, elapsed: 89s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.9 task/s, elapsed: 90s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.9 task/s, elapsed: 90s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.9 task/s, elapsed: 90s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.9 task/s, elapsed: 91s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.9 task/s, elapsed: 91s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.9 task/s, elapsed: 91s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.9 task/s, elapsed: 91s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.9 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.9 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.9 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.9 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.9 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.9 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.9 task/s, elapsed: 92s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.9 task/s, elapsed: 92s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.9 task/s, elapsed: 92s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.9 task/s, elapsed: 92s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.9 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.9 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.9 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.9 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.9 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.9 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.9 task/s, elapsed: 93s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.9 task/s, elapsed: 93s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.9 task/s, elapsed: 93s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.9 task/s, elapsed: 93s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.9 task/s, elapsed: 93s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.9 task/s, elapsed: 94s, ETA:     0s2022-10-10 10:05:47,933 - mmseg - INFO - per class results:2022-10-10 10:05:47,934 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 89.77 |  95.3 || rigid_plastic | 17.57 | 20.73 ||   cardboard   | 54.21 | 66.75 ||     metal     |  2.7  |  2.71 ||  soft_plastic | 56.34 | 75.25 |+---------------+-------+-------+2022-10-10 10:05:47,935 - mmseg - INFO - Summary:2022-10-10 10:05:47,935 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 90.25 | 44.12 | 52.15 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:05:47,940 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 10:05:47,940 - mmseg - INFO - Iter [929/40000]	lr: 5.400e-05, eta: 10:32:13, time: 1.226, data_time: 0.013, memory: 67493, aAcc: 0.9025, mIoU: 0.4412, mAcc: 0.5215, IoU.background: 0.8977, IoU.rigid_plastic: 0.1757, IoU.cardboard: 0.5421, IoU.metal: 0.0270, IoU.soft_plastic: 0.5634, Acc.background: 0.9530, Acc.rigid_plastic: 0.2073, Acc.cardboard: 0.6675, Acc.metal: 0.0271, Acc.soft_plastic: 0.7525, src.decode.loss_seg: 0.2210, src.decode.acc_seg: 92.1231, src.loss: 0.2371, mix.decode.loss_seg: 0.1130, mix.decode.acc_seg: 95.5661, mix.loss: 0.1130, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:06:54,034 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 11:12:06, time: 6.564, data_time: 5.257, memory: 67493, src.decode.loss_seg: 0.2164, src.decode.acc_seg: 92.3934, src.loss: 0.2324, mix.decode.loss_seg: 0.1276, mix.decode.acc_seg: 95.0156, mix.loss: 0.1276, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:07:56,273 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 11:12:04, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2132, src.decode.acc_seg: 92.3521, src.loss: 0.2293, mix.decode.loss_seg: 0.1363, mix.decode.acc_seg: 94.7548, mix.loss: 0.1363, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:08:58,117 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 11:11:57, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2341, src.decode.acc_seg: 91.4468, src.loss: 0.2501, mix.decode.loss_seg: 0.1414, mix.decode.acc_seg: 94.6249, mix.loss: 0.1414, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:10:00,519 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 11:11:53, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2025, src.decode.acc_seg: 92.5208, src.loss: 0.2185, mix.decode.loss_seg: 0.1245, mix.decode.acc_seg: 94.7374, mix.loss: 0.1245, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:11:01,909 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 11:11:39, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2032, src.decode.acc_seg: 92.5511, src.loss: 0.2193, mix.decode.loss_seg: 0.1107, mix.decode.acc_seg: 95.0397, mix.loss: 0.1107, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:12:03,519 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 11:11:27, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2165, src.decode.acc_seg: 92.2856, src.loss: 0.2326, mix.decode.loss_seg: 0.1093, mix.decode.acc_seg: 95.3283, mix.loss: 0.1093, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:13:05,901 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 11:11:19, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2079, src.decode.acc_seg: 92.7713, src.loss: 0.2239, mix.decode.loss_seg: 0.1162, mix.decode.acc_seg: 95.2087, mix.loss: 0.1162, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:14:07,882 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 11:11:07, time: 1.240, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1704, src.decode.acc_seg: 93.9800, src.loss: 0.1864, mix.decode.loss_seg: 0.1084, mix.decode.acc_seg: 95.8473, mix.loss: 0.1084, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:15:09,687 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 11:10:52, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1930, src.decode.acc_seg: 93.4885, src.loss: 0.2090, mix.decode.loss_seg: 0.0871, mix.decode.acc_seg: 96.5486, mix.loss: 0.0871, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:16:11,098 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 11:10:34, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1877, src.decode.acc_seg: 93.3899, src.loss: 0.2037, mix.decode.loss_seg: 0.0948, mix.decode.acc_seg: 96.1282, mix.loss: 0.0948, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:17:12,936 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 11:10:17, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2006, src.decode.acc_seg: 93.1711, src.loss: 0.2166, mix.decode.loss_seg: 0.0995, mix.decode.acc_seg: 96.0260, mix.loss: 0.0995, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:18:15,004 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 11:10:02, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1988, src.decode.acc_seg: 92.9321, src.loss: 0.2148, mix.decode.loss_seg: 0.1160, mix.decode.acc_seg: 95.4148, mix.loss: 0.1160, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:19:16,247 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 11:09:39, time: 1.225, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1788, src.decode.acc_seg: 93.6178, src.loss: 0.1949, mix.decode.loss_seg: 0.1103, mix.decode.acc_seg: 95.4757, mix.loss: 0.1103, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:20:17,587 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 11:09:16, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2243, src.decode.acc_seg: 92.5444, src.loss: 0.2404, mix.decode.loss_seg: 0.1268, mix.decode.acc_seg: 94.9157, mix.loss: 0.1268, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:21:19,355 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 11:08:55, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1795, src.decode.acc_seg: 93.5537, src.loss: 0.1955, mix.decode.loss_seg: 0.0927, mix.decode.acc_seg: 96.0925, mix.loss: 0.0927, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:22:21,096 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 11:08:33, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2110, src.decode.acc_seg: 92.4830, src.loss: 0.2271, mix.decode.loss_seg: 0.1240, mix.decode.acc_seg: 95.3688, mix.loss: 0.1240, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:23:23,170 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 11:08:13, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2010, src.decode.acc_seg: 93.0875, src.loss: 0.2171, mix.decode.loss_seg: 0.0975, mix.decode.acc_seg: 96.0348, mix.loss: 0.0975, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:24:25,140 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 11:07:52, time: 1.239, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1901, src.decode.acc_seg: 93.3390, src.loss: 0.2062, mix.decode.loss_seg: 0.0901, mix.decode.acc_seg: 96.3324, mix.loss: 0.0901, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:25:26,771 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 11:07:27, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2041, src.decode.acc_seg: 92.6841, src.loss: 0.2201, mix.decode.loss_seg: 0.1233, mix.decode.acc_seg: 95.3824, mix.loss: 0.1233, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:26:29,140 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 10:26:29,140 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 11:07:06, time: 1.247, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1933, src.decode.acc_seg: 93.3274, src.loss: 0.2094, mix.decode.loss_seg: 0.1108, mix.decode.acc_seg: 95.5679, mix.loss: 0.1108, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:27:30,470 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 11:06:38, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1776, src.decode.acc_seg: 93.4243, src.loss: 0.1937, mix.decode.loss_seg: 0.1025, mix.decode.acc_seg: 96.0529, mix.loss: 0.1025, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:28:32,921 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 11:06:16, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1645, src.decode.acc_seg: 94.3576, src.loss: 0.1805, mix.decode.loss_seg: 0.0838, mix.decode.acc_seg: 96.6824, mix.loss: 0.0838, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:29:34,603 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 11:05:49, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1972, src.decode.acc_seg: 92.8946, src.loss: 0.2133, mix.decode.loss_seg: 0.1120, mix.decode.acc_seg: 95.6235, mix.loss: 0.1120, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:30:36,309 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 11:05:21, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1812, src.decode.acc_seg: 93.4346, src.loss: 0.1973, mix.decode.loss_seg: 0.0969, mix.decode.acc_seg: 95.8581, mix.loss: 0.0969, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:31:37,949 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 11:04:52, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1739, src.decode.acc_seg: 94.1668, src.loss: 0.1900, mix.decode.loss_seg: 0.1006, mix.decode.acc_seg: 96.0249, mix.loss: 0.1006, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:32:40,000 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 11:04:25, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1734, src.decode.acc_seg: 93.7489, src.loss: 0.1894, mix.decode.loss_seg: 0.0928, mix.decode.acc_seg: 95.8628, mix.loss: 0.0928, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:33:41,476 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 11:03:54, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1841, src.decode.acc_seg: 93.5733, src.loss: 0.2002, mix.decode.loss_seg: 0.1076, mix.decode.acc_seg: 95.6723, mix.loss: 0.1076, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:34:43,290 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 11:03:24, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1713, src.decode.acc_seg: 94.1556, src.loss: 0.1874, mix.decode.loss_seg: 0.1074, mix.decode.acc_seg: 95.8585, mix.loss: 0.1074, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:35:44,765 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 11:02:52, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1869, src.decode.acc_seg: 93.3619, src.loss: 0.2030, mix.decode.loss_seg: 0.1023, mix.decode.acc_seg: 95.9371, mix.loss: 0.1023, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:36:46,821 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 11:02:22, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1845, src.decode.acc_seg: 93.5689, src.loss: 0.2005, mix.decode.loss_seg: 0.0895, mix.decode.acc_seg: 96.7715, mix.loss: 0.0895, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:37:48,590 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 11:01:51, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1647, src.decode.acc_seg: 94.1892, src.loss: 0.1807, mix.decode.loss_seg: 0.1044, mix.decode.acc_seg: 96.0745, mix.loss: 0.1044, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:38:50,131 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 11:01:17, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1781, src.decode.acc_seg: 93.6378, src.loss: 0.1942, mix.decode.loss_seg: 0.1032, mix.decode.acc_seg: 95.9893, mix.loss: 0.1032, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:39:51,825 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 11:00:44, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2240, src.decode.acc_seg: 92.3538, src.loss: 0.2401, mix.decode.loss_seg: 0.1552, mix.decode.acc_seg: 94.7281, mix.loss: 0.1552, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:40:53,131 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 11:00:08, time: 1.226, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1886, src.decode.acc_seg: 93.9824, src.loss: 0.2047, mix.decode.loss_seg: 0.1036, mix.decode.acc_seg: 95.9522, mix.loss: 0.1036, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:41:55,385 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 10:59:37, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1651, src.decode.acc_seg: 94.2386, src.loss: 0.1812, mix.decode.loss_seg: 0.0942, mix.decode.acc_seg: 96.2947, mix.loss: 0.0942, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:42:57,298 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 10:59:03, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1620, src.decode.acc_seg: 94.0344, src.loss: 0.1781, mix.decode.loss_seg: 0.0959, mix.decode.acc_seg: 96.2411, mix.loss: 0.0959, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:43:59,418 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 10:58:31, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1648, src.decode.acc_seg: 93.8729, src.loss: 0.1808, mix.decode.loss_seg: 0.0920, mix.decode.acc_seg: 96.3383, mix.loss: 0.0920, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:45:00,462 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 10:57:51, time: 1.221, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1703, src.decode.acc_seg: 93.7972, src.loss: 0.1864, mix.decode.loss_seg: 0.0942, mix.decode.acc_seg: 96.4914, mix.loss: 0.0942, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:46:01,792 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 10:57:13, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1497, src.decode.acc_seg: 94.6301, src.loss: 0.1658, mix.decode.loss_seg: 0.0862, mix.decode.acc_seg: 96.4880, mix.loss: 0.0862, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:47:03,418 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 10:47:03,418 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 10:56:36, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1920, src.decode.acc_seg: 93.2319, src.loss: 0.2080, mix.decode.loss_seg: 0.1154, mix.decode.acc_seg: 95.7482, mix.loss: 0.1154, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:48:04,874 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 10:55:58, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2030, src.decode.acc_seg: 92.6676, src.loss: 0.2191, mix.decode.loss_seg: 0.1192, mix.decode.acc_seg: 95.2319, mix.loss: 0.1192, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:49:06,909 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 10:55:23, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1862, src.decode.acc_seg: 93.3827, src.loss: 0.2022, mix.decode.loss_seg: 0.0932, mix.decode.acc_seg: 96.5856, mix.loss: 0.0932, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:50:08,813 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 10:54:46, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1698, src.decode.acc_seg: 94.3156, src.loss: 0.1858, mix.decode.loss_seg: 0.1089, mix.decode.acc_seg: 95.8598, mix.loss: 0.1089, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:51:09,980 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 10:54:05, time: 1.223, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1618, src.decode.acc_seg: 94.3540, src.loss: 0.1778, mix.decode.loss_seg: 0.0883, mix.decode.acc_seg: 96.3063, mix.loss: 0.0883, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:52:11,729 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 10:53:27, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1844, src.decode.acc_seg: 93.6020, src.loss: 0.2004, mix.decode.loss_seg: 0.1245, mix.decode.acc_seg: 95.1584, mix.loss: 0.1245, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:53:13,371 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 10:52:48, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1498, src.decode.acc_seg: 94.4250, src.loss: 0.1658, mix.decode.loss_seg: 0.0730, mix.decode.acc_seg: 97.1329, mix.loss: 0.0730, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:54:15,617 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 10:52:12, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1633, src.decode.acc_seg: 94.3999, src.loss: 0.1794, mix.decode.loss_seg: 0.0994, mix.decode.acc_seg: 96.2123, mix.loss: 0.0994, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:55:16,993 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 10:51:31, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1586, src.decode.acc_seg: 94.1392, src.loss: 0.1747, mix.decode.loss_seg: 0.0903, mix.decode.acc_seg: 96.5122, mix.loss: 0.0903, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:56:19,058 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 10:50:53, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1451, src.decode.acc_seg: 94.5785, src.loss: 0.1612, mix.decode.loss_seg: 0.0840, mix.decode.acc_seg: 96.7703, mix.loss: 0.0840, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:57:21,346 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 10:50:16, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1508, src.decode.acc_seg: 94.6228, src.loss: 0.1668, mix.decode.loss_seg: 0.0922, mix.decode.acc_seg: 96.2945, mix.loss: 0.0922, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:58:23,471 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 10:49:37, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1638, src.decode.acc_seg: 94.0757, src.loss: 0.1799, mix.decode.loss_seg: 0.0970, mix.decode.acc_seg: 95.9031, mix.loss: 0.0970, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:59:25,765 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 10:49:00, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1419, src.decode.acc_seg: 94.7045, src.loss: 0.1580, mix.decode.loss_seg: 0.0914, mix.decode.acc_seg: 96.3170, mix.loss: 0.0914, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:00:27,058 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 10:48:16, time: 1.226, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1593, src.decode.acc_seg: 94.7687, src.loss: 0.1753, mix.decode.loss_seg: 0.1009, mix.decode.acc_seg: 96.2177, mix.loss: 0.1009, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:01:28,979 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 10:47:36, time: 1.238, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1543, src.decode.acc_seg: 94.5590, src.loss: 0.1704, mix.decode.loss_seg: 0.1111, mix.decode.acc_seg: 95.5811, mix.loss: 0.1111, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:02:30,979 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 10:46:56, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1727, src.decode.acc_seg: 93.5853, src.loss: 0.1887, mix.decode.loss_seg: 0.1040, mix.decode.acc_seg: 95.9382, mix.loss: 0.1040, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:03:32,538 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 10:46:13, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1895, src.decode.acc_seg: 93.2113, src.loss: 0.2056, mix.decode.loss_seg: 0.1116, mix.decode.acc_seg: 95.5041, mix.loss: 0.1116, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:04:34,043 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 10:45:29, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1749, src.decode.acc_seg: 94.1490, src.loss: 0.1910, mix.decode.loss_seg: 0.1068, mix.decode.acc_seg: 95.9275, mix.loss: 0.1068, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:05:35,063 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 10:44:44, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1361, src.decode.acc_seg: 94.9183, src.loss: 0.1521, mix.decode.loss_seg: 0.0894, mix.decode.acc_seg: 96.1411, mix.loss: 0.0894, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:06:36,264 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 10:43:58, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1183, src.decode.acc_seg: 95.6947, src.loss: 0.1343, mix.decode.loss_seg: 0.0778, mix.decode.acc_seg: 96.6168, mix.loss: 0.0778, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:07:37,968 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 11:07:37,968 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 10:43:15, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1411, src.decode.acc_seg: 95.1203, src.loss: 0.1572, mix.decode.loss_seg: 0.0892, mix.decode.acc_seg: 96.3804, mix.loss: 0.0892, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:08:40,033 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 10:42:33, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1673, src.decode.acc_seg: 94.3768, src.loss: 0.1834, mix.decode.loss_seg: 0.0929, mix.decode.acc_seg: 96.1306, mix.loss: 0.0929, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:09:41,967 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 10:41:51, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1811, src.decode.acc_seg: 93.6032, src.loss: 0.1971, mix.decode.loss_seg: 0.1013, mix.decode.acc_seg: 95.9566, mix.loss: 0.1013, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:10:43,909 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 10:41:08, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1528, src.decode.acc_seg: 94.6272, src.loss: 0.1689, mix.decode.loss_seg: 0.0944, mix.decode.acc_seg: 96.1047, mix.loss: 0.0944, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:11:45,472 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 10:40:23, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1451, src.decode.acc_seg: 94.8309, src.loss: 0.1612, mix.decode.loss_seg: 0.0845, mix.decode.acc_seg: 96.5724, mix.loss: 0.0845, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:12:46,994 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 10:39:38, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1410, src.decode.acc_seg: 94.6800, src.loss: 0.1571, mix.decode.loss_seg: 0.0804, mix.decode.acc_seg: 96.4345, mix.loss: 0.0804, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:13:48,691 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 10:38:53, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1605, src.decode.acc_seg: 94.2076, src.loss: 0.1766, mix.decode.loss_seg: 0.0891, mix.decode.acc_seg: 96.5193, mix.loss: 0.0891, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:14:50,535 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 10:38:09, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1620, src.decode.acc_seg: 94.3776, src.loss: 0.1781, mix.decode.loss_seg: 0.1142, mix.decode.acc_seg: 95.7627, mix.loss: 0.1142, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:15:52,292 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 10:37:24, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1367, src.decode.acc_seg: 95.0483, src.loss: 0.1528, mix.decode.loss_seg: 0.0812, mix.decode.acc_seg: 96.6014, mix.loss: 0.0812, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:16:54,087 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 10:36:39, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1679, src.decode.acc_seg: 94.1261, src.loss: 0.1839, mix.decode.loss_seg: 0.1012, mix.decode.acc_seg: 96.0467, mix.loss: 0.1012, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:17:56,477 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 10:35:56, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1336, src.decode.acc_seg: 95.3959, src.loss: 0.1496, mix.decode.loss_seg: 0.0764, mix.decode.acc_seg: 97.1272, mix.loss: 0.0764, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:18:59,016 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 10:35:14, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1423, src.decode.acc_seg: 94.9523, src.loss: 0.1583, mix.decode.loss_seg: 0.0853, mix.decode.acc_seg: 96.2817, mix.loss: 0.0853, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:20:00,749 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 10:34:28, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1316, src.decode.acc_seg: 95.3027, src.loss: 0.1476, mix.decode.loss_seg: 0.0884, mix.decode.acc_seg: 96.5342, mix.loss: 0.0884, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:21:02,456 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 10:33:42, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1307, src.decode.acc_seg: 95.6857, src.loss: 0.1467, mix.decode.loss_seg: 0.0765, mix.decode.acc_seg: 96.9139, mix.loss: 0.0765, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:22:03,787 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 10:32:54, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1403, src.decode.acc_seg: 94.8441, src.loss: 0.1564, mix.decode.loss_seg: 0.0735, mix.decode.acc_seg: 97.1035, mix.loss: 0.0735, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:23:05,459 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 10:32:07, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1374, src.decode.acc_seg: 95.0372, src.loss: 0.1534, mix.decode.loss_seg: 0.0813, mix.decode.acc_seg: 96.9006, mix.loss: 0.0813, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:24:07,185 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 10:31:21, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1315, src.decode.acc_seg: 95.1895, src.loss: 0.1475, mix.decode.loss_seg: 0.0752, mix.decode.acc_seg: 96.8156, mix.loss: 0.0752, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:25:09,275 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 10:30:35, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1663, src.decode.acc_seg: 94.1845, src.loss: 0.1824, mix.decode.loss_seg: 0.0892, mix.decode.acc_seg: 96.4323, mix.loss: 0.0892, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:26:11,328 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 10:29:49, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1421, src.decode.acc_seg: 95.0927, src.loss: 0.1581, mix.decode.loss_seg: 0.0953, mix.decode.acc_seg: 96.2729, mix.loss: 0.0953, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:27:13,724 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 10:29:05, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1596, src.decode.acc_seg: 94.5241, src.loss: 0.1757, mix.decode.loss_seg: 0.0886, mix.decode.acc_seg: 96.6640, mix.loss: 0.0886, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.1 task/s, elapsed: 1s, ETA:   873s[                                 ] 2/929, 1.9 task/s, elapsed: 1s, ETA:   481s[                                 ] 3/929, 2.7 task/s, elapsed: 1s, ETA:   349s[                                 ] 4/929, 3.3 task/s, elapsed: 1s, ETA:   284s[                                 ] 5/929, 3.8 task/s, elapsed: 1s, ETA:   244s[                                 ] 6/929, 4.2 task/s, elapsed: 1s, ETA:   219s[                                 ] 7/929, 4.6 task/s, elapsed: 2s, ETA:   200s[                                 ] 8/929, 4.9 task/s, elapsed: 2s, ETA:   187s[                                 ] 9/929, 5.2 task/s, elapsed: 2s, ETA:   177s[                                ] 10/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 11/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 12/929, 5.8 task/s, elapsed: 2s, ETA:   158s[                                ] 13/929, 6.0 task/s, elapsed: 2s, ETA:   153s[                                ] 14/929, 6.2 task/s, elapsed: 2s, ETA:   148s[                                ] 15/929, 6.3 task/s, elapsed: 2s, ETA:   144s[                                ] 16/929, 6.5 task/s, elapsed: 2s, ETA:   141s[                                ] 17/929, 6.6 task/s, elapsed: 3s, ETA:   138s[                                ] 18/929, 6.7 task/s, elapsed: 3s, ETA:   135s[                                ] 19/929, 6.9 task/s, elapsed: 3s, ETA:   133s[                                ] 20/929, 7.0 task/s, elapsed: 3s, ETA:   131s[                                ] 21/929, 7.1 task/s, elapsed: 3s, ETA:   128s[                                ] 22/929, 7.2 task/s, elapsed: 3s, ETA:   126s[                                ] 23/929, 7.3 task/s, elapsed: 3s, ETA:   125s[                                ] 24/929, 7.4 task/s, elapsed: 3s, ETA:   123s[                                ] 25/929, 7.4 task/s, elapsed: 3s, ETA:   121s[                                ] 26/929, 7.5 task/s, elapsed: 3s, ETA:   120s[                                ] 27/929, 7.6 task/s, elapsed: 4s, ETA:   119s[                                ] 28/929, 7.7 task/s, elapsed: 4s, ETA:   117s[                                ] 29/929, 7.7 task/s, elapsed: 4s, ETA:   116s[>                               ] 30/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 31/929, 7.9 task/s, elapsed: 4s, ETA:   114s[>                               ] 32/929, 7.9 task/s, elapsed: 4s, ETA:   113s[>                               ] 33/929, 8.0 task/s, elapsed: 4s, ETA:   112s[>                               ] 34/929, 8.0 task/s, elapsed: 4s, ETA:   112s[>                               ] 35/929, 8.1 task/s, elapsed: 4s, ETA:   111s[>                               ] 36/929, 8.1 task/s, elapsed: 4s, ETA:   110s[>                               ] 37/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 38/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 39/929, 8.2 task/s, elapsed: 5s, ETA:   109s[>                               ] 40/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 41/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 42/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 43/929, 8.3 task/s, elapsed: 5s, ETA:   107s[>                               ] 44/929, 8.3 task/s, elapsed: 5s, ETA:   106s[>                               ] 45/929, 8.3 task/s, elapsed: 5s, ETA:   106s[>                               ] 46/929, 8.4 task/s, elapsed: 5s, ETA:   106s[>                               ] 47/929, 8.4 task/s, elapsed: 6s, ETA:   105s[>                               ] 48/929, 8.4 task/s, elapsed: 6s, ETA:   105s[>                               ] 49/929, 8.4 task/s, elapsed: 6s, ETA:   104s[>                               ] 50/929, 8.4 task/s, elapsed: 6s, ETA:   104s[>                               ] 51/929, 8.5 task/s, elapsed: 6s, ETA:   104s[>                               ] 52/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 53/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 54/929, 8.5 task/s, elapsed: 6s, ETA:   103s[>                               ] 55/929, 8.5 task/s, elapsed: 6s, ETA:   102s[>                               ] 56/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>                               ] 57/929, 8.6 task/s, elapsed: 7s, ETA:   102s[>                               ] 58/929, 8.6 task/s, elapsed: 7s, ETA:   102s[>>                              ] 59/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 60/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 61/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 62/929, 8.6 task/s, elapsed: 7s, ETA:   101s[>>                              ] 63/929, 8.6 task/s, elapsed: 7s, ETA:   100s[>>                              ] 64/929, 8.6 task/s, elapsed: 7s, ETA:   100s[>>                              ] 65/929, 8.7 task/s, elapsed: 8s, ETA:   100s[>>                              ] 66/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 67/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 68/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 69/929, 8.7 task/s, elapsed: 8s, ETA:    99s[>>                              ] 70/929, 8.7 task/s, elapsed: 8s, ETA:    98s[>>                              ] 71/929, 8.7 task/s, elapsed: 8s, ETA:    98s[>>                              ] 72/929, 8.7 task/s, elapsed: 8s, ETA:    98s[>>                              ] 73/929, 8.8 task/s, elapsed: 8s, ETA:    98s[>>                              ] 74/929, 8.8 task/s, elapsed: 8s, ETA:    98s[>>                              ] 75/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 76/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 77/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 78/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 79/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                              ] 80/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                              ] 81/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                              ] 82/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                              ] 83/929, 8.9 task/s, elapsed: 9s, ETA:    96s[>>                              ] 84/929, 8.9 task/s, elapsed: 9s, ETA:    95s[>>                             ] 85/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 86/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 87/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 88/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 89/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 90/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 91/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 92/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 93/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 94/929, 8.9 task/s, elapsed: 11s, ETA:    94s[>>>                            ] 95/929, 8.9 task/s, elapsed: 11s, ETA:    94s[>>>                            ] 96/929, 8.9 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 97/929, 8.9 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 98/929, 8.9 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 99/929, 8.9 task/s, elapsed: 11s, ETA:    93s[>>>                           ] 100/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                           ] 101/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 102/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 103/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 104/929, 9.0 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 105/929, 9.0 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 106/929, 9.0 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 107/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 108/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 109/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 110/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 111/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 112/929, 9.0 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 113/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 114/929, 9.1 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 115/929, 9.1 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 116/929, 9.1 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 117/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 118/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 119/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 120/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 121/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 122/929, 9.1 task/s, elapsed: 13s, ETA:    88s[>>>                           ] 123/929, 9.1 task/s, elapsed: 13s, ETA:    88s[>>>>                          ] 124/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 125/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 126/929, 9.2 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 127/929, 9.2 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 128/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 129/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 130/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 131/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 132/929, 9.2 task/s, elapsed: 14s, ETA:    87s[>>>>                          ] 133/929, 9.2 task/s, elapsed: 14s, ETA:    86s[>>>>                          ] 134/929, 9.2 task/s, elapsed: 15s, ETA:    86s[>>>>                          ] 135/929, 9.2 task/s, elapsed: 15s, ETA:    86s[>>>>                          ] 136/929, 9.2 task/s, elapsed: 15s, ETA:    86s[>>>>                          ] 137/929, 9.2 task/s, elapsed: 15s, ETA:    86s[>>>>                          ] 138/929, 9.2 task/s, elapsed: 15s, ETA:    86s[>>>>                          ] 139/929, 9.2 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 140/929, 9.2 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 141/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 142/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 143/929, 9.3 task/s, elapsed: 15s, ETA:    85s[>>>>                          ] 144/929, 9.3 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 145/929, 9.3 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 146/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 147/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 148/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 149/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 150/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 151/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 152/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 153/929, 9.3 task/s, elapsed: 16s, ETA:    84s[>>>>                          ] 154/929, 9.3 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 155/929, 9.3 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 156/929, 9.3 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 157/929, 9.3 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 158/929, 9.3 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 159/929, 9.3 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 160/929, 9.3 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 161/929, 9.3 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 162/929, 9.3 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 163/929, 9.3 task/s, elapsed: 17s, ETA:    82s[>>>>>                         ] 164/929, 9.3 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 165/929, 9.3 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 166/929, 9.3 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 167/929, 9.3 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 168/929, 9.3 task/s, elapsed: 18s, ETA:    81s[>>>>>                         ] 169/929, 9.3 task/s, elapsed: 18s, ETA:    81s[>>>>>                         ] 170/929, 9.4 task/s, elapsed: 18s, ETA:    81s[>>>>>                         ] 171/929, 9.4 task/s, elapsed: 18s, ETA:    81s[>>>>>                         ] 172/929, 9.4 task/s, elapsed: 18s, ETA:    81s[>>>>>                         ] 173/929, 9.4 task/s, elapsed: 18s, ETA:    81s[>>>>>                         ] 174/929, 9.4 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 175/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 176/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 177/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 178/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 179/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 180/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 181/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 182/929, 9.4 task/s, elapsed: 19s, ETA:    80s[>>>>>                         ] 183/929, 9.4 task/s, elapsed: 19s, ETA:    79s[>>>>>                         ] 184/929, 9.4 task/s, elapsed: 20s, ETA:    79s[>>>>>                         ] 185/929, 9.4 task/s, elapsed: 20s, ETA:    79s[>>>>>>                        ] 186/929, 9.4 task/s, elapsed: 20s, ETA:    79s[>>>>>>                        ] 187/929, 9.4 task/s, elapsed: 20s, ETA:    79s[>>>>>>                        ] 188/929, 9.4 task/s, elapsed: 20s, ETA:    79s[>>>>>>                        ] 189/929, 9.4 task/s, elapsed: 20s, ETA:    79s[>>>>>>                        ] 190/929, 9.4 task/s, elapsed: 20s, ETA:    78s[>>>>>>                        ] 191/929, 9.4 task/s, elapsed: 20s, ETA:    78s[>>>>>>                        ] 192/929, 9.4 task/s, elapsed: 20s, ETA:    78s[>>>>>>                        ] 193/929, 9.4 task/s, elapsed: 20s, ETA:    78s[>>>>>>                        ] 194/929, 9.4 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 195/929, 9.4 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 196/929, 9.4 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 197/929, 9.4 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 198/929, 9.4 task/s, elapsed: 21s, ETA:    77s[>>>>>>                        ] 199/929, 9.4 task/s, elapsed: 21s, ETA:    77s[>>>>>>                        ] 200/929, 9.4 task/s, elapsed: 21s, ETA:    77s[>>>>>>                        ] 201/929, 9.4 task/s, elapsed: 21s, ETA:    77s[>>>>>>                        ] 202/929, 9.4 task/s, elapsed: 21s, ETA:    77s[>>>>>>                        ] 203/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 204/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 205/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 206/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 207/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 208/929, 9.4 task/s, elapsed: 22s, ETA:    76s[>>>>>>                        ] 209/929, 9.4 task/s, elapsed: 22s, ETA:    76s[>>>>>>                        ] 210/929, 9.4 task/s, elapsed: 22s, ETA:    76s[>>>>>>                        ] 211/929, 9.4 task/s, elapsed: 22s, ETA:    76s[>>>>>>                        ] 212/929, 9.4 task/s, elapsed: 22s, ETA:    76s[>>>>>>                        ] 213/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 214/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 215/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 216/929, 9.4 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 217/929, 9.5 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 218/929, 9.5 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 219/929, 9.4 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 220/929, 9.5 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 221/929, 9.5 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 222/929, 9.5 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 223/929, 9.5 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 224/929, 9.5 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 225/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 226/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 227/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 228/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 229/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 230/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 231/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 232/929, 9.5 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 233/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 234/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 235/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 236/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 237/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 238/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 239/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 240/929, 9.5 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 241/929, 9.5 task/s, elapsed: 25s, ETA:    72s[>>>>>>>                       ] 242/929, 9.5 task/s, elapsed: 25s, ETA:    72s[>>>>>>>                       ] 243/929, 9.5 task/s, elapsed: 26s, ETA:    72s[>>>>>>>                       ] 244/929, 9.5 task/s, elapsed: 26s, ETA:    72s[>>>>>>>                       ] 245/929, 9.5 task/s, elapsed: 26s, ETA:    72s[>>>>>>>                       ] 246/929, 9.5 task/s, elapsed: 26s, ETA:    72s[>>>>>>>                       ] 247/929, 9.5 task/s, elapsed: 26s, ETA:    72s[>>>>>>>>                      ] 248/929, 9.5 task/s, elapsed: 26s, ETA:    71s[>>>>>>>>                      ] 249/929, 9.5 task/s, elapsed: 26s, ETA:    71s[>>>>>>>>                      ] 250/929, 9.5 task/s, elapsed: 26s, ETA:    71s[>>>>>>>>                      ] 251/929, 9.5 task/s, elapsed: 26s, ETA:    71s[>>>>>>>>                      ] 252/929, 9.5 task/s, elapsed: 26s, ETA:    71s[>>>>>>>>                      ] 253/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 254/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 255/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 256/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 257/929, 9.5 task/s, elapsed: 27s, ETA:    70s[>>>>>>>>                      ] 258/929, 9.5 task/s, elapsed: 27s, ETA:    70s[>>>>>>>>                      ] 259/929, 9.6 task/s, elapsed: 27s, ETA:    70s[>>>>>>>>                      ] 260/929, 9.6 task/s, elapsed: 27s, ETA:    70s[>>>>>>>>                      ] 261/929, 9.6 task/s, elapsed: 27s, ETA:    70s[>>>>>>>>                      ] 262/929, 9.6 task/s, elapsed: 27s, ETA:    70s[>>>>>>>>                      ] 263/929, 9.6 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 264/929, 9.6 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 265/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 266/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 267/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 268/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 269/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 270/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 271/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 272/929, 9.6 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 273/929, 9.6 task/s, elapsed: 28s, ETA:    68s[>>>>>>>>                      ] 274/929, 9.6 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>                      ] 275/929, 9.6 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>                      ] 276/929, 9.6 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>                      ] 277/929, 9.6 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>                      ] 278/929, 9.6 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 279/929, 9.6 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 280/929, 9.5 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 281/929, 9.6 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 282/929, 9.6 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 283/929, 9.6 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 284/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 285/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 286/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 287/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 288/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 289/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 290/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 291/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 292/929, 9.6 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 293/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 294/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 295/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 296/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 297/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 298/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 299/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 300/929, 9.6 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 301/929, 9.6 task/s, elapsed: 31s, ETA:    65s[>>>>>>>>>                     ] 302/929, 9.6 task/s, elapsed: 31s, ETA:    65s[>>>>>>>>>                     ] 303/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 304/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 305/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 306/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 307/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 308/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 309/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>>                    ] 310/929, 9.6 task/s, elapsed: 32s, ETA:    64s[>>>>>>>>>>                    ] 311/929, 9.6 task/s, elapsed: 32s, ETA:    64s[>>>>>>>>>>                    ] 312/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 313/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 314/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 315/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 316/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 317/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 318/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 319/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 320/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 321/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 322/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 323/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 324/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 325/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 326/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 327/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 328/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 329/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 330/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 331/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 332/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 333/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 334/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 335/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 336/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 337/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 338/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 339/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 340/929, 9.6 task/s, elapsed: 35s, ETA:    61s[>>>>>>>>>>>                   ] 341/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 342/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 343/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 344/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 345/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 346/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 347/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 348/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 349/929, 9.6 task/s, elapsed: 36s, ETA:    60s[>>>>>>>>>>>                   ] 350/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 351/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 352/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 353/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 354/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 355/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 356/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 357/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 358/929, 9.6 task/s, elapsed: 37s, ETA:    59s[>>>>>>>>>>>                   ] 359/929, 9.6 task/s, elapsed: 37s, ETA:    59s[>>>>>>>>>>>                   ] 360/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 361/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 362/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 363/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 364/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 365/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 366/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 367/929, 9.6 task/s, elapsed: 38s, ETA:    58s[>>>>>>>>>>>                   ] 368/929, 9.6 task/s, elapsed: 38s, ETA:    58s[>>>>>>>>>>>                   ] 369/929, 9.6 task/s, elapsed: 38s, ETA:    58s[>>>>>>>>>>>                   ] 370/929, 9.6 task/s, elapsed: 38s, ETA:    58s[>>>>>>>>>>>                   ] 371/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 372/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 373/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 374/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 375/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 376/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 377/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 378/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 379/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 380/929, 9.6 task/s, elapsed: 39s, ETA:    57s[>>>>>>>>>>>>                  ] 381/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 382/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 383/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 384/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 385/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 386/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 387/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 388/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 389/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 390/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 391/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 392/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 393/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 394/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 395/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 396/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 397/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 398/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 399/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 400/929, 9.6 task/s, elapsed: 41s, ETA:    55s[>>>>>>>>>>>>                  ] 401/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>                  ] 402/929, 9.7 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>>                 ] 403/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 404/929, 9.6 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 405/929, 9.6 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 406/929, 9.6 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 407/929, 9.6 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 408/929, 9.6 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 409/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 410/929, 9.7 task/s, elapsed: 42s, ETA:    54s[>>>>>>>>>>>>>                 ] 411/929, 9.7 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 412/929, 9.7 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 413/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 414/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 415/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 416/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 417/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 418/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 419/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 420/929, 9.7 task/s, elapsed: 43s, ETA:    53s[>>>>>>>>>>>>>                 ] 421/929, 9.7 task/s, elapsed: 44s, ETA:    53s[>>>>>>>>>>>>>                 ] 422/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 423/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 424/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 425/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 426/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 427/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 428/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 429/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 430/929, 9.7 task/s, elapsed: 44s, ETA:    52s[>>>>>>>>>>>>>                 ] 431/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>                 ] 432/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>                 ] 433/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 434/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 435/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 436/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 437/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 438/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 439/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 440/929, 9.7 task/s, elapsed: 45s, ETA:    51s[>>>>>>>>>>>>>>                ] 441/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 442/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 443/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 444/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 445/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 446/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 447/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 448/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 449/929, 9.7 task/s, elapsed: 46s, ETA:    50s[>>>>>>>>>>>>>>                ] 450/929, 9.7 task/s, elapsed: 47s, ETA:    50s[>>>>>>>>>>>>>>                ] 451/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 452/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 453/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 454/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 455/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 456/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 457/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 458/929, 9.7 task/s, elapsed: 47s, ETA:    49s[>>>>>>>>>>>>>>                ] 459/929, 9.7 task/s, elapsed: 48s, ETA:    49s[>>>>>>>>>>>>>>                ] 460/929, 9.7 task/s, elapsed: 48s, ETA:    49s[>>>>>>>>>>>>>>                ] 461/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>                ] 462/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>                ] 463/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>                ] 464/929, 9.7 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>>               ] 465/929, 9.6 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>>               ] 466/929, 9.6 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>>               ] 467/929, 9.6 task/s, elapsed: 48s, ETA:    48s[>>>>>>>>>>>>>>>               ] 468/929, 9.6 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 469/929, 9.6 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 470/929, 9.6 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 471/929, 9.6 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 472/929, 9.6 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 473/929, 9.6 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 474/929, 9.6 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 475/929, 9.6 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 476/929, 9.6 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 477/929, 9.6 task/s, elapsed: 49s, ETA:    47s[>>>>>>>>>>>>>>>               ] 478/929, 9.6 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 479/929, 9.6 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 480/929, 9.6 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 481/929, 9.6 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 482/929, 9.6 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 483/929, 9.6 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 484/929, 9.7 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 485/929, 9.6 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 486/929, 9.6 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 487/929, 9.6 task/s, elapsed: 50s, ETA:    46s[>>>>>>>>>>>>>>>               ] 488/929, 9.6 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 489/929, 9.6 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 490/929, 9.6 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 491/929, 9.6 task/s, elapsed: 51s, ETA:    45s[>>>>>>>>>>>>>>>               ] 492/929, 9.6 task/s, elapsed: 51s, ETA:    45s[>>>>>>>>>>>>>>>               ] 493/929, 9.6 task/s, elapsed: 51s, ETA:    45s[>>>>>>>>>>>>>>>               ] 494/929, 9.6 task/s, elapsed: 51s, ETA:    45s[>>>>>>>>>>>>>>>               ] 495/929, 9.6 task/s, elapsed: 51s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 496/929, 9.6 task/s, elapsed: 51s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 497/929, 9.6 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 498/929, 9.6 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 499/929, 9.6 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 500/929, 9.6 task/s, elapsed: 52s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 501/929, 9.6 task/s, elapsed: 52s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 502/929, 9.6 task/s, elapsed: 52s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 503/929, 9.6 task/s, elapsed: 52s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 504/929, 9.6 task/s, elapsed: 52s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 505/929, 9.6 task/s, elapsed: 52s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 506/929, 9.6 task/s, elapsed: 52s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 507/929, 9.6 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 508/929, 9.6 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 509/929, 9.6 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 510/929, 9.6 task/s, elapsed: 53s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 511/929, 9.6 task/s, elapsed: 53s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 512/929, 9.6 task/s, elapsed: 53s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 513/929, 9.6 task/s, elapsed: 53s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 514/929, 9.6 task/s, elapsed: 53s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 515/929, 9.6 task/s, elapsed: 53s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 516/929, 9.6 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 517/929, 9.6 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 518/929, 9.6 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 519/929, 9.6 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 520/929, 9.6 task/s, elapsed: 54s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 521/929, 9.6 task/s, elapsed: 54s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 522/929, 9.6 task/s, elapsed: 54s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 523/929, 9.6 task/s, elapsed: 54s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 524/929, 9.6 task/s, elapsed: 54s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 525/929, 9.6 task/s, elapsed: 54s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 526/929, 9.6 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.6 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.6 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.6 task/s, elapsed: 55s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.6 task/s, elapsed: 55s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.6 task/s, elapsed: 55s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.6 task/s, elapsed: 55s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.6 task/s, elapsed: 55s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.6 task/s, elapsed: 55s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.6 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.6 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.6 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.6 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.6 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.6 task/s, elapsed: 56s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.6 task/s, elapsed: 56s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.6 task/s, elapsed: 56s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.6 task/s, elapsed: 56s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.6 task/s, elapsed: 56s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.6 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.6 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.6 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.6 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.6 task/s, elapsed: 57s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.6 task/s, elapsed: 57s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.6 task/s, elapsed: 57s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.6 task/s, elapsed: 57s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.6 task/s, elapsed: 57s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.6 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.6 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.6 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.6 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.6 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.6 task/s, elapsed: 58s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.6 task/s, elapsed: 58s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.6 task/s, elapsed: 58s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.6 task/s, elapsed: 58s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.6 task/s, elapsed: 58s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.6 task/s, elapsed: 59s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.6 task/s, elapsed: 59s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.6 task/s, elapsed: 59s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.6 task/s, elapsed: 59s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.6 task/s, elapsed: 59s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.6 task/s, elapsed: 59s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.6 task/s, elapsed: 60s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.6 task/s, elapsed: 60s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.6 task/s, elapsed: 60s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.6 task/s, elapsed: 60s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.6 task/s, elapsed: 60s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.6 task/s, elapsed: 60s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.7 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.7 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.7 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.7 task/s, elapsed: 61s, ETA:    35s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.7 task/s, elapsed: 61s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.7 task/s, elapsed: 61s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.7 task/s, elapsed: 61s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.7 task/s, elapsed: 61s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.7 task/s, elapsed: 61s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.6 task/s, elapsed: 61s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.6 task/s, elapsed: 62s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.6 task/s, elapsed: 62s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.6 task/s, elapsed: 62s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.6 task/s, elapsed: 62s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.6 task/s, elapsed: 62s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.6 task/s, elapsed: 62s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.6 task/s, elapsed: 63s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.6 task/s, elapsed: 63s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.6 task/s, elapsed: 63s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.6 task/s, elapsed: 63s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.6 task/s, elapsed: 63s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.6 task/s, elapsed: 63s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.6 task/s, elapsed: 63s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.6 task/s, elapsed: 64s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.6 task/s, elapsed: 64s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.6 task/s, elapsed: 64s, ETA:    32s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.6 task/s, elapsed: 64s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.6 task/s, elapsed: 64s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.6 task/s, elapsed: 64s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.6 task/s, elapsed: 65s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.6 task/s, elapsed: 65s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.6 task/s, elapsed: 65s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.6 task/s, elapsed: 65s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.6 task/s, elapsed: 65s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.6 task/s, elapsed: 66s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.6 task/s, elapsed: 66s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.6 task/s, elapsed: 66s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.6 task/s, elapsed: 66s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.6 task/s, elapsed: 66s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.6 task/s, elapsed: 67s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.6 task/s, elapsed: 67s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.6 task/s, elapsed: 67s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.6 task/s, elapsed: 67s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.6 task/s, elapsed: 67s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.6 task/s, elapsed: 67s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.6 task/s, elapsed: 68s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.6 task/s, elapsed: 68s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.6 task/s, elapsed: 68s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.6 task/s, elapsed: 68s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.6 task/s, elapsed: 68s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.6 task/s, elapsed: 69s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.6 task/s, elapsed: 69s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.6 task/s, elapsed: 69s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.6 task/s, elapsed: 69s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.6 task/s, elapsed: 69s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.6 task/s, elapsed: 70s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.6 task/s, elapsed: 70s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.6 task/s, elapsed: 70s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.6 task/s, elapsed: 70s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.6 task/s, elapsed: 70s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.6 task/s, elapsed: 70s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.6 task/s, elapsed: 71s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.6 task/s, elapsed: 71s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.6 task/s, elapsed: 71s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.6 task/s, elapsed: 71s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.6 task/s, elapsed: 71s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.6 task/s, elapsed: 76s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.6 task/s, elapsed: 76s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.6 task/s, elapsed: 76s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.6 task/s, elapsed: 76s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.6 task/s, elapsed: 76s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.6 task/s, elapsed: 76s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.6 task/s, elapsed: 79s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.6 task/s, elapsed: 79s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.6 task/s, elapsed: 79s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.6 task/s, elapsed: 79s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.6 task/s, elapsed: 79s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.6 task/s, elapsed: 79s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.6 task/s, elapsed: 81s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.6 task/s, elapsed: 81s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.6 task/s, elapsed: 81s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.6 task/s, elapsed: 81s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.6 task/s, elapsed: 81s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.6 task/s, elapsed: 81s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.6 task/s, elapsed: 82s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.6 task/s, elapsed: 82s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.6 task/s, elapsed: 82s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.6 task/s, elapsed: 82s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.6 task/s, elapsed: 82s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.6 task/s, elapsed: 82s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.7 task/s, elapsed: 82s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.7 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.7 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.7 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.7 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.7 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.7 task/s, elapsed: 84s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.7 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.7 task/s, elapsed: 85s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.7 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.7 task/s, elapsed: 86s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.7 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.7 task/s, elapsed: 87s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.7 task/s, elapsed: 88s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.7 task/s, elapsed: 89s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.7 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.7 task/s, elapsed: 90s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.7 task/s, elapsed: 91s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.7 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.7 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.7 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.7 task/s, elapsed: 93s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.7 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.7 task/s, elapsed: 94s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.7 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.7 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.7 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.7 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.7 task/s, elapsed: 96s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.7 task/s, elapsed: 96s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.7 task/s, elapsed: 96s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.7 task/s, elapsed: 96s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.7 task/s, elapsed: 96s, ETA:     0s2022-10-10 11:32:25,339 - mmseg - INFO - per class results:2022-10-10 11:32:25,340 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 88.54 | 91.64 || rigid_plastic | 29.77 | 47.03 ||   cardboard   | 52.77 | 85.97 ||     metal     | 26.79 | 51.67 ||  soft_plastic | 55.94 |  61.5 |+---------------+-------+-------+2022-10-10 11:32:25,340 - mmseg - INFO - Summary:2022-10-10 11:32:25,340 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 88.89 | 50.76 | 67.56 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:32:25,344 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 11:32:25,345 - mmseg - INFO - Iter [929/40000]	lr: 4.800e-05, eta: 10:28:19, time: 1.241, data_time: 0.014, memory: 67493, aAcc: 0.8889, mIoU: 0.5076, mAcc: 0.6756, IoU.background: 0.8854, IoU.rigid_plastic: 0.2977, IoU.cardboard: 0.5277, IoU.metal: 0.2679, IoU.soft_plastic: 0.5594, Acc.background: 0.9164, Acc.rigid_plastic: 0.4703, Acc.cardboard: 0.8597, Acc.metal: 0.5167, Acc.soft_plastic: 0.6150, src.decode.loss_seg: 0.1280, src.decode.acc_seg: 95.3270, src.loss: 0.1441, mix.decode.loss_seg: 0.0873, mix.decode.acc_seg: 96.6814, mix.loss: 0.0873, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:33:29,600 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 10:44:11, time: 6.276, data_time: 5.006, memory: 67493, src.decode.loss_seg: 0.1583, src.decode.acc_seg: 94.3934, src.loss: 0.1743, mix.decode.loss_seg: 0.0785, mix.decode.acc_seg: 96.8760, mix.loss: 0.0785, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:34:31,983 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 10:43:18, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1280, src.decode.acc_seg: 95.4548, src.loss: 0.1441, mix.decode.loss_seg: 0.0886, mix.decode.acc_seg: 96.5824, mix.loss: 0.0886, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:35:34,077 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 10:42:24, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1297, src.decode.acc_seg: 95.3031, src.loss: 0.1458, mix.decode.loss_seg: 0.1005, mix.decode.acc_seg: 95.8386, mix.loss: 0.1005, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:36:36,039 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 10:41:29, time: 1.239, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1446, src.decode.acc_seg: 95.1790, src.loss: 0.1607, mix.decode.loss_seg: 0.0779, mix.decode.acc_seg: 96.4790, mix.loss: 0.0779, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:37:38,020 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 10:40:34, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1338, src.decode.acc_seg: 95.0896, src.loss: 0.1498, mix.decode.loss_seg: 0.0721, mix.decode.acc_seg: 96.9293, mix.loss: 0.0721, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:38:39,817 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 10:39:39, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1317, src.decode.acc_seg: 95.0541, src.loss: 0.1477, mix.decode.loss_seg: 0.0841, mix.decode.acc_seg: 96.6159, mix.loss: 0.0841, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:39:41,714 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 10:38:43, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1347, src.decode.acc_seg: 95.2541, src.loss: 0.1508, mix.decode.loss_seg: 0.0849, mix.decode.acc_seg: 96.8848, mix.loss: 0.0849, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:40:43,840 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 10:37:49, time: 1.243, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1604, src.decode.acc_seg: 94.5697, src.loss: 0.1765, mix.decode.loss_seg: 0.1006, mix.decode.acc_seg: 96.0934, mix.loss: 0.1006, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:41:45,859 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 10:36:54, time: 1.240, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1466, src.decode.acc_seg: 94.5916, src.loss: 0.1626, mix.decode.loss_seg: 0.0838, mix.decode.acc_seg: 96.4474, mix.loss: 0.0838, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:42:47,300 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 10:35:56, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1428, src.decode.acc_seg: 94.9016, src.loss: 0.1588, mix.decode.loss_seg: 0.0787, mix.decode.acc_seg: 96.8192, mix.loss: 0.0787, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:43:49,273 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 10:35:01, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1310, src.decode.acc_seg: 95.3521, src.loss: 0.1471, mix.decode.loss_seg: 0.0684, mix.decode.acc_seg: 97.0605, mix.loss: 0.0684, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:44:50,908 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 10:34:04, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1309, src.decode.acc_seg: 95.0906, src.loss: 0.1470, mix.decode.loss_seg: 0.0832, mix.decode.acc_seg: 96.7620, mix.loss: 0.0832, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:45:51,861 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 10:33:05, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1316, src.decode.acc_seg: 95.4099, src.loss: 0.1477, mix.decode.loss_seg: 0.0847, mix.decode.acc_seg: 96.7493, mix.loss: 0.0847, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:46:53,578 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 10:32:08, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1225, src.decode.acc_seg: 95.7650, src.loss: 0.1386, mix.decode.loss_seg: 0.0667, mix.decode.acc_seg: 97.2764, mix.loss: 0.0667, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:47:55,224 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 10:31:12, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1304, src.decode.acc_seg: 95.5226, src.loss: 0.1464, mix.decode.loss_seg: 0.0923, mix.decode.acc_seg: 96.2355, mix.loss: 0.0923, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:48:57,714 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 10:30:18, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.1386, src.decode.acc_seg: 95.4971, src.loss: 0.1547, mix.decode.loss_seg: 0.0915, mix.decode.acc_seg: 96.5644, mix.loss: 0.0915, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:49:59,485 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 10:29:21, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1287, src.decode.acc_seg: 95.2262, src.loss: 0.1447, mix.decode.loss_seg: 0.0739, mix.decode.acc_seg: 96.9796, mix.loss: 0.0739, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:51:01,158 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 10:28:24, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1317, src.decode.acc_seg: 95.5700, src.loss: 0.1477, mix.decode.loss_seg: 0.0850, mix.decode.acc_seg: 96.7943, mix.loss: 0.0850, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:52:02,653 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 10:27:27, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1308, src.decode.acc_seg: 95.7838, src.loss: 0.1469, mix.decode.loss_seg: 0.0871, mix.decode.acc_seg: 96.7147, mix.loss: 0.0871, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:53:05,083 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 11:53:05,083 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 10:26:32, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1162, src.decode.acc_seg: 95.9981, src.loss: 0.1322, mix.decode.loss_seg: 0.0630, mix.decode.acc_seg: 97.3815, mix.loss: 0.0630, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:54:07,572 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 10:25:38, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1303, src.decode.acc_seg: 95.3031, src.loss: 0.1463, mix.decode.loss_seg: 0.0706, mix.decode.acc_seg: 97.0315, mix.loss: 0.0706, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:55:09,041 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 10:24:40, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1165, src.decode.acc_seg: 95.7669, src.loss: 0.1325, mix.decode.loss_seg: 0.0723, mix.decode.acc_seg: 97.0828, mix.loss: 0.0723, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:56:11,098 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 10:23:44, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1322, src.decode.acc_seg: 95.3614, src.loss: 0.1482, mix.decode.loss_seg: 0.0788, mix.decode.acc_seg: 96.9938, mix.loss: 0.0788, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:57:13,101 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 10:22:48, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1220, src.decode.acc_seg: 95.7166, src.loss: 0.1380, mix.decode.loss_seg: 0.0794, mix.decode.acc_seg: 96.9673, mix.loss: 0.0794, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:58:15,256 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 10:21:52, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1179, src.decode.acc_seg: 95.6842, src.loss: 0.1339, mix.decode.loss_seg: 0.0699, mix.decode.acc_seg: 97.2694, mix.loss: 0.0699, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:59:17,033 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 10:20:55, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1080, src.decode.acc_seg: 96.2750, src.loss: 0.1241, mix.decode.loss_seg: 0.0696, mix.decode.acc_seg: 97.3186, mix.loss: 0.0696, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:00:18,629 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 10:19:58, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1228, src.decode.acc_seg: 95.7608, src.loss: 0.1388, mix.decode.loss_seg: 0.0873, mix.decode.acc_seg: 96.8408, mix.loss: 0.0873, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:01:20,630 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 10:19:01, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1206, src.decode.acc_seg: 95.7650, src.loss: 0.1366, mix.decode.loss_seg: 0.0714, mix.decode.acc_seg: 97.0366, mix.loss: 0.0714, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:02:22,312 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 10:18:04, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1314, src.decode.acc_seg: 95.4607, src.loss: 0.1474, mix.decode.loss_seg: 0.0756, mix.decode.acc_seg: 96.9768, mix.loss: 0.0756, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:03:24,515 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 10:17:08, time: 1.244, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1360, src.decode.acc_seg: 95.2526, src.loss: 0.1520, mix.decode.loss_seg: 0.0863, mix.decode.acc_seg: 96.7524, mix.loss: 0.0863, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:04:26,331 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 10:16:11, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1232, src.decode.acc_seg: 95.6595, src.loss: 0.1392, mix.decode.loss_seg: 0.0786, mix.decode.acc_seg: 96.7962, mix.loss: 0.0786, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:05:28,070 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 10:15:13, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1118, src.decode.acc_seg: 96.0695, src.loss: 0.1278, mix.decode.loss_seg: 0.0729, mix.decode.acc_seg: 97.1978, mix.loss: 0.0729, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:06:29,563 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 10:14:15, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1104, src.decode.acc_seg: 96.1254, src.loss: 0.1264, mix.decode.loss_seg: 0.0653, mix.decode.acc_seg: 97.4672, mix.loss: 0.0653, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:07:31,958 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 10:13:20, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1215, src.decode.acc_seg: 95.5755, src.loss: 0.1375, mix.decode.loss_seg: 0.0634, mix.decode.acc_seg: 97.2000, mix.loss: 0.0634, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:08:33,697 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 10:12:22, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1351, src.decode.acc_seg: 95.5886, src.loss: 0.1512, mix.decode.loss_seg: 0.0673, mix.decode.acc_seg: 97.2472, mix.loss: 0.0673, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:09:35,336 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 10:11:24, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1034, src.decode.acc_seg: 96.4365, src.loss: 0.1194, mix.decode.loss_seg: 0.0692, mix.decode.acc_seg: 97.3238, mix.loss: 0.0692, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:10:37,039 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 10:10:26, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1234, src.decode.acc_seg: 95.4997, src.loss: 0.1394, mix.decode.loss_seg: 0.0789, mix.decode.acc_seg: 96.6992, mix.loss: 0.0789, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:11:38,489 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 10:09:28, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1349, src.decode.acc_seg: 95.3744, src.loss: 0.1509, mix.decode.loss_seg: 0.0704, mix.decode.acc_seg: 97.1229, mix.loss: 0.0704, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:12:40,751 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 10:08:32, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1280, src.decode.acc_seg: 95.5681, src.loss: 0.1441, mix.decode.loss_seg: 0.0705, mix.decode.acc_seg: 97.1792, mix.loss: 0.0705, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:13:42,361 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 12:13:42,361 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 10:07:33, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1590, src.decode.acc_seg: 94.4202, src.loss: 0.1750, mix.decode.loss_seg: 0.1063, mix.decode.acc_seg: 96.1012, mix.loss: 0.1063, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:14:44,129 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 10:06:36, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1144, src.decode.acc_seg: 95.7842, src.loss: 0.1304, mix.decode.loss_seg: 0.0718, mix.decode.acc_seg: 97.1169, mix.loss: 0.0718, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:15:46,054 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 10:05:38, time: 1.238, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1362, src.decode.acc_seg: 95.3801, src.loss: 0.1523, mix.decode.loss_seg: 0.0964, mix.decode.acc_seg: 96.7098, mix.loss: 0.0964, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:16:48,302 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 10:04:42, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1248, src.decode.acc_seg: 95.5433, src.loss: 0.1409, mix.decode.loss_seg: 0.0718, mix.decode.acc_seg: 97.0582, mix.loss: 0.0718, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:17:50,401 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 10:03:45, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1084, src.decode.acc_seg: 96.1843, src.loss: 0.1245, mix.decode.loss_seg: 0.0689, mix.decode.acc_seg: 97.2701, mix.loss: 0.0689, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:18:51,448 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 10:02:45, time: 1.221, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1391, src.decode.acc_seg: 95.0793, src.loss: 0.1552, mix.decode.loss_seg: 0.0756, mix.decode.acc_seg: 96.9633, mix.loss: 0.0756, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:19:52,998 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 10:01:47, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0928, src.decode.acc_seg: 96.7219, src.loss: 0.1089, mix.decode.loss_seg: 0.0636, mix.decode.acc_seg: 97.3426, mix.loss: 0.0636, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:20:54,682 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 10:00:48, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1230, src.decode.acc_seg: 95.6330, src.loss: 0.1390, mix.decode.loss_seg: 0.0835, mix.decode.acc_seg: 96.6842, mix.loss: 0.0835, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:21:56,032 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 9:59:49, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1270, src.decode.acc_seg: 95.8569, src.loss: 0.1431, mix.decode.loss_seg: 0.0706, mix.decode.acc_seg: 96.9944, mix.loss: 0.0706, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:22:58,404 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 9:58:53, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1469, src.decode.acc_seg: 94.6972, src.loss: 0.1630, mix.decode.loss_seg: 0.0947, mix.decode.acc_seg: 96.0091, mix.loss: 0.0947, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:24:00,042 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 9:57:54, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1226, src.decode.acc_seg: 95.8393, src.loss: 0.1387, mix.decode.loss_seg: 0.0719, mix.decode.acc_seg: 97.1944, mix.loss: 0.0719, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:25:02,095 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 9:56:57, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1246, src.decode.acc_seg: 95.9614, src.loss: 0.1406, mix.decode.loss_seg: 0.0965, mix.decode.acc_seg: 96.8591, mix.loss: 0.0965, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:26:04,253 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 9:56:00, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1144, src.decode.acc_seg: 96.0462, src.loss: 0.1304, mix.decode.loss_seg: 0.0775, mix.decode.acc_seg: 96.9525, mix.loss: 0.0775, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:27:06,030 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 9:55:02, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1188, src.decode.acc_seg: 95.7485, src.loss: 0.1348, mix.decode.loss_seg: 0.0599, mix.decode.acc_seg: 97.6139, mix.loss: 0.0599, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:28:08,205 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 9:54:05, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1149, src.decode.acc_seg: 95.9366, src.loss: 0.1310, mix.decode.loss_seg: 0.0633, mix.decode.acc_seg: 97.2827, mix.loss: 0.0633, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:29:09,259 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 9:53:04, time: 1.221, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1580, src.decode.acc_seg: 94.8426, src.loss: 0.1740, mix.decode.loss_seg: 0.0898, mix.decode.acc_seg: 96.4993, mix.loss: 0.0898, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:30:11,048 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 9:52:06, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1356, src.decode.acc_seg: 94.9164, src.loss: 0.1516, mix.decode.loss_seg: 0.0874, mix.decode.acc_seg: 96.7694, mix.loss: 0.0874, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:31:12,577 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 9:51:07, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1163, src.decode.acc_seg: 95.7374, src.loss: 0.1323, mix.decode.loss_seg: 0.0661, mix.decode.acc_seg: 97.3717, mix.loss: 0.0661, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:32:14,275 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 9:50:09, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1091, src.decode.acc_seg: 95.9620, src.loss: 0.1251, mix.decode.loss_seg: 0.0707, mix.decode.acc_seg: 97.0368, mix.loss: 0.0707, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:33:15,695 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 9:49:09, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1210, src.decode.acc_seg: 96.0910, src.loss: 0.1370, mix.decode.loss_seg: 0.0670, mix.decode.acc_seg: 97.0642, mix.loss: 0.0670, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:34:17,817 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 12:34:17,817 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 9:48:12, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1170, src.decode.acc_seg: 95.9302, src.loss: 0.1331, mix.decode.loss_seg: 0.0777, mix.decode.acc_seg: 97.0113, mix.loss: 0.0777, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:35:19,534 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 9:47:13, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0903, src.decode.acc_seg: 96.8456, src.loss: 0.1063, mix.decode.loss_seg: 0.0610, mix.decode.acc_seg: 97.6210, mix.loss: 0.0610, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:36:21,127 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 9:46:14, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0994, src.decode.acc_seg: 96.5119, src.loss: 0.1155, mix.decode.loss_seg: 0.0649, mix.decode.acc_seg: 97.3879, mix.loss: 0.0649, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:37:23,281 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 9:45:17, time: 1.243, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1147, src.decode.acc_seg: 96.0364, src.loss: 0.1307, mix.decode.loss_seg: 0.0622, mix.decode.acc_seg: 97.5546, mix.loss: 0.0622, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:38:25,195 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 9:44:19, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0968, src.decode.acc_seg: 96.3737, src.loss: 0.1128, mix.decode.loss_seg: 0.0657, mix.decode.acc_seg: 97.3567, mix.loss: 0.0657, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:39:27,206 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 9:43:21, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0924, src.decode.acc_seg: 96.5809, src.loss: 0.1084, mix.decode.loss_seg: 0.0666, mix.decode.acc_seg: 97.0749, mix.loss: 0.0666, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:40:28,194 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 9:42:20, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1067, src.decode.acc_seg: 96.0202, src.loss: 0.1227, mix.decode.loss_seg: 0.0658, mix.decode.acc_seg: 97.3191, mix.loss: 0.0658, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:41:30,225 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 9:41:22, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0935, src.decode.acc_seg: 96.6005, src.loss: 0.1095, mix.decode.loss_seg: 0.0579, mix.decode.acc_seg: 97.6394, mix.loss: 0.0579, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:42:32,236 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 9:40:24, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1028, src.decode.acc_seg: 96.3375, src.loss: 0.1188, mix.decode.loss_seg: 0.0747, mix.decode.acc_seg: 97.0648, mix.loss: 0.0747, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:43:34,424 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 9:39:27, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1118, src.decode.acc_seg: 95.9177, src.loss: 0.1278, mix.decode.loss_seg: 0.0715, mix.decode.acc_seg: 97.2613, mix.loss: 0.0715, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:44:35,847 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 9:38:27, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1079, src.decode.acc_seg: 96.1609, src.loss: 0.1240, mix.decode.loss_seg: 0.0691, mix.decode.acc_seg: 97.2915, mix.loss: 0.0691, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:45:37,883 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 9:37:29, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0860, src.decode.acc_seg: 96.9982, src.loss: 0.1020, mix.decode.loss_seg: 0.0609, mix.decode.acc_seg: 97.5064, mix.loss: 0.0609, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:46:39,389 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 9:36:30, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1188, src.decode.acc_seg: 95.7303, src.loss: 0.1348, mix.decode.loss_seg: 0.0730, mix.decode.acc_seg: 97.0357, mix.loss: 0.0730, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:47:41,469 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 9:35:32, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1351, src.decode.acc_seg: 94.9965, src.loss: 0.1511, mix.decode.loss_seg: 0.0811, mix.decode.acc_seg: 96.9406, mix.loss: 0.0811, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:48:43,530 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 9:34:33, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0999, src.decode.acc_seg: 96.4365, src.loss: 0.1159, mix.decode.loss_seg: 0.0720, mix.decode.acc_seg: 96.9979, mix.loss: 0.0720, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:49:46,113 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 9:33:37, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1072, src.decode.acc_seg: 96.1579, src.loss: 0.1232, mix.decode.loss_seg: 0.0692, mix.decode.acc_seg: 97.2530, mix.loss: 0.0692, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:50:48,588 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 9:32:39, time: 1.249, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1225, src.decode.acc_seg: 95.6131, src.loss: 0.1386, mix.decode.loss_seg: 0.0744, mix.decode.acc_seg: 97.0601, mix.loss: 0.0744, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:51:50,423 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 9:31:41, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1224, src.decode.acc_seg: 95.6404, src.loss: 0.1384, mix.decode.loss_seg: 0.0748, mix.decode.acc_seg: 97.1059, mix.loss: 0.0748, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:52:52,411 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 9:30:42, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1160, src.decode.acc_seg: 95.8945, src.loss: 0.1321, mix.decode.loss_seg: 0.0870, mix.decode.acc_seg: 96.5459, mix.loss: 0.0870, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:53:54,145 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 9:29:43, time: 1.235, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.1057, src.decode.acc_seg: 96.3420, src.loss: 0.1218, mix.decode.loss_seg: 0.0675, mix.decode.acc_seg: 97.1120, mix.loss: 0.0675, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.1 task/s, elapsed: 1s, ETA:   871s[                                 ] 2/929, 1.9 task/s, elapsed: 1s, ETA:   486s[                                 ] 3/929, 2.5 task/s, elapsed: 1s, ETA:   370s[                                 ] 4/929, 3.1 task/s, elapsed: 1s, ETA:   301s[                                 ] 5/929, 3.6 task/s, elapsed: 1s, ETA:   258s[                                 ] 6/929, 4.0 task/s, elapsed: 1s, ETA:   230s[                                 ] 7/929, 4.4 task/s, elapsed: 2s, ETA:   210s[                                 ] 8/929, 4.7 task/s, elapsed: 2s, ETA:   195s[                                 ] 9/929, 5.0 task/s, elapsed: 2s, ETA:   184s[                                ] 10/929, 5.3 task/s, elapsed: 2s, ETA:   174s[                                ] 11/929, 5.5 task/s, elapsed: 2s, ETA:   167s[                                ] 12/929, 5.7 task/s, elapsed: 2s, ETA:   160s[                                ] 13/929, 5.9 task/s, elapsed: 2s, ETA:   155s[                                ] 14/929, 6.1 task/s, elapsed: 2s, ETA:   150s[                                ] 15/929, 6.2 task/s, elapsed: 2s, ETA:   147s[                                ] 16/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 17/929, 6.5 task/s, elapsed: 3s, ETA:   141s[                                ] 18/929, 6.6 task/s, elapsed: 3s, ETA:   138s[                                ] 19/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 20/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 21/929, 6.9 task/s, elapsed: 3s, ETA:   131s[                                ] 22/929, 7.0 task/s, elapsed: 3s, ETA:   130s[                                ] 23/929, 7.1 task/s, elapsed: 3s, ETA:   128s[                                ] 24/929, 7.2 task/s, elapsed: 3s, ETA:   126s[                                ] 25/929, 7.3 task/s, elapsed: 3s, ETA:   125s[                                ] 26/929, 7.3 task/s, elapsed: 4s, ETA:   123s[                                ] 27/929, 7.4 task/s, elapsed: 4s, ETA:   122s[                                ] 28/929, 7.5 task/s, elapsed: 4s, ETA:   121s[                                ] 29/929, 7.5 task/s, elapsed: 4s, ETA:   120s[>                               ] 30/929, 7.6 task/s, elapsed: 4s, ETA:   119s[>                               ] 31/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 32/929, 7.7 task/s, elapsed: 4s, ETA:   117s[>                               ] 33/929, 7.7 task/s, elapsed: 4s, ETA:   116s[>                               ] 34/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 35/929, 7.8 task/s, elapsed: 4s, ETA:   114s[>                               ] 36/929, 7.9 task/s, elapsed: 5s, ETA:   114s[>                               ] 37/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 38/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 39/929, 8.0 task/s, elapsed: 5s, ETA:   112s[>                               ] 40/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 41/929, 8.0 task/s, elapsed: 5s, ETA:   110s[>                               ] 42/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 43/929, 8.1 task/s, elapsed: 5s, ETA:   109s[>                               ] 44/929, 8.1 task/s, elapsed: 5s, ETA:   109s[>                               ] 45/929, 8.2 task/s, elapsed: 5s, ETA:   108s[>                               ] 46/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 47/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 48/929, 8.2 task/s, elapsed: 6s, ETA:   108s[>                               ] 49/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 50/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 51/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 52/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 53/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 54/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 55/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 56/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 57/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>                               ] 58/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>>                              ] 59/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 60/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 61/929, 8.5 task/s, elapsed: 7s, ETA:   103s[>>                              ] 62/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 63/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 64/929, 8.5 task/s, elapsed: 8s, ETA:   102s[>>                              ] 65/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 66/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 67/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 68/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 69/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 70/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 71/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 72/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 73/929, 8.6 task/s, elapsed: 8s, ETA:    99s[>>                              ] 74/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 75/929, 8.7 task/s, elapsed: 9s, ETA:    99s[>>                              ] 76/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 77/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 78/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 79/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 80/929, 8.7 task/s, elapsed: 9s, ETA:    97s[>>                              ] 81/929, 8.7 task/s, elapsed: 9s, ETA:    97s[>>                              ] 82/929, 8.7 task/s, elapsed: 9s, ETA:    97s[>>                             ] 83/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 84/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 85/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 86/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>                             ] 87/929, 8.8 task/s, elapsed: 10s, ETA:    96s[>>                             ] 88/929, 8.8 task/s, elapsed: 10s, ETA:    96s[>>                             ] 89/929, 8.8 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 90/929, 8.8 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 91/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 92/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 93/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 94/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 95/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 96/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 97/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 98/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                            ] 99/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 100/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 101/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 102/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 103/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 104/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 105/929, 8.9 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 106/929, 8.9 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 107/929, 8.9 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 108/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 109/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 110/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 111/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 112/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 113/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 114/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 115/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 116/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 117/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 118/929, 9.0 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 119/929, 9.0 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 120/929, 9.0 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 121/929, 9.0 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 122/929, 9.0 task/s, elapsed: 14s, ETA:    90s[>>>                           ] 123/929, 9.0 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 124/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 125/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 126/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 127/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 128/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 129/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 130/929, 9.0 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 131/929, 9.0 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 132/929, 9.1 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 133/929, 9.1 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 134/929, 9.1 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 135/929, 9.1 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 136/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 137/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 138/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 139/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 140/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 141/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 142/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 143/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 144/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 145/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 146/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 147/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 148/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 149/929, 9.1 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 150/929, 9.1 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 151/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 152/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 153/929, 9.2 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 154/929, 9.2 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 155/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 156/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 157/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 158/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 159/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 160/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 161/929, 9.2 task/s, elapsed: 17s, ETA:    83s[>>>>>                         ] 162/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 163/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 164/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 165/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 166/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 167/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 168/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 169/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 170/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 171/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 172/929, 9.3 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 173/929, 9.3 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 174/929, 9.3 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 175/929, 9.3 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 176/929, 9.3 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 177/929, 9.3 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 178/929, 9.3 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 179/929, 9.3 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 180/929, 9.3 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 181/929, 9.3 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 182/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>                         ] 183/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>                         ] 184/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>                         ] 185/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 186/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 187/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 188/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 189/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 190/929, 9.3 task/s, elapsed: 20s, ETA:    79s[>>>>>>                        ] 191/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 192/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 193/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 194/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 195/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 196/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 197/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 198/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 199/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 200/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 201/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 202/929, 9.4 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 203/929, 9.4 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 204/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 205/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 206/929, 9.3 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 207/929, 9.3 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 208/929, 9.3 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 209/929, 9.3 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 210/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 211/929, 9.4 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 212/929, 9.4 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 213/929, 9.4 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 214/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 215/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 216/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 217/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 218/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 219/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 220/929, 9.4 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 221/929, 9.4 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 222/929, 9.4 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 223/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 224/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 225/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 226/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 227/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 228/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 229/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 230/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 231/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 232/929, 9.4 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 233/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 234/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 235/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 236/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 237/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 238/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 239/929, 9.4 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 240/929, 9.4 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 241/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 242/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 243/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 244/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 245/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 246/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 247/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>>                      ] 248/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>>                      ] 249/929, 9.4 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 250/929, 9.4 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 251/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 252/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 253/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 254/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 255/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 256/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 257/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 258/929, 9.4 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 259/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 260/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 261/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 262/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 263/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 264/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 265/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 266/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 267/929, 9.4 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 268/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 269/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 270/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 271/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 272/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 273/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 274/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 275/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 276/929, 9.4 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 277/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>                      ] 278/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 279/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 280/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 281/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 282/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 283/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 284/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 285/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 286/929, 9.4 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 287/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 288/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 289/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 290/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 291/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 292/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 293/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 294/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 295/929, 9.4 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 296/929, 9.4 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 297/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 298/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 299/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 300/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 301/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 302/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 303/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 304/929, 9.4 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 305/929, 9.4 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 306/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 307/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 308/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 309/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 310/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 311/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 312/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 313/929, 9.4 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 314/929, 9.4 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 315/929, 9.4 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 316/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 317/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 318/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 319/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 320/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 321/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 322/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 323/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 324/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 325/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 326/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 327/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 328/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 329/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 330/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 331/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 332/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 333/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 334/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 335/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 336/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 337/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 338/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 339/929, 9.4 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>                    ] 340/929, 9.4 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 341/929, 9.4 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 342/929, 9.4 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 343/929, 9.4 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 344/929, 9.4 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 345/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 346/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 347/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 348/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 349/929, 9.4 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 350/929, 9.4 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 351/929, 9.4 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 352/929, 9.4 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 353/929, 9.4 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 354/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 355/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 356/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 357/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 358/929, 9.4 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 359/929, 9.4 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 360/929, 9.4 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 361/929, 9.4 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 362/929, 9.4 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 363/929, 9.4 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 364/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 365/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 366/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 367/929, 9.4 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 368/929, 9.4 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 369/929, 9.4 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 370/929, 9.4 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 371/929, 9.4 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>>                  ] 372/929, 9.4 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>>                  ] 373/929, 9.4 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>>                  ] 374/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 375/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 376/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 377/929, 9.4 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 378/929, 9.4 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 379/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 380/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 381/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 382/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 383/929, 9.5 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 384/929, 9.5 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 385/929, 9.5 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 386/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 387/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 388/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 389/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 390/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 391/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 392/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 393/929, 9.5 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 394/929, 9.5 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 395/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 396/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 397/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 398/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 399/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 400/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 401/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 402/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>>                 ] 403/929, 9.5 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 404/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 405/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 406/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 407/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 408/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 409/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 410/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 411/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 412/929, 9.5 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 413/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 414/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 415/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 416/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 417/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 418/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 419/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 420/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 421/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 422/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 423/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 424/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 425/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 426/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 427/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 428/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 429/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 430/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 431/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 432/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>                 ] 433/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 434/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 435/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 436/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 437/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 438/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 439/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 440/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 441/929, 9.5 task/s, elapsed: 46s, ETA:    51s[>>>>>>>>>>>>>>                ] 442/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 443/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 444/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 445/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 446/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 447/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 448/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 449/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 450/929, 9.5 task/s, elapsed: 47s, ETA:    50s[>>>>>>>>>>>>>>                ] 451/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 452/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 453/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 454/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 455/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 456/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 457/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 458/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 459/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 460/929, 9.5 task/s, elapsed: 48s, ETA:    49s[>>>>>>>>>>>>>>                ] 461/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 462/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 463/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 464/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 465/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 466/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 467/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 468/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 469/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 470/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 471/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 472/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 473/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 474/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 475/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 476/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 477/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 478/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 479/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 480/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 481/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 482/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 483/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 484/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 485/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 486/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 487/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 488/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 489/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 490/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 491/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 492/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 493/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 494/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 495/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 496/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 498/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 499/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 500/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 501/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 502/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 503/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 504/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 505/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 508/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 509/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 510/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 511/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 512/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 513/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 514/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 517/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 518/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 519/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 520/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 521/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 522/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 523/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 526/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.5 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.5 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.5 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.5 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.5 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.5 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.5 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.5 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.5 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.5 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.5 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.5 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.5 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.5 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.5 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.5 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.5 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.5 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.5 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.5 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.5 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.5 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.5 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.5 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.5 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.5 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.5 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.5 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.5 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.5 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.5 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.5 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.5 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.5 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.5 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.5 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.5 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.5 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.5 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.5 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.5 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.5 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.5 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.5 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.5 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.5 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.5 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.5 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.5 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.5 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.5 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.5 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.5 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.5 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.5 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.5 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.5 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.5 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.5 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.5 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.5 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.5 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.5 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.5 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.5 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.5 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.5 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.5 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.5 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.5 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.5 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.5 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.5 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.5 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.5 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.5 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.5 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.5 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.5 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.5 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.5 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.5 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.5 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.5 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.5 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.5 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.5 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.5 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.5 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.5 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.5 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.5 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.5 task/s, elapsed: 98s, ETA:     0s2022-10-10 12:58:43,095 - mmseg - INFO - per class results:2022-10-10 12:58:43,096 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.33 | 97.78 || rigid_plastic | 22.89 | 26.25 ||   cardboard   | 48.28 | 53.62 ||     metal     | 30.37 | 35.58 ||  soft_plastic | 63.07 | 74.42 |+---------------+-------+-------+2022-10-10 12:58:43,096 - mmseg - INFO - Summary:2022-10-10 12:58:43,096 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 90.81 | 50.99 | 57.53 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:58:43,101 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 12:58:43,101 - mmseg - INFO - Iter [929/40000]	lr: 4.200e-05, eta: 9:28:45, time: 1.241, data_time: 0.014, memory: 67493, aAcc: 0.9081, mIoU: 0.5099, mAcc: 0.5753, IoU.background: 0.9033, IoU.rigid_plastic: 0.2289, IoU.cardboard: 0.4828, IoU.metal: 0.3037, IoU.soft_plastic: 0.6307, Acc.background: 0.9778, Acc.rigid_plastic: 0.2625, Acc.cardboard: 0.5362, Acc.metal: 0.3558, Acc.soft_plastic: 0.7442, src.decode.loss_seg: 0.1042, src.decode.acc_seg: 96.3361, src.loss: 0.1202, mix.decode.loss_seg: 0.0659, mix.decode.acc_seg: 97.2986, mix.loss: 0.0659, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:59:45,749 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 9:36:34, time: 5.791, data_time: 4.552, memory: 67493, src.decode.loss_seg: 0.0965, src.decode.acc_seg: 96.4140, src.loss: 0.1125, mix.decode.loss_seg: 0.0593, mix.decode.acc_seg: 97.5694, mix.loss: 0.0593, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:00:49,204 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 9:35:36, time: 1.269, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0869, src.decode.acc_seg: 96.9730, src.loss: 0.1029, mix.decode.loss_seg: 0.0556, mix.decode.acc_seg: 97.5301, mix.loss: 0.0556, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:01:50,710 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 9:34:33, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0959, src.decode.acc_seg: 96.3571, src.loss: 0.1120, mix.decode.loss_seg: 0.0641, mix.decode.acc_seg: 97.3476, mix.loss: 0.0641, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:02:52,710 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 9:33:32, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1099, src.decode.acc_seg: 96.0289, src.loss: 0.1259, mix.decode.loss_seg: 0.0698, mix.decode.acc_seg: 96.9350, mix.loss: 0.0698, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:03:54,369 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 9:32:29, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1058, src.decode.acc_seg: 96.4101, src.loss: 0.1218, mix.decode.loss_seg: 0.0601, mix.decode.acc_seg: 97.7280, mix.loss: 0.0601, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:04:56,458 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 9:31:28, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1022, src.decode.acc_seg: 96.1683, src.loss: 0.1183, mix.decode.loss_seg: 0.0616, mix.decode.acc_seg: 97.6987, mix.loss: 0.0616, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:05:58,152 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 9:30:25, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1194, src.decode.acc_seg: 95.7481, src.loss: 0.1354, mix.decode.loss_seg: 0.0688, mix.decode.acc_seg: 97.3303, mix.loss: 0.0688, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:07:00,520 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 9:29:24, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1016, src.decode.acc_seg: 96.1974, src.loss: 0.1176, mix.decode.loss_seg: 0.0652, mix.decode.acc_seg: 97.2264, mix.loss: 0.0652, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:08:02,758 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 9:28:23, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1127, src.decode.acc_seg: 95.9394, src.loss: 0.1288, mix.decode.loss_seg: 0.0752, mix.decode.acc_seg: 96.7426, mix.loss: 0.0752, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:09:04,830 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 9:27:22, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1093, src.decode.acc_seg: 96.1827, src.loss: 0.1253, mix.decode.loss_seg: 0.0707, mix.decode.acc_seg: 97.1087, mix.loss: 0.0707, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:10:06,631 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 9:26:20, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1106, src.decode.acc_seg: 96.1476, src.loss: 0.1266, mix.decode.loss_seg: 0.0818, mix.decode.acc_seg: 96.8201, mix.loss: 0.0818, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:11:08,427 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 9:25:18, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1048, src.decode.acc_seg: 96.5417, src.loss: 0.1209, mix.decode.loss_seg: 0.0701, mix.decode.acc_seg: 97.1387, mix.loss: 0.0701, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:12:09,955 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 9:24:15, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0880, src.decode.acc_seg: 96.8222, src.loss: 0.1040, mix.decode.loss_seg: 0.0520, mix.decode.acc_seg: 97.8239, mix.loss: 0.0520, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:13:11,370 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 9:23:12, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1040, src.decode.acc_seg: 96.2902, src.loss: 0.1200, mix.decode.loss_seg: 0.0685, mix.decode.acc_seg: 97.3319, mix.loss: 0.0685, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:14:13,682 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 9:22:11, time: 1.246, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0979, src.decode.acc_seg: 96.5078, src.loss: 0.1139, mix.decode.loss_seg: 0.0629, mix.decode.acc_seg: 97.4998, mix.loss: 0.0629, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:15:15,765 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 9:21:10, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0981, src.decode.acc_seg: 96.5143, src.loss: 0.1142, mix.decode.loss_seg: 0.0592, mix.decode.acc_seg: 97.6886, mix.loss: 0.0592, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:16:17,504 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 9:20:07, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1095, src.decode.acc_seg: 96.0382, src.loss: 0.1256, mix.decode.loss_seg: 0.0723, mix.decode.acc_seg: 97.0542, mix.loss: 0.0723, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:17:19,337 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 9:19:05, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1129, src.decode.acc_seg: 96.0540, src.loss: 0.1289, mix.decode.loss_seg: 0.0643, mix.decode.acc_seg: 97.4659, mix.loss: 0.0643, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:18:21,186 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 9:18:03, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1065, src.decode.acc_seg: 96.4613, src.loss: 0.1225, mix.decode.loss_seg: 0.0624, mix.decode.acc_seg: 97.6000, mix.loss: 0.0624, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:19:23,019 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 13:19:23,019 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 9:17:01, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1073, src.decode.acc_seg: 95.9221, src.loss: 0.1233, mix.decode.loss_seg: 0.0657, mix.decode.acc_seg: 97.5165, mix.loss: 0.0657, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:20:25,316 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 9:16:00, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1354, src.decode.acc_seg: 94.8483, src.loss: 0.1514, mix.decode.loss_seg: 0.0759, mix.decode.acc_seg: 96.8323, mix.loss: 0.0759, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:21:27,494 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 9:14:59, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0893, src.decode.acc_seg: 96.7233, src.loss: 0.1054, mix.decode.loss_seg: 0.0518, mix.decode.acc_seg: 97.9023, mix.loss: 0.0518, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:22:29,284 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 9:13:57, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0881, src.decode.acc_seg: 96.6677, src.loss: 0.1042, mix.decode.loss_seg: 0.0546, mix.decode.acc_seg: 97.6107, mix.loss: 0.0546, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:23:31,211 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 9:12:55, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1046, src.decode.acc_seg: 96.1869, src.loss: 0.1206, mix.decode.loss_seg: 0.0631, mix.decode.acc_seg: 97.4064, mix.loss: 0.0631, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:24:32,616 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 9:11:52, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1088, src.decode.acc_seg: 96.0796, src.loss: 0.1249, mix.decode.loss_seg: 0.0622, mix.decode.acc_seg: 97.5855, mix.loss: 0.0622, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:25:34,883 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 9:10:51, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1033, src.decode.acc_seg: 96.3425, src.loss: 0.1194, mix.decode.loss_seg: 0.0661, mix.decode.acc_seg: 97.3413, mix.loss: 0.0661, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:26:37,215 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 9:09:50, time: 1.247, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0761, src.decode.acc_seg: 97.2203, src.loss: 0.0922, mix.decode.loss_seg: 0.0483, mix.decode.acc_seg: 98.1219, mix.loss: 0.0483, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:27:38,842 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 9:08:48, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1033, src.decode.acc_seg: 96.3516, src.loss: 0.1194, mix.decode.loss_seg: 0.0630, mix.decode.acc_seg: 97.5920, mix.loss: 0.0630, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:28:40,623 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 9:07:45, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0942, src.decode.acc_seg: 96.5859, src.loss: 0.1103, mix.decode.loss_seg: 0.0502, mix.decode.acc_seg: 97.9864, mix.loss: 0.0502, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:29:42,207 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 9:06:43, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0812, src.decode.acc_seg: 97.0712, src.loss: 0.0972, mix.decode.loss_seg: 0.0479, mix.decode.acc_seg: 97.9944, mix.loss: 0.0479, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:30:44,696 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 9:05:42, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1037, src.decode.acc_seg: 96.3535, src.loss: 0.1197, mix.decode.loss_seg: 0.0746, mix.decode.acc_seg: 96.9780, mix.loss: 0.0746, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:31:46,310 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 9:04:40, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1141, src.decode.acc_seg: 95.9168, src.loss: 0.1301, mix.decode.loss_seg: 0.0770, mix.decode.acc_seg: 96.9632, mix.loss: 0.0770, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:32:47,835 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 9:03:37, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1202, src.decode.acc_seg: 95.6142, src.loss: 0.1362, mix.decode.loss_seg: 0.0729, mix.decode.acc_seg: 96.8619, mix.loss: 0.0729, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:33:49,401 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 9:02:35, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1026, src.decode.acc_seg: 96.2195, src.loss: 0.1186, mix.decode.loss_seg: 0.0679, mix.decode.acc_seg: 96.9465, mix.loss: 0.0679, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:34:51,936 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 9:01:34, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1120, src.decode.acc_seg: 95.5602, src.loss: 0.1280, mix.decode.loss_seg: 0.0635, mix.decode.acc_seg: 97.4777, mix.loss: 0.0635, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:35:54,086 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 9:00:33, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1222, src.decode.acc_seg: 95.7508, src.loss: 0.1383, mix.decode.loss_seg: 0.0719, mix.decode.acc_seg: 97.1429, mix.loss: 0.0719, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:36:55,968 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 8:59:31, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0834, src.decode.acc_seg: 97.0370, src.loss: 0.0995, mix.decode.loss_seg: 0.0502, mix.decode.acc_seg: 97.7924, mix.loss: 0.0502, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:37:57,897 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 8:58:29, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1097, src.decode.acc_seg: 96.0920, src.loss: 0.1257, mix.decode.loss_seg: 0.0720, mix.decode.acc_seg: 97.3964, mix.loss: 0.0720, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:38:59,743 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 8:57:27, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1014, src.decode.acc_seg: 96.3228, src.loss: 0.1175, mix.decode.loss_seg: 0.0736, mix.decode.acc_seg: 97.0027, mix.loss: 0.0736, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:40:01,324 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 13:40:01,324 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 8:56:24, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0910, src.decode.acc_seg: 96.6950, src.loss: 0.1070, mix.decode.loss_seg: 0.0542, mix.decode.acc_seg: 97.6308, mix.loss: 0.0542, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:41:03,594 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 8:55:23, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0757, src.decode.acc_seg: 97.3021, src.loss: 0.0917, mix.decode.loss_seg: 0.0581, mix.decode.acc_seg: 97.5683, mix.loss: 0.0581, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:42:05,659 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 8:54:22, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1062, src.decode.acc_seg: 96.2217, src.loss: 0.1223, mix.decode.loss_seg: 0.0552, mix.decode.acc_seg: 97.8056, mix.loss: 0.0552, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:43:07,589 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 8:53:20, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0844, src.decode.acc_seg: 96.9826, src.loss: 0.1004, mix.decode.loss_seg: 0.0498, mix.decode.acc_seg: 97.9201, mix.loss: 0.0498, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:44:10,162 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 8:52:19, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0762, src.decode.acc_seg: 97.2172, src.loss: 0.0923, mix.decode.loss_seg: 0.0461, mix.decode.acc_seg: 98.0696, mix.loss: 0.0461, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:45:12,370 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 8:51:18, time: 1.244, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0872, src.decode.acc_seg: 96.8473, src.loss: 0.1033, mix.decode.loss_seg: 0.0601, mix.decode.acc_seg: 97.7606, mix.loss: 0.0601, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:46:14,315 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 8:50:16, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0884, src.decode.acc_seg: 96.7620, src.loss: 0.1044, mix.decode.loss_seg: 0.0575, mix.decode.acc_seg: 97.4810, mix.loss: 0.0575, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:47:16,125 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 8:49:14, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0930, src.decode.acc_seg: 96.8947, src.loss: 0.1090, mix.decode.loss_seg: 0.0575, mix.decode.acc_seg: 97.8983, mix.loss: 0.0575, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:48:17,980 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 8:48:12, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0961, src.decode.acc_seg: 96.6533, src.loss: 0.1121, mix.decode.loss_seg: 0.0579, mix.decode.acc_seg: 97.7515, mix.loss: 0.0579, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:49:20,326 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 8:47:11, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1028, src.decode.acc_seg: 96.4812, src.loss: 0.1189, mix.decode.loss_seg: 0.0670, mix.decode.acc_seg: 97.4719, mix.loss: 0.0670, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:50:21,934 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 8:46:08, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0856, src.decode.acc_seg: 97.0058, src.loss: 0.1017, mix.decode.loss_seg: 0.0606, mix.decode.acc_seg: 97.4815, mix.loss: 0.0606, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:51:23,373 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 8:45:06, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0877, src.decode.acc_seg: 96.7889, src.loss: 0.1038, mix.decode.loss_seg: 0.0590, mix.decode.acc_seg: 97.5111, mix.loss: 0.0590, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:52:25,220 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 8:44:04, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0811, src.decode.acc_seg: 97.0797, src.loss: 0.0972, mix.decode.loss_seg: 0.0494, mix.decode.acc_seg: 98.1629, mix.loss: 0.0494, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:53:27,034 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 8:43:02, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0887, src.decode.acc_seg: 97.2064, src.loss: 0.1047, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.3009, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:54:28,617 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 8:41:59, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0984, src.decode.acc_seg: 96.4058, src.loss: 0.1144, mix.decode.loss_seg: 0.0696, mix.decode.acc_seg: 97.2621, mix.loss: 0.0696, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:55:29,644 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 8:40:56, time: 1.221, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0939, src.decode.acc_seg: 96.7658, src.loss: 0.1099, mix.decode.loss_seg: 0.0668, mix.decode.acc_seg: 97.2335, mix.loss: 0.0668, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:56:31,375 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 8:39:54, time: 1.235, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0901, src.decode.acc_seg: 96.7804, src.loss: 0.1061, mix.decode.loss_seg: 0.0613, mix.decode.acc_seg: 97.4934, mix.loss: 0.0613, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:57:32,946 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 8:38:51, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0989, src.decode.acc_seg: 96.0970, src.loss: 0.1150, mix.decode.loss_seg: 0.0658, mix.decode.acc_seg: 97.4974, mix.loss: 0.0658, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:58:34,683 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 8:37:49, time: 1.235, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0942, src.decode.acc_seg: 96.4535, src.loss: 0.1103, mix.decode.loss_seg: 0.0589, mix.decode.acc_seg: 97.5508, mix.loss: 0.0589, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:59:36,506 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 8:36:47, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0844, src.decode.acc_seg: 96.7152, src.loss: 0.1005, mix.decode.loss_seg: 0.0531, mix.decode.acc_seg: 97.7220, mix.loss: 0.0531, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:00:37,875 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 14:00:37,876 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 8:35:44, time: 1.227, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0758, src.decode.acc_seg: 97.2085, src.loss: 0.0919, mix.decode.loss_seg: 0.0529, mix.decode.acc_seg: 97.9647, mix.loss: 0.0529, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:01:39,429 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 8:34:42, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0750, src.decode.acc_seg: 97.2757, src.loss: 0.0910, mix.decode.loss_seg: 0.0569, mix.decode.acc_seg: 97.6204, mix.loss: 0.0569, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:02:40,686 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 8:33:39, time: 1.225, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0767, src.decode.acc_seg: 97.0841, src.loss: 0.0927, mix.decode.loss_seg: 0.0568, mix.decode.acc_seg: 97.7775, mix.loss: 0.0568, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:03:41,678 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 8:32:35, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1008, src.decode.acc_seg: 96.5754, src.loss: 0.1168, mix.decode.loss_seg: 0.0673, mix.decode.acc_seg: 97.3146, mix.loss: 0.0673, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:04:42,878 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 8:31:32, time: 1.224, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0731, src.decode.acc_seg: 97.3938, src.loss: 0.0892, mix.decode.loss_seg: 0.0453, mix.decode.acc_seg: 98.1756, mix.loss: 0.0453, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:05:44,344 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 8:30:30, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0841, src.decode.acc_seg: 96.8138, src.loss: 0.1001, mix.decode.loss_seg: 0.0553, mix.decode.acc_seg: 97.6563, mix.loss: 0.0553, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:06:45,577 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 8:29:27, time: 1.225, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0927, src.decode.acc_seg: 96.9977, src.loss: 0.1087, mix.decode.loss_seg: 0.0498, mix.decode.acc_seg: 97.9798, mix.loss: 0.0498, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:07:46,963 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 8:28:24, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0669, src.decode.acc_seg: 97.7018, src.loss: 0.0829, mix.decode.loss_seg: 0.0498, mix.decode.acc_seg: 98.0263, mix.loss: 0.0498, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:08:48,096 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 8:27:21, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0967, src.decode.acc_seg: 96.4145, src.loss: 0.1127, mix.decode.loss_seg: 0.0519, mix.decode.acc_seg: 97.6797, mix.loss: 0.0519, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:09:50,130 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 8:26:20, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0914, src.decode.acc_seg: 96.6524, src.loss: 0.1074, mix.decode.loss_seg: 0.0532, mix.decode.acc_seg: 97.6728, mix.loss: 0.0532, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:10:51,621 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 8:25:17, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0790, src.decode.acc_seg: 97.2211, src.loss: 0.0950, mix.decode.loss_seg: 0.0512, mix.decode.acc_seg: 97.7858, mix.loss: 0.0512, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:11:53,229 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 8:24:15, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0901, src.decode.acc_seg: 96.9239, src.loss: 0.1061, mix.decode.loss_seg: 0.0564, mix.decode.acc_seg: 97.6386, mix.loss: 0.0564, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:12:55,348 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 8:23:13, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0751, src.decode.acc_seg: 97.2859, src.loss: 0.0911, mix.decode.loss_seg: 0.0530, mix.decode.acc_seg: 97.8757, mix.loss: 0.0530, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:13:56,479 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 8:22:10, time: 1.223, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0831, src.decode.acc_seg: 97.1183, src.loss: 0.0991, mix.decode.loss_seg: 0.0546, mix.decode.acc_seg: 97.5717, mix.loss: 0.0546, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:14:57,734 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 8:21:08, time: 1.225, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0941, src.decode.acc_seg: 96.5210, src.loss: 0.1101, mix.decode.loss_seg: 0.0633, mix.decode.acc_seg: 97.4452, mix.loss: 0.0633, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:15:59,065 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 8:20:05, time: 1.227, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0816, src.decode.acc_seg: 96.9911, src.loss: 0.0976, mix.decode.loss_seg: 0.0530, mix.decode.acc_seg: 97.7123, mix.loss: 0.0530, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:17:00,554 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 8:19:02, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0946, src.decode.acc_seg: 96.5970, src.loss: 0.1106, mix.decode.loss_seg: 0.0501, mix.decode.acc_seg: 97.9525, mix.loss: 0.0501, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:18:02,053 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 8:18:00, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0721, src.decode.acc_seg: 97.3312, src.loss: 0.0881, mix.decode.loss_seg: 0.0561, mix.decode.acc_seg: 97.6372, mix.loss: 0.0561, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:19:03,468 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 8:16:57, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0693, src.decode.acc_seg: 97.4184, src.loss: 0.0853, mix.decode.loss_seg: 0.0457, mix.decode.acc_seg: 98.0380, mix.loss: 0.0457, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:20:05,290 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 8:15:56, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0789, src.decode.acc_seg: 96.9129, src.loss: 0.0949, mix.decode.loss_seg: 0.0548, mix.decode.acc_seg: 97.8326, mix.loss: 0.0548, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1040s[                                 ] 2/929, 1.6 task/s, elapsed: 1s, ETA:   568s[                                 ] 3/929, 2.3 task/s, elapsed: 1s, ETA:   408s[                                 ] 4/929, 2.8 task/s, elapsed: 1s, ETA:   329s[                                 ] 5/929, 3.3 task/s, elapsed: 2s, ETA:   281s[                                 ] 6/929, 3.7 task/s, elapsed: 2s, ETA:   249s[                                 ] 7/929, 4.1 task/s, elapsed: 2s, ETA:   226s[                                 ] 8/929, 4.4 task/s, elapsed: 2s, ETA:   209s[                                 ] 9/929, 4.7 task/s, elapsed: 2s, ETA:   197s[                                ] 10/929, 4.9 task/s, elapsed: 2s, ETA:   186s[                                ] 11/929, 5.2 task/s, elapsed: 2s, ETA:   177s[                                ] 12/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 13/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 14/929, 5.8 task/s, elapsed: 2s, ETA:   158s[                                ] 15/929, 6.0 task/s, elapsed: 3s, ETA:   153s[                                ] 16/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 17/929, 6.3 task/s, elapsed: 3s, ETA:   145s[                                ] 18/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 19/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 20/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 21/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 22/929, 6.9 task/s, elapsed: 3s, ETA:   132s[                                ] 23/929, 7.0 task/s, elapsed: 3s, ETA:   130s[                                ] 24/929, 7.1 task/s, elapsed: 3s, ETA:   128s[                                ] 25/929, 7.2 task/s, elapsed: 3s, ETA:   126s[                                ] 26/929, 7.2 task/s, elapsed: 4s, ETA:   125s[                                ] 27/929, 7.3 task/s, elapsed: 4s, ETA:   123s[                                ] 28/929, 7.4 task/s, elapsed: 4s, ETA:   122s[                                ] 29/929, 7.5 task/s, elapsed: 4s, ETA:   121s[>                               ] 30/929, 7.5 task/s, elapsed: 4s, ETA:   119s[>                               ] 31/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 32/929, 7.6 task/s, elapsed: 4s, ETA:   117s[>                               ] 33/929, 7.7 task/s, elapsed: 4s, ETA:   116s[>                               ] 34/929, 7.8 task/s, elapsed: 4s, ETA:   115s[>                               ] 35/929, 7.8 task/s, elapsed: 4s, ETA:   114s[>                               ] 36/929, 7.9 task/s, elapsed: 5s, ETA:   114s[>                               ] 37/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 38/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 39/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 40/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 41/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 42/929, 8.1 task/s, elapsed: 5s, ETA:   109s[>                               ] 43/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 44/929, 8.0 task/s, elapsed: 5s, ETA:   110s[>                               ] 45/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 46/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 47/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 48/929, 8.1 task/s, elapsed: 6s, ETA:   108s[>                               ] 49/929, 8.2 task/s, elapsed: 6s, ETA:   108s[>                               ] 50/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 51/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 52/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 53/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 54/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 55/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 56/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 57/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>                               ] 58/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>>                              ] 59/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>>                              ] 60/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 61/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 62/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 63/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 64/929, 8.5 task/s, elapsed: 8s, ETA:   102s[>>                              ] 65/929, 8.5 task/s, elapsed: 8s, ETA:   102s[>>                              ] 66/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 67/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 68/929, 8.6 task/s, elapsed: 8s, ETA:   101s[>>                              ] 69/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 70/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 71/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 72/929, 8.6 task/s, elapsed: 8s, ETA:    99s[>>                              ] 73/929, 8.6 task/s, elapsed: 8s, ETA:    99s[>>                              ] 74/929, 8.7 task/s, elapsed: 9s, ETA:    99s[>>                              ] 75/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 76/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 77/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 78/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 79/929, 8.7 task/s, elapsed: 9s, ETA:    97s[>>                              ] 80/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 81/929, 8.8 task/s, elapsed: 9s, ETA:    97s[>>                              ] 82/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                              ] 83/929, 8.8 task/s, elapsed: 9s, ETA:    96s[>>                             ] 84/929, 8.8 task/s, elapsed: 10s, ETA:    96s[>>                             ] 85/929, 8.8 task/s, elapsed: 10s, ETA:    96s[>>                             ] 86/929, 8.8 task/s, elapsed: 10s, ETA:    95s[>>                             ] 87/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 88/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>                             ] 89/929, 8.9 task/s, elapsed: 10s, ETA:    95s[>>>                            ] 90/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 91/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 92/929, 8.9 task/s, elapsed: 10s, ETA:    94s[>>>                            ] 93/929, 8.9 task/s, elapsed: 10s, ETA:    93s[>>>                            ] 94/929, 9.0 task/s, elapsed: 10s, ETA:    93s[>>>                            ] 95/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 96/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 97/929, 9.0 task/s, elapsed: 11s, ETA:    93s[>>>                            ] 98/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                            ] 99/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 100/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 101/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 102/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 103/929, 9.0 task/s, elapsed: 11s, ETA:    92s[>>>                           ] 104/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 105/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 106/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 107/929, 9.0 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 108/929, 9.1 task/s, elapsed: 12s, ETA:    91s[>>>                           ] 109/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 110/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 111/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 112/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 113/929, 9.1 task/s, elapsed: 12s, ETA:    90s[>>>                           ] 114/929, 9.1 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 115/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 116/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 117/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 118/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 119/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 120/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 121/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 122/929, 9.1 task/s, elapsed: 13s, ETA:    89s[>>>                           ] 123/929, 9.1 task/s, elapsed: 13s, ETA:    88s[>>>>                          ] 124/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 125/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 126/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 127/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 128/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 129/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 130/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 131/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 132/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 133/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 134/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 135/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 136/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 137/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 138/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 139/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 140/929, 9.1 task/s, elapsed: 15s, ETA:    86s[>>>>                          ] 141/929, 9.1 task/s, elapsed: 15s, ETA:    86s[>>>>                          ] 142/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 143/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 144/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 145/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 146/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 147/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 148/929, 9.1 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 149/929, 9.2 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 150/929, 9.2 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 151/929, 9.2 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 152/929, 9.2 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 153/929, 9.2 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 154/929, 9.2 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 155/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 156/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 157/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 158/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 159/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 160/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 161/929, 9.2 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 162/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 163/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 164/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 165/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 166/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 167/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 168/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 169/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 170/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 171/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 172/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 173/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 174/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 175/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 176/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 177/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 178/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 179/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 180/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 181/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 182/929, 9.3 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 183/929, 9.3 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 184/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>                         ] 185/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 186/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 187/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 188/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 189/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 190/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 191/929, 9.3 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 192/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 193/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 194/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 195/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 196/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 197/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 198/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 199/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 200/929, 9.3 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 201/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 202/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 203/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 204/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 205/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 206/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 207/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 208/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 209/929, 9.3 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 210/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 211/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 212/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 213/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 214/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 215/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 216/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>>                       ] 217/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>>                       ] 218/929, 9.3 task/s, elapsed: 23s, ETA:    77s[>>>>>>>                       ] 219/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 220/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 221/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 222/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 223/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 224/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 225/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 226/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 227/929, 9.3 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 228/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 229/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 230/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 231/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 232/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 233/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 234/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 235/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 236/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 237/929, 9.3 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 238/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 239/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 240/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 241/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 242/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 243/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 244/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 245/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 246/929, 9.3 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 247/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 248/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 249/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 250/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 251/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 252/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 253/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 254/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 255/929, 9.3 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 256/929, 9.3 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 257/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 258/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 259/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 260/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 261/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 262/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 263/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 264/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.3 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 267/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 268/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 269/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 270/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 271/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 272/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 273/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 274/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>                      ] 276/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>                      ] 277/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>                      ] 278/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 279/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 280/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 281/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 282/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.3 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 284/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 285/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 286/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 287/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 288/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 289/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 290/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.3 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 293/929, 9.3 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 294/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 295/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 296/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 297/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 298/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 299/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.3 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 302/929, 9.3 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 303/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 304/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 305/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 306/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 307/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 308/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 309/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>>                    ] 310/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 311/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 312/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 313/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 314/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 315/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 316/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 317/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 318/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 319/929, 9.3 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 320/929, 9.3 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 321/929, 9.3 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 322/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 323/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 324/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 325/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 326/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 327/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.3 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 329/929, 9.3 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 330/929, 9.3 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 331/929, 9.3 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 332/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 333/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 334/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 335/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 336/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 337/929, 9.3 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 338/929, 9.3 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 339/929, 9.3 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 340/929, 9.3 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>>                   ] 341/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 342/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 343/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 344/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 345/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 346/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 347/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 348/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 349/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 350/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 351/929, 9.4 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 352/929, 9.4 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 353/929, 9.4 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 354/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 355/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 356/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 357/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 358/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 359/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 360/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 361/929, 9.4 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 362/929, 9.4 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 363/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 364/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 365/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 366/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 367/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 368/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 369/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 370/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 371/929, 9.4 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 372/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 373/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 374/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 375/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 376/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 377/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 378/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 379/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 380/929, 9.4 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 381/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 382/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 383/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 384/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 385/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 386/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 387/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 388/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 389/929, 9.4 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 390/929, 9.4 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 391/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 392/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 393/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 394/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 395/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 396/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 397/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.4 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 399/929, 9.4 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 400/929, 9.4 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 401/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>                  ] 402/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 403/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 404/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 405/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 406/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 407/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 408/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 409/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 410/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 411/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 412/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 413/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 414/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 415/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 416/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 417/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 418/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 419/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 420/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 421/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 422/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 423/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 424/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 425/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 426/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 427/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 428/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 429/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 430/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 431/929, 9.5 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 432/929, 9.5 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 433/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 434/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 435/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 436/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 437/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 438/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 439/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 440/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 441/929, 9.5 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 442/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 443/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 444/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 445/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 446/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 447/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 448/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 449/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 450/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 451/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 452/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 453/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 454/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 455/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 456/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 457/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 458/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 459/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 460/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 461/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 462/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 463/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 464/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 465/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 466/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 467/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 468/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 469/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 470/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 471/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 472/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 473/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 474/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 475/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 476/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 477/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 478/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 479/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 480/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 481/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 482/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 483/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 484/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 485/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 486/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 487/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 488/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 489/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 490/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 491/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 492/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 493/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 494/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 495/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 496/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 498/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 499/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 500/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 501/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 502/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 503/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 504/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 505/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 507/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 508/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 509/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 510/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 511/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 512/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 513/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 514/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 516/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 517/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 518/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 519/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 520/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 521/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 522/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 523/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 526/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.5 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.4 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.4 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.4 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.4 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.4 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.4 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.4 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.4 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.4 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.4 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.4 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.4 task/s, elapsed: 99s, ETA:     0s2022-10-10 14:24:20,202 - mmseg - INFO - per class results:2022-10-10 14:24:20,203 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.85 | 95.86 || rigid_plastic | 23.32 |  26.5 ||   cardboard   | 57.16 | 72.52 ||     metal     | 24.53 | 46.26 ||  soft_plastic | 63.46 | 73.55 |+---------------+-------+-------+2022-10-10 14:24:20,203 - mmseg - INFO - Summary:2022-10-10 14:24:20,203 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.34 | 51.87 | 62.94 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:24:20,208 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 14:24:20,208 - mmseg - INFO - Iter [929/40000]	lr: 3.600e-05, eta: 8:14:53, time: 1.224, data_time: 0.014, memory: 67493, aAcc: 0.9134, mIoU: 0.5187, mAcc: 0.6294, IoU.background: 0.9085, IoU.rigid_plastic: 0.2332, IoU.cardboard: 0.5716, IoU.metal: 0.2453, IoU.soft_plastic: 0.6346, Acc.background: 0.9586, Acc.rigid_plastic: 0.2650, Acc.cardboard: 0.7252, Acc.metal: 0.4626, Acc.soft_plastic: 0.7355, src.decode.loss_seg: 0.0735, src.decode.acc_seg: 97.2094, src.loss: 0.0895, mix.decode.loss_seg: 0.0574, mix.decode.acc_seg: 97.6406, mix.loss: 0.0574, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:25:22,863 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 8:18:41, time: 5.128, data_time: 3.890, memory: 67493, src.decode.loss_seg: 0.0931, src.decode.acc_seg: 96.5520, src.loss: 0.1091, mix.decode.loss_seg: 0.0520, mix.decode.acc_seg: 97.7374, mix.loss: 0.0520, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:26:24,538 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 8:17:37, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0732, src.decode.acc_seg: 97.4229, src.loss: 0.0893, mix.decode.loss_seg: 0.0455, mix.decode.acc_seg: 98.1284, mix.loss: 0.0455, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:27:27,551 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 8:16:36, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0684, src.decode.acc_seg: 97.4303, src.loss: 0.0844, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.3903, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:28:29,229 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 8:15:32, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0767, src.decode.acc_seg: 97.2301, src.loss: 0.0927, mix.decode.loss_seg: 0.0576, mix.decode.acc_seg: 97.6898, mix.loss: 0.0576, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:29:30,897 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 8:14:29, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0877, src.decode.acc_seg: 96.9960, src.loss: 0.1037, mix.decode.loss_seg: 0.0609, mix.decode.acc_seg: 97.5255, mix.loss: 0.0609, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:30:32,507 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 8:13:25, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0823, src.decode.acc_seg: 97.0314, src.loss: 0.0983, mix.decode.loss_seg: 0.0531, mix.decode.acc_seg: 97.8034, mix.loss: 0.0531, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:31:33,898 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 8:12:21, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0915, src.decode.acc_seg: 96.6745, src.loss: 0.1075, mix.decode.loss_seg: 0.0557, mix.decode.acc_seg: 97.5348, mix.loss: 0.0557, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:32:35,193 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 8:11:17, time: 1.226, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0846, src.decode.acc_seg: 96.9106, src.loss: 0.1006, mix.decode.loss_seg: 0.0604, mix.decode.acc_seg: 97.5059, mix.loss: 0.0604, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:33:36,349 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 8:10:12, time: 1.223, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0805, src.decode.acc_seg: 97.1057, src.loss: 0.0965, mix.decode.loss_seg: 0.0558, mix.decode.acc_seg: 97.7175, mix.loss: 0.0558, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:34:37,729 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 8:09:08, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0849, src.decode.acc_seg: 96.9200, src.loss: 0.1009, mix.decode.loss_seg: 0.0599, mix.decode.acc_seg: 97.5824, mix.loss: 0.0599, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:35:39,125 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 8:08:04, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0762, src.decode.acc_seg: 97.2997, src.loss: 0.0923, mix.decode.loss_seg: 0.0511, mix.decode.acc_seg: 97.7238, mix.loss: 0.0511, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:36:40,610 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 8:07:01, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0839, src.decode.acc_seg: 96.9687, src.loss: 0.0999, mix.decode.loss_seg: 0.0586, mix.decode.acc_seg: 97.4732, mix.loss: 0.0586, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:37:41,737 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 8:05:56, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1024, src.decode.acc_seg: 96.3182, src.loss: 0.1185, mix.decode.loss_seg: 0.0651, mix.decode.acc_seg: 97.5100, mix.loss: 0.0651, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:38:42,649 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 8:04:52, time: 1.218, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0726, src.decode.acc_seg: 97.3090, src.loss: 0.0886, mix.decode.loss_seg: 0.0487, mix.decode.acc_seg: 97.9836, mix.loss: 0.0487, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:39:44,234 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 8:03:48, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0995, src.decode.acc_seg: 96.4037, src.loss: 0.1155, mix.decode.loss_seg: 0.0602, mix.decode.acc_seg: 97.5049, mix.loss: 0.0602, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:40:46,003 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 8:02:45, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0677, src.decode.acc_seg: 97.6233, src.loss: 0.0837, mix.decode.loss_seg: 0.0625, mix.decode.acc_seg: 97.4134, mix.loss: 0.0625, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:41:47,888 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 8:01:42, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0794, src.decode.acc_seg: 97.0143, src.loss: 0.0955, mix.decode.loss_seg: 0.0518, mix.decode.acc_seg: 97.7356, mix.loss: 0.0518, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:42:48,827 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 8:00:37, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0899, src.decode.acc_seg: 96.9085, src.loss: 0.1059, mix.decode.loss_seg: 0.0573, mix.decode.acc_seg: 97.7309, mix.loss: 0.0573, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:43:50,019 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 7:59:33, time: 1.224, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0758, src.decode.acc_seg: 97.1745, src.loss: 0.0918, mix.decode.loss_seg: 0.0584, mix.decode.acc_seg: 97.5999, mix.loss: 0.0584, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:44:51,194 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 14:44:51,195 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 7:58:29, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0734, src.decode.acc_seg: 97.3196, src.loss: 0.0894, mix.decode.loss_seg: 0.0513, mix.decode.acc_seg: 98.0139, mix.loss: 0.0513, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:45:51,868 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 7:57:24, time: 1.213, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0707, src.decode.acc_seg: 97.4306, src.loss: 0.0868, mix.decode.loss_seg: 0.0555, mix.decode.acc_seg: 97.7903, mix.loss: 0.0555, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:46:52,719 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 7:56:20, time: 1.217, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0859, src.decode.acc_seg: 96.9321, src.loss: 0.1019, mix.decode.loss_seg: 0.0443, mix.decode.acc_seg: 98.1960, mix.loss: 0.0443, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:47:53,403 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 7:55:15, time: 1.214, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0746, src.decode.acc_seg: 97.2708, src.loss: 0.0907, mix.decode.loss_seg: 0.0503, mix.decode.acc_seg: 97.8994, mix.loss: 0.0503, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:48:53,895 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 7:54:10, time: 1.210, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0779, src.decode.acc_seg: 97.1641, src.loss: 0.0940, mix.decode.loss_seg: 0.0473, mix.decode.acc_seg: 98.0368, mix.loss: 0.0473, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:49:54,838 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 7:53:06, time: 1.219, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0725, src.decode.acc_seg: 97.5758, src.loss: 0.0885, mix.decode.loss_seg: 0.0456, mix.decode.acc_seg: 98.2293, mix.loss: 0.0456, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:50:55,591 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 7:52:01, time: 1.215, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0715, src.decode.acc_seg: 97.3520, src.loss: 0.0875, mix.decode.loss_seg: 0.0483, mix.decode.acc_seg: 97.9668, mix.loss: 0.0483, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:51:56,076 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 7:50:57, time: 1.210, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0845, src.decode.acc_seg: 97.0233, src.loss: 0.1005, mix.decode.loss_seg: 0.0543, mix.decode.acc_seg: 97.8251, mix.loss: 0.0543, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:52:57,177 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 7:49:53, time: 1.222, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0961, src.decode.acc_seg: 96.6832, src.loss: 0.1121, mix.decode.loss_seg: 0.0630, mix.decode.acc_seg: 97.4312, mix.loss: 0.0630, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:53:58,145 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 7:48:48, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0785, src.decode.acc_seg: 97.2150, src.loss: 0.0945, mix.decode.loss_seg: 0.0563, mix.decode.acc_seg: 97.6063, mix.loss: 0.0563, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:54:59,110 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 7:47:44, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0641, src.decode.acc_seg: 97.4932, src.loss: 0.0802, mix.decode.loss_seg: 0.0493, mix.decode.acc_seg: 97.9915, mix.loss: 0.0493, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:55:59,207 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 7:46:39, time: 1.202, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0850, src.decode.acc_seg: 97.0112, src.loss: 0.1011, mix.decode.loss_seg: 0.0581, mix.decode.acc_seg: 97.5910, mix.loss: 0.0581, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:56:59,644 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 7:45:34, time: 1.209, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.0622, src.decode.acc_seg: 97.8723, src.loss: 0.0783, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.2238, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:58:00,839 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 7:44:30, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0742, src.decode.acc_seg: 97.2766, src.loss: 0.0903, mix.decode.loss_seg: 0.0588, mix.decode.acc_seg: 97.7193, mix.loss: 0.0588, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:59:01,337 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 7:43:26, time: 1.210, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1027, src.decode.acc_seg: 96.4450, src.loss: 0.1187, mix.decode.loss_seg: 0.0657, mix.decode.acc_seg: 97.5079, mix.loss: 0.0657, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:00:02,764 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 7:42:22, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0800, src.decode.acc_seg: 97.1802, src.loss: 0.0960, mix.decode.loss_seg: 0.0556, mix.decode.acc_seg: 97.7282, mix.loss: 0.0556, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:01:04,309 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 7:41:19, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0752, src.decode.acc_seg: 97.2818, src.loss: 0.0912, mix.decode.loss_seg: 0.0543, mix.decode.acc_seg: 97.8835, mix.loss: 0.0543, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:02:05,930 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 7:40:15, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0871, src.decode.acc_seg: 96.8244, src.loss: 0.1032, mix.decode.loss_seg: 0.0580, mix.decode.acc_seg: 97.5987, mix.loss: 0.0580, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:03:06,813 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 7:39:11, time: 1.218, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0700, src.decode.acc_seg: 97.5716, src.loss: 0.0860, mix.decode.loss_seg: 0.0502, mix.decode.acc_seg: 98.0650, mix.loss: 0.0502, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:04:07,446 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 7:38:07, time: 1.213, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0678, src.decode.acc_seg: 97.4357, src.loss: 0.0839, mix.decode.loss_seg: 0.0445, mix.decode.acc_seg: 98.0542, mix.loss: 0.0445, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:05:08,330 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 15:05:08,330 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 7:37:03, time: 1.218, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0708, src.decode.acc_seg: 97.4164, src.loss: 0.0868, mix.decode.loss_seg: 0.0461, mix.decode.acc_seg: 98.1170, mix.loss: 0.0461, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:06:08,755 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 7:35:58, time: 1.209, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0635, src.decode.acc_seg: 97.6988, src.loss: 0.0795, mix.decode.loss_seg: 0.0471, mix.decode.acc_seg: 98.1187, mix.loss: 0.0471, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:07:09,535 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 7:34:54, time: 1.216, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0697, src.decode.acc_seg: 97.4638, src.loss: 0.0857, mix.decode.loss_seg: 0.0494, mix.decode.acc_seg: 97.9481, mix.loss: 0.0494, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:08:10,309 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 7:33:50, time: 1.215, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0790, src.decode.acc_seg: 97.2450, src.loss: 0.0950, mix.decode.loss_seg: 0.0496, mix.decode.acc_seg: 97.9648, mix.loss: 0.0496, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:09:11,354 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 7:32:46, time: 1.221, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0850, src.decode.acc_seg: 96.8714, src.loss: 0.1011, mix.decode.loss_seg: 0.0567, mix.decode.acc_seg: 97.7218, mix.loss: 0.0567, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:10:12,369 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 7:31:42, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0777, src.decode.acc_seg: 97.1228, src.loss: 0.0937, mix.decode.loss_seg: 0.0572, mix.decode.acc_seg: 97.6580, mix.loss: 0.0572, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:11:13,379 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 7:30:38, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0767, src.decode.acc_seg: 97.2195, src.loss: 0.0927, mix.decode.loss_seg: 0.0518, mix.decode.acc_seg: 97.7420, mix.loss: 0.0518, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:12:13,831 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 7:29:34, time: 1.209, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0716, src.decode.acc_seg: 97.4510, src.loss: 0.0876, mix.decode.loss_seg: 0.0418, mix.decode.acc_seg: 98.2877, mix.loss: 0.0418, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:13:15,038 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 7:28:30, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0618, src.decode.acc_seg: 97.8219, src.loss: 0.0779, mix.decode.loss_seg: 0.0451, mix.decode.acc_seg: 98.1182, mix.loss: 0.0451, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:14:16,052 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 7:27:26, time: 1.220, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0795, src.decode.acc_seg: 97.2343, src.loss: 0.0956, mix.decode.loss_seg: 0.0482, mix.decode.acc_seg: 97.9999, mix.loss: 0.0482, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:15:17,023 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 7:26:23, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0776, src.decode.acc_seg: 97.2327, src.loss: 0.0936, mix.decode.loss_seg: 0.0508, mix.decode.acc_seg: 97.6998, mix.loss: 0.0508, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:16:17,907 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 7:25:19, time: 1.218, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0719, src.decode.acc_seg: 97.5141, src.loss: 0.0879, mix.decode.loss_seg: 0.0508, mix.decode.acc_seg: 98.0236, mix.loss: 0.0508, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:17:18,472 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 7:24:14, time: 1.211, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0760, src.decode.acc_seg: 97.2809, src.loss: 0.0920, mix.decode.loss_seg: 0.0520, mix.decode.acc_seg: 97.8644, mix.loss: 0.0520, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:18:19,135 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 7:23:10, time: 1.213, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0781, src.decode.acc_seg: 97.1902, src.loss: 0.0942, mix.decode.loss_seg: 0.0534, mix.decode.acc_seg: 97.9595, mix.loss: 0.0534, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:19:20,252 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 7:22:07, time: 1.222, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0587, src.decode.acc_seg: 97.9177, src.loss: 0.0748, mix.decode.loss_seg: 0.0380, mix.decode.acc_seg: 98.4839, mix.loss: 0.0380, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:20:21,440 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 7:21:03, time: 1.224, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0745, src.decode.acc_seg: 97.2209, src.loss: 0.0906, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.1432, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:21:22,078 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 7:19:59, time: 1.213, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0727, src.decode.acc_seg: 97.1940, src.loss: 0.0888, mix.decode.loss_seg: 0.0474, mix.decode.acc_seg: 97.9684, mix.loss: 0.0474, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:22:23,093 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 7:18:55, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0690, src.decode.acc_seg: 97.5116, src.loss: 0.0850, mix.decode.loss_seg: 0.0420, mix.decode.acc_seg: 98.2958, mix.loss: 0.0420, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:23:23,306 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 7:17:51, time: 1.204, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0777, src.decode.acc_seg: 97.1520, src.loss: 0.0937, mix.decode.loss_seg: 0.0453, mix.decode.acc_seg: 98.0688, mix.loss: 0.0453, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:24:24,076 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 7:16:47, time: 1.215, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0720, src.decode.acc_seg: 97.3650, src.loss: 0.0881, mix.decode.loss_seg: 0.0493, mix.decode.acc_seg: 98.0660, mix.loss: 0.0493, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:25:24,807 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 15:25:24,807 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 7:15:43, time: 1.215, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0751, src.decode.acc_seg: 97.3074, src.loss: 0.0912, mix.decode.loss_seg: 0.0471, mix.decode.acc_seg: 98.0044, mix.loss: 0.0471, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:26:25,252 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 7:14:39, time: 1.209, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0704, src.decode.acc_seg: 97.4407, src.loss: 0.0864, mix.decode.loss_seg: 0.0498, mix.decode.acc_seg: 97.8276, mix.loss: 0.0498, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:27:26,049 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 7:13:35, time: 1.216, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0708, src.decode.acc_seg: 97.3968, src.loss: 0.0868, mix.decode.loss_seg: 0.0504, mix.decode.acc_seg: 97.8744, mix.loss: 0.0504, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:28:28,198 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 7:12:33, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0809, src.decode.acc_seg: 96.9664, src.loss: 0.0969, mix.decode.loss_seg: 0.0639, mix.decode.acc_seg: 97.6638, mix.loss: 0.0639, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:29:30,423 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 7:11:30, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0740, src.decode.acc_seg: 97.3343, src.loss: 0.0901, mix.decode.loss_seg: 0.0517, mix.decode.acc_seg: 97.9363, mix.loss: 0.0517, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:30:33,101 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 7:10:29, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0732, src.decode.acc_seg: 97.4081, src.loss: 0.0892, mix.decode.loss_seg: 0.0466, mix.decode.acc_seg: 98.1225, mix.loss: 0.0466, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:31:35,660 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 7:09:27, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0686, src.decode.acc_seg: 97.3969, src.loss: 0.0846, mix.decode.loss_seg: 0.0494, mix.decode.acc_seg: 97.9166, mix.loss: 0.0494, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:32:38,027 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 7:08:25, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0758, src.decode.acc_seg: 97.3458, src.loss: 0.0918, mix.decode.loss_seg: 0.0538, mix.decode.acc_seg: 97.6153, mix.loss: 0.0538, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:33:40,022 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 7:07:22, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0824, src.decode.acc_seg: 97.0640, src.loss: 0.0984, mix.decode.loss_seg: 0.0523, mix.decode.acc_seg: 97.8500, mix.loss: 0.0523, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:34:41,990 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 7:06:20, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0685, src.decode.acc_seg: 97.4756, src.loss: 0.0845, mix.decode.loss_seg: 0.0543, mix.decode.acc_seg: 97.6809, mix.loss: 0.0543, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:35:44,673 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 7:05:18, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0565, src.decode.acc_seg: 97.8989, src.loss: 0.0725, mix.decode.loss_seg: 0.0449, mix.decode.acc_seg: 97.9340, mix.loss: 0.0449, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:36:47,162 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 7:04:16, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0712, src.decode.acc_seg: 97.4617, src.loss: 0.0872, mix.decode.loss_seg: 0.0466, mix.decode.acc_seg: 98.0855, mix.loss: 0.0466, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:37:49,208 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 7:03:13, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0557, src.decode.acc_seg: 98.0677, src.loss: 0.0717, mix.decode.loss_seg: 0.0401, mix.decode.acc_seg: 98.4404, mix.loss: 0.0401, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:38:51,911 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 7:02:12, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0621, src.decode.acc_seg: 97.7514, src.loss: 0.0782, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.3788, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:39:54,374 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 7:01:10, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0745, src.decode.acc_seg: 97.3065, src.loss: 0.0905, mix.decode.loss_seg: 0.0518, mix.decode.acc_seg: 97.9168, mix.loss: 0.0518, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:40:56,018 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 7:00:07, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0689, src.decode.acc_seg: 97.5002, src.loss: 0.0850, mix.decode.loss_seg: 0.0560, mix.decode.acc_seg: 97.8461, mix.loss: 0.0560, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:41:57,915 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 6:59:04, time: 1.238, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0620, src.decode.acc_seg: 97.7233, src.loss: 0.0781, mix.decode.loss_seg: 0.0471, mix.decode.acc_seg: 97.9609, mix.loss: 0.0471, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:42:59,891 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 6:58:02, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0636, src.decode.acc_seg: 97.7425, src.loss: 0.0796, mix.decode.loss_seg: 0.0392, mix.decode.acc_seg: 98.3112, mix.loss: 0.0392, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:44:02,446 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 6:57:00, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0627, src.decode.acc_seg: 97.8182, src.loss: 0.0787, mix.decode.loss_seg: 0.0417, mix.decode.acc_seg: 98.3391, mix.loss: 0.0417, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:45:04,995 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 6:55:58, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0621, src.decode.acc_seg: 97.7434, src.loss: 0.0782, mix.decode.loss_seg: 0.0389, mix.decode.acc_seg: 98.3209, mix.loss: 0.0389, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1061s[                                 ] 2/929, 1.6 task/s, elapsed: 1s, ETA:   581s[                                 ] 3/929, 2.2 task/s, elapsed: 1s, ETA:   419s[                                 ] 4/929, 2.7 task/s, elapsed: 1s, ETA:   338s[                                 ] 5/929, 3.2 task/s, elapsed: 2s, ETA:   290s[                                 ] 6/929, 3.6 task/s, elapsed: 2s, ETA:   257s[                                 ] 7/929, 3.9 task/s, elapsed: 2s, ETA:   234s[                                 ] 8/929, 4.2 task/s, elapsed: 2s, ETA:   217s[                                 ] 9/929, 4.5 task/s, elapsed: 2s, ETA:   203s[                                ] 10/929, 4.8 task/s, elapsed: 2s, ETA:   193s[                                ] 11/929, 5.0 task/s, elapsed: 2s, ETA:   184s[                                ] 12/929, 5.2 task/s, elapsed: 2s, ETA:   176s[                                ] 13/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 14/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 15/929, 5.7 task/s, elapsed: 3s, ETA:   159s[                                ] 16/929, 5.9 task/s, elapsed: 3s, ETA:   155s[                                ] 17/929, 6.0 task/s, elapsed: 3s, ETA:   152s[                                ] 18/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 19/929, 6.1 task/s, elapsed: 3s, ETA:   148s[                                ] 20/929, 6.2 task/s, elapsed: 3s, ETA:   145s[                                ] 21/929, 6.3 task/s, elapsed: 3s, ETA:   143s[                                ] 22/929, 6.4 task/s, elapsed: 3s, ETA:   141s[                                ] 23/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 24/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 25/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 26/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 27/929, 6.9 task/s, elapsed: 4s, ETA:   132s[                                ] 28/929, 6.9 task/s, elapsed: 4s, ETA:   130s[                                ] 29/929, 7.0 task/s, elapsed: 4s, ETA:   129s[>                               ] 30/929, 7.1 task/s, elapsed: 4s, ETA:   127s[>                               ] 31/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 32/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 33/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 34/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 35/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 36/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 37/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 38/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 39/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 40/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 41/929, 7.6 task/s, elapsed: 5s, ETA:   116s[>                               ] 42/929, 7.7 task/s, elapsed: 5s, ETA:   115s[>                               ] 43/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 44/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 45/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 46/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 47/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 48/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 49/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 50/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 51/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 53/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 54/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 55/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 56/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 57/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 61/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>>                              ] 62/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 63/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 64/929, 8.3 task/s, elapsed: 8s, ETA:   105s[>>                              ] 65/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 66/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 67/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 68/929, 8.3 task/s, elapsed: 8s, ETA:   103s[>>                              ] 69/929, 8.3 task/s, elapsed: 8s, ETA:   103s[>>                              ] 70/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 71/929, 8.4 task/s, elapsed: 8s, ETA:   102s[>>                              ] 72/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 73/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 74/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 75/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 76/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 77/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 78/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 79/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 80/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 81/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                             ] 82/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 83/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 84/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 85/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 86/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 87/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 88/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 89/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>>                            ] 90/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 91/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 92/929, 8.8 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 93/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 94/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 95/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 96/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 97/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 98/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                            ] 99/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 100/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 101/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 102/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 103/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 104/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 105/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 106/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 107/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 108/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 109/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 110/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 111/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 112/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 113/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 114/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 115/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 116/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 117/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 118/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 119/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 120/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 121/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 122/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 123/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 124/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 125/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 126/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 127/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 128/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 129/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 130/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 131/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 132/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 133/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 134/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 135/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 136/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 137/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 138/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 139/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 140/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 141/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 142/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 143/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 144/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 145/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 146/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 147/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 148/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 149/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 150/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 151/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 152/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 153/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 154/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>>                         ] 155/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 156/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 157/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 158/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 159/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 160/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 161/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 162/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 163/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 164/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 165/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 166/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 167/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 168/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 169/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 170/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 171/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 172/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 173/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 174/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 175/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 176/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 177/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 178/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 179/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 180/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 181/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 182/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 183/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 184/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 185/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 186/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 187/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 188/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 189/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 190/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 191/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 192/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 193/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 194/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 195/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 196/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 197/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 198/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 199/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 200/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 201/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 202/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 203/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 204/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 205/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 206/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 207/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 208/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 209/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 210/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 211/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 212/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 213/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 214/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 215/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 216/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 217/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 218/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 219/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 220/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 221/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 222/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 223/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 224/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 225/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 226/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 227/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 228/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 229/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 230/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 231/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 232/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 233/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 234/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 235/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 236/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 237/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 239/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 240/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 241/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 242/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 243/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 244/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 245/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 246/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 247/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 248/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 249/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 250/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 251/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 252/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 254/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 255/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 256/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 257/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 258/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 259/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 260/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 261/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 262/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 263/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 264/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 265/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 266/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 267/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 268/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 269/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 270/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 271/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 272/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 273/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 274/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 275/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 276/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 277/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 278/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 279/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 280/929, 8.9 task/s, elapsed: 32s, ETA:    73s[>>>>>>>>>                     ] 281/929, 8.9 task/s, elapsed: 32s, ETA:    73s[>>>>>>>>>                     ] 282/929, 8.9 task/s, elapsed: 32s, ETA:    73s[>>>>>>>>>                     ] 283/929, 8.9 task/s, elapsed: 32s, ETA:    73s[>>>>>>>>>                     ] 284/929, 8.9 task/s, elapsed: 32s, ETA:    73s[>>>>>>>>>                     ] 285/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 286/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 287/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 288/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 289/929, 8.9 task/s, elapsed: 33s, ETA:    72s[>>>>>>>>>                     ] 290/929, 8.9 task/s, elapsed: 33s, ETA:    72s[>>>>>>>>>                     ] 291/929, 8.9 task/s, elapsed: 33s, ETA:    72s[>>>>>>>>>                     ] 292/929, 8.9 task/s, elapsed: 33s, ETA:    72s[>>>>>>>>>                     ] 293/929, 8.9 task/s, elapsed: 33s, ETA:    72s[>>>>>>>>>                     ] 294/929, 8.9 task/s, elapsed: 33s, ETA:    72s[>>>>>>>>>                     ] 295/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 296/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 297/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 298/929, 8.9 task/s, elapsed: 34s, ETA:    71s[>>>>>>>>>                     ] 299/929, 8.9 task/s, elapsed: 34s, ETA:    71s[>>>>>>>>>                     ] 300/929, 8.9 task/s, elapsed: 34s, ETA:    71s[>>>>>>>>>                     ] 301/929, 8.9 task/s, elapsed: 34s, ETA:    71s[>>>>>>>>>                     ] 302/929, 8.9 task/s, elapsed: 34s, ETA:    71s[>>>>>>>>>                     ] 303/929, 8.9 task/s, elapsed: 34s, ETA:    71s[>>>>>>>>>                     ] 304/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 305/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 306/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 307/929, 8.9 task/s, elapsed: 35s, ETA:    70s[>>>>>>>>>                     ] 308/929, 8.9 task/s, elapsed: 35s, ETA:    70s[>>>>>>>>>                     ] 309/929, 8.9 task/s, elapsed: 35s, ETA:    70s[>>>>>>>>>>                    ] 310/929, 8.9 task/s, elapsed: 35s, ETA:    70s[>>>>>>>>>>                    ] 311/929, 8.9 task/s, elapsed: 35s, ETA:    70s[>>>>>>>>>>                    ] 312/929, 8.9 task/s, elapsed: 35s, ETA:    70s[>>>>>>>>>>                    ] 313/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 314/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 315/929, 8.9 task/s, elapsed: 36s, ETA:    69s[>>>>>>>>>>                    ] 316/929, 8.9 task/s, elapsed: 36s, ETA:    69s[>>>>>>>>>>                    ] 317/929, 8.9 task/s, elapsed: 36s, ETA:    69s[>>>>>>>>>>                    ] 318/929, 8.9 task/s, elapsed: 36s, ETA:    69s[>>>>>>>>>>                    ] 319/929, 8.9 task/s, elapsed: 36s, ETA:    69s[>>>>>>>>>>                    ] 320/929, 8.9 task/s, elapsed: 36s, ETA:    69s[>>>>>>>>>>                    ] 321/929, 8.9 task/s, elapsed: 36s, ETA:    69s[>>>>>>>>>>                    ] 322/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 323/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 324/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 325/929, 8.9 task/s, elapsed: 37s, ETA:    68s[>>>>>>>>>>                    ] 326/929, 8.9 task/s, elapsed: 37s, ETA:    68s[>>>>>>>>>>                    ] 327/929, 8.9 task/s, elapsed: 37s, ETA:    68s[>>>>>>>>>>                    ] 328/929, 8.9 task/s, elapsed: 37s, ETA:    68s[>>>>>>>>>>                    ] 329/929, 8.9 task/s, elapsed: 37s, ETA:    68s[>>>>>>>>>>                    ] 330/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 331/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 332/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 333/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 334/929, 8.9 task/s, elapsed: 38s, ETA:    67s[>>>>>>>>>>                    ] 335/929, 8.9 task/s, elapsed: 38s, ETA:    67s[>>>>>>>>>>                    ] 336/929, 8.9 task/s, elapsed: 38s, ETA:    67s[>>>>>>>>>>                    ] 337/929, 8.9 task/s, elapsed: 38s, ETA:    67s[>>>>>>>>>>                    ] 338/929, 8.9 task/s, elapsed: 38s, ETA:    67s[>>>>>>>>>>                    ] 339/929, 8.9 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 340/929, 8.9 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 341/929, 8.9 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 342/929, 8.9 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 343/929, 8.9 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 344/929, 8.9 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 345/929, 8.9 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 346/929, 8.9 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 347/929, 8.9 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 348/929, 8.9 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 349/929, 8.9 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 350/929, 8.9 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 351/929, 8.9 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 352/929, 8.9 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 353/929, 8.9 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 354/929, 8.9 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 355/929, 8.9 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 356/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 357/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 358/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 359/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 360/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 361/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 362/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 363/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 364/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 365/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 366/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 367/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 368/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 369/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 370/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>                   ] 371/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>>                  ] 372/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>>                  ] 373/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>>                  ] 374/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 375/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 376/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 377/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 378/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 379/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 380/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 381/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 382/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 383/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 384/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 385/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 386/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 387/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 388/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 389/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 390/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 391/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 392/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 393/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 394/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 395/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 396/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 397/929, 8.9 task/s, elapsed: 45s, ETA:    60s[>>>>>>>>>>>>                  ] 398/929, 8.9 task/s, elapsed: 45s, ETA:    60s[>>>>>>>>>>>>                  ] 399/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 400/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 401/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 402/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 403/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 404/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 405/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 406/929, 8.9 task/s, elapsed: 46s, ETA:    59s[>>>>>>>>>>>>>                 ] 407/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 408/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 409/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 410/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 411/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 412/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 413/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 414/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 415/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 416/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 417/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 418/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 419/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 420/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 421/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 422/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 423/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 424/929, 8.9 task/s, elapsed: 48s, ETA:    57s[>>>>>>>>>>>>>                 ] 425/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 426/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 427/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 428/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 429/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 430/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 431/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 432/929, 8.9 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 433/929, 8.9 task/s, elapsed: 49s, ETA:    56s[>>>>>>>>>>>>>>                ] 434/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 435/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 436/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 437/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 438/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 439/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 440/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 441/929, 8.9 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 442/929, 8.9 task/s, elapsed: 50s, ETA:    55s[>>>>>>>>>>>>>>                ] 443/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 444/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 445/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 446/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 447/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 448/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 449/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 450/929, 8.9 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 451/929, 8.9 task/s, elapsed: 51s, ETA:    54s[>>>>>>>>>>>>>>                ] 452/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 453/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 454/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 455/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 456/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 457/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 458/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 459/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 460/929, 8.9 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 461/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>                ] 462/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>                ] 463/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>                ] 464/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 465/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 466/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 467/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 468/929, 8.9 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 469/929, 8.9 task/s, elapsed: 53s, ETA:    52s[>>>>>>>>>>>>>>>               ] 470/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 471/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 472/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 473/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 474/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 475/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 476/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 477/929, 8.9 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 478/929, 8.9 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 479/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 480/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 481/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 482/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 483/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 484/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 485/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 486/929, 8.9 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 487/929, 8.9 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 488/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 489/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 490/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 491/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 492/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 493/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 494/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 495/929, 8.9 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>>              ] 496/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 497/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 498/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 499/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 500/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 501/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 502/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 503/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 504/929, 8.9 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 505/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 506/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 507/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 508/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 509/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 510/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 511/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 512/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 513/929, 8.9 task/s, elapsed: 57s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 514/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 515/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 516/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 517/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 518/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 519/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 520/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 521/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 522/929, 8.9 task/s, elapsed: 58s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 523/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 524/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 525/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 526/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 527/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 528/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 529/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 530/929, 8.9 task/s, elapsed: 59s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 531/929, 8.9 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 8.9 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 533/929, 8.9 task/s, elapsed: 60s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.0 task/s, elapsed: 60s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.0 task/s, elapsed: 60s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.0 task/s, elapsed: 60s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.0 task/s, elapsed: 60s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.0 task/s, elapsed: 60s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.0 task/s, elapsed: 60s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.0 task/s, elapsed: 61s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.0 task/s, elapsed: 61s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.0 task/s, elapsed: 61s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.0 task/s, elapsed: 61s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.0 task/s, elapsed: 61s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.0 task/s, elapsed: 62s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.0 task/s, elapsed: 62s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.0 task/s, elapsed: 62s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.0 task/s, elapsed: 62s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.0 task/s, elapsed: 62s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.0 task/s, elapsed: 63s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.0 task/s, elapsed: 63s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.0 task/s, elapsed: 63s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.0 task/s, elapsed: 64s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.0 task/s, elapsed: 64s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.0 task/s, elapsed: 64s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.0 task/s, elapsed: 65s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.0 task/s, elapsed: 65s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.0 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.0 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.0 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.0 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.0 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.0 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.0 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.0 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.0 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.0 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.0 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.0 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.0 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.0 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.0 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.1 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.1 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.1 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.1 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.1 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.1 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.1 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.2 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.2 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.2 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.2 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.2 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.2 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.2 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.2 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.2 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.2 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.2 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.2 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.2 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.2 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.2 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.2 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.2 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.2 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.2 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.2 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.2 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.2 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.2 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.2 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.2 task/s, elapsed: 101s, ETA:     0s2022-10-10 15:49:29,091 - mmseg - INFO - per class results:2022-10-10 15:49:29,092 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.12 | 96.99 || rigid_plastic | 37.43 | 51.33 ||   cardboard   | 56.57 | 67.87 ||     metal     | 27.89 | 51.86 ||  soft_plastic | 60.72 | 66.56 |+---------------+-------+-------+2022-10-10 15:49:29,092 - mmseg - INFO - Summary:2022-10-10 15:49:29,092 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.54 | 54.75 | 66.92 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:49:29,098 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 15:49:29,098 - mmseg - INFO - Iter [929/40000]	lr: 3.000e-05, eta: 6:54:56, time: 1.245, data_time: 0.014, memory: 67493, aAcc: 0.9154, mIoU: 0.5475, mAcc: 0.6692, IoU.background: 0.9112, IoU.rigid_plastic: 0.3743, IoU.cardboard: 0.5657, IoU.metal: 0.2789, IoU.soft_plastic: 0.6072, Acc.background: 0.9699, Acc.rigid_plastic: 0.5133, Acc.cardboard: 0.6787, Acc.metal: 0.5186, Acc.soft_plastic: 0.6656, src.decode.loss_seg: 0.0800, src.decode.acc_seg: 97.2550, src.loss: 0.0960, mix.decode.loss_seg: 0.0559, mix.decode.acc_seg: 97.7795, mix.loss: 0.0559, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:50:33,184 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 6:57:16, time: 5.319, data_time: 4.052, memory: 67493, src.decode.loss_seg: 0.0753, src.decode.acc_seg: 97.3533, src.loss: 0.0913, mix.decode.loss_seg: 0.0462, mix.decode.acc_seg: 98.1207, mix.loss: 0.0462, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:51:35,658 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 6:56:13, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0791, src.decode.acc_seg: 97.3498, src.loss: 0.0952, mix.decode.loss_seg: 0.0504, mix.decode.acc_seg: 97.9415, mix.loss: 0.0504, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:52:38,287 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 6:55:10, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0606, src.decode.acc_seg: 97.7504, src.loss: 0.0766, mix.decode.loss_seg: 0.0411, mix.decode.acc_seg: 98.3947, mix.loss: 0.0411, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:53:42,445 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 6:54:09, time: 1.283, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0747, src.decode.acc_seg: 97.3057, src.loss: 0.0908, mix.decode.loss_seg: 0.0417, mix.decode.acc_seg: 98.2798, mix.loss: 0.0417, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:54:46,681 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 6:53:08, time: 1.285, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0742, src.decode.acc_seg: 97.2921, src.loss: 0.0902, mix.decode.loss_seg: 0.0477, mix.decode.acc_seg: 98.0621, mix.loss: 0.0477, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:55:49,129 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 6:52:05, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0693, src.decode.acc_seg: 97.4633, src.loss: 0.0853, mix.decode.loss_seg: 0.0465, mix.decode.acc_seg: 98.1455, mix.loss: 0.0465, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:56:51,621 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 6:51:02, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0747, src.decode.acc_seg: 97.3320, src.loss: 0.0908, mix.decode.loss_seg: 0.0478, mix.decode.acc_seg: 98.0482, mix.loss: 0.0478, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:57:54,586 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 6:49:59, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0754, src.decode.acc_seg: 97.3170, src.loss: 0.0914, mix.decode.loss_seg: 0.0504, mix.decode.acc_seg: 97.9334, mix.loss: 0.0504, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:58:56,644 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 6:48:56, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0701, src.decode.acc_seg: 97.3585, src.loss: 0.0861, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.0704, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:59:59,389 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 6:47:53, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0671, src.decode.acc_seg: 97.6548, src.loss: 0.0831, mix.decode.loss_seg: 0.0421, mix.decode.acc_seg: 98.2997, mix.loss: 0.0421, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:01:02,375 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 6:46:50, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0674, src.decode.acc_seg: 97.5542, src.loss: 0.0834, mix.decode.loss_seg: 0.0456, mix.decode.acc_seg: 98.0423, mix.loss: 0.0456, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:02:05,023 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 6:45:47, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0777, src.decode.acc_seg: 97.1865, src.loss: 0.0938, mix.decode.loss_seg: 0.0513, mix.decode.acc_seg: 97.9672, mix.loss: 0.0513, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:03:08,078 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 6:44:45, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0581, src.decode.acc_seg: 97.8454, src.loss: 0.0741, mix.decode.loss_seg: 0.0442, mix.decode.acc_seg: 98.2024, mix.loss: 0.0442, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:04:10,671 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 6:43:42, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0634, src.decode.acc_seg: 97.6362, src.loss: 0.0794, mix.decode.loss_seg: 0.0514, mix.decode.acc_seg: 97.7910, mix.loss: 0.0514, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:05:13,468 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 6:42:39, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0711, src.decode.acc_seg: 97.3609, src.loss: 0.0871, mix.decode.loss_seg: 0.0525, mix.decode.acc_seg: 97.9428, mix.loss: 0.0525, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:06:16,467 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 6:41:37, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0641, src.decode.acc_seg: 97.5867, src.loss: 0.0801, mix.decode.loss_seg: 0.0484, mix.decode.acc_seg: 97.9139, mix.loss: 0.0484, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:07:18,512 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 6:40:33, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0555, src.decode.acc_seg: 98.0066, src.loss: 0.0715, mix.decode.loss_seg: 0.0441, mix.decode.acc_seg: 98.2913, mix.loss: 0.0441, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:08:21,221 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 6:39:31, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0647, src.decode.acc_seg: 97.5346, src.loss: 0.0808, mix.decode.loss_seg: 0.0488, mix.decode.acc_seg: 97.9707, mix.loss: 0.0488, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:09:24,266 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 6:38:28, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0668, src.decode.acc_seg: 97.7163, src.loss: 0.0828, mix.decode.loss_seg: 0.0389, mix.decode.acc_seg: 98.3650, mix.loss: 0.0389, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:10:26,473 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 16:10:26,474 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 6:37:25, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0796, src.decode.acc_seg: 97.0815, src.loss: 0.0956, mix.decode.loss_seg: 0.0537, mix.decode.acc_seg: 97.8335, mix.loss: 0.0537, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:11:28,669 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 6:36:22, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0591, src.decode.acc_seg: 97.9281, src.loss: 0.0751, mix.decode.loss_seg: 0.0518, mix.decode.acc_seg: 97.9895, mix.loss: 0.0518, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:12:31,093 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 6:35:19, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0647, src.decode.acc_seg: 97.6165, src.loss: 0.0808, mix.decode.loss_seg: 0.0500, mix.decode.acc_seg: 98.0606, mix.loss: 0.0500, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:13:33,272 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 6:34:15, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0591, src.decode.acc_seg: 97.8113, src.loss: 0.0752, mix.decode.loss_seg: 0.0455, mix.decode.acc_seg: 98.0544, mix.loss: 0.0455, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:14:35,476 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 6:33:12, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0626, src.decode.acc_seg: 97.6496, src.loss: 0.0786, mix.decode.loss_seg: 0.0474, mix.decode.acc_seg: 98.1424, mix.loss: 0.0474, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:15:37,616 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 6:32:09, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0725, src.decode.acc_seg: 97.3295, src.loss: 0.0885, mix.decode.loss_seg: 0.0440, mix.decode.acc_seg: 98.0708, mix.loss: 0.0440, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:16:40,062 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 6:31:06, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0586, src.decode.acc_seg: 97.7796, src.loss: 0.0746, mix.decode.loss_seg: 0.0401, mix.decode.acc_seg: 98.1738, mix.loss: 0.0401, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:17:42,555 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 6:30:03, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0838, src.decode.acc_seg: 97.0462, src.loss: 0.0998, mix.decode.loss_seg: 0.0427, mix.decode.acc_seg: 98.2386, mix.loss: 0.0427, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:18:44,438 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 6:28:59, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0931, src.decode.acc_seg: 96.5753, src.loss: 0.1091, mix.decode.loss_seg: 0.0563, mix.decode.acc_seg: 97.8542, mix.loss: 0.0563, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:19:47,027 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 6:27:56, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0672, src.decode.acc_seg: 97.5982, src.loss: 0.0832, mix.decode.loss_seg: 0.0484, mix.decode.acc_seg: 97.9052, mix.loss: 0.0484, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:20:49,264 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 6:26:53, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0506, src.decode.acc_seg: 98.0496, src.loss: 0.0666, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.4456, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:21:51,100 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 6:25:50, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0685, src.decode.acc_seg: 97.4849, src.loss: 0.0846, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.1622, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:22:53,332 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 6:24:47, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0593, src.decode.acc_seg: 97.7947, src.loss: 0.0753, mix.decode.loss_seg: 0.0455, mix.decode.acc_seg: 98.0404, mix.loss: 0.0455, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:23:55,735 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 6:23:44, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0674, src.decode.acc_seg: 97.5185, src.loss: 0.0834, mix.decode.loss_seg: 0.0448, mix.decode.acc_seg: 98.1709, mix.loss: 0.0448, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:24:58,546 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 6:22:41, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0567, src.decode.acc_seg: 97.9004, src.loss: 0.0727, mix.decode.loss_seg: 0.0427, mix.decode.acc_seg: 98.1499, mix.loss: 0.0427, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:26:00,639 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 6:21:38, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0683, src.decode.acc_seg: 97.5484, src.loss: 0.0843, mix.decode.loss_seg: 0.0490, mix.decode.acc_seg: 98.1447, mix.loss: 0.0490, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:27:03,098 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 6:20:35, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0709, src.decode.acc_seg: 97.3333, src.loss: 0.0869, mix.decode.loss_seg: 0.0547, mix.decode.acc_seg: 97.8356, mix.loss: 0.0547, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:28:04,993 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 6:19:31, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0620, src.decode.acc_seg: 97.7062, src.loss: 0.0780, mix.decode.loss_seg: 0.0428, mix.decode.acc_seg: 98.3190, mix.loss: 0.0428, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:29:07,218 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 6:18:28, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0614, src.decode.acc_seg: 97.7652, src.loss: 0.0774, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.3429, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:30:09,738 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 6:17:25, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0539, src.decode.acc_seg: 97.9996, src.loss: 0.0699, mix.decode.loss_seg: 0.0442, mix.decode.acc_seg: 98.1213, mix.loss: 0.0442, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:31:12,271 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 16:31:12,271 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 6:16:22, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0633, src.decode.acc_seg: 97.7522, src.loss: 0.0793, mix.decode.loss_seg: 0.0436, mix.decode.acc_seg: 98.2505, mix.loss: 0.0436, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:32:14,828 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 6:15:19, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0588, src.decode.acc_seg: 97.7983, src.loss: 0.0748, mix.decode.loss_seg: 0.0358, mix.decode.acc_seg: 98.6278, mix.loss: 0.0358, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:33:16,590 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 6:14:16, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0556, src.decode.acc_seg: 98.0675, src.loss: 0.0716, mix.decode.loss_seg: 0.0374, mix.decode.acc_seg: 98.5063, mix.loss: 0.0374, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:34:18,860 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 6:13:13, time: 1.245, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0677, src.decode.acc_seg: 97.6519, src.loss: 0.0837, mix.decode.loss_seg: 0.0376, mix.decode.acc_seg: 98.4753, mix.loss: 0.0376, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:35:21,167 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 6:12:10, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0621, src.decode.acc_seg: 97.7227, src.loss: 0.0781, mix.decode.loss_seg: 0.0439, mix.decode.acc_seg: 98.1523, mix.loss: 0.0439, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:36:23,814 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 6:11:07, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0500, src.decode.acc_seg: 98.1678, src.loss: 0.0660, mix.decode.loss_seg: 0.0392, mix.decode.acc_seg: 98.4987, mix.loss: 0.0392, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:37:25,616 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 6:10:04, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0555, src.decode.acc_seg: 98.0467, src.loss: 0.0716, mix.decode.loss_seg: 0.0443, mix.decode.acc_seg: 98.1829, mix.loss: 0.0443, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:38:27,382 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 6:09:00, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0521, src.decode.acc_seg: 98.0499, src.loss: 0.0681, mix.decode.loss_seg: 0.0407, mix.decode.acc_seg: 98.4056, mix.loss: 0.0407, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:39:29,304 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 6:07:57, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0648, src.decode.acc_seg: 97.6755, src.loss: 0.0809, mix.decode.loss_seg: 0.0460, mix.decode.acc_seg: 98.1483, mix.loss: 0.0460, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:40:31,065 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 6:06:53, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0635, src.decode.acc_seg: 97.6160, src.loss: 0.0796, mix.decode.loss_seg: 0.0443, mix.decode.acc_seg: 98.2604, mix.loss: 0.0443, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:41:33,383 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 6:05:50, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0580, src.decode.acc_seg: 98.0258, src.loss: 0.0740, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.3783, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:42:35,204 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 6:04:47, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0573, src.decode.acc_seg: 97.9616, src.loss: 0.0733, mix.decode.loss_seg: 0.0429, mix.decode.acc_seg: 98.3066, mix.loss: 0.0429, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:43:37,513 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 6:03:44, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0489, src.decode.acc_seg: 98.2006, src.loss: 0.0649, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.2976, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:44:39,615 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 6:02:41, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0597, src.decode.acc_seg: 97.9580, src.loss: 0.0757, mix.decode.loss_seg: 0.0328, mix.decode.acc_seg: 98.6502, mix.loss: 0.0328, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:45:41,667 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 6:01:37, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0681, src.decode.acc_seg: 97.5840, src.loss: 0.0841, mix.decode.loss_seg: 0.0466, mix.decode.acc_seg: 98.0942, mix.loss: 0.0466, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:46:43,650 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 6:00:34, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0530, src.decode.acc_seg: 98.0531, src.loss: 0.0690, mix.decode.loss_seg: 0.0415, mix.decode.acc_seg: 98.3152, mix.loss: 0.0415, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:47:46,145 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 5:59:31, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0633, src.decode.acc_seg: 97.7569, src.loss: 0.0793, mix.decode.loss_seg: 0.0425, mix.decode.acc_seg: 98.2996, mix.loss: 0.0425, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:48:48,347 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 5:58:28, time: 1.244, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0598, src.decode.acc_seg: 97.9693, src.loss: 0.0759, mix.decode.loss_seg: 0.0426, mix.decode.acc_seg: 98.3360, mix.loss: 0.0426, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:49:51,073 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 5:57:25, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0568, src.decode.acc_seg: 97.9516, src.loss: 0.0728, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.4505, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:50:53,630 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 5:56:23, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0606, src.decode.acc_seg: 97.7043, src.loss: 0.0766, mix.decode.loss_seg: 0.0415, mix.decode.acc_seg: 98.3850, mix.loss: 0.0415, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:51:56,223 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 16:51:56,224 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 5:55:20, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0611, src.decode.acc_seg: 97.7099, src.loss: 0.0772, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 98.0541, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:52:57,978 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 5:54:16, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0707, src.decode.acc_seg: 97.7038, src.loss: 0.0868, mix.decode.loss_seg: 0.0442, mix.decode.acc_seg: 98.3789, mix.loss: 0.0442, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:53:59,827 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 5:53:13, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0667, src.decode.acc_seg: 97.5043, src.loss: 0.0827, mix.decode.loss_seg: 0.0479, mix.decode.acc_seg: 97.9455, mix.loss: 0.0479, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:55:02,338 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 5:52:10, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0518, src.decode.acc_seg: 98.0899, src.loss: 0.0679, mix.decode.loss_seg: 0.0411, mix.decode.acc_seg: 98.3287, mix.loss: 0.0411, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:56:04,964 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 5:51:07, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0722, src.decode.acc_seg: 97.3632, src.loss: 0.0883, mix.decode.loss_seg: 0.0466, mix.decode.acc_seg: 98.3078, mix.loss: 0.0466, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:57:06,759 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 5:50:04, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0689, src.decode.acc_seg: 97.4716, src.loss: 0.0849, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 98.0469, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:58:09,152 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 5:49:01, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0643, src.decode.acc_seg: 97.6508, src.loss: 0.0804, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.3397, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:59:11,655 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 5:47:58, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0490, src.decode.acc_seg: 98.2331, src.loss: 0.0650, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.4938, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:00:13,978 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 5:46:55, time: 1.246, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0477, src.decode.acc_seg: 98.2720, src.loss: 0.0638, mix.decode.loss_seg: 0.0295, mix.decode.acc_seg: 98.8071, mix.loss: 0.0295, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:01:16,127 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 5:45:52, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0517, src.decode.acc_seg: 98.1482, src.loss: 0.0677, mix.decode.loss_seg: 0.0439, mix.decode.acc_seg: 98.2139, mix.loss: 0.0439, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:02:18,345 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 5:44:49, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0533, src.decode.acc_seg: 98.0646, src.loss: 0.0693, mix.decode.loss_seg: 0.0381, mix.decode.acc_seg: 98.5129, mix.loss: 0.0381, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:03:20,630 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 5:43:46, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0663, src.decode.acc_seg: 97.5420, src.loss: 0.0823, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 98.1397, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:04:23,623 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 5:42:44, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0528, src.decode.acc_seg: 98.0677, src.loss: 0.0689, mix.decode.loss_seg: 0.0457, mix.decode.acc_seg: 98.1011, mix.loss: 0.0457, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:05:25,721 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 5:41:41, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0541, src.decode.acc_seg: 98.0661, src.loss: 0.0701, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.5241, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:06:28,670 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 5:40:38, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0458, src.decode.acc_seg: 98.3002, src.loss: 0.0619, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.3751, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:07:31,239 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 5:39:35, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0474, src.decode.acc_seg: 98.2260, src.loss: 0.0634, mix.decode.loss_seg: 0.0385, mix.decode.acc_seg: 98.2939, mix.loss: 0.0385, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:08:33,464 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 5:38:32, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0497, src.decode.acc_seg: 98.1427, src.loss: 0.0657, mix.decode.loss_seg: 0.0394, mix.decode.acc_seg: 98.3707, mix.loss: 0.0394, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:09:36,282 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 5:37:30, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0581, src.decode.acc_seg: 97.9301, src.loss: 0.0741, mix.decode.loss_seg: 0.0403, mix.decode.acc_seg: 98.3382, mix.loss: 0.0403, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:10:38,957 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 5:36:27, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0549, src.decode.acc_seg: 97.8832, src.loss: 0.0709, mix.decode.loss_seg: 0.0440, mix.decode.acc_seg: 98.3052, mix.loss: 0.0440, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:11:41,926 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 5:35:25, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0582, src.decode.acc_seg: 97.8080, src.loss: 0.0742, mix.decode.loss_seg: 0.0409, mix.decode.acc_seg: 98.1950, mix.loss: 0.0409, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1180s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   639s[                                 ] 3/929, 2.0 task/s, elapsed: 1s, ETA:   460s[                                 ] 4/929, 2.5 task/s, elapsed: 2s, ETA:   368s[                                 ] 5/929, 3.0 task/s, elapsed: 2s, ETA:   313s[                                 ] 6/929, 3.3 task/s, elapsed: 2s, ETA:   277s[                                 ] 7/929, 3.6 task/s, elapsed: 2s, ETA:   255s[                                 ] 8/929, 3.9 task/s, elapsed: 2s, ETA:   235s[                                 ] 9/929, 4.1 task/s, elapsed: 2s, ETA:   225s[                                ] 10/929, 4.3 task/s, elapsed: 2s, ETA:   214s[                                ] 11/929, 4.5 task/s, elapsed: 2s, ETA:   204s[                                ] 12/929, 4.7 task/s, elapsed: 3s, ETA:   196s[                                ] 13/929, 4.9 task/s, elapsed: 3s, ETA:   189s[                                ] 14/929, 5.0 task/s, elapsed: 3s, ETA:   182s[                                ] 15/929, 5.2 task/s, elapsed: 3s, ETA:   177s[                                ] 16/929, 5.3 task/s, elapsed: 3s, ETA:   172s[                                ] 17/929, 5.4 task/s, elapsed: 3s, ETA:   168s[                                ] 18/929, 5.5 task/s, elapsed: 3s, ETA:   164s[                                ] 19/929, 5.7 task/s, elapsed: 3s, ETA:   161s[                                ] 20/929, 5.8 task/s, elapsed: 3s, ETA:   158s[                                ] 21/929, 5.9 task/s, elapsed: 4s, ETA:   155s[                                ] 22/929, 6.0 task/s, elapsed: 4s, ETA:   152s[                                ] 23/929, 6.0 task/s, elapsed: 4s, ETA:   151s[                                ] 24/929, 6.1 task/s, elapsed: 4s, ETA:   149s[                                ] 25/929, 6.2 task/s, elapsed: 4s, ETA:   147s[                                ] 26/929, 6.2 task/s, elapsed: 4s, ETA:   145s[                                ] 27/929, 6.3 task/s, elapsed: 4s, ETA:   143s[                                ] 28/929, 6.4 task/s, elapsed: 4s, ETA:   141s[                                ] 29/929, 6.4 task/s, elapsed: 5s, ETA:   140s[>                               ] 30/929, 6.5 task/s, elapsed: 5s, ETA:   138s[>                               ] 31/929, 6.5 task/s, elapsed: 5s, ETA:   137s[>                               ] 32/929, 6.6 task/s, elapsed: 5s, ETA:   136s[>                               ] 33/929, 6.7 task/s, elapsed: 5s, ETA:   135s[>                               ] 34/929, 6.7 task/s, elapsed: 5s, ETA:   133s[>                               ] 35/929, 6.8 task/s, elapsed: 5s, ETA:   132s[>                               ] 36/929, 6.8 task/s, elapsed: 5s, ETA:   131s[>                               ] 37/929, 6.8 task/s, elapsed: 5s, ETA:   130s[>                               ] 38/929, 6.9 task/s, elapsed: 6s, ETA:   130s[>                               ] 39/929, 6.9 task/s, elapsed: 6s, ETA:   129s[>                               ] 40/929, 7.0 task/s, elapsed: 6s, ETA:   128s[>                               ] 41/929, 7.0 task/s, elapsed: 6s, ETA:   128s[>                               ] 42/929, 7.0 task/s, elapsed: 6s, ETA:   127s[>                               ] 43/929, 7.0 task/s, elapsed: 6s, ETA:   126s[>                               ] 44/929, 7.1 task/s, elapsed: 6s, ETA:   125s[>                               ] 45/929, 7.1 task/s, elapsed: 6s, ETA:   124s[>                               ] 46/929, 7.1 task/s, elapsed: 6s, ETA:   124s[>                               ] 47/929, 7.2 task/s, elapsed: 7s, ETA:   123s[>                               ] 48/929, 7.2 task/s, elapsed: 7s, ETA:   122s[>                               ] 49/929, 7.2 task/s, elapsed: 7s, ETA:   122s[>                               ] 50/929, 7.3 task/s, elapsed: 7s, ETA:   121s[>                               ] 51/929, 7.3 task/s, elapsed: 7s, ETA:   121s[>                               ] 52/929, 7.3 task/s, elapsed: 7s, ETA:   120s[>                               ] 53/929, 7.3 task/s, elapsed: 7s, ETA:   120s[>                               ] 54/929, 7.3 task/s, elapsed: 7s, ETA:   120s[>                               ] 55/929, 7.3 task/s, elapsed: 7s, ETA:   119s[>                               ] 56/929, 7.4 task/s, elapsed: 8s, ETA:   118s[>                               ] 57/929, 7.4 task/s, elapsed: 8s, ETA:   118s[>                               ] 58/929, 7.4 task/s, elapsed: 8s, ETA:   117s[>>                              ] 59/929, 7.5 task/s, elapsed: 8s, ETA:   117s[>>                              ] 60/929, 7.5 task/s, elapsed: 8s, ETA:   116s[>>                              ] 61/929, 7.5 task/s, elapsed: 8s, ETA:   116s[>>                              ] 62/929, 7.5 task/s, elapsed: 8s, ETA:   115s[>>                              ] 63/929, 7.5 task/s, elapsed: 8s, ETA:   115s[>>                              ] 64/929, 7.6 task/s, elapsed: 8s, ETA:   114s[>>                              ] 65/929, 7.6 task/s, elapsed: 9s, ETA:   114s[>>                              ] 66/929, 7.6 task/s, elapsed: 9s, ETA:   114s[>>                              ] 67/929, 7.6 task/s, elapsed: 9s, ETA:   113s[>>                              ] 68/929, 7.6 task/s, elapsed: 9s, ETA:   113s[>>                              ] 69/929, 7.6 task/s, elapsed: 9s, ETA:   113s[>>                              ] 70/929, 7.7 task/s, elapsed: 9s, ETA:   112s[>>                              ] 71/929, 7.7 task/s, elapsed: 9s, ETA:   112s[>>                              ] 72/929, 7.7 task/s, elapsed: 9s, ETA:   112s[>>                              ] 73/929, 7.7 task/s, elapsed: 9s, ETA:   111s[>>                             ] 74/929, 7.7 task/s, elapsed: 10s, ETA:   111s[>>                             ] 75/929, 7.7 task/s, elapsed: 10s, ETA:   111s[>>                             ] 76/929, 7.7 task/s, elapsed: 10s, ETA:   110s[>>                             ] 77/929, 7.7 task/s, elapsed: 10s, ETA:   110s[>>                             ] 78/929, 7.8 task/s, elapsed: 10s, ETA:   110s[>>                             ] 79/929, 7.8 task/s, elapsed: 10s, ETA:   109s[>>                             ] 80/929, 7.8 task/s, elapsed: 10s, ETA:   109s[>>                             ] 81/929, 7.8 task/s, elapsed: 10s, ETA:   109s[>>                             ] 82/929, 7.8 task/s, elapsed: 11s, ETA:   108s[>>                             ] 83/929, 7.8 task/s, elapsed: 11s, ETA:   108s[>>                             ] 84/929, 7.8 task/s, elapsed: 11s, ETA:   108s[>>                             ] 85/929, 7.8 task/s, elapsed: 11s, ETA:   108s[>>                             ] 86/929, 7.9 task/s, elapsed: 11s, ETA:   107s[>>                             ] 87/929, 7.9 task/s, elapsed: 11s, ETA:   107s[>>                             ] 88/929, 7.9 task/s, elapsed: 11s, ETA:   107s[>>                             ] 89/929, 7.9 task/s, elapsed: 11s, ETA:   107s[>>>                            ] 90/929, 7.9 task/s, elapsed: 11s, ETA:   106s[>>>                            ] 91/929, 7.9 task/s, elapsed: 12s, ETA:   106s[>>>                            ] 92/929, 7.9 task/s, elapsed: 12s, ETA:   106s[>>>                            ] 93/929, 7.9 task/s, elapsed: 12s, ETA:   106s[>>>                            ] 94/929, 7.9 task/s, elapsed: 12s, ETA:   105s[>>>                            ] 95/929, 7.9 task/s, elapsed: 12s, ETA:   105s[>>>                            ] 96/929, 7.9 task/s, elapsed: 12s, ETA:   105s[>>>                            ] 97/929, 7.9 task/s, elapsed: 12s, ETA:   105s[>>>                            ] 98/929, 8.0 task/s, elapsed: 12s, ETA:   104s[>>>                            ] 99/929, 8.0 task/s, elapsed: 12s, ETA:   104s[>>>                           ] 100/929, 8.0 task/s, elapsed: 13s, ETA:   104s[>>>                           ] 101/929, 8.0 task/s, elapsed: 13s, ETA:   104s[>>>                           ] 102/929, 8.0 task/s, elapsed: 13s, ETA:   104s[>>>                           ] 103/929, 8.0 task/s, elapsed: 13s, ETA:   103s[>>>                           ] 104/929, 8.0 task/s, elapsed: 13s, ETA:   103s[>>>                           ] 105/929, 8.0 task/s, elapsed: 13s, ETA:   103s[>>>                           ] 106/929, 8.0 task/s, elapsed: 13s, ETA:   103s[>>>                           ] 107/929, 8.0 task/s, elapsed: 13s, ETA:   102s[>>>                           ] 108/929, 8.0 task/s, elapsed: 13s, ETA:   102s[>>>                           ] 109/929, 8.1 task/s, elapsed: 14s, ETA:   102s[>>>                           ] 110/929, 8.1 task/s, elapsed: 14s, ETA:   102s[>>>                           ] 111/929, 8.1 task/s, elapsed: 14s, ETA:   101s[>>>                           ] 112/929, 8.1 task/s, elapsed: 14s, ETA:   101s[>>>                           ] 113/929, 8.1 task/s, elapsed: 14s, ETA:   101s[>>>                           ] 114/929, 8.1 task/s, elapsed: 14s, ETA:   101s[>>>                           ] 115/929, 8.1 task/s, elapsed: 14s, ETA:   100s[>>>                           ] 116/929, 8.1 task/s, elapsed: 14s, ETA:   100s[>>>                           ] 117/929, 8.1 task/s, elapsed: 14s, ETA:   100s[>>>                           ] 118/929, 8.1 task/s, elapsed: 15s, ETA:   100s[>>>                           ] 119/929, 8.1 task/s, elapsed: 15s, ETA:   100s[>>>                           ] 120/929, 8.1 task/s, elapsed: 15s, ETA:    99s[>>>                           ] 121/929, 8.1 task/s, elapsed: 15s, ETA:    99s[>>>                           ] 122/929, 8.2 task/s, elapsed: 15s, ETA:    99s[>>>                           ] 123/929, 8.2 task/s, elapsed: 15s, ETA:    99s[>>>>                          ] 124/929, 8.2 task/s, elapsed: 15s, ETA:    98s[>>>>                          ] 125/929, 8.2 task/s, elapsed: 15s, ETA:    98s[>>>>                          ] 126/929, 8.2 task/s, elapsed: 15s, ETA:    98s[>>>>                          ] 127/929, 8.2 task/s, elapsed: 15s, ETA:    97s[>>>>                          ] 128/929, 8.2 task/s, elapsed: 16s, ETA:    97s[>>>>                          ] 129/929, 8.3 task/s, elapsed: 16s, ETA:    97s[>>>>                          ] 130/929, 8.3 task/s, elapsed: 16s, ETA:    97s[>>>>                          ] 131/929, 8.3 task/s, elapsed: 16s, ETA:    96s[>>>>                          ] 132/929, 8.3 task/s, elapsed: 16s, ETA:    96s[>>>>                          ] 133/929, 8.3 task/s, elapsed: 16s, ETA:    96s[>>>>                          ] 134/929, 8.3 task/s, elapsed: 16s, ETA:    96s[>>>>                          ] 135/929, 8.3 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 136/929, 8.3 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 137/929, 8.3 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 138/929, 8.4 task/s, elapsed: 17s, ETA:    95s[>>>>                          ] 139/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 140/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 141/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 142/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 143/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 144/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 145/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 146/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 147/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 148/929, 8.4 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 149/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 150/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 151/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 152/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 153/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>                          ] 154/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 155/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 156/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 157/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 158/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 159/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 160/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 161/929, 8.6 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 162/929, 8.6 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 163/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 164/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 165/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 166/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 167/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 168/929, 8.6 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 169/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 170/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 171/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 172/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 173/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 174/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 175/929, 8.6 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 176/929, 8.6 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 177/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 178/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 179/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 180/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 181/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 182/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 183/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 184/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 185/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>>                        ] 186/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>>                        ] 187/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 188/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 189/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 190/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 191/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 192/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 193/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 194/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 195/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 196/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 197/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 198/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 199/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 200/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 201/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 202/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 203/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 204/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 205/929, 8.8 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 206/929, 8.8 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 207/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 208/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 209/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 210/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 211/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 212/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 213/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 214/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 215/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 216/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>>                       ] 217/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 218/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 219/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 220/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 221/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 222/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 223/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 224/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 225/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 226/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 227/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 228/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 229/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 230/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 231/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 232/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 233/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 234/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 235/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 236/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 237/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 239/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 240/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 241/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 242/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 243/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 244/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 245/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 246/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>                       ] 247/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 248/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 249/929, 9.0 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 250/929, 9.0 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 251/929, 9.0 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 252/929, 9.0 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 254/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 255/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 256/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 257/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 258/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 259/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 260/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 261/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 262/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 263/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 264/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 265/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 266/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 267/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 268/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 269/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 270/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 271/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 272/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 273/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 274/929, 9.0 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 275/929, 9.0 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 276/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>                      ] 277/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>                      ] 278/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 279/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 280/929, 9.1 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 281/929, 9.1 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 282/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 283/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 284/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 285/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 286/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 287/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 288/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 289/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 290/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 292/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 293/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 294/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 295/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 296/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 297/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 298/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 299/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 300/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 301/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 302/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 303/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 304/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 305/929, 9.1 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 306/929, 9.1 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 307/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>                     ] 308/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>                     ] 309/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 310/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 311/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 312/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 313/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 314/929, 9.1 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 315/929, 9.1 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 316/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 317/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 318/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 319/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 320/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 321/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 322/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 323/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 324/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 325/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 326/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 327/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 328/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 329/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 330/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 331/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 332/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 333/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 336/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 337/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 338/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 339/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 340/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>>                   ] 341/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>>                   ] 342/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 346/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 347/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 348/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 349/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 350/929, 9.1 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.1 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 355/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 356/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 357/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 358/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 359/929, 9.1 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.1 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 366/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 367/929, 9.1 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.1 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 384/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 385/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 394/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 398/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 412/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 430/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 439/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 440/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 448/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 449/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.2 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 456/929, 9.2 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 457/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 458/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 464/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 465/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 466/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 467/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 473/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 474/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 475/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 476/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.3 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.3 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.3 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.3 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 482/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 483/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 484/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 485/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.3 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.3 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.3 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 492/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 493/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 494/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.3 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.3 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.3 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 501/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 502/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 503/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.3 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.3 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 511/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 512/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 513/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.3 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.3 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 520/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 521/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 522/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.3 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.3 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.3 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.3 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.3 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.3 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.3 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.3 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.3 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.3 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.3 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.3 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.3 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.3 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.3 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.3 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.3 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.3 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.3 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.3 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.3 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.3 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.3 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.3 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.3 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.3 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.3 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.3 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.3 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.4 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.4 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.4 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.4 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.4 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.4 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.4 task/s, elapsed: 99s, ETA:     0s2022-10-10 17:15:56,379 - mmseg - INFO - per class results:2022-10-10 17:15:56,380 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.11 |  97.2 || rigid_plastic | 35.73 | 42.52 ||   cardboard   | 55.01 | 64.64 ||     metal     | 34.71 | 41.58 ||  soft_plastic | 63.42 |  72.0 |+---------------+-------+-------+2022-10-10 17:15:56,380 - mmseg - INFO - Summary:2022-10-10 17:15:56,381 - mmseg - INFO - +-------+------+-------+|  aAcc | mIoU |  mAcc |+-------+------+-------+| 91.58 | 56.0 | 63.59 |+-------+------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:15:56,395 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 17:15:56,395 - mmseg - INFO - Iter [929/40000]	lr: 2.400e-05, eta: 5:34:23, time: 1.277, data_time: 0.015, memory: 67493, aAcc: 0.9158, mIoU: 0.5600, mAcc: 0.6359, IoU.background: 0.9111, IoU.rigid_plastic: 0.3573, IoU.cardboard: 0.5501, IoU.metal: 0.3471, IoU.soft_plastic: 0.6342, Acc.background: 0.9720, Acc.rigid_plastic: 0.4252, Acc.cardboard: 0.6464, Acc.metal: 0.4158, Acc.soft_plastic: 0.7200, src.decode.loss_seg: 0.0575, src.decode.acc_seg: 98.0299, src.loss: 0.0735, mix.decode.loss_seg: 0.0477, mix.decode.acc_seg: 98.0647, mix.loss: 0.0477, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:17:04,385 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 5:35:30, time: 5.173, data_time: 3.831, memory: 67493, src.decode.loss_seg: 0.0552, src.decode.acc_seg: 97.8849, src.loss: 0.0712, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.4251, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:18:07,065 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 5:34:26, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0619, src.decode.acc_seg: 97.8401, src.loss: 0.0779, mix.decode.loss_seg: 0.0461, mix.decode.acc_seg: 98.1666, mix.loss: 0.0461, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:19:09,437 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 5:33:23, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0501, src.decode.acc_seg: 98.1974, src.loss: 0.0661, mix.decode.loss_seg: 0.0398, mix.decode.acc_seg: 98.3071, mix.loss: 0.0398, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:20:12,113 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 5:32:20, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0637, src.decode.acc_seg: 97.7011, src.loss: 0.0797, mix.decode.loss_seg: 0.0460, mix.decode.acc_seg: 98.1768, mix.loss: 0.0460, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:21:15,424 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 5:31:17, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0621, src.decode.acc_seg: 97.6557, src.loss: 0.0781, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.3177, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:22:19,283 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 5:30:14, time: 1.277, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0648, src.decode.acc_seg: 97.7020, src.loss: 0.0808, mix.decode.loss_seg: 0.0467, mix.decode.acc_seg: 98.0647, mix.loss: 0.0467, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:23:21,656 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 5:29:10, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0579, src.decode.acc_seg: 97.7710, src.loss: 0.0739, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.3543, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:24:23,825 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 5:28:07, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0583, src.decode.acc_seg: 97.9212, src.loss: 0.0743, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.4524, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:25:25,947 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 5:27:03, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0600, src.decode.acc_seg: 97.7661, src.loss: 0.0760, mix.decode.loss_seg: 0.0409, mix.decode.acc_seg: 98.3421, mix.loss: 0.0409, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:26:28,700 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 5:26:00, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0562, src.decode.acc_seg: 97.9746, src.loss: 0.0722, mix.decode.loss_seg: 0.0454, mix.decode.acc_seg: 98.0859, mix.loss: 0.0454, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:27:31,855 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 5:24:57, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0532, src.decode.acc_seg: 98.0477, src.loss: 0.0693, mix.decode.loss_seg: 0.0388, mix.decode.acc_seg: 98.4658, mix.loss: 0.0388, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:28:34,561 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 5:23:53, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0606, src.decode.acc_seg: 97.7893, src.loss: 0.0767, mix.decode.loss_seg: 0.0487, mix.decode.acc_seg: 97.9960, mix.loss: 0.0487, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:29:37,006 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 5:22:50, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0564, src.decode.acc_seg: 97.9029, src.loss: 0.0724, mix.decode.loss_seg: 0.0380, mix.decode.acc_seg: 98.4798, mix.loss: 0.0380, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:30:39,468 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 5:21:46, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0486, src.decode.acc_seg: 98.2389, src.loss: 0.0647, mix.decode.loss_seg: 0.0337, mix.decode.acc_seg: 98.6240, mix.loss: 0.0337, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:31:42,122 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 5:20:43, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0514, src.decode.acc_seg: 98.1158, src.loss: 0.0674, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.7165, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:32:45,127 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 5:19:40, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0564, src.decode.acc_seg: 97.9591, src.loss: 0.0725, mix.decode.loss_seg: 0.0465, mix.decode.acc_seg: 98.0347, mix.loss: 0.0465, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:33:47,849 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 5:18:36, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0540, src.decode.acc_seg: 98.0015, src.loss: 0.0700, mix.decode.loss_seg: 0.0407, mix.decode.acc_seg: 98.1779, mix.loss: 0.0407, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:34:50,808 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 5:17:33, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0444, src.decode.acc_seg: 98.3820, src.loss: 0.0605, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.5040, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:35:53,466 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 5:16:30, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0496, src.decode.acc_seg: 98.2897, src.loss: 0.0656, mix.decode.loss_seg: 0.0335, mix.decode.acc_seg: 98.5506, mix.loss: 0.0335, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:36:55,941 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 17:36:55,942 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 5:15:26, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 98.0880, src.loss: 0.0684, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.4177, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:37:58,539 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 5:14:23, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0534, src.decode.acc_seg: 97.9756, src.loss: 0.0694, mix.decode.loss_seg: 0.0425, mix.decode.acc_seg: 98.2236, mix.loss: 0.0425, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:39:01,049 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 5:13:20, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 97.9927, src.loss: 0.0684, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.5383, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:40:03,797 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 5:12:16, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0553, src.decode.acc_seg: 97.8461, src.loss: 0.0713, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.2973, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:41:06,306 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 5:11:13, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0542, src.decode.acc_seg: 97.9681, src.loss: 0.0703, mix.decode.loss_seg: 0.0334, mix.decode.acc_seg: 98.5394, mix.loss: 0.0334, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:42:08,822 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 5:10:09, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0527, src.decode.acc_seg: 98.0107, src.loss: 0.0687, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.4944, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:43:11,843 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 5:09:06, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0537, src.decode.acc_seg: 98.0475, src.loss: 0.0697, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.6326, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:44:14,328 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 5:08:03, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0534, src.decode.acc_seg: 98.0235, src.loss: 0.0695, mix.decode.loss_seg: 0.0351, mix.decode.acc_seg: 98.6364, mix.loss: 0.0351, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:45:16,352 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 5:06:59, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0569, src.decode.acc_seg: 97.9346, src.loss: 0.0729, mix.decode.loss_seg: 0.0394, mix.decode.acc_seg: 98.3332, mix.loss: 0.0394, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:46:19,464 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 5:05:56, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0515, src.decode.acc_seg: 98.0784, src.loss: 0.0676, mix.decode.loss_seg: 0.0383, mix.decode.acc_seg: 98.4442, mix.loss: 0.0383, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:47:22,566 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 5:04:53, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0643, src.decode.acc_seg: 97.6681, src.loss: 0.0803, mix.decode.loss_seg: 0.0440, mix.decode.acc_seg: 98.1721, mix.loss: 0.0440, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:48:25,936 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 5:03:50, time: 1.267, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0704, src.decode.acc_seg: 97.3778, src.loss: 0.0864, mix.decode.loss_seg: 0.0455, mix.decode.acc_seg: 98.1943, mix.loss: 0.0455, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:49:28,139 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 5:02:47, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0502, src.decode.acc_seg: 98.2073, src.loss: 0.0663, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.4930, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:50:30,524 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 5:01:43, time: 1.248, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0575, src.decode.acc_seg: 97.8691, src.loss: 0.0735, mix.decode.loss_seg: 0.0392, mix.decode.acc_seg: 98.3163, mix.loss: 0.0392, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:51:32,933 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 5:00:40, time: 1.248, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0500, src.decode.acc_seg: 98.1735, src.loss: 0.0660, mix.decode.loss_seg: 0.0283, mix.decode.acc_seg: 98.7600, mix.loss: 0.0283, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:52:35,210 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 4:59:36, time: 1.246, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0578, src.decode.acc_seg: 97.8878, src.loss: 0.0738, mix.decode.loss_seg: 0.0465, mix.decode.acc_seg: 98.2443, mix.loss: 0.0465, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:53:38,242 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 4:58:33, time: 1.261, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0551, src.decode.acc_seg: 97.9635, src.loss: 0.0711, mix.decode.loss_seg: 0.0358, mix.decode.acc_seg: 98.4065, mix.loss: 0.0358, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:54:40,830 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 4:57:30, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0548, src.decode.acc_seg: 97.9636, src.loss: 0.0708, mix.decode.loss_seg: 0.0474, mix.decode.acc_seg: 98.2475, mix.loss: 0.0474, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:55:44,115 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 4:56:27, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0572, src.decode.acc_seg: 97.9898, src.loss: 0.0732, mix.decode.loss_seg: 0.0334, mix.decode.acc_seg: 98.5464, mix.loss: 0.0334, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:56:46,576 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 4:55:23, time: 1.249, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0497, src.decode.acc_seg: 98.2329, src.loss: 0.0657, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.6157, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:57:49,147 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 17:57:49,147 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 4:54:20, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0559, src.decode.acc_seg: 97.9352, src.loss: 0.0719, mix.decode.loss_seg: 0.0430, mix.decode.acc_seg: 98.2351, mix.loss: 0.0430, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:58:51,951 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 4:53:17, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0613, src.decode.acc_seg: 97.8135, src.loss: 0.0773, mix.decode.loss_seg: 0.0427, mix.decode.acc_seg: 98.1995, mix.loss: 0.0427, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:59:54,591 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 4:52:13, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0549, src.decode.acc_seg: 97.8898, src.loss: 0.0709, mix.decode.loss_seg: 0.0361, mix.decode.acc_seg: 98.5313, mix.loss: 0.0361, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:00:57,342 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 4:51:10, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0523, src.decode.acc_seg: 98.1012, src.loss: 0.0683, mix.decode.loss_seg: 0.0392, mix.decode.acc_seg: 98.4012, mix.loss: 0.0392, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:01:59,980 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 4:50:07, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0590, src.decode.acc_seg: 97.8334, src.loss: 0.0750, mix.decode.loss_seg: 0.0443, mix.decode.acc_seg: 98.1705, mix.loss: 0.0443, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:03:02,866 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 4:49:04, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 98.0817, src.loss: 0.0684, mix.decode.loss_seg: 0.0372, mix.decode.acc_seg: 98.3598, mix.loss: 0.0372, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:04:05,118 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 4:48:00, time: 1.245, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0490, src.decode.acc_seg: 98.1408, src.loss: 0.0650, mix.decode.loss_seg: 0.0382, mix.decode.acc_seg: 98.3656, mix.loss: 0.0382, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:05:07,861 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 4:46:57, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0568, src.decode.acc_seg: 97.9182, src.loss: 0.0728, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.2588, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:06:10,569 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 4:45:54, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0461, src.decode.acc_seg: 98.2783, src.loss: 0.0621, mix.decode.loss_seg: 0.0345, mix.decode.acc_seg: 98.5997, mix.loss: 0.0345, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:07:13,038 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 4:44:50, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0589, src.decode.acc_seg: 97.9206, src.loss: 0.0749, mix.decode.loss_seg: 0.0489, mix.decode.acc_seg: 98.1621, mix.loss: 0.0489, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:08:15,622 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 4:43:47, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0519, src.decode.acc_seg: 98.1003, src.loss: 0.0680, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.4480, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:09:18,117 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 4:42:44, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0537, src.decode.acc_seg: 98.0541, src.loss: 0.0697, mix.decode.loss_seg: 0.0393, mix.decode.acc_seg: 98.3175, mix.loss: 0.0393, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:10:20,512 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 4:41:40, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0534, src.decode.acc_seg: 97.8750, src.loss: 0.0694, mix.decode.loss_seg: 0.0417, mix.decode.acc_seg: 98.3258, mix.loss: 0.0417, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:11:23,101 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 4:40:37, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0451, src.decode.acc_seg: 98.2714, src.loss: 0.0611, mix.decode.loss_seg: 0.0375, mix.decode.acc_seg: 98.4162, mix.loss: 0.0375, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:12:25,285 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 4:39:34, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0507, src.decode.acc_seg: 98.2441, src.loss: 0.0667, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.7659, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:13:28,224 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 4:38:30, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0472, src.decode.acc_seg: 98.2620, src.loss: 0.0632, mix.decode.loss_seg: 0.0367, mix.decode.acc_seg: 98.4186, mix.loss: 0.0367, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:14:30,816 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 4:37:27, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0510, src.decode.acc_seg: 98.1239, src.loss: 0.0670, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.3870, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:15:33,987 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 4:36:24, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0445, src.decode.acc_seg: 98.3174, src.loss: 0.0605, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.4741, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:16:35,977 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 4:35:21, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0587, src.decode.acc_seg: 97.8679, src.loss: 0.0748, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.3232, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:17:38,418 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 4:34:17, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0478, src.decode.acc_seg: 98.2546, src.loss: 0.0638, mix.decode.loss_seg: 0.0393, mix.decode.acc_seg: 98.4156, mix.loss: 0.0393, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:18:41,272 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 18:18:41,272 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 4:33:14, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0438, src.decode.acc_seg: 98.3722, src.loss: 0.0598, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.5490, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:19:43,493 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 4:32:11, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0467, src.decode.acc_seg: 98.1811, src.loss: 0.0627, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.4668, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:20:46,001 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 4:31:07, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0469, src.decode.acc_seg: 98.2050, src.loss: 0.0629, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.2625, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:21:48,920 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 4:30:04, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0566, src.decode.acc_seg: 97.9390, src.loss: 0.0726, mix.decode.loss_seg: 0.0416, mix.decode.acc_seg: 98.1935, mix.loss: 0.0416, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:22:51,042 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 4:29:01, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0520, src.decode.acc_seg: 98.1413, src.loss: 0.0680, mix.decode.loss_seg: 0.0383, mix.decode.acc_seg: 98.4171, mix.loss: 0.0383, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:23:53,615 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 4:27:57, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0527, src.decode.acc_seg: 98.0214, src.loss: 0.0687, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.6526, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:24:56,098 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 4:26:54, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 98.0117, src.loss: 0.0684, mix.decode.loss_seg: 0.0388, mix.decode.acc_seg: 98.2771, mix.loss: 0.0388, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:25:58,192 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 4:25:51, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0471, src.decode.acc_seg: 98.2851, src.loss: 0.0631, mix.decode.loss_seg: 0.0421, mix.decode.acc_seg: 98.3033, mix.loss: 0.0421, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:27:00,392 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 4:24:47, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0465, src.decode.acc_seg: 98.3350, src.loss: 0.0625, mix.decode.loss_seg: 0.0349, mix.decode.acc_seg: 98.5730, mix.loss: 0.0349, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:28:03,316 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 4:23:44, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 98.1055, src.loss: 0.0685, mix.decode.loss_seg: 0.0407, mix.decode.acc_seg: 98.3311, mix.loss: 0.0407, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:29:05,888 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 4:22:41, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0513, src.decode.acc_seg: 98.0439, src.loss: 0.0673, mix.decode.loss_seg: 0.0390, mix.decode.acc_seg: 98.4215, mix.loss: 0.0390, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:30:08,221 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 4:21:37, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0530, src.decode.acc_seg: 97.9821, src.loss: 0.0691, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.5971, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:31:10,651 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 4:20:34, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0584, src.decode.acc_seg: 97.8078, src.loss: 0.0744, mix.decode.loss_seg: 0.0387, mix.decode.acc_seg: 98.5051, mix.loss: 0.0387, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:32:13,593 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 4:19:31, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0469, src.decode.acc_seg: 98.2796, src.loss: 0.0629, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.6106, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:33:16,416 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 4:18:28, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0511, src.decode.acc_seg: 98.1870, src.loss: 0.0672, mix.decode.loss_seg: 0.0392, mix.decode.acc_seg: 98.3784, mix.loss: 0.0392, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:34:19,024 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 4:17:25, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0475, src.decode.acc_seg: 98.2255, src.loss: 0.0635, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.5403, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:35:21,957 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 4:16:22, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0596, src.decode.acc_seg: 97.8836, src.loss: 0.0756, mix.decode.loss_seg: 0.0420, mix.decode.acc_seg: 98.3294, mix.loss: 0.0420, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:36:24,328 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 4:15:18, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0499, src.decode.acc_seg: 98.1541, src.loss: 0.0659, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.6005, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:37:27,094 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 4:14:15, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0493, src.decode.acc_seg: 98.1830, src.loss: 0.0653, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.5345, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:38:30,761 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 4:13:12, time: 1.273, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0446, src.decode.acc_seg: 98.3083, src.loss: 0.0606, mix.decode.loss_seg: 0.0324, mix.decode.acc_seg: 98.5813, mix.loss: 0.0324, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1018s[                                 ] 2/929, 1.7 task/s, elapsed: 1s, ETA:   559s[                                 ] 3/929, 2.3 task/s, elapsed: 1s, ETA:   406s[                                 ] 4/929, 2.8 task/s, elapsed: 1s, ETA:   329s[                                 ] 5/929, 3.3 task/s, elapsed: 2s, ETA:   283s[                                 ] 6/929, 3.7 task/s, elapsed: 2s, ETA:   252s[                                 ] 7/929, 4.0 task/s, elapsed: 2s, ETA:   229s[                                 ] 8/929, 4.3 task/s, elapsed: 2s, ETA:   213s[                                 ] 9/929, 4.6 task/s, elapsed: 2s, ETA:   200s[                                ] 10/929, 4.8 task/s, elapsed: 2s, ETA:   190s[                                ] 11/929, 5.1 task/s, elapsed: 2s, ETA:   181s[                                ] 12/929, 5.2 task/s, elapsed: 2s, ETA:   177s[                                ] 13/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 14/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 15/929, 5.7 task/s, elapsed: 3s, ETA:   159s[                                ] 16/929, 5.9 task/s, elapsed: 3s, ETA:   155s[                                ] 17/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 18/929, 6.2 task/s, elapsed: 3s, ETA:   148s[                                ] 19/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 20/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 21/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 22/929, 6.6 task/s, elapsed: 3s, ETA:   137s[                                ] 23/929, 6.7 task/s, elapsed: 3s, ETA:   134s[                                ] 24/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 25/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 26/929, 7.0 task/s, elapsed: 4s, ETA:   129s[                                ] 27/929, 7.1 task/s, elapsed: 4s, ETA:   128s[                                ] 28/929, 7.1 task/s, elapsed: 4s, ETA:   126s[                                ] 29/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 30/929, 7.3 task/s, elapsed: 4s, ETA:   124s[>                               ] 31/929, 7.3 task/s, elapsed: 4s, ETA:   123s[>                               ] 32/929, 7.4 task/s, elapsed: 4s, ETA:   121s[>                               ] 33/929, 7.4 task/s, elapsed: 4s, ETA:   120s[>                               ] 34/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 35/929, 7.6 task/s, elapsed: 5s, ETA:   118s[>                               ] 36/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 37/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 38/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 39/929, 7.7 task/s, elapsed: 5s, ETA:   115s[>                               ] 40/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 41/929, 7.8 task/s, elapsed: 5s, ETA:   113s[>                               ] 42/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 43/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 44/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 45/929, 8.0 task/s, elapsed: 6s, ETA:   111s[>                               ] 46/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 47/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 48/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 49/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 50/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 51/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 52/929, 8.1 task/s, elapsed: 6s, ETA:   108s[>                               ] 53/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 54/929, 8.2 task/s, elapsed: 7s, ETA:   107s[>                               ] 55/929, 8.2 task/s, elapsed: 7s, ETA:   107s[>                               ] 56/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>                               ] 57/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>                               ] 58/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>>                              ] 59/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>>                              ] 60/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>>                              ] 61/929, 8.3 task/s, elapsed: 7s, ETA:   104s[>>                              ] 62/929, 8.3 task/s, elapsed: 7s, ETA:   104s[>>                              ] 63/929, 8.4 task/s, elapsed: 8s, ETA:   104s[>>                              ] 64/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 65/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 66/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 67/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 68/929, 8.4 task/s, elapsed: 8s, ETA:   102s[>>                              ] 69/929, 8.4 task/s, elapsed: 8s, ETA:   102s[>>                              ] 70/929, 8.4 task/s, elapsed: 8s, ETA:   102s[>>                              ] 71/929, 8.4 task/s, elapsed: 8s, ETA:   102s[>>                              ] 72/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 73/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 74/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 75/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 76/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 77/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 78/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 79/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 80/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                             ] 81/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 82/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 83/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 85/929, 8.6 task/s, elapsed: 10s, ETA:    99s[>>                             ] 86/929, 8.6 task/s, elapsed: 10s, ETA:    99s[>>                             ] 87/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 88/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 89/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 90/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 91/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 92/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 93/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 94/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 95/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 96/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 97/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 98/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 99/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                           ] 100/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 101/929, 8.7 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 102/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 103/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 106/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 107/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 108/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 109/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 110/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 111/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 112/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 113/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 114/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 115/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 116/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 117/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 118/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 119/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 120/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 121/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 122/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 123/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>>                          ] 124/929, 8.7 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 125/929, 8.7 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 126/929, 8.7 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 127/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 128/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 129/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 130/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 131/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 132/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 133/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 134/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 135/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 136/929, 8.8 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 137/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 138/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 139/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 140/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 141/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 142/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 143/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 144/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 145/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 146/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 147/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 148/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 149/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 150/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 151/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 152/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 153/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 154/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>>                         ] 155/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 156/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 157/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 158/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 159/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 160/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 161/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 162/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 163/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 164/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 165/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 166/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 167/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 168/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 169/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 170/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 171/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 172/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 173/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 174/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 175/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 176/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 177/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 178/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 179/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 180/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 181/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 183/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 184/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 185/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 186/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 187/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 188/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 191/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 192/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 193/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 194/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 195/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 196/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 198/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 199/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 200/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 222/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 223/929, 9.1 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 224/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 225/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 230/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 231/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 232/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.1 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 234/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 239/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 240/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 241/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 242/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 243/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 247/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 248/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 249/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 250/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 251/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 255/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 256/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 257/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 258/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 259/929, 9.1 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.1 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 264/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 265/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 266/929, 9.1 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.1 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.1 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.1 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.1 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.1 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 272/929, 9.1 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 273/929, 9.1 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 274/929, 9.1 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 275/929, 9.1 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.1 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.1 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 280/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 281/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 282/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 283/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 284/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 285/929, 9.1 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.1 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.1 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 289/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 290/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 291/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 292/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 293/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 294/929, 9.1 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.1 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.1 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 297/929, 9.1 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 298/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 299/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 300/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 301/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 302/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 303/929, 9.1 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.1 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.1 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 306/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 307/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>                     ] 308/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>                     ] 309/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 310/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 311/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 315/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 316/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 317/929, 9.2 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 318/929, 9.2 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 319/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 323/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 324/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 325/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 326/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 327/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 332/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 333/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 336/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 337/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 340/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 341/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 342/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.2 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 346/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 348/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 349/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 350/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 355/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 356/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 357/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 358/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 359/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 364/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 365/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 366/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 367/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 375/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.2 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 382/929, 9.2 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 383/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 384/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 385/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.2 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 390/929, 9.2 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 391/929, 9.2 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 392/929, 9.2 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 393/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 394/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 399/929, 9.2 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 400/929, 9.2 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 401/929, 9.2 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 402/929, 9.2 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.3 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.3 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 408/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 409/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 410/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 411/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 412/929, 9.3 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.3 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.3 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.3 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 417/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 418/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 419/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 420/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 421/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.3 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.3 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.3 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 426/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 427/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 428/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 429/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 430/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.3 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.3 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.3 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 435/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 436/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 437/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 438/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 439/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 440/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.3 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 443/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 444/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 445/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 446/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 447/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 448/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 449/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 452/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 453/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 454/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 455/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 456/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 457/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 458/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.3 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 462/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 463/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 464/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 465/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 466/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 467/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.3 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 470/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 471/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 472/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 473/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 474/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 475/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 476/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.3 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 479/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 480/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 481/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 482/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 483/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 484/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 485/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.3 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 489/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 490/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 492/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 493/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 494/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 498/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 499/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 501/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 502/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 503/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 508/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 511/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 512/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 513/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 520/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 521/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 522/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.4 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.4 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.4 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.4 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.4 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.4 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.3 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.3 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.3 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.3 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.3 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.3 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.3 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.3 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.3 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.3 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.3 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.3 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.3 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.3 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.3 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.3 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.3 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.3 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.3 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.3 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.3 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.3 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.3 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.3 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.3 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.3 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.3 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.3 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.3 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.3 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.4 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.4 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.4 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.4 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.4 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.4 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.4 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.4 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.4 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.4 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.4 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.4 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.4 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.4 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.4 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.4 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.4 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.4 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.4 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.4 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.4 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.4 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.4 task/s, elapsed: 99s, ETA:     0s2022-10-10 18:42:18,663 - mmseg - INFO - per class results:2022-10-10 18:42:18,663 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.35 | 96.39 || rigid_plastic |  39.7 |  49.7 ||   cardboard   | 58.97 | 73.11 ||     metal     | 32.36 | 42.13 ||  soft_plastic | 62.68 | 70.23 |+---------------+-------+-------+2022-10-10 18:42:18,663 - mmseg - INFO - Summary:2022-10-10 18:42:18,663 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.84 | 57.01 | 66.31 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:42:18,668 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 18:42:18,668 - mmseg - INFO - Iter [929/40000]	lr: 1.800e-05, eta: 4:12:10, time: 1.274, data_time: 0.014, memory: 67493, aAcc: 0.9184, mIoU: 0.5701, mAcc: 0.6631, IoU.background: 0.9135, IoU.rigid_plastic: 0.3970, IoU.cardboard: 0.5897, IoU.metal: 0.3236, IoU.soft_plastic: 0.6268, Acc.background: 0.9639, Acc.rigid_plastic: 0.4970, Acc.cardboard: 0.7311, Acc.metal: 0.4213, Acc.soft_plastic: 0.7023, src.decode.loss_seg: 0.0477, src.decode.acc_seg: 98.2403, src.loss: 0.0637, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.6403, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:43:26,892 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 4:12:19, time: 4.648, data_time: 3.301, memory: 67493, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.3873, src.loss: 0.0594, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.7925, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:44:29,614 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 4:11:15, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0436, src.decode.acc_seg: 98.3665, src.loss: 0.0596, mix.decode.loss_seg: 0.0507, mix.decode.acc_seg: 98.1542, mix.loss: 0.0507, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:45:32,356 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 4:10:11, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0517, src.decode.acc_seg: 98.0460, src.loss: 0.0677, mix.decode.loss_seg: 0.0383, mix.decode.acc_seg: 98.3931, mix.loss: 0.0383, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:46:34,686 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 4:09:08, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0539, src.decode.acc_seg: 98.1329, src.loss: 0.0699, mix.decode.loss_seg: 0.0387, mix.decode.acc_seg: 98.4344, mix.loss: 0.0387, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:47:37,645 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 4:08:04, time: 1.259, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0456, src.decode.acc_seg: 98.2931, src.loss: 0.0617, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.5969, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:48:40,533 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 4:07:01, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0504, src.decode.acc_seg: 98.1843, src.loss: 0.0664, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.5185, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:49:44,687 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 4:05:58, time: 1.283, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.4068, src.loss: 0.0577, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6031, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:50:47,780 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 4:04:54, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0606, src.decode.acc_seg: 97.8845, src.loss: 0.0767, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.5541, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:51:50,305 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 4:03:51, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0558, src.decode.acc_seg: 97.9214, src.loss: 0.0718, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.3490, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:52:52,180 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 4:02:47, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0568, src.decode.acc_seg: 97.9004, src.loss: 0.0728, mix.decode.loss_seg: 0.0386, mix.decode.acc_seg: 98.4258, mix.loss: 0.0386, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:53:54,344 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 4:01:43, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0571, src.decode.acc_seg: 97.8144, src.loss: 0.0731, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.3379, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:54:57,620 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 4:00:39, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0523, src.decode.acc_seg: 98.1548, src.loss: 0.0684, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.4534, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:56:00,104 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 3:59:36, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0483, src.decode.acc_seg: 98.2237, src.loss: 0.0644, mix.decode.loss_seg: 0.0369, mix.decode.acc_seg: 98.2824, mix.loss: 0.0369, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:57:02,693 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 3:58:32, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0549, src.decode.acc_seg: 98.0162, src.loss: 0.0709, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.5141, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:58:05,701 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 3:57:29, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0458, src.decode.acc_seg: 98.2554, src.loss: 0.0618, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4525, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:59:08,510 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 3:56:25, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0451, src.decode.acc_seg: 98.3356, src.loss: 0.0611, mix.decode.loss_seg: 0.0306, mix.decode.acc_seg: 98.6934, mix.loss: 0.0306, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:00:10,923 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 3:55:21, time: 1.248, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0504, src.decode.acc_seg: 98.1949, src.loss: 0.0664, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.6290, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:01:13,446 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 3:54:18, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0518, src.decode.acc_seg: 98.1207, src.loss: 0.0678, mix.decode.loss_seg: 0.0366, mix.decode.acc_seg: 98.4632, mix.loss: 0.0366, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:02:15,520 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 3:53:14, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0486, src.decode.acc_seg: 98.2308, src.loss: 0.0646, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.5750, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:03:18,232 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 19:03:18,232 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 3:52:10, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0439, src.decode.acc_seg: 98.3765, src.loss: 0.0599, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.6625, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:04:20,860 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 3:51:07, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0505, src.decode.acc_seg: 98.0642, src.loss: 0.0665, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.4933, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:05:24,236 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 3:50:04, time: 1.267, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0462, src.decode.acc_seg: 98.2893, src.loss: 0.0622, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.8299, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:06:26,887 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 3:49:00, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0505, src.decode.acc_seg: 98.1132, src.loss: 0.0665, mix.decode.loss_seg: 0.0390, mix.decode.acc_seg: 98.2038, mix.loss: 0.0390, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:07:29,230 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 3:47:56, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0497, src.decode.acc_seg: 98.2007, src.loss: 0.0657, mix.decode.loss_seg: 0.0387, mix.decode.acc_seg: 98.4547, mix.loss: 0.0387, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:08:31,939 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 3:46:53, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0469, src.decode.acc_seg: 98.2894, src.loss: 0.0630, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5630, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:09:34,178 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 3:45:49, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0494, src.decode.acc_seg: 98.2455, src.loss: 0.0654, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.4666, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:10:37,105 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 3:44:46, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0457, src.decode.acc_seg: 98.3184, src.loss: 0.0618, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.6069, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:11:39,454 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 3:43:42, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0419, src.decode.acc_seg: 98.3284, src.loss: 0.0579, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.5708, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:12:42,053 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 3:42:38, time: 1.252, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0480, src.decode.acc_seg: 98.2284, src.loss: 0.0641, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.5759, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:13:44,581 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 3:41:35, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0457, src.decode.acc_seg: 98.3515, src.loss: 0.0617, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.6812, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:14:47,474 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 3:40:31, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0500, src.decode.acc_seg: 98.1683, src.loss: 0.0660, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.7436, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:15:50,321 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 3:39:28, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.3696, src.loss: 0.0593, mix.decode.loss_seg: 0.0366, mix.decode.acc_seg: 98.5012, mix.loss: 0.0366, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:16:53,082 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 3:38:24, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.3287, src.loss: 0.0601, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.6107, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:17:55,955 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 3:37:21, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0439, src.decode.acc_seg: 98.2927, src.loss: 0.0600, mix.decode.loss_seg: 0.0331, mix.decode.acc_seg: 98.5942, mix.loss: 0.0331, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:18:58,829 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 3:36:17, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0456, src.decode.acc_seg: 98.3518, src.loss: 0.0617, mix.decode.loss_seg: 0.0406, mix.decode.acc_seg: 98.3782, mix.loss: 0.0406, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:20:02,141 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 3:35:14, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0450, src.decode.acc_seg: 98.3232, src.loss: 0.0611, mix.decode.loss_seg: 0.0326, mix.decode.acc_seg: 98.7058, mix.loss: 0.0326, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:21:05,252 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 3:34:11, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0448, src.decode.acc_seg: 98.3547, src.loss: 0.0609, mix.decode.loss_seg: 0.0337, mix.decode.acc_seg: 98.5393, mix.loss: 0.0337, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:22:08,984 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 3:33:08, time: 1.275, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0445, src.decode.acc_seg: 98.4114, src.loss: 0.0605, mix.decode.loss_seg: 0.0356, mix.decode.acc_seg: 98.5939, mix.loss: 0.0356, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:23:11,180 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 3:32:04, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0472, src.decode.acc_seg: 98.2732, src.loss: 0.0632, mix.decode.loss_seg: 0.0359, mix.decode.acc_seg: 98.5258, mix.loss: 0.0359, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:24:13,517 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 19:24:13,517 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 3:31:00, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0432, src.decode.acc_seg: 98.3824, src.loss: 0.0592, mix.decode.loss_seg: 0.0326, mix.decode.acc_seg: 98.6807, mix.loss: 0.0326, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:25:16,070 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 3:29:57, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0532, src.decode.acc_seg: 98.0592, src.loss: 0.0692, mix.decode.loss_seg: 0.0354, mix.decode.acc_seg: 98.5843, mix.loss: 0.0354, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:26:18,919 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 3:28:53, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0537, src.decode.acc_seg: 98.0269, src.loss: 0.0697, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.5475, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:27:22,365 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 3:27:50, time: 1.269, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0496, src.decode.acc_seg: 98.1324, src.loss: 0.0656, mix.decode.loss_seg: 0.0401, mix.decode.acc_seg: 98.2995, mix.loss: 0.0401, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:28:24,202 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 3:26:46, time: 1.237, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0425, src.decode.acc_seg: 98.3973, src.loss: 0.0586, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.5356, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:29:27,713 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 3:25:43, time: 1.270, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0465, src.decode.acc_seg: 98.2339, src.loss: 0.0625, mix.decode.loss_seg: 0.0355, mix.decode.acc_seg: 98.5487, mix.loss: 0.0355, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:30:30,852 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 3:24:40, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0481, src.decode.acc_seg: 98.1901, src.loss: 0.0641, mix.decode.loss_seg: 0.0310, mix.decode.acc_seg: 98.6988, mix.loss: 0.0310, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:31:32,859 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 3:23:36, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0459, src.decode.acc_seg: 98.2637, src.loss: 0.0619, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.6757, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:32:35,102 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 3:22:32, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0483, src.decode.acc_seg: 98.1822, src.loss: 0.0643, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.4563, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:33:38,242 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 3:21:29, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0481, src.decode.acc_seg: 98.1947, src.loss: 0.0641, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.4990, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:34:40,477 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 3:20:25, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0519, src.decode.acc_seg: 98.1652, src.loss: 0.0679, mix.decode.loss_seg: 0.0331, mix.decode.acc_seg: 98.5050, mix.loss: 0.0331, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:35:43,380 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 3:19:22, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0424, src.decode.acc_seg: 98.4119, src.loss: 0.0585, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.7064, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:36:45,780 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 3:18:18, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0513, src.decode.acc_seg: 98.1207, src.loss: 0.0674, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.6101, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:37:47,896 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 3:17:15, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0402, src.decode.acc_seg: 98.4876, src.loss: 0.0562, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.5714, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:38:50,547 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 3:16:11, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0473, src.decode.acc_seg: 98.2208, src.loss: 0.0633, mix.decode.loss_seg: 0.0288, mix.decode.acc_seg: 98.7860, mix.loss: 0.0288, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:39:53,000 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 3:15:08, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0425, src.decode.acc_seg: 98.3914, src.loss: 0.0585, mix.decode.loss_seg: 0.0356, mix.decode.acc_seg: 98.4871, mix.loss: 0.0356, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:40:56,034 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 3:14:04, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0451, src.decode.acc_seg: 98.3199, src.loss: 0.0611, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.4181, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:41:58,842 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 3:13:01, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0423, src.decode.acc_seg: 98.3581, src.loss: 0.0583, mix.decode.loss_seg: 0.0268, mix.decode.acc_seg: 98.8592, mix.loss: 0.0268, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:43:01,604 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 3:11:57, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 98.0825, src.loss: 0.0685, mix.decode.loss_seg: 0.0313, mix.decode.acc_seg: 98.7041, mix.loss: 0.0313, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:44:03,770 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 3:10:54, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.3916, src.loss: 0.0602, mix.decode.loss_seg: 0.0321, mix.decode.acc_seg: 98.5416, mix.loss: 0.0321, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:45:05,731 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 19:45:05,731 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 3:09:50, time: 1.239, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.5005, src.loss: 0.0568, mix.decode.loss_seg: 0.0288, mix.decode.acc_seg: 98.8175, mix.loss: 0.0288, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:46:08,236 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 3:08:47, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0521, src.decode.acc_seg: 98.1315, src.loss: 0.0681, mix.decode.loss_seg: 0.0369, mix.decode.acc_seg: 98.4487, mix.loss: 0.0369, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:47:10,933 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 3:07:43, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0460, src.decode.acc_seg: 98.2859, src.loss: 0.0620, mix.decode.loss_seg: 0.0406, mix.decode.acc_seg: 98.4150, mix.loss: 0.0406, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:48:13,599 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 3:06:40, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0626, src.decode.acc_seg: 97.7358, src.loss: 0.0786, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.6315, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:49:16,453 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 3:05:36, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0452, src.decode.acc_seg: 98.2627, src.loss: 0.0612, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.5725, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:50:19,174 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 3:04:33, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.1614, src.loss: 0.0648, mix.decode.loss_seg: 0.0317, mix.decode.acc_seg: 98.6759, mix.loss: 0.0317, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:51:21,660 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 3:03:29, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0475, src.decode.acc_seg: 98.2749, src.loss: 0.0635, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.5147, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:52:24,464 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 3:02:26, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0497, src.decode.acc_seg: 98.1140, src.loss: 0.0657, mix.decode.loss_seg: 0.0296, mix.decode.acc_seg: 98.6600, mix.loss: 0.0296, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:53:27,091 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 3:01:23, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0455, src.decode.acc_seg: 98.3269, src.loss: 0.0615, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.4958, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:54:30,138 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 3:00:19, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0458, src.decode.acc_seg: 98.2366, src.loss: 0.0618, mix.decode.loss_seg: 0.0364, mix.decode.acc_seg: 98.4364, mix.loss: 0.0364, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:55:33,298 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 2:59:16, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.4007, src.loss: 0.0608, mix.decode.loss_seg: 0.0289, mix.decode.acc_seg: 98.7907, mix.loss: 0.0289, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:56:35,892 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 2:58:13, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0450, src.decode.acc_seg: 98.3470, src.loss: 0.0611, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.6195, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:57:38,697 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 2:57:09, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0457, src.decode.acc_seg: 98.3138, src.loss: 0.0617, mix.decode.loss_seg: 0.0451, mix.decode.acc_seg: 98.4711, mix.loss: 0.0451, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:58:41,481 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 2:56:06, time: 1.256, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0461, src.decode.acc_seg: 98.3106, src.loss: 0.0621, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.5946, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:59:43,966 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 2:55:02, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0448, src.decode.acc_seg: 98.3095, src.loss: 0.0608, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.6854, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:00:47,193 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 2:53:59, time: 1.265, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0539, src.decode.acc_seg: 97.9975, src.loss: 0.0699, mix.decode.loss_seg: 0.0410, mix.decode.acc_seg: 98.3862, mix.loss: 0.0410, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:01:50,244 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 2:52:56, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0421, src.decode.acc_seg: 98.4199, src.loss: 0.0582, mix.decode.loss_seg: 0.0328, mix.decode.acc_seg: 98.6482, mix.loss: 0.0328, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:02:53,033 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 2:51:52, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0396, src.decode.acc_seg: 98.5347, src.loss: 0.0556, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.5496, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:03:55,848 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 2:50:49, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0512, src.decode.acc_seg: 98.1594, src.loss: 0.0672, mix.decode.loss_seg: 0.0340, mix.decode.acc_seg: 98.6136, mix.loss: 0.0340, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:05:00,022 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 2:49:46, time: 1.283, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0503, src.decode.acc_seg: 98.1369, src.loss: 0.0663, mix.decode.loss_seg: 0.0356, mix.decode.acc_seg: 98.5365, mix.loss: 0.0356, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1058s[                                 ] 2/929, 1.6 task/s, elapsed: 1s, ETA:   575s[                                 ] 3/929, 2.2 task/s, elapsed: 1s, ETA:   413s[                                 ] 4/929, 2.8 task/s, elapsed: 1s, ETA:   333s[                                 ] 5/929, 3.2 task/s, elapsed: 2s, ETA:   285s[                                 ] 6/929, 3.7 task/s, elapsed: 2s, ETA:   252s[                                 ] 7/929, 4.0 task/s, elapsed: 2s, ETA:   230s[                                 ] 8/929, 4.3 task/s, elapsed: 2s, ETA:   213s[                                 ] 9/929, 4.6 task/s, elapsed: 2s, ETA:   199s[                                ] 10/929, 4.9 task/s, elapsed: 2s, ETA:   189s[                                ] 11/929, 5.1 task/s, elapsed: 2s, ETA:   180s[                                ] 12/929, 5.3 task/s, elapsed: 2s, ETA:   173s[                                ] 13/929, 5.5 task/s, elapsed: 2s, ETA:   166s[                                ] 14/929, 5.7 task/s, elapsed: 2s, ETA:   161s[                                ] 15/929, 5.9 task/s, elapsed: 3s, ETA:   156s[                                ] 16/929, 5.9 task/s, elapsed: 3s, ETA:   155s[                                ] 17/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 18/929, 6.2 task/s, elapsed: 3s, ETA:   147s[                                ] 19/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 20/929, 6.4 task/s, elapsed: 3s, ETA:   141s[                                ] 21/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 22/929, 6.6 task/s, elapsed: 3s, ETA:   136s[                                ] 23/929, 6.7 task/s, elapsed: 3s, ETA:   134s[                                ] 24/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 25/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 26/929, 6.9 task/s, elapsed: 4s, ETA:   132s[                                ] 27/929, 6.9 task/s, elapsed: 4s, ETA:   130s[                                ] 28/929, 7.0 task/s, elapsed: 4s, ETA:   128s[                                ] 29/929, 7.1 task/s, elapsed: 4s, ETA:   127s[>                               ] 30/929, 7.2 task/s, elapsed: 4s, ETA:   126s[>                               ] 31/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 32/929, 7.3 task/s, elapsed: 4s, ETA:   123s[>                               ] 33/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 34/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 35/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 36/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 37/929, 7.5 task/s, elapsed: 5s, ETA:   120s[>                               ] 38/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 39/929, 7.6 task/s, elapsed: 5s, ETA:   118s[>                               ] 40/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 41/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 42/929, 7.7 task/s, elapsed: 5s, ETA:   115s[>                               ] 43/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 44/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 45/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 46/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 47/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 48/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 49/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 50/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 51/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 52/929, 8.0 task/s, elapsed: 6s, ETA:   109s[>                               ] 53/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 54/929, 8.1 task/s, elapsed: 7s, ETA:   109s[>                               ] 55/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 56/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 57/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 61/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>>                              ] 62/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 63/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 64/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 65/929, 8.3 task/s, elapsed: 8s, ETA:   105s[>>                              ] 66/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 67/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 68/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 69/929, 8.3 task/s, elapsed: 8s, ETA:   103s[>>                              ] 70/929, 8.3 task/s, elapsed: 8s, ETA:   103s[>>                              ] 71/929, 8.4 task/s, elapsed: 9s, ETA:   103s[>>                              ] 72/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 73/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 74/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 75/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 76/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 78/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 79/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 80/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                             ] 81/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 82/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 83/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 85/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 86/929, 8.6 task/s, elapsed: 10s, ETA:    99s[>>                             ] 87/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 88/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 89/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 90/929, 8.6 task/s, elapsed: 10s, ETA:    97s[>>>                            ] 91/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 92/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 93/929, 8.7 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 94/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 95/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 96/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 97/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 98/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 99/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                           ] 100/929, 8.7 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 101/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 102/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 103/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 106/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 107/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 108/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 109/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 110/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 111/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 112/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 113/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 114/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 115/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 116/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 117/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 118/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 119/929, 8.8 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 120/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 121/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 122/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 123/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 124/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 125/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 126/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 127/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 128/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 129/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 130/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 131/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 132/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 133/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 134/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 135/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 136/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 137/929, 8.8 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 138/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 139/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 140/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 141/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 142/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 143/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 144/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 145/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 146/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 147/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 148/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 149/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 150/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 151/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 152/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 153/929, 8.8 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 154/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>>                         ] 155/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 156/929, 8.9 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 157/929, 8.9 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 158/929, 8.9 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 159/929, 8.9 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 160/929, 8.9 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 161/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 162/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 163/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 164/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 165/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 166/929, 8.9 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 167/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 168/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 169/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 170/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 171/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 172/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 173/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 174/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 175/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 176/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 177/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 178/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 179/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 180/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 181/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 182/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 183/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 184/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 185/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 186/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 187/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 188/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 189/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 190/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 191/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 192/929, 8.9 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 193/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 194/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 195/929, 9.0 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 196/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 197/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 198/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 199/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 200/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 201/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 202/929, 9.0 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 203/929, 9.0 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 204/929, 9.0 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 205/929, 9.0 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 206/929, 9.0 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 207/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 208/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 209/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 210/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 211/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 212/929, 9.0 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 213/929, 9.0 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 214/929, 9.0 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 215/929, 9.0 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 216/929, 9.0 task/s, elapsed: 24s, ETA:    79s[>>>>>>>                       ] 217/929, 9.0 task/s, elapsed: 24s, ETA:    79s[>>>>>>>                       ] 218/929, 9.0 task/s, elapsed: 24s, ETA:    79s[>>>>>>>                       ] 219/929, 9.0 task/s, elapsed: 24s, ETA:    79s[>>>>>>>                       ] 220/929, 9.0 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.0 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 222/929, 9.0 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 223/929, 9.0 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 224/929, 9.1 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 225/929, 9.1 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 226/929, 9.1 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 227/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 230/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 231/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 232/929, 9.1 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 233/929, 9.1 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 234/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 239/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 240/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 241/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 242/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 243/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 247/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 248/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 249/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 255/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 256/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 257/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 258/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 264/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 290/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 293/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 297/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 298/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 299/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 306/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 307/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 308/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 309/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 310/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 315/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 316/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 317/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 318/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 319/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 323/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 324/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 325/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 326/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 327/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 332/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 333/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 335/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 336/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 337/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 340/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 341/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 342/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 343/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 344/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 345/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 346/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.3 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 348/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 349/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 350/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 353/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 354/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 355/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 356/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 357/929, 9.3 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 358/929, 9.3 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 359/929, 9.3 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.3 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 362/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 363/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 364/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 365/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 366/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 367/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 375/929, 9.3 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.3 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.3 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.3 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 380/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 381/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 382/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 383/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 384/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 385/929, 9.3 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.3 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 388/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 389/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 390/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 391/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 392/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 393/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 394/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 397/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 399/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 400/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 401/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 402/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.3 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 406/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 407/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 408/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 409/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 410/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 411/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 412/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 415/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 416/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 417/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 418/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 419/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 420/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 421/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.3 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 425/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 426/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 427/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 428/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 429/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 430/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.3 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.3 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 435/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 436/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 437/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 438/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 439/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 440/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.3 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.3 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 444/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 445/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 446/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 447/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 448/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 449/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.3 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.3 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 453/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 454/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 455/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 456/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 457/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 458/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.3 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.3 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 462/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 463/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 464/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 465/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 466/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 467/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.3 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 471/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 472/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 473/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 474/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 475/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 476/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 480/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 481/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 482/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 483/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 484/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 485/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.3 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 489/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 490/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 492/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 493/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 494/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 498/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 499/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 501/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 502/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 503/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 508/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 511/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 512/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 513/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 520/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 521/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 522/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.4 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.4 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.4 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.4 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.4 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.4 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.4 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.4 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.4 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.4 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.4 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.4 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.4 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.4 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.4 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.4 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.4 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.4 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.4 task/s, elapsed: 99s, ETA:     0s2022-10-10 20:08:41,451 - mmseg - INFO - per class results:2022-10-10 20:08:41,452 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.27 | 96.25 || rigid_plastic | 34.47 | 43.35 ||   cardboard   | 58.77 | 72.76 ||     metal     | 34.81 | 46.04 ||  soft_plastic | 63.29 | 72.52 |+---------------+-------+-------+2022-10-10 20:08:41,452 - mmseg - INFO - Summary:2022-10-10 20:08:41,452 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.76 | 56.52 | 66.18 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:08:41,461 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 20:08:41,461 - mmseg - INFO - Iter [929/40000]	lr: 1.200e-05, eta: 2:48:43, time: 1.269, data_time: 0.015, memory: 67493, aAcc: 0.9176, mIoU: 0.5652, mAcc: 0.6618, IoU.background: 0.9127, IoU.rigid_plastic: 0.3447, IoU.cardboard: 0.5877, IoU.metal: 0.3481, IoU.soft_plastic: 0.6329, Acc.background: 0.9625, Acc.rigid_plastic: 0.4335, Acc.cardboard: 0.7276, Acc.metal: 0.4604, Acc.soft_plastic: 0.7252, src.decode.loss_seg: 0.0432, src.decode.acc_seg: 98.4548, src.loss: 0.0592, mix.decode.loss_seg: 0.0379, mix.decode.acc_seg: 98.3413, mix.loss: 0.0379, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:09:48,788 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 2:48:20, time: 4.506, data_time: 3.177, memory: 67493, src.decode.loss_seg: 0.0446, src.decode.acc_seg: 98.3744, src.loss: 0.0606, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.5956, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:10:51,666 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 2:47:16, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0438, src.decode.acc_seg: 98.3809, src.loss: 0.0598, mix.decode.loss_seg: 0.0313, mix.decode.acc_seg: 98.7066, mix.loss: 0.0313, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:11:54,300 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 2:46:12, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0493, src.decode.acc_seg: 98.3205, src.loss: 0.0653, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4877, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:12:57,789 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 2:45:09, time: 1.270, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0420, src.decode.acc_seg: 98.4457, src.loss: 0.0581, mix.decode.loss_seg: 0.0309, mix.decode.acc_seg: 98.5951, mix.loss: 0.0309, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:14:00,668 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 2:44:05, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0454, src.decode.acc_seg: 98.3477, src.loss: 0.0614, mix.decode.loss_seg: 0.0292, mix.decode.acc_seg: 98.7750, mix.loss: 0.0292, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:15:03,981 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 2:43:01, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.4858, src.loss: 0.0576, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.7933, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:16:06,955 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 2:41:58, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0496, src.decode.acc_seg: 98.2115, src.loss: 0.0656, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.5907, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:17:09,881 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 2:40:54, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0443, src.decode.acc_seg: 98.3671, src.loss: 0.0603, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5966, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:18:14,075 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 2:39:51, time: 1.284, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0495, src.decode.acc_seg: 98.0910, src.loss: 0.0655, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.8001, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:19:17,216 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 2:38:47, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0371, src.decode.acc_seg: 98.6344, src.loss: 0.0531, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.7393, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:20:20,085 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 2:37:43, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0440, src.decode.acc_seg: 98.3328, src.loss: 0.0600, mix.decode.loss_seg: 0.0373, mix.decode.acc_seg: 98.4810, mix.loss: 0.0373, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:21:22,795 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 2:36:40, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0458, src.decode.acc_seg: 98.3269, src.loss: 0.0618, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.7448, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:22:25,891 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 2:35:36, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.4574, src.loss: 0.0570, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.7705, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:23:28,761 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 2:34:32, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0446, src.decode.acc_seg: 98.3433, src.loss: 0.0606, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.4875, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:24:31,578 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 2:33:29, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.4138, src.loss: 0.0593, mix.decode.loss_seg: 0.0324, mix.decode.acc_seg: 98.6596, mix.loss: 0.0324, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:25:33,952 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 2:32:25, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.3898, src.loss: 0.0587, mix.decode.loss_seg: 0.0348, mix.decode.acc_seg: 98.6329, mix.loss: 0.0348, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:26:36,506 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 2:31:21, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0400, src.decode.acc_seg: 98.4841, src.loss: 0.0560, mix.decode.loss_seg: 0.0296, mix.decode.acc_seg: 98.6883, mix.loss: 0.0296, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:27:38,759 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 2:30:18, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0460, src.decode.acc_seg: 98.3236, src.loss: 0.0620, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.7459, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:28:41,188 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 2:29:14, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0418, src.decode.acc_seg: 98.4571, src.loss: 0.0578, mix.decode.loss_seg: 0.0381, mix.decode.acc_seg: 98.4151, mix.loss: 0.0381, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:29:43,931 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 20:29:43,932 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 2:28:10, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0423, src.decode.acc_seg: 98.4810, src.loss: 0.0584, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.7829, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:30:46,856 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 2:27:06, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0481, src.decode.acc_seg: 98.1481, src.loss: 0.0642, mix.decode.loss_seg: 0.0354, mix.decode.acc_seg: 98.6006, mix.loss: 0.0354, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:31:49,857 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 2:26:03, time: 1.260, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.4385, src.loss: 0.0594, mix.decode.loss_seg: 0.0340, mix.decode.acc_seg: 98.5235, mix.loss: 0.0340, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:32:52,551 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 2:24:59, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0399, src.decode.acc_seg: 98.5002, src.loss: 0.0559, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.4250, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:33:55,200 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 2:23:56, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0482, src.decode.acc_seg: 98.2997, src.loss: 0.0642, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6783, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:34:57,555 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 2:22:52, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.3699, src.loss: 0.0565, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.7251, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:36:00,462 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 2:21:48, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0432, src.decode.acc_seg: 98.3754, src.loss: 0.0592, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.7605, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:37:02,828 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 2:20:44, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0437, src.decode.acc_seg: 98.3570, src.loss: 0.0597, mix.decode.loss_seg: 0.0292, mix.decode.acc_seg: 98.7797, mix.loss: 0.0292, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:38:05,403 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 2:19:41, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0479, src.decode.acc_seg: 98.2649, src.loss: 0.0639, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.6780, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:39:07,815 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 2:18:37, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0387, src.decode.acc_seg: 98.5334, src.loss: 0.0547, mix.decode.loss_seg: 0.0383, mix.decode.acc_seg: 98.5141, mix.loss: 0.0383, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:40:10,638 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 2:17:33, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.4303, src.loss: 0.0569, mix.decode.loss_seg: 0.0281, mix.decode.acc_seg: 98.8472, mix.loss: 0.0281, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:41:13,714 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 2:16:30, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0459, src.decode.acc_seg: 98.2715, src.loss: 0.0619, mix.decode.loss_seg: 0.0337, mix.decode.acc_seg: 98.5384, mix.loss: 0.0337, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:42:15,922 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 2:15:26, time: 1.244, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4067, src.loss: 0.0578, mix.decode.loss_seg: 0.0259, mix.decode.acc_seg: 98.7823, mix.loss: 0.0259, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:43:18,492 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 2:14:22, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4971, src.loss: 0.0567, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.5397, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:44:20,803 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 2:13:19, time: 1.246, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.4372, src.loss: 0.0568, mix.decode.loss_seg: 0.0310, mix.decode.acc_seg: 98.7064, mix.loss: 0.0310, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:45:23,436 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 2:12:15, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0383, src.decode.acc_seg: 98.6114, src.loss: 0.0543, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.5671, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:46:26,452 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 2:11:12, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0366, src.decode.acc_seg: 98.6476, src.loss: 0.0527, mix.decode.loss_seg: 0.0292, mix.decode.acc_seg: 98.8945, mix.loss: 0.0292, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:47:29,748 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 2:10:08, time: 1.266, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0466, src.decode.acc_seg: 98.3000, src.loss: 0.0626, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.7009, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:48:32,375 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 2:09:04, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0398, src.decode.acc_seg: 98.4502, src.loss: 0.0558, mix.decode.loss_seg: 0.0327, mix.decode.acc_seg: 98.6634, mix.loss: 0.0327, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:49:34,891 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 2:08:01, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0350, src.decode.acc_seg: 98.6906, src.loss: 0.0510, mix.decode.loss_seg: 0.0253, mix.decode.acc_seg: 98.9189, mix.loss: 0.0253, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:50:37,990 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 20:50:37,990 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 2:06:57, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0395, src.decode.acc_seg: 98.4845, src.loss: 0.0555, mix.decode.loss_seg: 0.0281, mix.decode.acc_seg: 98.7802, mix.loss: 0.0281, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:51:41,023 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 2:05:54, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0415, src.decode.acc_seg: 98.4172, src.loss: 0.0575, mix.decode.loss_seg: 0.0288, mix.decode.acc_seg: 98.6766, mix.loss: 0.0288, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:52:43,642 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 2:04:50, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0382, src.decode.acc_seg: 98.5447, src.loss: 0.0542, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.5637, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:53:46,134 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 2:03:46, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0396, src.decode.acc_seg: 98.5190, src.loss: 0.0556, mix.decode.loss_seg: 0.0364, mix.decode.acc_seg: 98.5311, mix.loss: 0.0364, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:54:49,405 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 2:02:43, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0363, src.decode.acc_seg: 98.6118, src.loss: 0.0524, mix.decode.loss_seg: 0.0286, mix.decode.acc_seg: 98.7646, mix.loss: 0.0286, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:55:51,864 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 2:01:39, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0410, src.decode.acc_seg: 98.4012, src.loss: 0.0570, mix.decode.loss_seg: 0.0384, mix.decode.acc_seg: 98.4074, mix.loss: 0.0384, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:56:54,316 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 2:00:36, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.5264, src.loss: 0.0568, mix.decode.loss_seg: 0.0324, mix.decode.acc_seg: 98.6631, mix.loss: 0.0324, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:57:57,462 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 1:59:32, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0406, src.decode.acc_seg: 98.4514, src.loss: 0.0566, mix.decode.loss_seg: 0.0306, mix.decode.acc_seg: 98.7556, mix.loss: 0.0306, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:59:00,942 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 1:58:29, time: 1.270, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0430, src.decode.acc_seg: 98.4006, src.loss: 0.0591, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.5758, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:00:03,702 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 1:57:25, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0419, src.decode.acc_seg: 98.3559, src.loss: 0.0579, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.4603, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:01:06,480 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 1:56:21, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0369, src.decode.acc_seg: 98.6245, src.loss: 0.0529, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.7154, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:02:09,211 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 1:55:18, time: 1.255, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0368, src.decode.acc_seg: 98.6046, src.loss: 0.0529, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.7357, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:03:11,580 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 1:54:14, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0455, src.decode.acc_seg: 98.3147, src.loss: 0.0615, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6823, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:04:14,564 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 1:53:11, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0419, src.decode.acc_seg: 98.4311, src.loss: 0.0579, mix.decode.loss_seg: 0.0300, mix.decode.acc_seg: 98.7778, mix.loss: 0.0300, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:05:16,884 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 1:52:07, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0538, src.decode.acc_seg: 97.9717, src.loss: 0.0698, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.5790, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:06:19,737 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 1:51:03, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0350, src.decode.acc_seg: 98.7013, src.loss: 0.0510, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.7783, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:07:22,086 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 1:50:00, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0386, src.decode.acc_seg: 98.6254, src.loss: 0.0546, mix.decode.loss_seg: 0.0300, mix.decode.acc_seg: 98.7248, mix.loss: 0.0300, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:08:24,921 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 1:48:56, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0393, src.decode.acc_seg: 98.5178, src.loss: 0.0553, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.6130, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:09:27,112 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 1:47:53, time: 1.244, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0397, src.decode.acc_seg: 98.4895, src.loss: 0.0557, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.7580, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:10:30,030 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 1:46:49, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0428, src.decode.acc_seg: 98.3846, src.loss: 0.0589, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.5435, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:11:32,614 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 21:11:32,614 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 1:45:45, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4787, src.loss: 0.0577, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.7916, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:12:34,950 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 1:44:42, time: 1.247, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0352, src.decode.acc_seg: 98.7029, src.loss: 0.0512, mix.decode.loss_seg: 0.0359, mix.decode.acc_seg: 98.4210, mix.loss: 0.0359, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:13:37,590 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 1:43:38, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.5660, src.loss: 0.0550, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.5439, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:14:40,864 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 1:42:35, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0379, src.decode.acc_seg: 98.5681, src.loss: 0.0539, mix.decode.loss_seg: 0.0289, mix.decode.acc_seg: 98.7396, mix.loss: 0.0289, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:15:43,291 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 1:41:31, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0363, src.decode.acc_seg: 98.5950, src.loss: 0.0523, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.5709, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:16:46,332 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 1:40:28, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0340, src.decode.acc_seg: 98.6441, src.loss: 0.0500, mix.decode.loss_seg: 0.0240, mix.decode.acc_seg: 99.0139, mix.loss: 0.0240, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:17:49,081 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 1:39:24, time: 1.255, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.3987, src.loss: 0.0586, mix.decode.loss_seg: 0.0264, mix.decode.acc_seg: 98.8555, mix.loss: 0.0264, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:18:51,951 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 1:38:21, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0437, src.decode.acc_seg: 98.3552, src.loss: 0.0597, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.6770, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:19:54,574 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 1:37:17, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0436, src.decode.acc_seg: 98.3876, src.loss: 0.0596, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.7787, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:20:57,032 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 1:36:13, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0395, src.decode.acc_seg: 98.4255, src.loss: 0.0555, mix.decode.loss_seg: 0.0373, mix.decode.acc_seg: 98.5370, mix.loss: 0.0373, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:21:59,762 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 1:35:10, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0415, src.decode.acc_seg: 98.4988, src.loss: 0.0575, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.7147, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:23:02,357 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 1:34:06, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0414, src.decode.acc_seg: 98.4291, src.loss: 0.0574, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6715, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:24:05,336 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 1:33:03, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0466, src.decode.acc_seg: 98.2497, src.loss: 0.0626, mix.decode.loss_seg: 0.0381, mix.decode.acc_seg: 98.4977, mix.loss: 0.0381, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:25:07,818 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 1:31:59, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.5488, src.loss: 0.0551, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.5193, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:26:10,953 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 1:30:56, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0437, src.decode.acc_seg: 98.3385, src.loss: 0.0598, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.6874, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:27:13,325 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 1:29:52, time: 1.247, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0353, src.decode.acc_seg: 98.7151, src.loss: 0.0513, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.7920, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:28:16,087 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 1:28:49, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0346, src.decode.acc_seg: 98.6760, src.loss: 0.0506, mix.decode.loss_seg: 0.0243, mix.decode.acc_seg: 98.9304, mix.loss: 0.0243, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:29:18,710 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 1:27:45, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0406, src.decode.acc_seg: 98.4947, src.loss: 0.0567, mix.decode.loss_seg: 0.0294, mix.decode.acc_seg: 98.8096, mix.loss: 0.0294, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:30:21,791 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 1:26:42, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0476, src.decode.acc_seg: 98.1208, src.loss: 0.0636, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.5772, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:31:26,343 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 1:25:38, time: 1.291, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0466, src.decode.acc_seg: 98.2804, src.loss: 0.0627, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.5044, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.0 task/s, elapsed: 1s, ETA:   973s[                                 ] 2/929, 1.7 task/s, elapsed: 1s, ETA:   534s[                                 ] 3/929, 2.4 task/s, elapsed: 1s, ETA:   386s[                                 ] 4/929, 3.0 task/s, elapsed: 1s, ETA:   312s[                                 ] 5/929, 3.4 task/s, elapsed: 1s, ETA:   268s[                                 ] 6/929, 3.8 task/s, elapsed: 2s, ETA:   240s[                                 ] 7/929, 4.1 task/s, elapsed: 2s, ETA:   226s[                                 ] 8/929, 4.4 task/s, elapsed: 2s, ETA:   209s[                                 ] 9/929, 4.7 task/s, elapsed: 2s, ETA:   197s[                                ] 10/929, 4.9 task/s, elapsed: 2s, ETA:   186s[                                ] 11/929, 5.1 task/s, elapsed: 2s, ETA:   179s[                                ] 12/929, 5.3 task/s, elapsed: 2s, ETA:   172s[                                ] 13/929, 5.5 task/s, elapsed: 2s, ETA:   166s[                                ] 14/929, 5.7 task/s, elapsed: 2s, ETA:   161s[                                ] 15/929, 5.7 task/s, elapsed: 3s, ETA:   160s[                                ] 16/929, 5.9 task/s, elapsed: 3s, ETA:   156s[                                ] 17/929, 6.0 task/s, elapsed: 3s, ETA:   152s[                                ] 18/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 19/929, 6.2 task/s, elapsed: 3s, ETA:   147s[                                ] 20/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 21/929, 6.4 task/s, elapsed: 3s, ETA:   141s[                                ] 22/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 23/929, 6.6 task/s, elapsed: 3s, ETA:   137s[                                ] 24/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 25/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 26/929, 6.9 task/s, elapsed: 4s, ETA:   132s[                                ] 27/929, 6.9 task/s, elapsed: 4s, ETA:   130s[                                ] 28/929, 7.0 task/s, elapsed: 4s, ETA:   129s[                                ] 29/929, 7.1 task/s, elapsed: 4s, ETA:   128s[>                               ] 30/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 31/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 32/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 33/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 34/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 35/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 36/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 37/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 38/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 39/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 40/929, 7.6 task/s, elapsed: 5s, ETA:   118s[>                               ] 41/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 42/929, 7.6 task/s, elapsed: 5s, ETA:   116s[>                               ] 43/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 44/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 45/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 46/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 47/929, 7.8 task/s, elapsed: 6s, ETA:   112s[>                               ] 48/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 49/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 50/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 51/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 53/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 54/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 55/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 56/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 57/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 61/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 62/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 63/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 64/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 65/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 66/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 68/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 69/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 70/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 71/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 72/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 73/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 74/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 75/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 76/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 78/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 79/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 80/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                             ] 81/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 82/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 83/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 85/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 86/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 87/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 88/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 89/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 90/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 91/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 92/929, 8.6 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 93/929, 8.6 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 94/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 95/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 96/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 97/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 98/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 99/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                           ] 100/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 101/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 102/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 103/929, 8.6 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 106/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 107/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 108/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 109/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 110/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 111/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 112/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 113/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 114/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 115/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 116/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 117/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 118/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 119/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 120/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 121/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 122/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 123/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 124/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 125/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 126/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 127/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 128/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 129/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 130/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 131/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 132/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 133/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 134/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 135/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 136/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 137/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 138/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 139/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 140/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 141/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 142/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 143/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 144/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 145/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 146/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 147/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 148/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 149/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 150/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 151/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 152/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 153/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 154/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 155/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 156/929, 8.9 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 157/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 158/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 159/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 160/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 161/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 162/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 163/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 164/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 165/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 166/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 167/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 168/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 169/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 170/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 171/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 172/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 173/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 174/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 175/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 176/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 177/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 178/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 180/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 181/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 183/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 184/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 185/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 186/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 187/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 188/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 191/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 192/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 193/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 194/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 195/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 196/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 198/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 199/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 200/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 201/929, 9.0 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 202/929, 9.0 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.0 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 205/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 206/929, 9.0 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 222/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 223/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 224/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 225/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 230/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 231/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 232/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 234/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 239/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 240/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 241/929, 9.1 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 242/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 243/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 247/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 248/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 249/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 255/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 256/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 257/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 258/929, 9.1 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.1 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.1 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 264/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 265/929, 9.1 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 266/929, 9.1 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.1 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 290/929, 9.2 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 291/929, 9.2 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 292/929, 9.2 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 293/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 297/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 298/929, 9.2 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 299/929, 9.2 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 300/929, 9.2 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 301/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 306/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 307/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 308/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>                     ] 309/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 310/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 315/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 316/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 317/929, 9.2 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 318/929, 9.2 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 319/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 323/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 324/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 325/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 326/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 327/929, 9.2 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 328/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 332/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 333/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 336/929, 9.2 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 337/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 340/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 341/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 342/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.2 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 346/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 348/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 349/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 350/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 355/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 356/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 357/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 358/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 359/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 363/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 364/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 365/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 366/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 367/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 375/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.3 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.3 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 380/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 381/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 382/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 383/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 384/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 385/929, 9.3 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.3 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 388/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 389/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 390/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 391/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 392/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 393/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 394/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 399/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 400/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 401/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 402/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.3 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.3 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 407/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 408/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 409/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 410/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 411/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 412/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.3 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.3 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 416/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 417/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 418/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 419/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 420/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 421/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.3 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.3 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 425/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 426/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 427/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 428/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 429/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 430/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.3 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 434/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 435/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 436/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 437/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 438/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 439/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 440/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.3 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.3 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 444/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 445/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 446/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 447/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 448/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 449/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.3 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.3 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 453/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 454/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 455/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 456/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 457/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 458/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.3 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 462/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 463/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 464/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 465/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 466/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 467/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.3 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 471/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 472/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 473/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 474/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 475/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 476/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 480/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 481/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 482/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 483/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 484/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 485/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.3 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 489/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 490/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 492/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 493/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 494/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 498/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 499/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 501/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 502/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 503/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 508/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 511/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 512/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 513/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 520/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 521/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 522/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.3 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.3 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.4 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.4 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.4 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.4 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.4 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.4 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.4 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.4 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.4 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.4 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.4 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.4 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.4 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.4 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.4 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.4 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.4 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.4 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.4 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.4 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.4 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.4 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.4 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.3 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.4 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.4 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.4 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.4 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.4 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.4 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.4 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.4 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.4 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.4 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.4 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.4 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.4 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.4 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.4 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.4 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.4 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.4 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.4 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.4 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.4 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.4 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.4 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.4 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.4 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.4 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.4 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.4 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.4 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.4 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.4 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.4 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.4 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.4 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.4 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.4 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.4 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.4 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.4 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.4 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.4 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.4 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.4 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.4 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.4 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.4 task/s, elapsed: 99s, ETA:     0s2022-10-10 21:35:03,723 - mmseg - INFO - per class results:2022-10-10 21:35:03,724 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.32 | 96.13 || rigid_plastic | 32.62 | 38.08 ||   cardboard   | 58.81 | 74.36 ||     metal     |  34.4 | 44.25 ||  soft_plastic |  64.4 | 72.48 |+---------------+-------+-------+2022-10-10 21:35:03,724 - mmseg - INFO - Summary:2022-10-10 21:35:03,724 - mmseg - INFO - +------+-------+-------+| aAcc |  mIoU |  mAcc |+------+-------+-------+| 91.8 | 56.31 | 65.06 |+------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:35:03,729 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 21:35:03,729 - mmseg - INFO - Iter [929/40000]	lr: 6.002e-06, eta: 1:24:35, time: 1.255, data_time: 0.015, memory: 67493, aAcc: 0.9180, mIoU: 0.5631, mAcc: 0.6506, IoU.background: 0.9132, IoU.rigid_plastic: 0.3262, IoU.cardboard: 0.5881, IoU.metal: 0.3440, IoU.soft_plastic: 0.6440, Acc.background: 0.9613, Acc.rigid_plastic: 0.3808, Acc.cardboard: 0.7436, Acc.metal: 0.4425, Acc.soft_plastic: 0.7248, src.decode.loss_seg: 0.0423, src.decode.acc_seg: 98.4428, src.loss: 0.0584, mix.decode.loss_seg: 0.0335, mix.decode.acc_seg: 98.5512, mix.loss: 0.0335, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:36:10,710 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 1:23:49, time: 4.433, data_time: 3.111, memory: 67493, src.decode.loss_seg: 0.0375, src.decode.acc_seg: 98.5464, src.loss: 0.0536, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.7486, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:37:14,689 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 1:22:45, time: 1.280, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0355, src.decode.acc_seg: 98.6981, src.loss: 0.0515, mix.decode.loss_seg: 0.0273, mix.decode.acc_seg: 98.8521, mix.loss: 0.0273, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:38:17,697 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 1:21:41, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0470, src.decode.acc_seg: 98.2509, src.loss: 0.0630, mix.decode.loss_seg: 0.0281, mix.decode.acc_seg: 98.7156, mix.loss: 0.0281, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:39:20,322 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 1:20:38, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0476, src.decode.acc_seg: 98.1545, src.loss: 0.0637, mix.decode.loss_seg: 0.0309, mix.decode.acc_seg: 98.5838, mix.loss: 0.0309, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:40:23,266 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 1:19:34, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.4365, src.loss: 0.0593, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.7719, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:41:26,527 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 1:18:30, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0438, src.decode.acc_seg: 98.4686, src.loss: 0.0598, mix.decode.loss_seg: 0.0319, mix.decode.acc_seg: 98.7257, mix.loss: 0.0319, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:42:29,471 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 1:17:26, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0398, src.decode.acc_seg: 98.4593, src.loss: 0.0558, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.7003, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:43:31,842 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 1:16:23, time: 1.247, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0423, src.decode.acc_seg: 98.4088, src.loss: 0.0584, mix.decode.loss_seg: 0.0334, mix.decode.acc_seg: 98.5425, mix.loss: 0.0334, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:44:35,133 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 1:15:19, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0381, src.decode.acc_seg: 98.5896, src.loss: 0.0541, mix.decode.loss_seg: 0.0288, mix.decode.acc_seg: 98.7685, mix.loss: 0.0288, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:45:38,703 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 1:14:15, time: 1.271, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0351, src.decode.acc_seg: 98.6191, src.loss: 0.0511, mix.decode.loss_seg: 0.0309, mix.decode.acc_seg: 98.7346, mix.loss: 0.0309, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:46:42,804 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 1:13:12, time: 1.282, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0371, src.decode.acc_seg: 98.5553, src.loss: 0.0532, mix.decode.loss_seg: 0.0261, mix.decode.acc_seg: 98.8817, mix.loss: 0.0261, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:47:45,248 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 1:12:08, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.3806, src.loss: 0.0601, mix.decode.loss_seg: 0.0324, mix.decode.acc_seg: 98.6822, mix.loss: 0.0324, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:48:48,059 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 1:11:04, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0368, src.decode.acc_seg: 98.6124, src.loss: 0.0528, mix.decode.loss_seg: 0.0269, mix.decode.acc_seg: 98.8608, mix.loss: 0.0269, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:49:50,960 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 1:10:00, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0351, src.decode.acc_seg: 98.6840, src.loss: 0.0511, mix.decode.loss_seg: 0.0296, mix.decode.acc_seg: 98.7684, mix.loss: 0.0296, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:50:53,696 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 1:08:57, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.4719, src.loss: 0.0568, mix.decode.loss_seg: 0.0298, mix.decode.acc_seg: 98.6825, mix.loss: 0.0298, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:51:56,650 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 1:07:53, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0359, src.decode.acc_seg: 98.6562, src.loss: 0.0519, mix.decode.loss_seg: 0.0284, mix.decode.acc_seg: 98.8049, mix.loss: 0.0284, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:53:00,142 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 1:06:49, time: 1.270, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.4196, src.loss: 0.0593, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.5989, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:54:03,542 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 1:05:46, time: 1.268, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0459, src.decode.acc_seg: 98.3045, src.loss: 0.0619, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6941, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:55:06,449 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 1:04:42, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4578, src.loss: 0.0577, mix.decode.loss_seg: 0.0292, mix.decode.acc_seg: 98.8588, mix.loss: 0.0292, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:56:09,100 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 21:56:09,100 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 1:03:38, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0369, src.decode.acc_seg: 98.6154, src.loss: 0.0529, mix.decode.loss_seg: 0.0259, mix.decode.acc_seg: 98.7913, mix.loss: 0.0259, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:57:12,513 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 1:02:35, time: 1.268, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.4445, src.loss: 0.0569, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.6134, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:58:15,030 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 1:01:31, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0445, src.decode.acc_seg: 98.3441, src.loss: 0.0605, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.5190, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:59:18,132 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 1:00:27, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0354, src.decode.acc_seg: 98.6219, src.loss: 0.0514, mix.decode.loss_seg: 0.0281, mix.decode.acc_seg: 98.7421, mix.loss: 0.0281, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:00:20,101 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 0:59:23, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0381, src.decode.acc_seg: 98.5491, src.loss: 0.0541, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.5661, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:01:22,770 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:58:20, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0402, src.decode.acc_seg: 98.4869, src.loss: 0.0563, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.7352, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:02:26,193 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:57:16, time: 1.268, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0411, src.decode.acc_seg: 98.4328, src.loss: 0.0571, mix.decode.loss_seg: 0.0277, mix.decode.acc_seg: 98.7976, mix.loss: 0.0277, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:03:29,208 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:56:12, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0450, src.decode.acc_seg: 98.2746, src.loss: 0.0610, mix.decode.loss_seg: 0.0374, mix.decode.acc_seg: 98.5009, mix.loss: 0.0374, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:04:32,240 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:55:09, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0357, src.decode.acc_seg: 98.6910, src.loss: 0.0517, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.7441, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:05:34,819 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:54:05, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4387, src.loss: 0.0577, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.7102, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:06:37,815 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:53:01, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.5246, src.loss: 0.0569, mix.decode.loss_seg: 0.0279, mix.decode.acc_seg: 98.7758, mix.loss: 0.0279, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:07:41,311 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:51:58, time: 1.270, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0372, src.decode.acc_seg: 98.5657, src.loss: 0.0533, mix.decode.loss_seg: 0.0283, mix.decode.acc_seg: 98.7759, mix.loss: 0.0283, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:08:43,956 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:50:54, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0420, src.decode.acc_seg: 98.4069, src.loss: 0.0580, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.5110, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:09:46,470 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:49:50, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0425, src.decode.acc_seg: 98.3554, src.loss: 0.0586, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.6622, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:10:48,873 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:48:47, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0335, src.decode.acc_seg: 98.7651, src.loss: 0.0496, mix.decode.loss_seg: 0.0278, mix.decode.acc_seg: 98.8494, mix.loss: 0.0278, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:11:51,287 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:47:43, time: 1.248, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0351, src.decode.acc_seg: 98.6577, src.loss: 0.0511, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.9068, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:12:53,993 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:46:39, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0429, src.decode.acc_seg: 98.3832, src.loss: 0.0589, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.6837, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:13:56,783 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:45:35, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0366, src.decode.acc_seg: 98.7080, src.loss: 0.0527, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.7176, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:14:59,605 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:44:32, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0354, src.decode.acc_seg: 98.7012, src.loss: 0.0514, mix.decode.loss_seg: 0.0275, mix.decode.acc_seg: 98.8942, mix.loss: 0.0275, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:16:02,083 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:43:28, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0509, src.decode.acc_seg: 98.1367, src.loss: 0.0669, mix.decode.loss_seg: 0.0350, mix.decode.acc_seg: 98.5664, mix.loss: 0.0350, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:17:05,063 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 22:17:05,063 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:42:24, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.4237, src.loss: 0.0601, mix.decode.loss_seg: 0.0369, mix.decode.acc_seg: 98.5030, mix.loss: 0.0369, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:18:07,810 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:41:21, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0363, src.decode.acc_seg: 98.6172, src.loss: 0.0523, mix.decode.loss_seg: 0.0252, mix.decode.acc_seg: 98.9355, mix.loss: 0.0252, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:19:10,479 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:40:17, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0384, src.decode.acc_seg: 98.5247, src.loss: 0.0544, mix.decode.loss_seg: 0.0258, mix.decode.acc_seg: 98.8756, mix.loss: 0.0258, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:20:12,946 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:39:13, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0474, src.decode.acc_seg: 98.2739, src.loss: 0.0635, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.6963, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:21:16,004 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:38:10, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.4289, src.loss: 0.0576, mix.decode.loss_seg: 0.0326, mix.decode.acc_seg: 98.7200, mix.loss: 0.0326, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:22:18,729 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:37:06, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0371, src.decode.acc_seg: 98.6100, src.loss: 0.0531, mix.decode.loss_seg: 0.0251, mix.decode.acc_seg: 98.8659, mix.loss: 0.0251, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:23:21,760 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:36:02, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0387, src.decode.acc_seg: 98.5140, src.loss: 0.0548, mix.decode.loss_seg: 0.0288, mix.decode.acc_seg: 98.7545, mix.loss: 0.0288, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:24:25,259 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:34:59, time: 1.270, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0366, src.decode.acc_seg: 98.6357, src.loss: 0.0526, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6206, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:25:28,170 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:33:55, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0360, src.decode.acc_seg: 98.6372, src.loss: 0.0520, mix.decode.loss_seg: 0.0300, mix.decode.acc_seg: 98.7116, mix.loss: 0.0300, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:26:31,094 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:32:52, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0458, src.decode.acc_seg: 98.3329, src.loss: 0.0618, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.6644, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:27:34,186 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:31:48, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0392, src.decode.acc_seg: 98.5621, src.loss: 0.0552, mix.decode.loss_seg: 0.0280, mix.decode.acc_seg: 98.8012, mix.loss: 0.0280, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:28:37,546 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:30:44, time: 1.267, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0385, src.decode.acc_seg: 98.5389, src.loss: 0.0545, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.8582, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:29:40,398 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:29:41, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4626, src.loss: 0.0577, mix.decode.loss_seg: 0.0285, mix.decode.acc_seg: 98.8237, mix.loss: 0.0285, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:30:43,587 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:28:37, time: 1.264, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0399, src.decode.acc_seg: 98.4558, src.loss: 0.0559, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.6752, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:31:45,917 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:27:33, time: 1.247, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0438, src.decode.acc_seg: 98.3092, src.loss: 0.0598, mix.decode.loss_seg: 0.0317, mix.decode.acc_seg: 98.7097, mix.loss: 0.0317, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:32:48,203 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:26:30, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0291, src.decode.acc_seg: 98.9015, src.loss: 0.0451, mix.decode.loss_seg: 0.0272, mix.decode.acc_seg: 98.9051, mix.loss: 0.0272, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:33:50,770 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:25:26, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0388, src.decode.acc_seg: 98.4755, src.loss: 0.0548, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.5657, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:34:53,657 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:24:22, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0326, src.decode.acc_seg: 98.7631, src.loss: 0.0486, mix.decode.loss_seg: 0.0310, mix.decode.acc_seg: 98.6643, mix.loss: 0.0310, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:35:56,767 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:23:19, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0381, src.decode.acc_seg: 98.5432, src.loss: 0.0541, mix.decode.loss_seg: 0.0269, mix.decode.acc_seg: 98.9131, mix.loss: 0.0269, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:36:59,568 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:22:15, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0396, src.decode.acc_seg: 98.5515, src.loss: 0.0556, mix.decode.loss_seg: 0.0405, mix.decode.acc_seg: 98.4966, mix.loss: 0.0405, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:38:02,022 - mmseg - INFO - Exp name: 221010_0850_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed42_47e6c2022-10-10 22:38:02,022 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:21:12, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0388, src.decode.acc_seg: 98.5266, src.loss: 0.0548, mix.decode.loss_seg: 0.0268, mix.decode.acc_seg: 98.8753, mix.loss: 0.0268, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:39:05,252 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:20:08, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0377, src.decode.acc_seg: 98.5489, src.loss: 0.0537, mix.decode.loss_seg: 0.0287, mix.decode.acc_seg: 98.8216, mix.loss: 0.0287, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:40:08,468 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:19:04, time: 1.264, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0415, src.decode.acc_seg: 98.3836, src.loss: 0.0575, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.7436, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:41:11,820 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:18:01, time: 1.267, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0368, src.decode.acc_seg: 98.5872, src.loss: 0.0528, mix.decode.loss_seg: 0.0284, mix.decode.acc_seg: 98.8217, mix.loss: 0.0284, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:42:14,762 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:16:57, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0385, src.decode.acc_seg: 98.5079, src.loss: 0.0545, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.7913, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:43:18,020 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:15:54, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0373, src.decode.acc_seg: 98.6360, src.loss: 0.0533, mix.decode.loss_seg: 0.0283, mix.decode.acc_seg: 98.8556, mix.loss: 0.0283, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:44:21,199 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:14:50, time: 1.264, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0362, src.decode.acc_seg: 98.5668, src.loss: 0.0523, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.8373, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:45:23,713 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:13:46, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0386, src.decode.acc_seg: 98.5502, src.loss: 0.0546, mix.decode.loss_seg: 0.0279, mix.decode.acc_seg: 98.8939, mix.loss: 0.0279, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:46:26,862 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:12:43, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0443, src.decode.acc_seg: 98.3028, src.loss: 0.0603, mix.decode.loss_seg: 0.0347, mix.decode.acc_seg: 98.4902, mix.loss: 0.0347, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:47:29,374 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:11:39, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.3970, src.loss: 0.0577, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.8263, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:48:32,300 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:10:35, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0347, src.decode.acc_seg: 98.7172, src.loss: 0.0507, mix.decode.loss_seg: 0.0292, mix.decode.acc_seg: 98.8243, mix.loss: 0.0292, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:49:35,272 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:09:32, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0427, src.decode.acc_seg: 98.5432, src.loss: 0.0587, mix.decode.loss_seg: 0.0351, mix.decode.acc_seg: 98.7109, mix.loss: 0.0351, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:50:37,956 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:08:28, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0384, src.decode.acc_seg: 98.5132, src.loss: 0.0544, mix.decode.loss_seg: 0.0288, mix.decode.acc_seg: 98.8722, mix.loss: 0.0288, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:51:40,731 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:07:25, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0418, src.decode.acc_seg: 98.4769, src.loss: 0.0579, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.7913, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:52:43,453 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:06:21, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0392, src.decode.acc_seg: 98.5183, src.loss: 0.0552, mix.decode.loss_seg: 0.0270, mix.decode.acc_seg: 98.8343, mix.loss: 0.0270, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:53:45,754 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:05:17, time: 1.246, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.4451, src.loss: 0.0569, mix.decode.loss_seg: 0.0254, mix.decode.acc_seg: 98.9262, mix.loss: 0.0254, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:54:48,156 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:04:14, time: 1.248, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0361, src.decode.acc_seg: 98.6708, src.loss: 0.0522, mix.decode.loss_seg: 0.0296, mix.decode.acc_seg: 98.8467, mix.loss: 0.0296, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:55:51,127 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:03:10, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0382, src.decode.acc_seg: 98.5574, src.loss: 0.0542, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.7018, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:56:54,033 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:02:07, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0457, src.decode.acc_seg: 98.2423, src.loss: 0.0617, mix.decode.loss_seg: 0.0269, mix.decode.acc_seg: 98.8719, mix.loss: 0.0269, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:57:58,569 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:01:03, time: 1.291, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.4468, src.loss: 0.0569, mix.decode.loss_seg: 0.0319, mix.decode.acc_seg: 98.7303, mix.loss: 0.0319, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1155s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   625s[                                 ] 3/929, 2.0 task/s, elapsed: 1s, ETA:   455s[                                 ] 4/929, 2.5 task/s, elapsed: 2s, ETA:   371s[                                 ] 5/929, 2.9 task/s, elapsed: 2s, ETA:   319s[                                 ] 6/929, 3.3 task/s, elapsed: 2s, ETA:   281s[                                 ] 7/929, 3.6 task/s, elapsed: 2s, ETA:   254s[                                 ] 8/929, 3.9 task/s, elapsed: 2s, ETA:   234s[                                 ] 9/929, 4.2 task/s, elapsed: 2s, ETA:   218s[                                ] 10/929, 4.5 task/s, elapsed: 2s, ETA:   205s[                                ] 11/929, 4.7 task/s, elapsed: 2s, ETA:   195s[                                ] 12/929, 4.9 task/s, elapsed: 2s, ETA:   186s[                                ] 13/929, 5.1 task/s, elapsed: 3s, ETA:   178s[                                ] 14/929, 5.3 task/s, elapsed: 3s, ETA:   172s[                                ] 15/929, 5.5 task/s, elapsed: 3s, ETA:   166s[                                ] 16/929, 5.7 task/s, elapsed: 3s, ETA:   162s[                                ] 17/929, 5.8 task/s, elapsed: 3s, ETA:   157s[                                ] 18/929, 5.9 task/s, elapsed: 3s, ETA:   154s[                                ] 19/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 20/929, 6.2 task/s, elapsed: 3s, ETA:   148s[                                ] 21/929, 6.3 task/s, elapsed: 3s, ETA:   145s[                                ] 22/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 23/929, 6.5 task/s, elapsed: 4s, ETA:   140s[                                ] 24/929, 6.6 task/s, elapsed: 4s, ETA:   138s[                                ] 25/929, 6.6 task/s, elapsed: 4s, ETA:   136s[                                ] 26/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 27/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 28/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 29/929, 6.9 task/s, elapsed: 4s, ETA:   130s[>                               ] 30/929, 7.0 task/s, elapsed: 4s, ETA:   128s[>                               ] 31/929, 7.1 task/s, elapsed: 4s, ETA:   127s[>                               ] 32/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 33/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 34/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 35/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 36/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 37/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 38/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 39/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 40/929, 7.6 task/s, elapsed: 5s, ETA:   118s[>                               ] 41/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 42/929, 7.6 task/s, elapsed: 5s, ETA:   116s[>                               ] 43/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 44/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 45/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 46/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 47/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 48/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 49/929, 7.8 task/s, elapsed: 6s, ETA:   112s[>                               ] 50/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 51/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 53/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 54/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 55/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 56/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 57/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 61/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 62/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 63/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 64/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 65/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 66/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 67/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 68/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 69/929, 8.3 task/s, elapsed: 8s, ETA:   103s[>>                              ] 70/929, 8.3 task/s, elapsed: 8s, ETA:   103s[>>                              ] 71/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 72/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 73/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 74/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 75/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 76/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 78/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 79/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 80/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                             ] 81/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 82/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 83/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 85/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 86/929, 8.6 task/s, elapsed: 10s, ETA:    99s[>>                             ] 87/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 88/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 89/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 90/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 91/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 92/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 93/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 94/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 95/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 96/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 97/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 98/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 99/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                           ] 100/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                           ] 101/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 102/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 103/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 106/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 107/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 108/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 109/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 110/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 111/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 112/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 113/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 114/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 115/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 116/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 117/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 118/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 119/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 120/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 121/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 122/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 123/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 124/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 125/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 126/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 127/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 128/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 129/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 130/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 131/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 132/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 133/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 134/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 135/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 136/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 137/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 138/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 139/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 140/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 141/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 142/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 143/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 144/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 145/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 146/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 147/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 148/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 149/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 150/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 151/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 152/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 153/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 154/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 155/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 156/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 157/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 158/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 159/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 160/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 161/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 162/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 163/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 164/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 165/929, 8.9 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 166/929, 8.9 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 167/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 168/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 169/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 170/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 171/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 172/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 173/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 174/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 175/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 176/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 177/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 178/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 180/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 181/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 183/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 184/929, 9.0 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 185/929, 9.0 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 186/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 187/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 188/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 191/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 192/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 193/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 194/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 195/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 196/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 198/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 199/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 200/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 222/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 223/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 224/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 225/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 230/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 231/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 232/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 233/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 234/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 239/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 240/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 241/929, 9.1 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 242/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 243/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 247/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 248/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 249/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.1 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 255/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 256/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 257/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 258/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 264/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 290/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 293/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 297/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 298/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 299/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 306/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 307/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 308/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 309/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>>                    ] 310/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.3 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.3 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.3 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 315/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 316/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 317/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 318/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 319/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.3 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.3 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 323/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 324/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 325/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 326/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 327/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 331/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 332/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 333/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 334/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 335/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 336/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 337/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.3 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 340/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 341/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 342/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 343/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 344/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 345/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 346/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 348/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 349/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 350/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 351/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 352/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 353/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 354/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 355/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 356/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 357/929, 9.3 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 358/929, 9.3 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 359/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 360/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 361/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 362/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 363/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 364/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 365/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 366/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 367/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 368/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 369/929, 9.3 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>                   ] 370/929, 9.3 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>                   ] 371/929, 9.3 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 372/929, 9.3 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 373/929, 9.3 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 374/929, 9.3 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 375/929, 9.3 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 376/929, 9.3 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 377/929, 9.3 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 378/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 379/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 380/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 381/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 382/929, 9.3 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 383/929, 9.3 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 384/929, 9.3 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 385/929, 9.3 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 386/929, 9.3 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 387/929, 9.3 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 388/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 389/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 390/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 391/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 392/929, 9.3 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 393/929, 9.3 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 394/929, 9.3 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 395/929, 9.3 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 396/929, 9.3 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 397/929, 9.3 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 399/929, 9.4 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 400/929, 9.4 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 401/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>                  ] 402/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 403/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 404/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 405/929, 9.3 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 406/929, 9.3 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 407/929, 9.4 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 408/929, 9.4 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 409/929, 9.4 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 410/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 411/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 412/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 413/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 414/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 415/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 416/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 417/929, 9.4 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 418/929, 9.4 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 419/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 420/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 421/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 422/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 423/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 424/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 425/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 426/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 427/929, 9.4 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 428/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 429/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 430/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 431/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 432/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 433/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>>                ] 434/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>>                ] 435/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>>                ] 436/929, 9.4 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 437/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 438/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 439/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 440/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 441/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 442/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 443/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 444/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 445/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 446/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 447/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 448/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 449/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 450/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 451/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 452/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 453/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 454/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 455/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 456/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 457/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 458/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 459/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 460/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 461/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 462/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 463/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 464/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 465/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 466/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 467/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 468/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 469/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 470/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 471/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 472/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 473/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 474/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 475/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 476/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 477/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 478/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 479/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 480/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 481/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 482/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 483/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 484/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 485/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 486/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 487/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 488/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 489/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 490/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 492/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 493/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 494/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 495/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 496/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 498/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 499/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 501/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 502/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 503/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 504/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 505/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 508/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 511/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 512/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 513/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 514/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 520/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 521/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 522/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 523/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.4 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.4 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.5 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.5 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.5 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.5 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.5 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.5 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.5 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.5 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.5 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.5 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.5 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.5 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.5 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.5 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.5 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.5 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.5 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.5 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.5 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.5 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.5 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.5 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.5 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.5 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.5 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.5 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.5 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.5 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.5 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.5 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.5 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.5 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.5 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.5 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.5 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.5 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.5 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.5 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.5 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.5 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.5 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.5 task/s, elapsed: 98s, ETA:     0s2022-10-10 23:01:35,164 - mmseg - INFO - per class results:2022-10-10 23:01:35,165 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.34 | 95.99 || rigid_plastic | 32.39 | 37.94 ||   cardboard   |  59.4 | 75.55 ||     metal     | 34.52 | 43.81 ||  soft_plastic | 63.95 |  72.4 |+---------------+-------+-------+2022-10-10 23:01:35,165 - mmseg - INFO - Summary:2022-10-10 23:01:35,165 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.82 | 56.32 | 65.14 |+-------+-------+-------+2022-10-10 23:01:35,168 - mmseg - INFO - Saving checkpoint at 40000 iterations