2022-10-10 08:51:07,513 - mmseg - INFO - Environment info:------------------------------------------------------------sys.platform: linuxPython: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]CUDA available: TrueGPU 0: NVIDIA A100-SXM4-80GBCUDA_HOME: /usr/local/cudaNVCC: Build cuda_11.3.r11.3/compiler.29745058_0GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0PyTorch: 1.7.1+cu110PyTorch compiling details: PyTorch built with:  - GCC 7.3  - C++ Version: 201402  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)  - OpenMP 201511 (a.k.a. OpenMP 4.5)  - NNPACK is enabled  - CPU capability usage: AVX2  - CUDA Runtime 11.0  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80  - CuDNN 8.0.5  - Magma 2.5.2  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, TorchVision: 0.8.2+cu110OpenCV: 4.4.0MMCV: 1.3.7MMCV Compiler: GCC 7.3MMCV CUDA Compiler: 11.0MMSegmentation: 0.16.0+e6a2fe4------------------------------------------------------------2022-10-10 08:51:07,513 - mmseg - INFO - Distributed training: False2022-10-10 08:51:08,246 - mmseg - INFO - Config:log_config = dict(    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])dist_params = dict(backend='nccl')log_level = 'INFO'load_from = Noneresume_from = Noneworkflow = [('train', 1)]cudnn_benchmark = Truenorm_cfg = dict(type='BN', requires_grad=True)find_unused_parameters = Truemodel = dict(    type='EncoderDecoderProjector',    pretrained='pretrained/mit_b5.pth',    backbone=dict(type='mit_b5', style='pytorch'),    decode_head=dict(        type='DAFormerHead',        in_channels=[64, 128, 320, 512],        in_index=[0, 1, 2, 3],        channels=256,        dropout_ratio=0.1,        num_classes=5,        norm_cfg=dict(type='BN', requires_grad=True),        align_corners=False,        decoder_params=dict(            embed_dims=256,            embed_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),            embed_neck_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),            fusion_cfg=dict(                type='aspp',                sep=True,                dilations=(1, 6, 12, 18),                pool=False,                act_cfg=dict(type='ReLU'),                norm_cfg=dict(type='BN', requires_grad=True))),        loss_decode=dict(            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),    auxiliary_head=dict(        type='ProjHead',        in_channels=[64, 128, 320, 512],        in_index=[0, 1, 2, 3],        input_transform='resize_concat',        channels=512,        num_convs=2,        dropout_ratio=0.1,        num_classes=5,        norm_cfg=dict(type='BN', requires_grad=True),        align_corners=False,        loss_decode=dict(            type='ContrastiveLoss',            use_dist=True,            use_bank=False,            use_reg=True,            use_avg_pool=True,            scale_min_ratio=0.75,            num_classes=5,            contrast_temp=100.0,            loss_weight=0.01,            reg_relative_weight=0.001)),    train_cfg=dict(        work_dir=        'work_dirs_test/local-exp9/221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d23'    ),    test_cfg=dict(mode='whole'))img_norm_cfg = dict(    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)crop_size = (640, 640)source_train_pipeline = [    dict(type='LoadImageFromFile'),    dict(type='LoadAnnotations'),    dict(type='Resize', img_scale=(1138, 640)),    dict(type='RandomCrop', crop_size=(640, 640), cat_max_ratio=0.75),    dict(type='RandomFlip', prob=0.5),    dict(        type='Normalize',        mean=[123.675, 116.28, 103.53],        std=[58.395, 57.12, 57.375],        to_rgb=True),    dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),    dict(type='DefaultFormatBundle'),    dict(type='Collect', keys=['img', 'gt_semantic_seg'])]target_train_pipeline = [    dict(type='LoadImageFromFile'),    dict(type='LoadAnnotations'),    dict(type='Resize', img_scale=(1138, 640)),    dict(type='RandomCrop', crop_size=(640, 640)),    dict(type='RandomFlip', prob=0.5),    dict(        type='Normalize',        mean=[123.675, 116.28, 103.53],        std=[58.395, 57.12, 57.375],        to_rgb=True),    dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),    dict(type='DefaultFormatBundle'),    dict(type='Collect', keys=['img', 'gt_semantic_seg'])]test_pipeline = [    dict(type='LoadImageFromFile'),    dict(        type='MultiScaleFlipAug',        img_scale=(1138, 640),        flip=False,        transforms=[            dict(type='Resize', keep_ratio=True),            dict(type='RandomFlip'),            dict(                type='Normalize',                mean=[123.675, 116.28, 103.53],                std=[58.395, 57.12, 57.375],                to_rgb=True),            dict(type='ImageToTensor', keys=['img']),            dict(type='Collect', keys=['img'])        ])]data = dict(    samples_per_gpu=2,    workers_per_gpu=4,    train=dict(        type='UDADataset',        source=dict(            type='ZeroWasteDataset',            data_root='data/zerowaste-f/train',            img_dir='data',            ann_dir='sem_seg',            pipeline=[                dict(type='LoadImageFromFile'),                dict(type='LoadAnnotations'),                dict(type='Resize', img_scale=(1138, 640)),                dict(                    type='RandomCrop',                    crop_size=(640, 640),                    cat_max_ratio=0.75),                dict(type='RandomFlip', prob=0.5),                dict(                    type='Normalize',                    mean=[123.675, 116.28, 103.53],                    std=[58.395, 57.12, 57.375],                    to_rgb=True),                dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),                dict(type='DefaultFormatBundle'),                dict(type='Collect', keys=['img', 'gt_semantic_seg'])            ]),        target=dict(            type='ZeroWasteV2Dataset',            data_root='data/zerowaste-v2-splits/train',            img_dir='data',            ann_dir='sem_seg',            pipeline=[                dict(type='LoadImageFromFile'),                dict(type='LoadAnnotations'),                dict(type='Resize', img_scale=(1138, 640)),                dict(type='RandomCrop', crop_size=(640, 640)),                dict(type='RandomFlip', prob=0.5),                dict(                    type='Normalize',                    mean=[123.675, 116.28, 103.53],                    std=[58.395, 57.12, 57.375],                    to_rgb=True),                dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),                dict(type='DefaultFormatBundle'),                dict(type='Collect', keys=['img', 'gt_semantic_seg'])            ])),    val=dict(        type='ZeroWasteDataset',        data_root='data/zerowaste-f/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]),    test=dict(        type='ZeroWasteV2Dataset',        data_root='data/zerowaste-v2-splits/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]))uda = dict(    type='SePiCo',    alpha=0.999,    pseudo_threshold=0.968,    pseudo_weight_ignore_top=15,    pseudo_weight_ignore_bottom=120,    imnet_feature_dist_lambda=0,    imnet_feature_dist_classes=None,    imnet_feature_dist_scale_min_ratio=None,    mix='class',    blur=True,    color_jitter_strength=0.2,    color_jitter_probability=0.2,    debug_img_interval=1000,    print_grad_magnitude=False,    enable_self_training=True,    enable_strong_aug=True,    start_distribution_iter=3000)use_ddp_wrapper = Trueoptimizer = dict(    type='AdamW',    lr=6e-05,    betas=(0.9, 0.999),    weight_decay=0.01,    paramwise_cfg=dict(        custom_keys=dict(            head=dict(lr_mult=10.0),            pos_block=dict(decay_mult=0.0),            norm=dict(decay_mult=0.0))))optimizer_config = Nonelr_config = dict(    policy='poly',    warmup='linear',    warmup_iters=1500,    warmup_ratio=1e-06,    power=1.0,    min_lr=0.0,    by_epoch=False)n_gpus = 1seed = 6926runner = dict(type='IterBasedRunner', max_iters=40000)checkpoint_config = dict(by_epoch=False, interval=40000, max_keep_ckpts=1)evaluation = dict(interval=4000, metric='mIoU')exp = 9name_dataset = 'zerov12zerov2'name_architecture = 'daformer_sepaspp_proj_mitb5'name_encoder = 'mitb5'name_decoder = 'daformer_sepaspp_proj'name_uda = 'dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self'name_opt = 'adamw_6e-05_pmTrue_poly10warm_1x2_40k'name = '221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d23'work_dir = 'work_dirs_test/local-exp9/221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d23'git_rev = 'e6a2fe470f8338b6aa4778416c9ec54b3fdf2542'gpu_ids = range(0, 1)2022-10-10 08:51:08,246 - mmseg - INFO - Set random seed to 6926, deterministic: False/mnt/data/bit/xbh/_visda2022/visda2022-ours/mmseg/models/backbones/mix_transformer.py:214: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead  warnings.warn('DeprecationWarning: pretrained is a deprecated, '2022-10-10 08:51:09,703 - mmseg - INFO - Load mit checkpoint.2022-10-10 08:51:09,704 - mmseg - INFO - Use load_from_local loader/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/cnn/utils/weight_init.py:118: UserWarning: init_cfg without layer key, if you do not define override key either, this init_cfg will do nothing  warnings.warn(2022-10-10 08:51:10,102 - mmseg - INFO - Load mit checkpoint.2022-10-10 08:51:10,102 - mmseg - INFO - Use load_from_local loader2022-10-10 08:51:10,323 - mmseg - INFO - SePiCo(  (model): EncoderDecoderProjector(    (backbone): mit_b5(      (patch_embed1): OverlapPatchEmbed(        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)      )      (patch_embed2): OverlapPatchEmbed(        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)      )      (patch_embed3): OverlapPatchEmbed(        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)      )      (patch_embed4): OverlapPatchEmbed(        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)      )      (block1): ModuleList(        (0): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): Identity()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)      (block2): ModuleList(        (0): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)      (block3): ModuleList(        (0): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (6): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (7): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (8): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (9): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (10): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (11): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (12): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (13): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (14): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (15): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (16): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (17): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (18): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (19): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (20): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (21): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (22): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (23): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (24): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (25): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (26): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (27): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (28): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (29): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (30): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (31): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (32): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (33): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (34): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (35): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (36): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (37): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (38): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (39): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)      (block4): ModuleList(        (0): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)    )    (decode_head): DAFormerHead(      input_transform=multiple_select, ignore_index=255, align_corners=False      (loss_decode): CrossEntropyLoss()      (conv_seg): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))      (dropout): Dropout2d(p=0.1, inplace=False)      (embed_layers): ModuleDict(        (0): MLP(          (proj): Linear(in_features=64, out_features=256, bias=True)        )        (1): MLP(          (proj): Linear(in_features=128, out_features=256, bias=True)        )        (2): MLP(          (proj): Linear(in_features=320, out_features=256, bias=True)        )        (3): MLP(          (proj): Linear(in_features=512, out_features=256, bias=True)        )      )      (fuse_layer): ASPPWrapper(        (aspp_modules): DepthwiseSeparableASPPModule(          (0): ConvModule(            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)            (activate): ReLU(inplace=True)          )          (1): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (2): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (3): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )        )        (bottleneck): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}    (auxiliary_head): ProjHead(      input_transform=resize_concat, ignore_index=255, align_corners=False      (loss_decode): ContrastiveLoss()      (dropout): Dropout2d(p=0.1, inplace=False)      (convs): Sequential(        (0): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )        (1): ConvModule(          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )  )  (ema_model): EncoderDecoderProjector(    (backbone): mit_b5(      (patch_embed1): OverlapPatchEmbed(        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)      )      (patch_embed2): OverlapPatchEmbed(        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)      )      (patch_embed3): OverlapPatchEmbed(        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)      )      (patch_embed4): OverlapPatchEmbed(        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)      )      (block1): ModuleList(        (0): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): Identity()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)      (block2): ModuleList(        (0): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)      (block3): ModuleList(        (0): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (6): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (7): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (8): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (9): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (10): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (11): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (12): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (13): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (14): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (15): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (16): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (17): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (18): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (19): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (20): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (21): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (22): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (23): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (24): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (25): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (26): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (27): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (28): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (29): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (30): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (31): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (32): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (33): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (34): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (35): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (36): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (37): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (38): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (39): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)      (block4): ModuleList(        (0): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)    )    (decode_head): DAFormerHead(      input_transform=multiple_select, ignore_index=255, align_corners=False      (loss_decode): CrossEntropyLoss()      (conv_seg): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))      (dropout): Dropout2d(p=0.1, inplace=False)      (embed_layers): ModuleDict(        (0): MLP(          (proj): Linear(in_features=64, out_features=256, bias=True)        )        (1): MLP(          (proj): Linear(in_features=128, out_features=256, bias=True)        )        (2): MLP(          (proj): Linear(in_features=320, out_features=256, bias=True)        )        (3): MLP(          (proj): Linear(in_features=512, out_features=256, bias=True)        )      )      (fuse_layer): ASPPWrapper(        (aspp_modules): DepthwiseSeparableASPPModule(          (0): ConvModule(            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)            (activate): ReLU(inplace=True)          )          (1): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (2): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (3): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )        )        (bottleneck): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}    (auxiliary_head): ProjHead(      input_transform=resize_concat, ignore_index=255, align_corners=False      (loss_decode): ContrastiveLoss()      (dropout): Dropout2d(p=0.1, inplace=False)      (convs): Sequential(        (0): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )        (1): ConvModule(          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )  ))2022-10-10 08:51:10,388 - mmseg - INFO - Loaded 3002 images from data/zerowaste-f/train/data2022-10-10 08:51:10,484 - mmseg - INFO - Loaded 6216 images from data/zerowaste-v2-splits/train/data2022-10-10 08:51:16,347 - mmseg - INFO - Loaded 929 images from data/zerowaste-f/test/data2022-10-10 08:51:16,347 - mmseg - INFO - Start running, host: root@perception-jupyter, work_dir: /mnt/data/bit/xbh/_visda2022/visda2022-ours/work_dirs_test/local-exp9/221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 08:51:16,347 - mmseg - INFO - workflow: [('train', 1)], max: 40000 itersRun job 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d23/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:52:10,252 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 11:41:20, time: 1.053, data_time: 0.019, memory: 67493, src.decode.loss_seg: 1.5939, src.decode.acc_seg: 27.1931, src.loss: 1.5939, mix.decode.loss_seg: 0.9235, mix.decode.acc_seg: 34.2199, mix.loss: 0.9235/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:52:59,805 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 11:19:45, time: 0.991, data_time: 0.012, memory: 67493, src.decode.loss_seg: 1.4546, src.decode.acc_seg: 61.9509, src.loss: 1.4546, mix.decode.loss_seg: 0.8241, mix.decode.acc_seg: 59.5497, mix.loss: 0.8241/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:53:50,113 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 11:15:21, time: 1.006, data_time: 0.013, memory: 67493, src.decode.loss_seg: 1.2126, src.decode.acc_seg: 77.4520, src.loss: 1.2126, mix.decode.loss_seg: 0.6660, mix.decode.acc_seg: 75.4980, mix.loss: 0.6660/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:54:39,786 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 11:10:38, time: 0.993, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.9475, src.decode.acc_seg: 82.0123, src.loss: 0.9475, mix.decode.loss_seg: 0.5310, mix.decode.acc_seg: 83.4834, mix.loss: 0.5310/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:55:29,331 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 11:07:07, time: 0.991, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.7503, src.decode.acc_seg: 84.4477, src.loss: 0.7503, mix.decode.loss_seg: 0.4074, mix.decode.acc_seg: 85.5736, mix.loss: 0.4074/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:56:18,924 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 11:04:37, time: 0.992, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.5856, src.decode.acc_seg: 86.4547, src.loss: 0.5856, mix.decode.loss_seg: 0.2866, mix.decode.acc_seg: 85.9131, mix.loss: 0.2866/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:57:08,290 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 11:02:09, time: 0.987, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.4925, src.decode.acc_seg: 87.5459, src.loss: 0.4925, mix.decode.loss_seg: 0.2163, mix.decode.acc_seg: 88.9792, mix.loss: 0.2163/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:57:58,042 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 11:00:45, time: 0.995, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.4522, src.decode.acc_seg: 86.4673, src.loss: 0.4522, mix.decode.loss_seg: 0.2547, mix.decode.acc_seg: 87.6221, mix.loss: 0.2547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:58:47,654 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 10:59:15, time: 0.992, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.4410, src.decode.acc_seg: 85.9552, src.loss: 0.4410, mix.decode.loss_seg: 0.2014, mix.decode.acc_seg: 88.4711, mix.loss: 0.2014/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:59:37,159 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 10:57:46, time: 0.990, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3782, src.decode.acc_seg: 88.0296, src.loss: 0.3782, mix.decode.loss_seg: 0.2038, mix.decode.acc_seg: 89.8998, mix.loss: 0.2038/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:00:27,175 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 10:57:00, time: 1.000, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3437, src.decode.acc_seg: 88.6958, src.loss: 0.3437, mix.decode.loss_seg: 0.1702, mix.decode.acc_seg: 90.1201, mix.loss: 0.1702/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:01:17,546 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 10:56:37, time: 1.007, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3836, src.decode.acc_seg: 87.4455, src.loss: 0.3836, mix.decode.loss_seg: 0.2086, mix.decode.acc_seg: 89.4590, mix.loss: 0.2086/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:02:07,892 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 10:56:08, time: 1.007, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3535, src.decode.acc_seg: 88.6022, src.loss: 0.3535, mix.decode.loss_seg: 0.1765, mix.decode.acc_seg: 90.1922, mix.loss: 0.1765/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:02:57,540 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 10:54:57, time: 0.993, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.3666, src.decode.acc_seg: 87.6140, src.loss: 0.3666, mix.decode.loss_seg: 0.1916, mix.decode.acc_seg: 88.6524, mix.loss: 0.1916/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:03:47,232 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 10:53:51, time: 0.994, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3875, src.decode.acc_seg: 86.8271, src.loss: 0.3875, mix.decode.loss_seg: 0.1809, mix.decode.acc_seg: 88.5290, mix.loss: 0.1809/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:04:36,754 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 10:52:39, time: 0.990, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3343, src.decode.acc_seg: 88.5590, src.loss: 0.3343, mix.decode.loss_seg: 0.1582, mix.decode.acc_seg: 89.7865, mix.loss: 0.1582/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:05:26,820 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 10:51:54, time: 1.001, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3634, src.decode.acc_seg: 87.3136, src.loss: 0.3634, mix.decode.loss_seg: 0.1873, mix.decode.acc_seg: 87.7606, mix.loss: 0.1873/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:06:16,289 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 10:50:43, time: 0.989, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3244, src.decode.acc_seg: 88.9992, src.loss: 0.3244, mix.decode.loss_seg: 0.1555, mix.decode.acc_seg: 90.1540, mix.loss: 0.1555/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:07:06,412 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 10:50:01, time: 1.002, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3397, src.decode.acc_seg: 88.0026, src.loss: 0.3397, mix.decode.loss_seg: 0.1649, mix.decode.acc_seg: 89.6884, mix.loss: 0.1649/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:07:56,147 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 09:07:56,147 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 10:49:03, time: 0.995, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3121, src.decode.acc_seg: 89.2007, src.loss: 0.3121, mix.decode.loss_seg: 0.1569, mix.decode.acc_seg: 90.7638, mix.loss: 0.1569/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:08:46,318 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 10:48:22, time: 1.003, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3411, src.decode.acc_seg: 87.8582, src.loss: 0.3411, mix.decode.loss_seg: 0.1683, mix.decode.acc_seg: 89.5701, mix.loss: 0.1683/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:09:35,454 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 10:47:04, time: 0.983, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3123, src.decode.acc_seg: 88.8057, src.loss: 0.3123, mix.decode.loss_seg: 0.1347, mix.decode.acc_seg: 91.4708, mix.loss: 0.1347/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:10:25,321 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 10:46:13, time: 0.997, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2795, src.decode.acc_seg: 90.0181, src.loss: 0.2795, mix.decode.loss_seg: 0.1443, mix.decode.acc_seg: 91.3913, mix.loss: 0.1443/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:11:15,004 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 10:45:16, time: 0.994, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.3118, src.decode.acc_seg: 88.6188, src.loss: 0.3118, mix.decode.loss_seg: 0.1769, mix.decode.acc_seg: 90.7202, mix.loss: 0.1769/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:12:04,126 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 10:44:02, time: 0.982, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2952, src.decode.acc_seg: 89.1911, src.loss: 0.2952, mix.decode.loss_seg: 0.1461, mix.decode.acc_seg: 90.8344, mix.loss: 0.1461/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:12:54,488 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 10:43:27, time: 1.007, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3163, src.decode.acc_seg: 89.1443, src.loss: 0.3163, mix.decode.loss_seg: 0.1774, mix.decode.acc_seg: 90.5179, mix.loss: 0.1774/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:13:44,060 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 10:42:28, time: 0.991, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2788, src.decode.acc_seg: 89.8985, src.loss: 0.2788, mix.decode.loss_seg: 0.1540, mix.decode.acc_seg: 91.1506, mix.loss: 0.1540/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:14:34,193 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 10:41:46, time: 1.003, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2867, src.decode.acc_seg: 89.7858, src.loss: 0.2867, mix.decode.loss_seg: 0.1556, mix.decode.acc_seg: 91.2862, mix.loss: 0.1556/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:15:24,023 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 10:40:55, time: 0.997, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2946, src.decode.acc_seg: 90.2475, src.loss: 0.2946, mix.decode.loss_seg: 0.1707, mix.decode.acc_seg: 91.4340, mix.loss: 0.1707/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:16:14,105 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 10:40:10, time: 1.002, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2957, src.decode.acc_seg: 90.1968, src.loss: 0.2957, mix.decode.loss_seg: 0.1424, mix.decode.acc_seg: 92.4345, mix.loss: 0.1424/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:17:03,992 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 10:39:20, time: 0.998, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3245, src.decode.acc_seg: 88.2025, src.loss: 0.3245, mix.decode.loss_seg: 0.1732, mix.decode.acc_seg: 90.6736, mix.loss: 0.1732/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:17:54,019 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 10:38:34, time: 1.001, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2760, src.decode.acc_seg: 89.9131, src.loss: 0.2760, mix.decode.loss_seg: 0.1536, mix.decode.acc_seg: 91.3288, mix.loss: 0.1536/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:18:43,187 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 10:37:27, time: 0.983, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2810, src.decode.acc_seg: 89.7808, src.loss: 0.2810, mix.decode.loss_seg: 0.1353, mix.decode.acc_seg: 91.9138, mix.loss: 0.1353/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:19:32,324 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 10:36:21, time: 0.983, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2767, src.decode.acc_seg: 90.8303, src.loss: 0.2767, mix.decode.loss_seg: 0.1495, mix.decode.acc_seg: 92.9873, mix.loss: 0.1495/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:20:21,433 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 10:35:15, time: 0.982, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2817, src.decode.acc_seg: 89.8915, src.loss: 0.2817, mix.decode.loss_seg: 0.1547, mix.decode.acc_seg: 92.4956, mix.loss: 0.1547/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:21:10,988 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 10:34:19, time: 0.991, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2981, src.decode.acc_seg: 89.8305, src.loss: 0.2981, mix.decode.loss_seg: 0.1760, mix.decode.acc_seg: 91.5086, mix.loss: 0.1760/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:22:00,960 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 10:33:33, time: 0.999, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.3265, src.decode.acc_seg: 88.3627, src.loss: 0.3265, mix.decode.loss_seg: 0.1853, mix.decode.acc_seg: 91.0868, mix.loss: 0.1853/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:22:50,843 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 10:32:44, time: 0.998, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2644, src.decode.acc_seg: 90.4433, src.loss: 0.2644, mix.decode.loss_seg: 0.1414, mix.decode.acc_seg: 92.4158, mix.loss: 0.1414/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:23:40,134 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 10:31:44, time: 0.986, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2955, src.decode.acc_seg: 89.1172, src.loss: 0.2955, mix.decode.loss_seg: 0.1755, mix.decode.acc_seg: 92.2813, mix.loss: 0.1755/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:24:29,562 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 09:24:29,562 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 10:30:47, time: 0.989, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2601, src.decode.acc_seg: 90.8653, src.loss: 0.2601, mix.decode.loss_seg: 0.1591, mix.decode.acc_seg: 92.5619, mix.loss: 0.1591/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:25:18,640 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 10:29:44, time: 0.982, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2724, src.decode.acc_seg: 90.1763, src.loss: 0.2724, mix.decode.loss_seg: 0.1465, mix.decode.acc_seg: 93.0261, mix.loss: 0.1465/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:26:07,872 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 10:28:44, time: 0.985, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2431, src.decode.acc_seg: 91.0675, src.loss: 0.2431, mix.decode.loss_seg: 0.1415, mix.decode.acc_seg: 93.3369, mix.loss: 0.1415/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:26:57,787 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 10:27:57, time: 0.998, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2549, src.decode.acc_seg: 91.0294, src.loss: 0.2549, mix.decode.loss_seg: 0.1352, mix.decode.acc_seg: 94.0716, mix.loss: 0.1352/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:27:47,500 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 10:27:06, time: 0.994, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2527, src.decode.acc_seg: 90.3211, src.loss: 0.2527, mix.decode.loss_seg: 0.1456, mix.decode.acc_seg: 92.6879, mix.loss: 0.1456/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:28:36,867 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 10:26:10, time: 0.987, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2713, src.decode.acc_seg: 90.5762, src.loss: 0.2713, mix.decode.loss_seg: 0.1354, mix.decode.acc_seg: 93.9180, mix.loss: 0.1354/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:29:26,727 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 10:25:21, time: 0.997, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2520, src.decode.acc_seg: 91.1026, src.loss: 0.2520, mix.decode.loss_seg: 0.1330, mix.decode.acc_seg: 94.0950, mix.loss: 0.1330/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:30:16,267 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 10:24:28, time: 0.991, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2226, src.decode.acc_seg: 91.9667, src.loss: 0.2226, mix.decode.loss_seg: 0.1319, mix.decode.acc_seg: 93.5813, mix.loss: 0.1319/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:31:06,276 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 10:23:42, time: 1.000, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2376, src.decode.acc_seg: 91.7810, src.loss: 0.2376, mix.decode.loss_seg: 0.1221, mix.decode.acc_seg: 93.9110, mix.loss: 0.1221/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:31:55,699 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 10:22:47, time: 0.988, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2559, src.decode.acc_seg: 90.8889, src.loss: 0.2559, mix.decode.loss_seg: 0.1562, mix.decode.acc_seg: 92.9788, mix.loss: 0.1562/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:32:45,375 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 10:21:56, time: 0.994, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2635, src.decode.acc_seg: 90.8933, src.loss: 0.2635, mix.decode.loss_seg: 0.1387, mix.decode.acc_seg: 93.5784, mix.loss: 0.1387/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:33:35,282 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 10:21:09, time: 0.998, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2683, src.decode.acc_seg: 89.9231, src.loss: 0.2683, mix.decode.loss_seg: 0.1331, mix.decode.acc_seg: 93.0938, mix.loss: 0.1331/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:34:24,808 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 10:20:16, time: 0.991, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2295, src.decode.acc_seg: 92.0894, src.loss: 0.2295, mix.decode.loss_seg: 0.1161, mix.decode.acc_seg: 94.3112, mix.loss: 0.1161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:35:13,792 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 10:19:15, time: 0.980, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2652, src.decode.acc_seg: 90.2639, src.loss: 0.2652, mix.decode.loss_seg: 0.1580, mix.decode.acc_seg: 93.0513, mix.loss: 0.1580/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:36:03,171 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 10:18:20, time: 0.988, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2420, src.decode.acc_seg: 91.5997, src.loss: 0.2420, mix.decode.loss_seg: 0.1273, mix.decode.acc_seg: 94.2776, mix.loss: 0.1273/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:36:52,838 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 10:17:30, time: 0.993, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2188, src.decode.acc_seg: 91.7730, src.loss: 0.2188, mix.decode.loss_seg: 0.1126, mix.decode.acc_seg: 94.5121, mix.loss: 0.1126/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:37:43,057 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 10:16:46, time: 1.004, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2386, src.decode.acc_seg: 91.2317, src.loss: 0.2386, mix.decode.loss_seg: 0.1317, mix.decode.acc_seg: 94.3306, mix.loss: 0.1317/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:38:32,880 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 10:15:58, time: 0.996, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2413, src.decode.acc_seg: 91.5543, src.loss: 0.2413, mix.decode.loss_seg: 0.1281, mix.decode.acc_seg: 93.8515, mix.loss: 0.1281/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:39:22,250 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 10:15:03, time: 0.987, data_time: 0.012, memory: 67493, src.decode.loss_seg: 0.2405, src.decode.acc_seg: 91.2958, src.loss: 0.2405, mix.decode.loss_seg: 0.1501, mix.decode.acc_seg: 93.2545, mix.loss: 0.1501/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:40:12,071 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 10:14:15, time: 0.996, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2247, src.decode.acc_seg: 91.7497, src.loss: 0.2247, mix.decode.loss_seg: 0.1398, mix.decode.acc_seg: 93.3181, mix.loss: 0.1398/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:41:02,062 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 09:41:02,062 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 10:13:28, time: 1.000, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2175, src.decode.acc_seg: 92.0472, src.loss: 0.2175, mix.decode.loss_seg: 0.1171, mix.decode.acc_seg: 94.4127, mix.loss: 0.1171/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:42:03,566 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 10:15:01, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2417, src.decode.acc_seg: 90.8221, src.loss: 0.2578, mix.decode.loss_seg: 0.1323, mix.decode.acc_seg: 93.8993, mix.loss: 0.1323, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:43:05,142 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 10:16:29, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2142, src.decode.acc_seg: 92.4481, src.loss: 0.2302, mix.decode.loss_seg: 0.1183, mix.decode.acc_seg: 95.0420, mix.loss: 0.1183, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:44:06,641 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 10:17:52, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2746, src.decode.acc_seg: 89.8140, src.loss: 0.2907, mix.decode.loss_seg: 0.1527, mix.decode.acc_seg: 93.4993, mix.loss: 0.1527, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:45:07,788 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 10:19:07, time: 1.223, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2490, src.decode.acc_seg: 91.0724, src.loss: 0.2650, mix.decode.loss_seg: 0.1329, mix.decode.acc_seg: 94.6898, mix.loss: 0.1329, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:46:09,970 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 10:20:29, time: 1.244, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2549, src.decode.acc_seg: 91.0654, src.loss: 0.2710, mix.decode.loss_seg: 0.1359, mix.decode.acc_seg: 93.8999, mix.loss: 0.1359, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:47:11,796 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 10:21:42, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2389, src.decode.acc_seg: 91.4912, src.loss: 0.2550, mix.decode.loss_seg: 0.1298, mix.decode.acc_seg: 94.0164, mix.loss: 0.1298, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:48:13,148 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 10:22:47, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2202, src.decode.acc_seg: 91.9112, src.loss: 0.2363, mix.decode.loss_seg: 0.1135, mix.decode.acc_seg: 94.7854, mix.loss: 0.1135, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:49:14,894 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 10:23:52, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2293, src.decode.acc_seg: 91.5204, src.loss: 0.2454, mix.decode.loss_seg: 0.1320, mix.decode.acc_seg: 94.4985, mix.loss: 0.1320, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:50:16,442 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 10:24:51, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2041, src.decode.acc_seg: 92.4466, src.loss: 0.2202, mix.decode.loss_seg: 0.1035, mix.decode.acc_seg: 95.2810, mix.loss: 0.1035, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:51:17,784 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 10:25:44, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1970, src.decode.acc_seg: 92.9413, src.loss: 0.2131, mix.decode.loss_seg: 0.1134, mix.decode.acc_seg: 94.8809, mix.loss: 0.1134, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:52:19,667 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 10:26:40, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1782, src.decode.acc_seg: 93.6325, src.loss: 0.1943, mix.decode.loss_seg: 0.1099, mix.decode.acc_seg: 95.2477, mix.loss: 0.1099, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:53:21,318 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 10:27:30, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2050, src.decode.acc_seg: 93.0140, src.loss: 0.2211, mix.decode.loss_seg: 0.1285, mix.decode.acc_seg: 94.5333, mix.loss: 0.1285, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:54:23,007 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 10:28:18, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2079, src.decode.acc_seg: 92.4866, src.loss: 0.2240, mix.decode.loss_seg: 0.1043, mix.decode.acc_seg: 95.5082, mix.loss: 0.1043, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:55:24,668 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 10:29:02, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2572, src.decode.acc_seg: 90.7220, src.loss: 0.2732, mix.decode.loss_seg: 0.1326, mix.decode.acc_seg: 94.2757, mix.loss: 0.1326, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:56:26,250 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 10:29:43, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2188, src.decode.acc_seg: 92.3449, src.loss: 0.2349, mix.decode.loss_seg: 0.1245, mix.decode.acc_seg: 94.6002, mix.loss: 0.1245, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:57:27,688 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 10:30:20, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2230, src.decode.acc_seg: 92.0961, src.loss: 0.2391, mix.decode.loss_seg: 0.1173, mix.decode.acc_seg: 94.8048, mix.loss: 0.1173, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:58:29,477 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 10:30:57, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1975, src.decode.acc_seg: 93.0816, src.loss: 0.2136, mix.decode.loss_seg: 0.1055, mix.decode.acc_seg: 95.4343, mix.loss: 0.1055, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:59:31,110 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 10:31:31, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2036, src.decode.acc_seg: 92.3489, src.loss: 0.2197, mix.decode.loss_seg: 0.1241, mix.decode.acc_seg: 94.4496, mix.loss: 0.1241, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:00:32,710 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 10:32:01, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2049, src.decode.acc_seg: 92.4108, src.loss: 0.2210, mix.decode.loss_seg: 0.1079, mix.decode.acc_seg: 95.4787, mix.loss: 0.1079, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.4 task/s, elapsed: 1s, ETA:   643s[                                 ] 2/929, 2.5 task/s, elapsed: 1s, ETA:   366s[                                 ] 3/929, 3.4 task/s, elapsed: 1s, ETA:   275s[                                 ] 4/929, 4.1 task/s, elapsed: 1s, ETA:   228s[                                 ] 5/929, 4.6 task/s, elapsed: 1s, ETA:   200s[                                 ] 6/929, 5.0 task/s, elapsed: 1s, ETA:   183s[                                 ] 7/929, 5.4 task/s, elapsed: 1s, ETA:   171s[                                 ] 8/929, 5.7 task/s, elapsed: 1s, ETA:   162s[                                 ] 9/929, 6.0 task/s, elapsed: 2s, ETA:   154s[                                ] 10/929, 6.2 task/s, elapsed: 2s, ETA:   148s[                                ] 11/929, 6.4 task/s, elapsed: 2s, ETA:   143s[                                ] 12/929, 6.6 task/s, elapsed: 2s, ETA:   140s[                                ] 13/929, 6.7 task/s, elapsed: 2s, ETA:   136s[                                ] 14/929, 6.9 task/s, elapsed: 2s, ETA:   133s[                                ] 15/929, 7.0 task/s, elapsed: 2s, ETA:   130s[                                ] 16/929, 7.1 task/s, elapsed: 2s, ETA:   128s[                                ] 17/929, 7.3 task/s, elapsed: 2s, ETA:   126s[                                ] 18/929, 7.4 task/s, elapsed: 2s, ETA:   123s[                                ] 19/929, 7.5 task/s, elapsed: 3s, ETA:   122s[                                ] 20/929, 7.6 task/s, elapsed: 3s, ETA:   120s[                                ] 21/929, 7.7 task/s, elapsed: 3s, ETA:   118s[                                ] 22/929, 7.8 task/s, elapsed: 3s, ETA:   117s[                                ] 23/929, 7.8 task/s, elapsed: 3s, ETA:   116s[                                ] 24/929, 7.9 task/s, elapsed: 3s, ETA:   114s[                                ] 25/929, 8.0 task/s, elapsed: 3s, ETA:   113s[                                ] 26/929, 8.1 task/s, elapsed: 3s, ETA:   112s[                                ] 27/929, 8.1 task/s, elapsed: 3s, ETA:   111s[                                ] 28/929, 8.1 task/s, elapsed: 3s, ETA:   111s[                                ] 29/929, 8.2 task/s, elapsed: 4s, ETA:   110s[>                               ] 30/929, 8.2 task/s, elapsed: 4s, ETA:   110s[>                               ] 31/929, 8.2 task/s, elapsed: 4s, ETA:   109s[>                               ] 32/929, 8.3 task/s, elapsed: 4s, ETA:   109s[>                               ] 33/929, 8.3 task/s, elapsed: 4s, ETA:   108s[>                               ] 34/929, 8.3 task/s, elapsed: 4s, ETA:   107s[>                               ] 35/929, 8.4 task/s, elapsed: 4s, ETA:   106s[>                               ] 36/929, 8.5 task/s, elapsed: 4s, ETA:   106s[>                               ] 37/929, 8.5 task/s, elapsed: 4s, ETA:   105s[>                               ] 38/929, 8.6 task/s, elapsed: 4s, ETA:   104s[>                               ] 39/929, 8.6 task/s, elapsed: 5s, ETA:   104s[>                               ] 40/929, 8.6 task/s, elapsed: 5s, ETA:   103s[>                               ] 41/929, 8.7 task/s, elapsed: 5s, ETA:   102s[>                               ] 42/929, 8.7 task/s, elapsed: 5s, ETA:   102s[>                               ] 43/929, 8.7 task/s, elapsed: 5s, ETA:   102s[>                               ] 44/929, 8.8 task/s, elapsed: 5s, ETA:   101s[>                               ] 45/929, 8.8 task/s, elapsed: 5s, ETA:   100s[>                               ] 46/929, 8.8 task/s, elapsed: 5s, ETA:   100s[>                               ] 47/929, 8.9 task/s, elapsed: 5s, ETA:    99s[>                               ] 48/929, 8.9 task/s, elapsed: 5s, ETA:    99s[>                               ] 49/929, 8.9 task/s, elapsed: 5s, ETA:    98s[>                               ] 50/929, 9.0 task/s, elapsed: 6s, ETA:    98s[>                               ] 51/929, 9.0 task/s, elapsed: 6s, ETA:    98s[>                               ] 52/929, 9.0 task/s, elapsed: 6s, ETA:    97s[>                               ] 53/929, 9.1 task/s, elapsed: 6s, ETA:    97s[>                               ] 54/929, 9.1 task/s, elapsed: 6s, ETA:    96s[>                               ] 55/929, 9.1 task/s, elapsed: 6s, ETA:    96s[>                               ] 56/929, 9.1 task/s, elapsed: 6s, ETA:    96s[>                               ] 57/929, 9.1 task/s, elapsed: 6s, ETA:    96s[>                               ] 58/929, 9.1 task/s, elapsed: 6s, ETA:    96s[>>                              ] 59/929, 9.1 task/s, elapsed: 6s, ETA:    95s[>>                              ] 60/929, 9.2 task/s, elapsed: 7s, ETA:    95s[>>                              ] 61/929, 9.2 task/s, elapsed: 7s, ETA:    95s[>>                              ] 62/929, 9.2 task/s, elapsed: 7s, ETA:    94s[>>                              ] 63/929, 9.2 task/s, elapsed: 7s, ETA:    94s[>>                              ] 64/929, 9.2 task/s, elapsed: 7s, ETA:    94s[>>                              ] 65/929, 9.3 task/s, elapsed: 7s, ETA:    93s[>>                              ] 66/929, 9.3 task/s, elapsed: 7s, ETA:    93s[>>                              ] 67/929, 9.3 task/s, elapsed: 7s, ETA:    93s[>>                              ] 68/929, 9.3 task/s, elapsed: 7s, ETA:    92s[>>                              ] 69/929, 9.3 task/s, elapsed: 7s, ETA:    92s[>>                              ] 70/929, 9.4 task/s, elapsed: 7s, ETA:    92s[>>                              ] 71/929, 9.4 task/s, elapsed: 8s, ETA:    92s[>>                              ] 72/929, 9.4 task/s, elapsed: 8s, ETA:    91s[>>                              ] 73/929, 9.4 task/s, elapsed: 8s, ETA:    91s[>>                              ] 74/929, 9.4 task/s, elapsed: 8s, ETA:    91s[>>                              ] 75/929, 9.4 task/s, elapsed: 8s, ETA:    91s[>>                              ] 76/929, 9.4 task/s, elapsed: 8s, ETA:    90s[>>                              ] 77/929, 9.5 task/s, elapsed: 8s, ETA:    90s[>>                              ] 78/929, 9.5 task/s, elapsed: 8s, ETA:    90s[>>                              ] 79/929, 9.5 task/s, elapsed: 8s, ETA:    90s[>>                              ] 80/929, 9.5 task/s, elapsed: 8s, ETA:    89s[>>                              ] 81/929, 9.5 task/s, elapsed: 9s, ETA:    89s[>>                              ] 82/929, 9.5 task/s, elapsed: 9s, ETA:    89s[>>                              ] 83/929, 9.5 task/s, elapsed: 9s, ETA:    89s[>>                              ] 84/929, 9.5 task/s, elapsed: 9s, ETA:    89s[>>                              ] 85/929, 9.5 task/s, elapsed: 9s, ETA:    89s[>>                              ] 86/929, 9.5 task/s, elapsed: 9s, ETA:    88s[>>                              ] 87/929, 9.5 task/s, elapsed: 9s, ETA:    88s[>>>                             ] 88/929, 9.5 task/s, elapsed: 9s, ETA:    88s[>>>                             ] 89/929, 9.6 task/s, elapsed: 9s, ETA:    88s[>>>                             ] 90/929, 9.6 task/s, elapsed: 9s, ETA:    88s[>>>                            ] 91/929, 9.6 task/s, elapsed: 10s, ETA:    88s[>>>                            ] 92/929, 9.6 task/s, elapsed: 10s, ETA:    87s[>>>                            ] 93/929, 9.6 task/s, elapsed: 10s, ETA:    87s[>>>                            ] 94/929, 9.6 task/s, elapsed: 10s, ETA:    87s[>>>                            ] 95/929, 9.5 task/s, elapsed: 10s, ETA:    87s[>>>                            ] 96/929, 9.6 task/s, elapsed: 10s, ETA:    87s[>>>                            ] 97/929, 9.6 task/s, elapsed: 10s, ETA:    87s[>>>                            ] 98/929, 9.6 task/s, elapsed: 10s, ETA:    87s[>>>                            ] 99/929, 9.6 task/s, elapsed: 10s, ETA:    87s[>>>                           ] 100/929, 9.6 task/s, elapsed: 10s, ETA:    86s[>>>                           ] 101/929, 9.6 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 102/929, 9.6 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 103/929, 9.6 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 104/929, 9.6 task/s, elapsed: 11s, ETA:    86s[>>>                           ] 105/929, 9.6 task/s, elapsed: 11s, ETA:    85s[>>>                           ] 106/929, 9.7 task/s, elapsed: 11s, ETA:    85s[>>>                           ] 107/929, 9.7 task/s, elapsed: 11s, ETA:    85s[>>>                           ] 108/929, 9.7 task/s, elapsed: 11s, ETA:    85s[>>>                           ] 109/929, 9.7 task/s, elapsed: 11s, ETA:    85s[>>>                           ] 110/929, 9.7 task/s, elapsed: 11s, ETA:    85s[>>>                           ] 111/929, 9.7 task/s, elapsed: 11s, ETA:    85s[>>>                           ] 112/929, 9.7 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 113/929, 9.7 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 114/929, 9.7 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 115/929, 9.7 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 116/929, 9.7 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 117/929, 9.7 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 118/929, 9.7 task/s, elapsed: 12s, ETA:    84s[>>>                           ] 119/929, 9.7 task/s, elapsed: 12s, ETA:    83s[>>>                           ] 120/929, 9.7 task/s, elapsed: 12s, ETA:    83s[>>>                           ] 121/929, 9.7 task/s, elapsed: 12s, ETA:    83s[>>>                           ] 122/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>                           ] 123/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 124/929, 9.7 task/s, elapsed: 13s, ETA:    83s[>>>>                          ] 125/929, 9.7 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 126/929, 9.8 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 127/929, 9.8 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 128/929, 9.8 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 129/929, 9.8 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 130/929, 9.8 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 131/929, 9.8 task/s, elapsed: 13s, ETA:    82s[>>>>                          ] 132/929, 9.8 task/s, elapsed: 13s, ETA:    81s[>>>>                          ] 133/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 134/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 135/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 136/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 137/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 138/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 139/929, 9.8 task/s, elapsed: 14s, ETA:    81s[>>>>                          ] 140/929, 9.8 task/s, elapsed: 14s, ETA:    80s[>>>>                          ] 141/929, 9.8 task/s, elapsed: 14s, ETA:    80s[>>>>                          ] 142/929, 9.8 task/s, elapsed: 14s, ETA:    80s[>>>>                          ] 143/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 144/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 145/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 146/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 147/929, 9.8 task/s, elapsed: 15s, ETA:    80s[>>>>                          ] 148/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 149/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 150/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 151/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 152/929, 9.8 task/s, elapsed: 15s, ETA:    79s[>>>>                          ] 153/929, 9.8 task/s, elapsed: 16s, ETA:    79s[>>>>                          ] 154/929, 9.9 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 155/929, 9.9 task/s, elapsed: 16s, ETA:    79s[>>>>>                         ] 156/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 157/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 158/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 159/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 160/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 161/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 162/929, 9.9 task/s, elapsed: 16s, ETA:    78s[>>>>>                         ] 163/929, 9.9 task/s, elapsed: 17s, ETA:    78s[>>>>>                         ] 164/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 165/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 166/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 167/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 168/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 169/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 170/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 171/929, 9.9 task/s, elapsed: 17s, ETA:    77s[>>>>>                         ] 172/929, 9.9 task/s, elapsed: 17s, ETA:    76s[>>>>>                         ] 173/929, 9.9 task/s, elapsed: 17s, ETA:    76s[>>>>>                         ] 174/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 175/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 176/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 177/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 178/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 179/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 180/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 181/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 182/929, 9.9 task/s, elapsed: 18s, ETA:    76s[>>>>>                         ] 183/929, 9.9 task/s, elapsed: 18s, ETA:    75s[>>>>>                         ] 184/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>                         ] 185/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 186/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 187/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 188/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 189/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 190/929, 9.9 task/s, elapsed: 19s, ETA:    75s[>>>>>>                        ] 191/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 192/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 193/929, 9.9 task/s, elapsed: 19s, ETA:    74s[>>>>>>                        ] 194/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 195/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 196/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 197/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 198/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 199/929, 9.9 task/s, elapsed: 20s, ETA:    74s[>>>>>>                        ] 200/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 201/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 202/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 203/929, 9.9 task/s, elapsed: 20s, ETA:    73s[>>>>>>                        ] 204/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 205/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 206/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 207/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 208/929, 9.9 task/s, elapsed: 21s, ETA:    73s[>>>>>>                        ] 209/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 210/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 211/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 212/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                        ] 213/929, 9.9 task/s, elapsed: 21s, ETA:    72s[>>>>>>                       ] 214/929, 10.0 task/s, elapsed: 22s, ETA:    72s[>>>>>>                       ] 215/929, 10.0 task/s, elapsed: 22s, ETA:    72s[>>>>>>                       ] 216/929, 10.0 task/s, elapsed: 22s, ETA:    72s[>>>>>>                       ] 217/929, 10.0 task/s, elapsed: 22s, ETA:    72s[>>>>>>>                       ] 218/929, 9.9 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 219/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 220/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 221/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 222/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 223/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>                       ] 224/929, 10.0 task/s, elapsed: 22s, ETA:    71s[>>>>>>>                      ] 225/929, 10.0 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                      ] 226/929, 10.0 task/s, elapsed: 23s, ETA:    71s[>>>>>>>                      ] 227/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 228/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 229/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 230/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 231/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 232/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 233/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 234/929, 10.0 task/s, elapsed: 23s, ETA:    70s[>>>>>>>                      ] 235/929, 10.0 task/s, elapsed: 24s, ETA:    70s[>>>>>>>                      ] 236/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 237/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 238/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 239/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 240/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 241/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 242/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 243/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 244/929, 10.0 task/s, elapsed: 24s, ETA:    69s[>>>>>>>                      ] 245/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 246/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 247/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 248/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 249/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 250/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 251/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 252/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 253/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 254/929, 10.0 task/s, elapsed: 25s, ETA:    68s[>>>>>>>                      ] 255/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>                      ] 256/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 257/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 258/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 259/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 260/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 261/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 262/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 263/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 264/929, 10.0 task/s, elapsed: 26s, ETA:    67s[>>>>>>>>                     ] 265/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 266/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 267/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 268/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 269/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 270/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 271/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 272/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 273/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 274/929, 10.0 task/s, elapsed: 27s, ETA:    66s[>>>>>>>>                     ] 275/929, 10.0 task/s, elapsed: 28s, ETA:    66s[>>>>>>>>                     ] 276/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 277/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 278/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 279/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 280/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 281/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 282/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 283/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 284/929, 10.0 task/s, elapsed: 28s, ETA:    65s[>>>>>>>>                     ] 285/929, 10.0 task/s, elapsed: 29s, ETA:    65s[>>>>>>>>                     ] 286/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 287/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>                     ] 288/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 289/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 290/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 291/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 292/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 293/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 294/929, 10.0 task/s, elapsed: 29s, ETA:    64s[>>>>>>>>>                    ] 295/929, 10.0 task/s, elapsed: 30s, ETA:    64s[>>>>>>>>>                    ] 296/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 297/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 298/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 299/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 300/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 301/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 302/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 303/929, 10.0 task/s, elapsed: 30s, ETA:    63s[>>>>>>>>>                    ] 304/929, 10.0 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                    ] 305/929, 10.0 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                    ] 306/929, 10.0 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                    ] 307/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 308/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 309/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 310/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 311/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 312/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 313/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 314/929, 10.0 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>                    ] 315/929, 10.0 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>                    ] 316/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 317/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 318/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 319/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>                    ] 320/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 321/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 322/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 323/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 324/929, 10.0 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                   ] 325/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 326/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 327/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 328/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 329/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 330/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 331/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 332/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 333/929, 10.0 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                   ] 334/929, 10.0 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 335/929, 10.0 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                   ] 336/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 337/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 338/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 339/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 340/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 341/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 342/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 343/929, 10.0 task/s, elapsed: 34s, ETA:    59s[>>>>>>>>>>                   ] 344/929, 10.0 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 345/929, 10.0 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>                   ] 346/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 347/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 348/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 349/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 350/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 351/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>                   ] 352/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                  ] 353/929, 10.0 task/s, elapsed: 35s, ETA:    58s[>>>>>>>>>>>                  ] 354/929, 10.0 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 355/929, 10.0 task/s, elapsed: 35s, ETA:    57s[>>>>>>>>>>>                  ] 356/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 357/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 358/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 359/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 360/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 361/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 362/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 363/929, 10.0 task/s, elapsed: 36s, ETA:    57s[>>>>>>>>>>>                  ] 364/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 365/929, 10.0 task/s, elapsed: 36s, ETA:    56s[>>>>>>>>>>>                  ] 366/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 367/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 368/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 369/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 370/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 371/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 372/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 373/929, 10.0 task/s, elapsed: 37s, ETA:    56s[>>>>>>>>>>>                  ] 374/929, 10.0 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 375/929, 10.0 task/s, elapsed: 37s, ETA:    55s[>>>>>>>>>>>                  ] 376/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 377/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 378/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 379/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 380/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 381/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 382/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 383/929, 10.0 task/s, elapsed: 38s, ETA:    55s[>>>>>>>>>>>                  ] 384/929, 10.0 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 385/929, 10.0 task/s, elapsed: 38s, ETA:    54s[>>>>>>>>>>>>                 ] 386/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 387/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 388/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 389/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 390/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 391/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 392/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 393/929, 10.0 task/s, elapsed: 39s, ETA:    54s[>>>>>>>>>>>>                 ] 394/929, 10.0 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 395/929, 10.0 task/s, elapsed: 39s, ETA:    53s[>>>>>>>>>>>>                 ] 396/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 397/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 398/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 399/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 400/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 401/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 402/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 403/929, 10.0 task/s, elapsed: 40s, ETA:    53s[>>>>>>>>>>>>                 ] 404/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 405/929, 10.0 task/s, elapsed: 40s, ETA:    52s[>>>>>>>>>>>>                 ] 406/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 407/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 408/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 409/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 410/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 411/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 412/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 413/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 414/929, 10.0 task/s, elapsed: 41s, ETA:    52s[>>>>>>>>>>>>                 ] 415/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>                 ] 416/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 417/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 418/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 419/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 420/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 421/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 422/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 423/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 424/929, 10.0 task/s, elapsed: 42s, ETA:    51s[>>>>>>>>>>>>>                ] 425/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 426/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 427/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 428/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 429/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 430/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 431/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 432/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 433/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 434/929, 10.0 task/s, elapsed: 43s, ETA:    50s[>>>>>>>>>>>>>                ] 435/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 436/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 437/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 438/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 439/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 440/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 441/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 442/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 443/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 444/929, 10.0 task/s, elapsed: 44s, ETA:    49s[>>>>>>>>>>>>>                ] 445/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>                ] 446/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>                ] 447/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>                ] 448/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 449/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 450/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 451/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 452/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 453/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 454/929, 10.0 task/s, elapsed: 45s, ETA:    48s[>>>>>>>>>>>>>>               ] 455/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 456/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 457/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 458/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 459/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 460/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 461/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 462/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 463/929, 10.0 task/s, elapsed: 46s, ETA:    47s[>>>>>>>>>>>>>>               ] 464/929, 10.0 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>               ] 465/929, 10.0 task/s, elapsed: 47s, ETA:    47s[>>>>>>>>>>>>>>               ] 466/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 467/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 468/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 469/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 470/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 471/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 472/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 473/929, 10.0 task/s, elapsed: 47s, ETA:    46s[>>>>>>>>>>>>>>               ] 474/929, 10.0 task/s, elapsed: 48s, ETA:    46s[>>>>>>>>>>>>>>               ] 475/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 476/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 477/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 478/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 479/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>               ] 480/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 481/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 482/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 483/929, 10.0 task/s, elapsed: 48s, ETA:    45s[>>>>>>>>>>>>>>>              ] 484/929, 10.0 task/s, elapsed: 49s, ETA:    45s[>>>>>>>>>>>>>>>              ] 485/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 486/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 487/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 488/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 489/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 490/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 491/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 492/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 493/929, 10.0 task/s, elapsed: 49s, ETA:    44s[>>>>>>>>>>>>>>>              ] 494/929, 10.0 task/s, elapsed: 50s, ETA:    44s[>>>>>>>>>>>>>>>              ] 495/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 496/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 497/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 498/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 499/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 500/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 501/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 502/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 503/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 504/929, 10.0 task/s, elapsed: 50s, ETA:    43s[>>>>>>>>>>>>>>>              ] 505/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 506/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 507/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 508/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 509/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 510/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 511/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>              ] 512/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>>             ] 513/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>>             ] 514/929, 10.0 task/s, elapsed: 51s, ETA:    42s[>>>>>>>>>>>>>>>>             ] 515/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 516/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 517/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 518/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 519/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 520/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 521/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 522/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 523/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 524/929, 10.0 task/s, elapsed: 52s, ETA:    41s[>>>>>>>>>>>>>>>>             ] 525/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 526/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 527/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 528/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 529/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 530/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 531/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 532/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 533/929, 10.0 task/s, elapsed: 53s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 534/929, 10.0 task/s, elapsed: 54s, ETA:    40s[>>>>>>>>>>>>>>>>             ] 535/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 536/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 537/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 538/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 539/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 540/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 541/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 542/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 543/929, 10.0 task/s, elapsed: 54s, ETA:    39s[>>>>>>>>>>>>>>>>             ] 544/929, 10.0 task/s, elapsed: 55s, ETA:    39s[>>>>>>>>>>>>>>>>>            ] 545/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 546/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 547/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 548/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 549/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 550/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 551/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 552/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 553/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 554/929, 10.0 task/s, elapsed: 55s, ETA:    38s[>>>>>>>>>>>>>>>>>            ] 555/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 556/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 557/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 558/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 559/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 560/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 561/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 562/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 563/929, 10.0 task/s, elapsed: 56s, ETA:    37s[>>>>>>>>>>>>>>>>>            ] 564/929, 10.0 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 565/929, 10.0 task/s, elapsed: 56s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 566/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 567/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 568/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 569/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 570/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 571/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 572/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 573/929, 10.0 task/s, elapsed: 57s, ETA:    36s[>>>>>>>>>>>>>>>>>            ] 574/929, 10.0 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 575/929, 10.0 task/s, elapsed: 57s, ETA:    35s[>>>>>>>>>>>>>>>>>            ] 576/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 577/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 578/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 579/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 580/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 581/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 582/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 583/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 584/929, 10.0 task/s, elapsed: 58s, ETA:    35s[>>>>>>>>>>>>>>>>>>           ] 585/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 586/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 587/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 588/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 589/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 590/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 591/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 592/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 593/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 594/929, 10.0 task/s, elapsed: 59s, ETA:    34s[>>>>>>>>>>>>>>>>>>           ] 595/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 596/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 597/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 598/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 599/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 600/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 601/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 602/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 603/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 604/929, 10.0 task/s, elapsed: 60s, ETA:    33s[>>>>>>>>>>>>>>>>>>           ] 605/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 606/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 607/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>           ] 608/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 609/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 610/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 611/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 612/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 613/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 614/929, 10.0 task/s, elapsed: 61s, ETA:    32s[>>>>>>>>>>>>>>>>>>>          ] 615/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 616/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 617/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 618/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 619/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 620/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 621/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 622/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 623/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 624/929, 10.0 task/s, elapsed: 62s, ETA:    31s[>>>>>>>>>>>>>>>>>>>          ] 625/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 626/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 627/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 628/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 629/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 630/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 631/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 632/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 633/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 634/929, 10.0 task/s, elapsed: 63s, ETA:    30s[>>>>>>>>>>>>>>>>>>>          ] 635/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 636/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 637/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 638/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 639/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>          ] 640/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>         ] 641/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>         ] 642/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>         ] 643/929, 10.0 task/s, elapsed: 64s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>         ] 644/929, 10.0 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 645/929, 10.0 task/s, elapsed: 64s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 646/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 647/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 648/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 649/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 650/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 651/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 652/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 653/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 654/929, 10.0 task/s, elapsed: 65s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>         ] 655/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 656/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 657/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 658/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 659/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 660/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 661/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 662/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 663/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 664/929, 10.0 task/s, elapsed: 66s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>         ] 665/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 666/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 667/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 668/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 669/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 670/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 671/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>         ] 672/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>        ] 673/929, 10.0 task/s, elapsed: 67s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>        ] 674/929, 10.0 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 675/929, 10.0 task/s, elapsed: 67s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 676/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 677/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 678/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 679/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 680/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 681/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 10.0 task/s, elapsed: 68s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 10.0 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 10.0 task/s, elapsed: 68s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 10.0 task/s, elapsed: 69s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 10.0 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 10.0 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 10.0 task/s, elapsed: 69s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 10.0 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 10.0 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 10.0 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 10.0 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 10.0 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 10.0 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 10.0 task/s, elapsed: 70s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 10.0 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 705/929, 10.0 task/s, elapsed: 70s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 706/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 707/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 708/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 709/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 710/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 711/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 712/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 10.0 task/s, elapsed: 71s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 10.0 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 10.0 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 10.0 task/s, elapsed: 71s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 10.0 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 10.0 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 10.0 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 10.0 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 10.0 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 10.0 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 10.0 task/s, elapsed: 72s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 10.0 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 10.0 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 10.0 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 10.0 task/s, elapsed: 72s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 10.0 task/s, elapsed: 73s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 10.0 task/s, elapsed: 73s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 10.0 task/s, elapsed: 73s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 10.0 task/s, elapsed: 73s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 10.0 task/s, elapsed: 73s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 10.0 task/s, elapsed: 73s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 10.0 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 10.0 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 10.0 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 10.0 task/s, elapsed: 73s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 10.0 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 10.0 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 10.0 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 10.0 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 10.0 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 10.0 task/s, elapsed: 74s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 10.0 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 10.0 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 10.0 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 10.0 task/s, elapsed: 74s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 10.0 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 10.0 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 10.0 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 10.0 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 10.0 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 10.0 task/s, elapsed: 75s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 10.0 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 10.0 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 10.0 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 10.0 task/s, elapsed: 75s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 10.0 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 10.0 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 10.0 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 10.0 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 10.0 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 10.0 task/s, elapsed: 76s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 10.0 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 10.0 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 10.0 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 10.0 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 10.0 task/s, elapsed: 76s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 10.0 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 10.0 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 10.0 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 10.0 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 10.0 task/s, elapsed: 77s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 10.0 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 10.0 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 10.0 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 10.0 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 10.0 task/s, elapsed: 77s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 10.0 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 10.1 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 10.1 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 10.1 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 10.1 task/s, elapsed: 78s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 10.1 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 10.1 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 10.1 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 10.1 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 10.1 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 10.1 task/s, elapsed: 78s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 10.1 task/s, elapsed: 79s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 10.1 task/s, elapsed: 79s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 10.1 task/s, elapsed: 79s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 10.1 task/s, elapsed: 79s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 10.1 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 10.1 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 10.1 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 10.1 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 10.1 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 10.1 task/s, elapsed: 79s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 10.1 task/s, elapsed: 80s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 10.1 task/s, elapsed: 80s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 10.1 task/s, elapsed: 80s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 10.1 task/s, elapsed: 80s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 10.1 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 10.1 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 10.1 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 10.1 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 10.1 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 10.1 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 10.1 task/s, elapsed: 80s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 10.1 task/s, elapsed: 81s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 10.1 task/s, elapsed: 81s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 10.1 task/s, elapsed: 81s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 10.1 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 10.1 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 10.1 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 10.1 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 10.1 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 10.1 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 10.1 task/s, elapsed: 81s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 10.1 task/s, elapsed: 82s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 10.1 task/s, elapsed: 82s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 10.1 task/s, elapsed: 82s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 10.1 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 10.1 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 10.1 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 10.1 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 10.1 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 10.1 task/s, elapsed: 82s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 10.1 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 10.1 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 10.1 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 10.1 task/s, elapsed: 83s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 10.1 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 10.1 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 10.1 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 10.1 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 10.1 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 10.1 task/s, elapsed: 83s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 10.1 task/s, elapsed: 84s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 10.1 task/s, elapsed: 84s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 10.1 task/s, elapsed: 84s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 10.1 task/s, elapsed: 84s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 10.1 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 10.1 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 10.1 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 10.1 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 10.1 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 10.1 task/s, elapsed: 84s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 10.1 task/s, elapsed: 85s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 10.1 task/s, elapsed: 85s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 10.1 task/s, elapsed: 85s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 10.1 task/s, elapsed: 85s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 10.1 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 10.1 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 10.1 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 10.1 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 10.1 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 10.1 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 10.1 task/s, elapsed: 85s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 10.1 task/s, elapsed: 86s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 10.1 task/s, elapsed: 86s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 10.1 task/s, elapsed: 86s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 10.1 task/s, elapsed: 86s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 10.1 task/s, elapsed: 87s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 10.1 task/s, elapsed: 87s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 10.1 task/s, elapsed: 87s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 10.1 task/s, elapsed: 88s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 10.1 task/s, elapsed: 88s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 10.1 task/s, elapsed: 88s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 10.1 task/s, elapsed: 89s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 10.1 task/s, elapsed: 89s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 10.1 task/s, elapsed: 89s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 10.1 task/s, elapsed: 90s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 10.1 task/s, elapsed: 90s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 10.1 task/s, elapsed: 90s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 10.1 task/s, elapsed: 91s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 10.1 task/s, elapsed: 91s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 10.1 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 10.1 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 10.1 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 10.1 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 10.1 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 10.1 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 10.1 task/s, elapsed: 91s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 10.1 task/s, elapsed: 92s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 10.1 task/s, elapsed: 92s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 10.1 task/s, elapsed: 92s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 10.1 task/s, elapsed: 92s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 10.1 task/s, elapsed: 92s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 10.1 task/s, elapsed: 92s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 10.1 task/s, elapsed: 92s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 10.1 task/s, elapsed: 92s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 10.1 task/s, elapsed: 92s, ETA:     0s2022-10-10 10:06:05,558 - mmseg - INFO - per class results:2022-10-10 10:06:05,559 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.27 | 96.11 || rigid_plastic | 27.03 | 36.59 ||   cardboard   |  54.3 | 67.49 ||     metal     |  0.0  |  0.0  ||  soft_plastic | 57.49 | 67.31 |+---------------+-------+-------+2022-10-10 10:06:05,560 - mmseg - INFO - Summary:2022-10-10 10:06:05,560 - mmseg - INFO - +-------+-------+------+|  aAcc |  mIoU | mAcc |+-------+-------+------+| 90.67 | 45.82 | 53.5 |+-------+-------+------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:06:05,565 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 10:06:05,565 - mmseg - INFO - Iter [929/40000]	lr: 5.400e-05, eta: 10:32:26, time: 1.223, data_time: 0.013, memory: 67493, aAcc: 0.9067, mIoU: 0.4582, mAcc: 0.5350, IoU.background: 0.9027, IoU.rigid_plastic: 0.2703, IoU.cardboard: 0.5430, IoU.metal: 0.0000, IoU.soft_plastic: 0.5749, Acc.background: 0.9611, Acc.rigid_plastic: 0.3659, Acc.cardboard: 0.6749, Acc.metal: 0.0000, Acc.soft_plastic: 0.6731, src.decode.loss_seg: 0.2104, src.decode.acc_seg: 92.5772, src.loss: 0.2264, mix.decode.loss_seg: 0.1237, mix.decode.acc_seg: 94.1768, mix.loss: 0.1237, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:07:09,648 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 11:13:26, time: 6.716, data_time: 5.449, memory: 67493, src.decode.loss_seg: 0.2198, src.decode.acc_seg: 92.7028, src.loss: 0.2358, mix.decode.loss_seg: 0.1293, mix.decode.acc_seg: 94.7386, mix.loss: 0.1293, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:08:11,082 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 11:13:16, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2166, src.decode.acc_seg: 92.3424, src.loss: 0.2327, mix.decode.loss_seg: 0.1207, mix.decode.acc_seg: 94.8913, mix.loss: 0.1207, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:09:12,696 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 11:13:06, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2117, src.decode.acc_seg: 92.5267, src.loss: 0.2277, mix.decode.loss_seg: 0.1131, mix.decode.acc_seg: 95.1087, mix.loss: 0.1131, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:10:14,967 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 11:13:00, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2011, src.decode.acc_seg: 93.0944, src.loss: 0.2172, mix.decode.loss_seg: 0.1022, mix.decode.acc_seg: 95.6960, mix.loss: 0.1022, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:11:16,921 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 11:12:50, time: 1.239, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2213, src.decode.acc_seg: 92.4435, src.loss: 0.2374, mix.decode.loss_seg: 0.1397, mix.decode.acc_seg: 94.0460, mix.loss: 0.1397, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:12:18,542 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 11:12:37, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1689, src.decode.acc_seg: 94.0518, src.loss: 0.1850, mix.decode.loss_seg: 0.0995, mix.decode.acc_seg: 95.6940, mix.loss: 0.0995, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:13:20,126 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 11:12:22, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1889, src.decode.acc_seg: 93.5064, src.loss: 0.2050, mix.decode.loss_seg: 0.1021, mix.decode.acc_seg: 95.6526, mix.loss: 0.1021, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:14:22,160 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 11:12:09, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2203, src.decode.acc_seg: 92.2425, src.loss: 0.2364, mix.decode.loss_seg: 0.1248, mix.decode.acc_seg: 94.2813, mix.loss: 0.1248, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:15:23,574 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 11:11:51, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2319, src.decode.acc_seg: 91.7628, src.loss: 0.2480, mix.decode.loss_seg: 0.1258, mix.decode.acc_seg: 94.4472, mix.loss: 0.1258, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:16:24,758 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 11:11:29, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1917, src.decode.acc_seg: 92.6423, src.loss: 0.2078, mix.decode.loss_seg: 0.1160, mix.decode.acc_seg: 94.6510, mix.loss: 0.1160, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:17:26,822 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 11:11:14, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2012, src.decode.acc_seg: 92.8574, src.loss: 0.2172, mix.decode.loss_seg: 0.1183, mix.decode.acc_seg: 95.0825, mix.loss: 0.1183, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:18:28,343 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 11:10:54, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1928, src.decode.acc_seg: 93.4500, src.loss: 0.2089, mix.decode.loss_seg: 0.0985, mix.decode.acc_seg: 95.8074, mix.loss: 0.0985, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:19:30,021 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 11:10:33, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2017, src.decode.acc_seg: 93.4596, src.loss: 0.2178, mix.decode.loss_seg: 0.1065, mix.decode.acc_seg: 95.8149, mix.loss: 0.1065, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:20:31,721 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 11:10:12, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1620, src.decode.acc_seg: 94.3584, src.loss: 0.1780, mix.decode.loss_seg: 0.0781, mix.decode.acc_seg: 96.5891, mix.loss: 0.0781, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:21:34,072 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 11:09:55, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1557, src.decode.acc_seg: 94.6390, src.loss: 0.1718, mix.decode.loss_seg: 0.0823, mix.decode.acc_seg: 96.4410, mix.loss: 0.0823, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:22:35,397 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 11:09:30, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1804, src.decode.acc_seg: 93.2678, src.loss: 0.1965, mix.decode.loss_seg: 0.1016, mix.decode.acc_seg: 95.6031, mix.loss: 0.1016, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:23:36,805 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 11:09:04, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1976, src.decode.acc_seg: 93.0010, src.loss: 0.2136, mix.decode.loss_seg: 0.1151, mix.decode.acc_seg: 95.2230, mix.loss: 0.1151, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:24:38,018 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 11:08:37, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1532, src.decode.acc_seg: 94.3854, src.loss: 0.1692, mix.decode.loss_seg: 0.0978, mix.decode.acc_seg: 95.9844, mix.loss: 0.0978, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:25:39,356 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 11:08:09, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1972, src.decode.acc_seg: 93.0640, src.loss: 0.2133, mix.decode.loss_seg: 0.1161, mix.decode.acc_seg: 95.4542, mix.loss: 0.1161, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:26:41,462 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 10:26:41,462 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 11:07:47, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1963, src.decode.acc_seg: 92.9950, src.loss: 0.2124, mix.decode.loss_seg: 0.1052, mix.decode.acc_seg: 95.6453, mix.loss: 0.1052, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:27:43,589 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 11:07:23, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2060, src.decode.acc_seg: 92.9539, src.loss: 0.2221, mix.decode.loss_seg: 0.1101, mix.decode.acc_seg: 95.8816, mix.loss: 0.1101, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:28:45,790 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 11:06:59, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1881, src.decode.acc_seg: 93.1175, src.loss: 0.2042, mix.decode.loss_seg: 0.1344, mix.decode.acc_seg: 94.5312, mix.loss: 0.1344, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:29:47,182 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 11:06:30, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1511, src.decode.acc_seg: 94.8803, src.loss: 0.1671, mix.decode.loss_seg: 0.0889, mix.decode.acc_seg: 96.5529, mix.loss: 0.0889, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:30:49,136 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 11:06:03, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1642, src.decode.acc_seg: 93.8593, src.loss: 0.1802, mix.decode.loss_seg: 0.0945, mix.decode.acc_seg: 95.9207, mix.loss: 0.0945, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:31:50,933 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 11:05:34, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1635, src.decode.acc_seg: 94.0899, src.loss: 0.1796, mix.decode.loss_seg: 0.0981, mix.decode.acc_seg: 96.0203, mix.loss: 0.0981, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:32:52,778 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 11:05:06, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.2150, src.decode.acc_seg: 91.9941, src.loss: 0.2310, mix.decode.loss_seg: 0.1605, mix.decode.acc_seg: 93.1981, mix.loss: 0.1605, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:33:54,247 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 11:04:34, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1949, src.decode.acc_seg: 92.8856, src.loss: 0.2109, mix.decode.loss_seg: 0.1098, mix.decode.acc_seg: 95.3612, mix.loss: 0.1098, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:34:56,638 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 11:04:07, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1975, src.decode.acc_seg: 93.0650, src.loss: 0.2136, mix.decode.loss_seg: 0.1144, mix.decode.acc_seg: 95.4123, mix.loss: 0.1144, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:35:58,529 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 11:03:37, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1630, src.decode.acc_seg: 94.1169, src.loss: 0.1790, mix.decode.loss_seg: 0.1064, mix.decode.acc_seg: 95.6365, mix.loss: 0.1064, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:37:00,223 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 11:03:05, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1689, src.decode.acc_seg: 93.9197, src.loss: 0.1849, mix.decode.loss_seg: 0.0864, mix.decode.acc_seg: 96.1875, mix.loss: 0.0864, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:38:02,288 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 11:02:35, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1847, src.decode.acc_seg: 93.6230, src.loss: 0.2008, mix.decode.loss_seg: 0.1114, mix.decode.acc_seg: 95.3847, mix.loss: 0.1114, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:39:04,163 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 11:02:03, time: 1.238, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.2035, src.decode.acc_seg: 92.8632, src.loss: 0.2195, mix.decode.loss_seg: 0.1168, mix.decode.acc_seg: 95.4318, mix.loss: 0.1168, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:40:05,574 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 11:01:27, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1502, src.decode.acc_seg: 94.7280, src.loss: 0.1663, mix.decode.loss_seg: 0.0884, mix.decode.acc_seg: 96.2061, mix.loss: 0.0884, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:41:07,392 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 11:00:54, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1829, src.decode.acc_seg: 93.3529, src.loss: 0.1989, mix.decode.loss_seg: 0.1184, mix.decode.acc_seg: 95.2894, mix.loss: 0.1184, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:42:09,502 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 11:00:22, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1830, src.decode.acc_seg: 93.4342, src.loss: 0.1991, mix.decode.loss_seg: 0.1166, mix.decode.acc_seg: 95.3444, mix.loss: 0.1166, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:43:11,748 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 10:59:50, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1971, src.decode.acc_seg: 93.1068, src.loss: 0.2132, mix.decode.loss_seg: 0.1158, mix.decode.acc_seg: 95.4723, mix.loss: 0.1158, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:44:13,525 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 10:59:15, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1780, src.decode.acc_seg: 93.6104, src.loss: 0.1940, mix.decode.loss_seg: 0.1018, mix.decode.acc_seg: 95.8133, mix.loss: 0.1018, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:45:14,803 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 10:58:36, time: 1.226, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1558, src.decode.acc_seg: 94.6004, src.loss: 0.1719, mix.decode.loss_seg: 0.1058, mix.decode.acc_seg: 95.8381, mix.loss: 0.1058, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:46:17,079 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 10:58:03, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1634, src.decode.acc_seg: 94.1816, src.loss: 0.1794, mix.decode.loss_seg: 0.1092, mix.decode.acc_seg: 95.4786, mix.loss: 0.1092, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:47:19,073 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 10:47:19,073 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 10:57:28, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1334, src.decode.acc_seg: 95.1982, src.loss: 0.1494, mix.decode.loss_seg: 0.0830, mix.decode.acc_seg: 96.4492, mix.loss: 0.0830, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:48:20,909 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 10:56:51, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1457, src.decode.acc_seg: 94.4562, src.loss: 0.1618, mix.decode.loss_seg: 0.0832, mix.decode.acc_seg: 96.7524, mix.loss: 0.0832, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:49:23,204 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 10:56:17, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1673, src.decode.acc_seg: 94.0158, src.loss: 0.1834, mix.decode.loss_seg: 0.0911, mix.decode.acc_seg: 96.1970, mix.loss: 0.0911, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:50:24,684 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 10:55:38, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1956, src.decode.acc_seg: 92.9113, src.loss: 0.2117, mix.decode.loss_seg: 0.1354, mix.decode.acc_seg: 94.9362, mix.loss: 0.1354, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:51:26,181 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 10:54:58, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1676, src.decode.acc_seg: 94.1154, src.loss: 0.1837, mix.decode.loss_seg: 0.0870, mix.decode.acc_seg: 96.6345, mix.loss: 0.0870, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:52:27,573 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 10:54:17, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1682, src.decode.acc_seg: 94.0178, src.loss: 0.1843, mix.decode.loss_seg: 0.1035, mix.decode.acc_seg: 95.9360, mix.loss: 0.1035, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:53:28,996 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 10:53:37, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1734, src.decode.acc_seg: 93.9301, src.loss: 0.1895, mix.decode.loss_seg: 0.0908, mix.decode.acc_seg: 96.2058, mix.loss: 0.0908, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:54:30,848 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 10:52:58, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1677, src.decode.acc_seg: 93.9580, src.loss: 0.1837, mix.decode.loss_seg: 0.1036, mix.decode.acc_seg: 95.6853, mix.loss: 0.1036, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:55:32,688 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 10:52:19, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1582, src.decode.acc_seg: 94.6338, src.loss: 0.1743, mix.decode.loss_seg: 0.0846, mix.decode.acc_seg: 96.3993, mix.loss: 0.0846, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:56:34,897 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 10:51:41, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1824, src.decode.acc_seg: 93.9520, src.loss: 0.1984, mix.decode.loss_seg: 0.1104, mix.decode.acc_seg: 95.8971, mix.loss: 0.1104, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:57:36,249 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 10:50:59, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1644, src.decode.acc_seg: 94.0293, src.loss: 0.1805, mix.decode.loss_seg: 0.0945, mix.decode.acc_seg: 96.4237, mix.loss: 0.0945, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:58:38,066 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 10:50:18, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1663, src.decode.acc_seg: 94.6841, src.loss: 0.1824, mix.decode.loss_seg: 0.1054, mix.decode.acc_seg: 96.2967, mix.loss: 0.1054, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:59:39,497 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 10:49:36, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1788, src.decode.acc_seg: 93.6143, src.loss: 0.1948, mix.decode.loss_seg: 0.1091, mix.decode.acc_seg: 95.5743, mix.loss: 0.1091, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:00:40,912 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 10:48:53, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1555, src.decode.acc_seg: 94.4768, src.loss: 0.1716, mix.decode.loss_seg: 0.0914, mix.decode.acc_seg: 96.3193, mix.loss: 0.0914, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:01:42,642 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 10:48:11, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1627, src.decode.acc_seg: 94.1038, src.loss: 0.1788, mix.decode.loss_seg: 0.1118, mix.decode.acc_seg: 95.7297, mix.loss: 0.1118, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:02:44,504 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 10:47:30, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1634, src.decode.acc_seg: 94.0418, src.loss: 0.1794, mix.decode.loss_seg: 0.1014, mix.decode.acc_seg: 95.7499, mix.loss: 0.1014, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:03:46,473 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 10:46:49, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1486, src.decode.acc_seg: 94.7998, src.loss: 0.1647, mix.decode.loss_seg: 0.0832, mix.decode.acc_seg: 96.4103, mix.loss: 0.0832, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:04:48,256 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 10:46:06, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1736, src.decode.acc_seg: 93.5761, src.loss: 0.1897, mix.decode.loss_seg: 0.1035, mix.decode.acc_seg: 95.8005, mix.loss: 0.1035, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:05:49,654 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 10:45:22, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1629, src.decode.acc_seg: 94.0580, src.loss: 0.1789, mix.decode.loss_seg: 0.0979, mix.decode.acc_seg: 95.8642, mix.loss: 0.0979, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:06:51,162 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 10:44:38, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1577, src.decode.acc_seg: 94.4428, src.loss: 0.1738, mix.decode.loss_seg: 0.0863, mix.decode.acc_seg: 96.6541, mix.loss: 0.0863, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:07:53,314 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 11:07:53,314 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 10:43:56, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1604, src.decode.acc_seg: 94.4154, src.loss: 0.1764, mix.decode.loss_seg: 0.0810, mix.decode.acc_seg: 96.5929, mix.loss: 0.0810, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:08:55,804 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 10:43:16, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1555, src.decode.acc_seg: 94.5141, src.loss: 0.1715, mix.decode.loss_seg: 0.1011, mix.decode.acc_seg: 96.4399, mix.loss: 0.1011, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:09:57,923 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 10:42:34, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1478, src.decode.acc_seg: 94.8847, src.loss: 0.1639, mix.decode.loss_seg: 0.0889, mix.decode.acc_seg: 96.4061, mix.loss: 0.0889, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:10:59,341 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 10:41:49, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1312, src.decode.acc_seg: 95.5167, src.loss: 0.1472, mix.decode.loss_seg: 0.0919, mix.decode.acc_seg: 96.4174, mix.loss: 0.0919, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:12:01,468 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 10:41:06, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1390, src.decode.acc_seg: 94.9602, src.loss: 0.1551, mix.decode.loss_seg: 0.0883, mix.decode.acc_seg: 96.5652, mix.loss: 0.0883, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:13:03,372 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 10:40:22, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1710, src.decode.acc_seg: 93.7520, src.loss: 0.1870, mix.decode.loss_seg: 0.1063, mix.decode.acc_seg: 95.8419, mix.loss: 0.1063, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:14:05,368 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 10:39:38, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1430, src.decode.acc_seg: 94.7322, src.loss: 0.1591, mix.decode.loss_seg: 0.1013, mix.decode.acc_seg: 95.6935, mix.loss: 0.1013, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:15:06,948 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 10:38:53, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1280, src.decode.acc_seg: 95.7542, src.loss: 0.1441, mix.decode.loss_seg: 0.0839, mix.decode.acc_seg: 96.5559, mix.loss: 0.0839, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:16:08,792 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 10:38:08, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1992, src.decode.acc_seg: 93.2338, src.loss: 0.2152, mix.decode.loss_seg: 0.1292, mix.decode.acc_seg: 95.4668, mix.loss: 0.1292, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:17:10,565 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 10:37:22, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1761, src.decode.acc_seg: 93.8369, src.loss: 0.1922, mix.decode.loss_seg: 0.1223, mix.decode.acc_seg: 94.7117, mix.loss: 0.1223, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:18:12,783 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 10:36:39, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1629, src.decode.acc_seg: 94.2755, src.loss: 0.1789, mix.decode.loss_seg: 0.0924, mix.decode.acc_seg: 96.0859, mix.loss: 0.0924, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:19:14,674 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 10:35:53, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1543, src.decode.acc_seg: 94.4854, src.loss: 0.1703, mix.decode.loss_seg: 0.0940, mix.decode.acc_seg: 95.8081, mix.loss: 0.0940, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:20:16,494 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 10:35:07, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1554, src.decode.acc_seg: 94.6218, src.loss: 0.1714, mix.decode.loss_seg: 0.0980, mix.decode.acc_seg: 96.0905, mix.loss: 0.0980, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:21:18,375 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 10:34:22, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1384, src.decode.acc_seg: 94.9547, src.loss: 0.1544, mix.decode.loss_seg: 0.0825, mix.decode.acc_seg: 96.8061, mix.loss: 0.0825, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:22:20,218 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 10:33:35, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1169, src.decode.acc_seg: 95.3161, src.loss: 0.1330, mix.decode.loss_seg: 0.0797, mix.decode.acc_seg: 96.5084, mix.loss: 0.0797, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:23:21,643 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 10:32:47, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1772, src.decode.acc_seg: 93.7598, src.loss: 0.1933, mix.decode.loss_seg: 0.0961, mix.decode.acc_seg: 96.1396, mix.loss: 0.0961, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:24:23,372 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 10:32:00, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1610, src.decode.acc_seg: 94.0958, src.loss: 0.1771, mix.decode.loss_seg: 0.0929, mix.decode.acc_seg: 96.1756, mix.loss: 0.0929, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:25:25,417 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 10:31:14, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1531, src.decode.acc_seg: 94.3598, src.loss: 0.1691, mix.decode.loss_seg: 0.0936, mix.decode.acc_seg: 96.0522, mix.loss: 0.0936, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:26:26,798 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 10:30:25, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1457, src.decode.acc_seg: 94.6281, src.loss: 0.1618, mix.decode.loss_seg: 0.0813, mix.decode.acc_seg: 96.5040, mix.loss: 0.0813, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:27:28,429 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 10:29:37, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1723, src.decode.acc_seg: 93.7409, src.loss: 0.1883, mix.decode.loss_seg: 0.0887, mix.decode.acc_seg: 96.5084, mix.loss: 0.0887, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.1 task/s, elapsed: 1s, ETA:   841s[                                 ] 2/929, 2.0 task/s, elapsed: 1s, ETA:   469s[                                 ] 3/929, 2.7 task/s, elapsed: 1s, ETA:   346s[                                 ] 4/929, 3.3 task/s, elapsed: 1s, ETA:   283s[                                 ] 5/929, 3.8 task/s, elapsed: 1s, ETA:   246s[                                 ] 6/929, 4.2 task/s, elapsed: 1s, ETA:   221s[                                 ] 7/929, 4.5 task/s, elapsed: 2s, ETA:   203s[                                 ] 8/929, 4.9 task/s, elapsed: 2s, ETA:   189s[                                 ] 9/929, 5.0 task/s, elapsed: 2s, ETA:   185s[                                ] 10/929, 5.2 task/s, elapsed: 2s, ETA:   176s[                                ] 11/929, 5.4 task/s, elapsed: 2s, ETA:   169s[                                ] 12/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 13/929, 5.8 task/s, elapsed: 2s, ETA:   157s[                                ] 14/929, 6.0 task/s, elapsed: 2s, ETA:   153s[                                ] 15/929, 6.1 task/s, elapsed: 2s, ETA:   150s[                                ] 16/929, 6.2 task/s, elapsed: 3s, ETA:   146s[                                ] 17/929, 6.4 task/s, elapsed: 3s, ETA:   143s[                                ] 18/929, 6.5 task/s, elapsed: 3s, ETA:   141s[                                ] 19/929, 6.6 task/s, elapsed: 3s, ETA:   138s[                                ] 20/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 21/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 22/929, 6.9 task/s, elapsed: 3s, ETA:   132s[                                ] 23/929, 7.0 task/s, elapsed: 3s, ETA:   130s[                                ] 24/929, 7.0 task/s, elapsed: 3s, ETA:   129s[                                ] 25/929, 7.1 task/s, elapsed: 4s, ETA:   127s[                                ] 26/929, 7.2 task/s, elapsed: 4s, ETA:   126s[                                ] 27/929, 7.2 task/s, elapsed: 4s, ETA:   124s[                                ] 28/929, 7.3 task/s, elapsed: 4s, ETA:   123s[                                ] 29/929, 7.4 task/s, elapsed: 4s, ETA:   122s[>                               ] 30/929, 7.5 task/s, elapsed: 4s, ETA:   121s[>                               ] 31/929, 7.5 task/s, elapsed: 4s, ETA:   119s[>                               ] 32/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 33/929, 7.6 task/s, elapsed: 4s, ETA:   117s[>                               ] 34/929, 7.7 task/s, elapsed: 4s, ETA:   116s[>                               ] 35/929, 7.8 task/s, elapsed: 5s, ETA:   115s[>                               ] 36/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 37/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 38/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 39/929, 8.0 task/s, elapsed: 5s, ETA:   112s[>                               ] 40/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 41/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 42/929, 8.1 task/s, elapsed: 5s, ETA:   110s[>                               ] 43/929, 8.1 task/s, elapsed: 5s, ETA:   109s[>                               ] 44/929, 8.1 task/s, elapsed: 5s, ETA:   109s[>                               ] 45/929, 8.2 task/s, elapsed: 6s, ETA:   108s[>                               ] 46/929, 8.2 task/s, elapsed: 6s, ETA:   108s[>                               ] 47/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 48/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 49/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 50/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 51/929, 8.3 task/s, elapsed: 6s, ETA:   105s[>                               ] 52/929, 8.3 task/s, elapsed: 6s, ETA:   105s[>                               ] 53/929, 8.4 task/s, elapsed: 6s, ETA:   105s[>                               ] 54/929, 8.3 task/s, elapsed: 6s, ETA:   105s[>                               ] 55/929, 8.4 task/s, elapsed: 7s, ETA:   105s[>                               ] 56/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>                               ] 57/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>                               ] 58/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>>                              ] 59/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 60/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 61/929, 8.5 task/s, elapsed: 7s, ETA:   103s[>>                              ] 62/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 63/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 64/929, 8.5 task/s, elapsed: 8s, ETA:   102s[>>                              ] 65/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 66/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 67/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 68/929, 8.6 task/s, elapsed: 8s, ETA:   101s[>>                              ] 69/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 70/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 71/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 72/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 73/929, 8.6 task/s, elapsed: 8s, ETA:    99s[>>                              ] 74/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 75/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 76/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 77/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 78/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 79/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 80/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 81/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 82/929, 8.7 task/s, elapsed: 9s, ETA:    97s[>>                             ] 83/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 84/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 85/929, 8.7 task/s, elapsed: 10s, ETA:    98s[>>                             ] 86/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 87/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 88/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 89/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 90/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 91/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 92/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 93/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 94/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 95/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 96/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 97/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 98/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 99/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                           ] 100/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 101/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 102/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 103/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 104/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 105/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 106/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 107/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 108/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 109/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 110/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 111/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 112/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 113/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 114/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 115/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 116/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 117/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 118/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 119/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 120/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 121/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 122/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 123/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 124/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 125/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 126/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 127/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 128/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 129/929, 8.9 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 130/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 131/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 132/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 133/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 134/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 135/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 136/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 137/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 138/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 139/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 140/929, 9.0 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 141/929, 9.0 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 142/929, 9.0 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 143/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 144/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 145/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 146/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 147/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 148/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 149/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 150/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 151/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 152/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 153/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 154/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 155/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 156/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 157/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 158/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 159/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 160/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 161/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 162/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 163/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 164/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 165/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 166/929, 9.0 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 167/929, 9.0 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 168/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 169/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 170/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 171/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 172/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 173/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 174/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 175/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 176/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 177/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 178/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 180/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 181/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 182/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 183/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 184/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 185/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 186/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 187/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 188/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 189/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 190/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 191/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 192/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 193/929, 9.1 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 194/929, 9.1 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 195/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 196/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 197/929, 9.2 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 198/929, 9.2 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 199/929, 9.2 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 200/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 201/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 202/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 203/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 204/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 205/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 206/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 207/929, 9.2 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 208/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 209/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 210/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 211/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 212/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 213/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 214/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 215/929, 9.2 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 216/929, 9.2 task/s, elapsed: 23s, ETA:    77s[>>>>>>>                       ] 217/929, 9.2 task/s, elapsed: 23s, ETA:    77s[>>>>>>>                       ] 218/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 219/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 220/929, 9.3 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 221/929, 9.3 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 222/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 223/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 224/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 225/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 226/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 227/929, 9.3 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 228/929, 9.3 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 229/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 230/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 231/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 232/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 233/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 234/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 235/929, 9.3 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 236/929, 9.3 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 237/929, 9.3 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 238/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 239/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 240/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 241/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 242/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 243/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 244/929, 9.3 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 245/929, 9.3 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 246/929, 9.3 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 247/929, 9.3 task/s, elapsed: 26s, ETA:    73s[>>>>>>>>                      ] 248/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 249/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 250/929, 9.4 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 251/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 252/929, 9.3 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 253/929, 9.3 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 254/929, 9.3 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 255/929, 9.3 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 256/929, 9.3 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 257/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 258/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 259/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 260/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 261/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 262/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 263/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 264/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 265/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 266/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 267/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 268/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 269/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 270/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 271/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 272/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 273/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 274/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 275/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 276/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>                      ] 277/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>                      ] 278/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 279/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 280/929, 9.3 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 281/929, 9.3 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 282/929, 9.3 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 283/929, 9.3 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 284/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 285/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 286/929, 9.4 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 287/929, 9.4 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 288/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 289/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 290/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 291/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 292/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 293/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 294/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 295/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 296/929, 9.4 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 297/929, 9.4 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 298/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 299/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 300/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 301/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 302/929, 9.3 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 303/929, 9.3 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 304/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 305/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 306/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 307/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 308/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 309/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 310/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 311/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 312/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 313/929, 9.3 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 314/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 315/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 316/929, 9.4 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 317/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 318/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 319/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 320/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 321/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 322/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 323/929, 9.4 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 324/929, 9.4 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 325/929, 9.4 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 326/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 327/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 328/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 329/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 330/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 331/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 332/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 333/929, 9.4 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 334/929, 9.4 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 335/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 336/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 337/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 338/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 339/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 340/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>>                   ] 341/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>>                   ] 342/929, 9.4 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 343/929, 9.4 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 344/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 345/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 346/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 347/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 348/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 349/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 350/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 351/929, 9.4 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 352/929, 9.4 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 353/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 354/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 355/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 356/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 357/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 358/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 359/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 360/929, 9.4 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 361/929, 9.4 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 362/929, 9.4 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 363/929, 9.4 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 364/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 365/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 366/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 367/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 368/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 369/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 370/929, 9.4 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>                   ] 371/929, 9.4 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 372/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 373/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 374/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 375/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 376/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 377/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 378/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 379/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 380/929, 9.4 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 381/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 382/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 383/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 384/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 385/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 386/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 387/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 388/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 389/929, 9.4 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 390/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 391/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 392/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 393/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 394/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 395/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 396/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 397/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 399/929, 9.4 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 400/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>                  ] 401/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>                  ] 402/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 403/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 404/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 405/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 406/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 407/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 408/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 409/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 410/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 411/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 412/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 413/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 414/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 415/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 416/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 417/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 418/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 419/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 420/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 421/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 422/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 423/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 424/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 425/929, 9.4 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 426/929, 9.4 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 427/929, 9.4 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 428/929, 9.4 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 429/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 430/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 431/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 432/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 433/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>>                ] 434/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>>                ] 435/929, 9.4 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 436/929, 9.4 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 437/929, 9.4 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 438/929, 9.4 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 439/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 440/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 441/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 442/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 443/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 444/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 445/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 446/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 447/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 448/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 449/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 450/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 451/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 452/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 453/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 454/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 455/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 456/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 457/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 458/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 459/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 460/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 461/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 462/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 463/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 464/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 465/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 466/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 467/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 468/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 469/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 470/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 471/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 472/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 473/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 474/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 475/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 476/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 477/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 478/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 479/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 480/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 481/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 482/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 483/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 484/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 485/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 486/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 487/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 488/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 489/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 490/929, 9.4 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 492/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 493/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 494/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 495/929, 9.4 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 496/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 498/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 499/929, 9.4 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 501/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 502/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 503/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 504/929, 9.4 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 505/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 508/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.4 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 511/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 512/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 513/929, 9.4 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 514/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.4 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 520/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 521/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 522/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 523/929, 9.4 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.4 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.4 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.4 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.4 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.4 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.4 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.4 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.4 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.4 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.5 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.5 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.5 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.5 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.5 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.5 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.5 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.5 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.5 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.5 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.5 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.5 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.5 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.5 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.5 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.5 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.5 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.5 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.5 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.5 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.5 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.5 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.5 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.5 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.5 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.5 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.5 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.5 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.5 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.5 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.5 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.5 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.5 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.5 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.5 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.5 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.5 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.5 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.5 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.5 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.5 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.5 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.5 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.5 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.6 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.6 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.6 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.6 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.6 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.6 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.6 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.6 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.6 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.6 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.5 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.5 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.5 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.5 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.5 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.5 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.5 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.5 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.5 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.5 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.5 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.5 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.5 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.5 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.5 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.5 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.5 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.5 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.5 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.5 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.5 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.5 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.5 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.5 task/s, elapsed: 98s, ETA:     0s2022-10-10 11:32:43,219 - mmseg - INFO - per class results:2022-10-10 11:32:43,220 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.63 | 96.73 || rigid_plastic | 18.31 | 19.58 ||   cardboard   |  52.5 | 60.68 ||     metal     | 18.04 | 21.36 ||  soft_plastic |  59.4 | 77.62 |+---------------+-------+-------+2022-10-10 11:32:43,220 - mmseg - INFO - Summary:2022-10-10 11:32:43,220 - mmseg - INFO - +-------+-------+------+|  aAcc |  mIoU | mAcc |+-------+-------+------+| 90.88 | 47.78 | 55.2 |+-------+-------+------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:32:43,224 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 11:32:43,225 - mmseg - INFO - Iter [929/40000]	lr: 4.800e-05, eta: 10:28:51, time: 1.243, data_time: 0.014, memory: 67493, aAcc: 0.9088, mIoU: 0.4778, mAcc: 0.5520, IoU.background: 0.9063, IoU.rigid_plastic: 0.1831, IoU.cardboard: 0.5250, IoU.metal: 0.1804, IoU.soft_plastic: 0.5940, Acc.background: 0.9673, Acc.rigid_plastic: 0.1958, Acc.cardboard: 0.6068, Acc.metal: 0.2136, Acc.soft_plastic: 0.7762, src.decode.loss_seg: 0.1485, src.decode.acc_seg: 94.5979, src.loss: 0.1645, mix.decode.loss_seg: 0.0861, mix.decode.acc_seg: 96.4981, mix.loss: 0.0861, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:33:46,684 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 10:44:53, time: 6.322, data_time: 5.067, memory: 67493, src.decode.loss_seg: 0.1482, src.decode.acc_seg: 94.1727, src.loss: 0.1643, mix.decode.loss_seg: 0.0874, mix.decode.acc_seg: 96.5042, mix.loss: 0.0874, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:34:48,230 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 10:43:56, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1403, src.decode.acc_seg: 94.8557, src.loss: 0.1563, mix.decode.loss_seg: 0.0867, mix.decode.acc_seg: 96.5538, mix.loss: 0.0867, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:35:50,041 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 10:43:01, time: 1.236, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1468, src.decode.acc_seg: 94.5104, src.loss: 0.1628, mix.decode.loss_seg: 0.0850, mix.decode.acc_seg: 96.5457, mix.loss: 0.0850, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:36:52,120 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 10:42:06, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1488, src.decode.acc_seg: 94.4523, src.loss: 0.1649, mix.decode.loss_seg: 0.0864, mix.decode.acc_seg: 96.2110, mix.loss: 0.0864, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:37:53,853 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 10:41:10, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1339, src.decode.acc_seg: 95.1700, src.loss: 0.1500, mix.decode.loss_seg: 0.0883, mix.decode.acc_seg: 96.4426, mix.loss: 0.0883, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:38:56,112 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 10:40:16, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1378, src.decode.acc_seg: 94.9656, src.loss: 0.1539, mix.decode.loss_seg: 0.0788, mix.decode.acc_seg: 96.4674, mix.loss: 0.0788, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:39:57,433 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 10:39:18, time: 1.226, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1253, src.decode.acc_seg: 95.6503, src.loss: 0.1413, mix.decode.loss_seg: 0.0754, mix.decode.acc_seg: 96.9271, mix.loss: 0.0754, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:40:58,996 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 10:38:21, time: 1.231, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1307, src.decode.acc_seg: 95.3301, src.loss: 0.1467, mix.decode.loss_seg: 0.0747, mix.decode.acc_seg: 96.9482, mix.loss: 0.0747, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:42:00,574 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 10:37:24, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1211, src.decode.acc_seg: 95.6494, src.loss: 0.1372, mix.decode.loss_seg: 0.0827, mix.decode.acc_seg: 96.6774, mix.loss: 0.0827, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:43:02,879 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 10:36:30, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1333, src.decode.acc_seg: 94.9857, src.loss: 0.1494, mix.decode.loss_seg: 0.0842, mix.decode.acc_seg: 96.1587, mix.loss: 0.0842, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:44:04,905 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 10:35:34, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1472, src.decode.acc_seg: 94.7865, src.loss: 0.1632, mix.decode.loss_seg: 0.0821, mix.decode.acc_seg: 96.8675, mix.loss: 0.0821, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:45:06,361 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 10:34:37, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1304, src.decode.acc_seg: 94.8726, src.loss: 0.1464, mix.decode.loss_seg: 0.0822, mix.decode.acc_seg: 96.7267, mix.loss: 0.0822, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:46:08,374 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 10:33:41, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1622, src.decode.acc_seg: 94.1437, src.loss: 0.1783, mix.decode.loss_seg: 0.0881, mix.decode.acc_seg: 96.3065, mix.loss: 0.0881, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:47:10,509 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 10:32:46, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1352, src.decode.acc_seg: 95.1283, src.loss: 0.1512, mix.decode.loss_seg: 0.0886, mix.decode.acc_seg: 96.4691, mix.loss: 0.0886, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:48:13,031 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 10:31:52, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1422, src.decode.acc_seg: 94.9605, src.loss: 0.1582, mix.decode.loss_seg: 0.0917, mix.decode.acc_seg: 96.2537, mix.loss: 0.0917, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:49:15,314 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 10:30:57, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1433, src.decode.acc_seg: 94.9815, src.loss: 0.1593, mix.decode.loss_seg: 0.0811, mix.decode.acc_seg: 96.7974, mix.loss: 0.0811, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:50:18,048 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 10:30:03, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1197, src.decode.acc_seg: 95.8255, src.loss: 0.1357, mix.decode.loss_seg: 0.0651, mix.decode.acc_seg: 97.2379, mix.loss: 0.0651, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:51:20,339 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 10:29:08, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1352, src.decode.acc_seg: 95.1916, src.loss: 0.1512, mix.decode.loss_seg: 0.0776, mix.decode.acc_seg: 96.8451, mix.loss: 0.0776, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:52:21,910 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 10:28:11, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1466, src.decode.acc_seg: 94.5063, src.loss: 0.1626, mix.decode.loss_seg: 0.0818, mix.decode.acc_seg: 96.6638, mix.loss: 0.0818, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:53:23,514 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 11:53:23,514 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 10:27:13, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1297, src.decode.acc_seg: 95.3702, src.loss: 0.1458, mix.decode.loss_seg: 0.0728, mix.decode.acc_seg: 97.1674, mix.loss: 0.0728, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:54:26,136 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 10:26:19, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1174, src.decode.acc_seg: 95.6718, src.loss: 0.1334, mix.decode.loss_seg: 0.0614, mix.decode.acc_seg: 97.3932, mix.loss: 0.0614, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:55:28,111 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 10:25:23, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1308, src.decode.acc_seg: 95.1709, src.loss: 0.1468, mix.decode.loss_seg: 0.0832, mix.decode.acc_seg: 96.7316, mix.loss: 0.0832, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:56:29,689 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 10:24:25, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1378, src.decode.acc_seg: 94.7337, src.loss: 0.1539, mix.decode.loss_seg: 0.0885, mix.decode.acc_seg: 96.1967, mix.loss: 0.0885, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:57:31,152 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 10:23:27, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1354, src.decode.acc_seg: 95.1305, src.loss: 0.1515, mix.decode.loss_seg: 0.0777, mix.decode.acc_seg: 96.6041, mix.loss: 0.0777, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:58:33,417 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 10:22:31, time: 1.245, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1253, src.decode.acc_seg: 95.7341, src.loss: 0.1414, mix.decode.loss_seg: 0.0781, mix.decode.acc_seg: 96.8008, mix.loss: 0.0781, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:59:35,614 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 10:21:35, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1220, src.decode.acc_seg: 95.6322, src.loss: 0.1380, mix.decode.loss_seg: 0.0780, mix.decode.acc_seg: 96.6612, mix.loss: 0.0780, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:00:37,477 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 10:20:38, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1265, src.decode.acc_seg: 95.5027, src.loss: 0.1425, mix.decode.loss_seg: 0.0846, mix.decode.acc_seg: 96.4542, mix.loss: 0.0846, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:01:39,148 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 10:19:40, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1349, src.decode.acc_seg: 95.1806, src.loss: 0.1510, mix.decode.loss_seg: 0.0792, mix.decode.acc_seg: 97.1482, mix.loss: 0.0792, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:02:41,273 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 10:18:44, time: 1.243, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1116, src.decode.acc_seg: 96.0691, src.loss: 0.1276, mix.decode.loss_seg: 0.0726, mix.decode.acc_seg: 96.8537, mix.loss: 0.0726, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:03:42,999 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 10:17:46, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1336, src.decode.acc_seg: 95.2461, src.loss: 0.1497, mix.decode.loss_seg: 0.0850, mix.decode.acc_seg: 96.3670, mix.loss: 0.0850, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:04:45,041 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 10:16:50, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1248, src.decode.acc_seg: 95.5931, src.loss: 0.1408, mix.decode.loss_seg: 0.0743, mix.decode.acc_seg: 97.0396, mix.loss: 0.0743, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:05:47,374 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 10:15:54, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1345, src.decode.acc_seg: 95.4795, src.loss: 0.1505, mix.decode.loss_seg: 0.0839, mix.decode.acc_seg: 96.7473, mix.loss: 0.0839, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:06:49,881 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 10:14:58, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1627, src.decode.acc_seg: 94.2451, src.loss: 0.1787, mix.decode.loss_seg: 0.1005, mix.decode.acc_seg: 96.1964, mix.loss: 0.1005, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:07:51,857 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 10:14:01, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1416, src.decode.acc_seg: 94.9491, src.loss: 0.1577, mix.decode.loss_seg: 0.0860, mix.decode.acc_seg: 96.6921, mix.loss: 0.0860, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:08:54,120 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 10:13:05, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1276, src.decode.acc_seg: 95.4969, src.loss: 0.1437, mix.decode.loss_seg: 0.0877, mix.decode.acc_seg: 96.7944, mix.loss: 0.0877, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:09:55,979 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 10:12:08, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1184, src.decode.acc_seg: 95.6223, src.loss: 0.1345, mix.decode.loss_seg: 0.0811, mix.decode.acc_seg: 96.7728, mix.loss: 0.0811, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:10:57,627 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 10:11:09, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1280, src.decode.acc_seg: 95.4701, src.loss: 0.1441, mix.decode.loss_seg: 0.0786, mix.decode.acc_seg: 96.7622, mix.loss: 0.0786, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:11:59,212 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 10:10:11, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1059, src.decode.acc_seg: 95.9965, src.loss: 0.1220, mix.decode.loss_seg: 0.0628, mix.decode.acc_seg: 97.5049, mix.loss: 0.0628, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:13:01,030 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 10:09:13, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1107, src.decode.acc_seg: 96.0801, src.loss: 0.1267, mix.decode.loss_seg: 0.0676, mix.decode.acc_seg: 97.3936, mix.loss: 0.0676, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:14:03,007 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 12:14:03,008 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 10:08:16, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1138, src.decode.acc_seg: 95.8903, src.loss: 0.1299, mix.decode.loss_seg: 0.0738, mix.decode.acc_seg: 96.9844, mix.loss: 0.0738, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:15:04,933 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 10:07:18, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1216, src.decode.acc_seg: 95.2949, src.loss: 0.1377, mix.decode.loss_seg: 0.0716, mix.decode.acc_seg: 96.9637, mix.loss: 0.0716, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:16:07,155 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 10:06:21, time: 1.244, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1122, src.decode.acc_seg: 96.3129, src.loss: 0.1282, mix.decode.loss_seg: 0.0691, mix.decode.acc_seg: 97.1648, mix.loss: 0.0691, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:17:09,028 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 10:05:24, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1100, src.decode.acc_seg: 96.1898, src.loss: 0.1260, mix.decode.loss_seg: 0.0658, mix.decode.acc_seg: 97.4367, mix.loss: 0.0658, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:18:10,701 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 10:04:25, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1199, src.decode.acc_seg: 95.7192, src.loss: 0.1360, mix.decode.loss_seg: 0.0781, mix.decode.acc_seg: 96.8174, mix.loss: 0.0781, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:19:12,644 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 10:03:28, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1222, src.decode.acc_seg: 95.6647, src.loss: 0.1383, mix.decode.loss_seg: 0.0678, mix.decode.acc_seg: 97.2167, mix.loss: 0.0678, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:20:14,489 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 10:02:30, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1175, src.decode.acc_seg: 95.8825, src.loss: 0.1335, mix.decode.loss_seg: 0.0683, mix.decode.acc_seg: 97.2360, mix.loss: 0.0683, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:21:15,699 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 10:01:30, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1291, src.decode.acc_seg: 95.2942, src.loss: 0.1451, mix.decode.loss_seg: 0.0766, mix.decode.acc_seg: 96.9651, mix.loss: 0.0766, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:22:17,364 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 10:00:31, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1304, src.decode.acc_seg: 95.2398, src.loss: 0.1464, mix.decode.loss_seg: 0.0709, mix.decode.acc_seg: 97.1721, mix.loss: 0.0709, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:23:19,104 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 9:59:33, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1139, src.decode.acc_seg: 95.9811, src.loss: 0.1300, mix.decode.loss_seg: 0.0808, mix.decode.acc_seg: 96.7820, mix.loss: 0.0808, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:24:20,692 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 9:58:34, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1069, src.decode.acc_seg: 96.0765, src.loss: 0.1229, mix.decode.loss_seg: 0.0698, mix.decode.acc_seg: 97.0774, mix.loss: 0.0698, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:25:22,825 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 9:57:36, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1199, src.decode.acc_seg: 95.9547, src.loss: 0.1359, mix.decode.loss_seg: 0.0749, mix.decode.acc_seg: 97.1556, mix.loss: 0.0749, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:26:24,576 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 9:56:38, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1419, src.decode.acc_seg: 94.9342, src.loss: 0.1580, mix.decode.loss_seg: 0.0893, mix.decode.acc_seg: 96.4718, mix.loss: 0.0893, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:27:25,906 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 9:55:38, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1244, src.decode.acc_seg: 95.5796, src.loss: 0.1404, mix.decode.loss_seg: 0.0763, mix.decode.acc_seg: 96.8556, mix.loss: 0.0763, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:28:27,653 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 9:54:40, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1164, src.decode.acc_seg: 96.0312, src.loss: 0.1324, mix.decode.loss_seg: 0.0797, mix.decode.acc_seg: 96.7827, mix.loss: 0.0797, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:29:29,672 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 9:53:42, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1050, src.decode.acc_seg: 95.9921, src.loss: 0.1211, mix.decode.loss_seg: 0.0673, mix.decode.acc_seg: 97.1779, mix.loss: 0.0673, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:30:31,239 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 9:52:43, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1111, src.decode.acc_seg: 96.0552, src.loss: 0.1271, mix.decode.loss_seg: 0.0671, mix.decode.acc_seg: 97.1024, mix.loss: 0.0671, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:31:33,098 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 9:51:45, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1137, src.decode.acc_seg: 96.0316, src.loss: 0.1297, mix.decode.loss_seg: 0.0701, mix.decode.acc_seg: 97.1619, mix.loss: 0.0701, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:32:35,262 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 9:50:47, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1232, src.decode.acc_seg: 95.7531, src.loss: 0.1392, mix.decode.loss_seg: 0.0605, mix.decode.acc_seg: 97.5898, mix.loss: 0.0605, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:33:37,022 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 9:49:49, time: 1.235, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1182, src.decode.acc_seg: 95.7332, src.loss: 0.1343, mix.decode.loss_seg: 0.0836, mix.decode.acc_seg: 96.8129, mix.loss: 0.0836, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:34:38,643 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 12:34:38,644 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 9:48:49, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1112, src.decode.acc_seg: 96.0223, src.loss: 0.1272, mix.decode.loss_seg: 0.0716, mix.decode.acc_seg: 97.2066, mix.loss: 0.0716, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:35:40,683 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 9:47:52, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0953, src.decode.acc_seg: 96.4842, src.loss: 0.1114, mix.decode.loss_seg: 0.0584, mix.decode.acc_seg: 97.5927, mix.loss: 0.0584, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:36:42,227 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 9:46:52, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1138, src.decode.acc_seg: 95.8784, src.loss: 0.1299, mix.decode.loss_seg: 0.0698, mix.decode.acc_seg: 97.1845, mix.loss: 0.0698, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:37:43,988 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 9:45:53, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1087, src.decode.acc_seg: 96.0607, src.loss: 0.1248, mix.decode.loss_seg: 0.0710, mix.decode.acc_seg: 96.5958, mix.loss: 0.0710, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:38:46,247 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 9:44:56, time: 1.245, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.1281, src.decode.acc_seg: 95.6296, src.loss: 0.1441, mix.decode.loss_seg: 0.0742, mix.decode.acc_seg: 97.1222, mix.loss: 0.0742, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:39:48,330 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 9:43:58, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1132, src.decode.acc_seg: 95.9325, src.loss: 0.1292, mix.decode.loss_seg: 0.0792, mix.decode.acc_seg: 96.6749, mix.loss: 0.0792, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:40:49,931 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 9:42:59, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1005, src.decode.acc_seg: 96.4782, src.loss: 0.1166, mix.decode.loss_seg: 0.0636, mix.decode.acc_seg: 97.1833, mix.loss: 0.0636, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:41:51,589 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 9:42:00, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1181, src.decode.acc_seg: 95.7036, src.loss: 0.1341, mix.decode.loss_seg: 0.0749, mix.decode.acc_seg: 96.9723, mix.loss: 0.0749, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:42:53,051 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 9:41:00, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1240, src.decode.acc_seg: 95.6621, src.loss: 0.1400, mix.decode.loss_seg: 0.0819, mix.decode.acc_seg: 96.9110, mix.loss: 0.0819, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:43:55,134 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 9:40:02, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1222, src.decode.acc_seg: 95.5551, src.loss: 0.1383, mix.decode.loss_seg: 0.0748, mix.decode.acc_seg: 97.0789, mix.loss: 0.0748, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:44:57,250 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 9:39:04, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1126, src.decode.acc_seg: 96.0854, src.loss: 0.1286, mix.decode.loss_seg: 0.0640, mix.decode.acc_seg: 97.3651, mix.loss: 0.0640, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:45:59,243 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 9:38:05, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1230, src.decode.acc_seg: 95.6800, src.loss: 0.1390, mix.decode.loss_seg: 0.0745, mix.decode.acc_seg: 96.9639, mix.loss: 0.0745, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:47:00,448 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 9:37:05, time: 1.224, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1206, src.decode.acc_seg: 95.3682, src.loss: 0.1366, mix.decode.loss_seg: 0.0711, mix.decode.acc_seg: 96.7195, mix.loss: 0.0711, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:48:01,590 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 9:36:05, time: 1.223, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0974, src.decode.acc_seg: 96.4190, src.loss: 0.1135, mix.decode.loss_seg: 0.0693, mix.decode.acc_seg: 97.1882, mix.loss: 0.0693, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:49:03,216 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 9:35:05, time: 1.233, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1117, src.decode.acc_seg: 95.9360, src.loss: 0.1277, mix.decode.loss_seg: 0.0598, mix.decode.acc_seg: 97.6333, mix.loss: 0.0598, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:50:05,241 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 9:34:07, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1282, src.decode.acc_seg: 95.2951, src.loss: 0.1443, mix.decode.loss_seg: 0.0775, mix.decode.acc_seg: 96.6998, mix.loss: 0.0775, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:51:07,351 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 9:33:09, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1099, src.decode.acc_seg: 95.6700, src.loss: 0.1260, mix.decode.loss_seg: 0.0617, mix.decode.acc_seg: 97.4533, mix.loss: 0.0617, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:52:09,433 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 9:32:10, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1115, src.decode.acc_seg: 96.0163, src.loss: 0.1275, mix.decode.loss_seg: 0.0678, mix.decode.acc_seg: 97.4053, mix.loss: 0.0678, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:53:11,144 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 9:31:11, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1190, src.decode.acc_seg: 95.8462, src.loss: 0.1350, mix.decode.loss_seg: 0.0737, mix.decode.acc_seg: 97.0102, mix.loss: 0.0737, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:54:13,270 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 9:30:13, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1183, src.decode.acc_seg: 95.6458, src.loss: 0.1344, mix.decode.loss_seg: 0.0715, mix.decode.acc_seg: 97.0906, mix.loss: 0.0715, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1017s[                                 ] 2/929, 1.7 task/s, elapsed: 1s, ETA:   555s[                                 ] 3/929, 2.3 task/s, elapsed: 1s, ETA:   402s[                                 ] 4/929, 2.8 task/s, elapsed: 1s, ETA:   325s[                                 ] 5/929, 3.3 task/s, elapsed: 2s, ETA:   280s[                                 ] 6/929, 3.7 task/s, elapsed: 2s, ETA:   249s[                                 ] 7/929, 4.1 task/s, elapsed: 2s, ETA:   227s[                                 ] 8/929, 4.4 task/s, elapsed: 2s, ETA:   211s[                                 ] 9/929, 4.7 task/s, elapsed: 2s, ETA:   198s[                                ] 10/929, 4.9 task/s, elapsed: 2s, ETA:   187s[                                ] 11/929, 5.1 task/s, elapsed: 2s, ETA:   178s[                                ] 12/929, 5.4 task/s, elapsed: 2s, ETA:   171s[                                ] 13/929, 5.5 task/s, elapsed: 2s, ETA:   165s[                                ] 14/929, 5.7 task/s, elapsed: 2s, ETA:   160s[                                ] 15/929, 5.9 task/s, elapsed: 3s, ETA:   156s[                                ] 16/929, 6.0 task/s, elapsed: 3s, ETA:   152s[                                ] 17/929, 6.2 task/s, elapsed: 3s, ETA:   148s[                                ] 18/929, 6.3 task/s, elapsed: 3s, ETA:   145s[                                ] 19/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 20/929, 6.5 task/s, elapsed: 3s, ETA:   141s[                                ] 21/929, 6.6 task/s, elapsed: 3s, ETA:   138s[                                ] 22/929, 6.6 task/s, elapsed: 3s, ETA:   138s[                                ] 23/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 24/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 25/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 26/929, 7.0 task/s, elapsed: 4s, ETA:   129s[                                ] 27/929, 7.1 task/s, elapsed: 4s, ETA:   128s[                                ] 28/929, 7.1 task/s, elapsed: 4s, ETA:   126s[                                ] 29/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 30/929, 7.3 task/s, elapsed: 4s, ETA:   123s[>                               ] 31/929, 7.3 task/s, elapsed: 4s, ETA:   122s[>                               ] 32/929, 7.4 task/s, elapsed: 4s, ETA:   121s[>                               ] 33/929, 7.5 task/s, elapsed: 4s, ETA:   120s[>                               ] 34/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 35/929, 7.6 task/s, elapsed: 5s, ETA:   118s[>                               ] 36/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 37/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 38/929, 7.7 task/s, elapsed: 5s, ETA:   115s[>                               ] 39/929, 7.7 task/s, elapsed: 5s, ETA:   115s[>                               ] 40/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 41/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 42/929, 7.8 task/s, elapsed: 5s, ETA:   113s[>                               ] 43/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 44/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 45/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 46/929, 8.0 task/s, elapsed: 6s, ETA:   111s[>                               ] 47/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 48/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 49/929, 8.0 task/s, elapsed: 6s, ETA:   109s[>                               ] 50/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 51/929, 8.1 task/s, elapsed: 6s, ETA:   108s[>                               ] 52/929, 8.0 task/s, elapsed: 6s, ETA:   109s[>                               ] 53/929, 8.1 task/s, elapsed: 7s, ETA:   109s[>                               ] 54/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 55/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 56/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>                               ] 57/929, 8.2 task/s, elapsed: 7s, ETA:   107s[>                               ] 58/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>>                              ] 59/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>>                              ] 60/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>>                              ] 61/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>>                              ] 62/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>>                              ] 63/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 64/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 65/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 66/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 67/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 68/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 69/929, 8.4 task/s, elapsed: 8s, ETA:   103s[>>                              ] 70/929, 8.4 task/s, elapsed: 8s, ETA:   102s[>>                              ] 71/929, 8.4 task/s, elapsed: 8s, ETA:   102s[>>                              ] 72/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 73/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 74/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 75/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 76/929, 8.5 task/s, elapsed: 9s, ETA:   101s[>>                              ] 77/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 78/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 79/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 80/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                              ] 81/929, 8.5 task/s, elapsed: 9s, ETA:    99s[>>                             ] 82/929, 8.6 task/s, elapsed: 10s, ETA:    99s[>>                             ] 83/929, 8.6 task/s, elapsed: 10s, ETA:    99s[>>                             ] 84/929, 8.6 task/s, elapsed: 10s, ETA:    99s[>>                             ] 85/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 86/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 87/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 88/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 89/929, 8.6 task/s, elapsed: 10s, ETA:    97s[>>>                            ] 90/929, 8.6 task/s, elapsed: 10s, ETA:    97s[>>>                            ] 91/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 92/929, 8.7 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 93/929, 8.7 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 94/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 95/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 96/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 97/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 98/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 99/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                           ] 100/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                           ] 101/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 102/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 103/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 106/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 107/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 108/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 109/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 110/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 111/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 112/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 113/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 114/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 115/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 116/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 117/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 118/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 119/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 120/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 121/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 122/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 123/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 124/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 125/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 126/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 127/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 128/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 129/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 130/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 131/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 132/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 133/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 134/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 135/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 136/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 137/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 138/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 139/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 140/929, 9.0 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 141/929, 9.0 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 142/929, 9.0 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 143/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 144/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 145/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 146/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 147/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 148/929, 9.0 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 149/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 150/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 151/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 152/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 153/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 154/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 155/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 156/929, 9.0 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 157/929, 9.0 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 158/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 159/929, 9.1 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 160/929, 9.1 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 161/929, 9.1 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 162/929, 9.1 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 163/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 164/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 165/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 166/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 167/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 168/929, 9.1 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 169/929, 9.1 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 170/929, 9.1 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 171/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 172/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 173/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 174/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 175/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 176/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 177/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 178/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 180/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 181/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 182/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 183/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 184/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 185/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 186/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 187/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 188/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 191/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 192/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 193/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 194/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 195/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 196/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 197/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 198/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 199/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 200/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 222/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 223/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 224/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 225/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 230/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 231/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 232/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 234/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 239/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 240/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 241/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 242/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 243/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 247/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 248/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 249/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 255/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 256/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 257/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 258/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 264/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 290/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.3 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.3 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 293/929, 9.3 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.3 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 296/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 297/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 298/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 299/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.3 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.3 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.3 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.3 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 305/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 306/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 307/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 308/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 309/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>>                    ] 310/929, 9.3 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.3 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.3 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 314/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 315/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 316/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 317/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 318/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 319/929, 9.3 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.3 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.3 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 323/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 324/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 325/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 326/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 327/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.3 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.3 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 332/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 333/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 334/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 335/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 336/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 337/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.3 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.3 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 340/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 341/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 342/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 343/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 344/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 345/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 346/929, 9.3 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 348/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 349/929, 9.3 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 350/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 351/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 352/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 353/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 354/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 355/929, 9.3 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 356/929, 9.3 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 357/929, 9.3 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 358/929, 9.3 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 359/929, 9.3 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 360/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 361/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 362/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 363/929, 9.3 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 364/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 365/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 366/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 367/929, 9.3 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 368/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 369/929, 9.4 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 370/929, 9.4 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>                   ] 371/929, 9.4 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 372/929, 9.4 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 373/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 374/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 375/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 376/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 377/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 378/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 379/929, 9.4 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 380/929, 9.4 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 381/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 382/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 383/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 384/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 385/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 386/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 387/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 388/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 389/929, 9.4 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 390/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 391/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 392/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 393/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 394/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 395/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 396/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 397/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.4 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 399/929, 9.4 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 400/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>                  ] 401/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>                  ] 402/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 403/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 404/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 405/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 406/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 407/929, 9.4 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 408/929, 9.4 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 409/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 410/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 411/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 412/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 413/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 414/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 415/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 416/929, 9.4 task/s, elapsed: 44s, ETA:    55s[>>>>>>>>>>>>>                 ] 417/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 418/929, 9.4 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 419/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 420/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 421/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 422/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 423/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 424/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 425/929, 9.4 task/s, elapsed: 45s, ETA:    54s[>>>>>>>>>>>>>                 ] 426/929, 9.4 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 427/929, 9.4 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 428/929, 9.4 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 429/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 430/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 431/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 432/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 433/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>>                ] 434/929, 9.4 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>>                ] 435/929, 9.4 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 436/929, 9.4 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 437/929, 9.4 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 438/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 439/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 440/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 441/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 442/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 443/929, 9.4 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 444/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 445/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 446/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 447/929, 9.4 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 448/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 449/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 450/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 451/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 452/929, 9.4 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 453/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 454/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 455/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 456/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 457/929, 9.4 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 458/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 459/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 460/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 461/929, 9.4 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 462/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 463/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 464/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 465/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 466/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 467/929, 9.4 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 468/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 469/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 470/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 471/929, 9.4 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 472/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 473/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 474/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 475/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 476/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 477/929, 9.4 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 478/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 479/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 480/929, 9.4 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 481/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 482/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 483/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 484/929, 9.4 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 485/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 486/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 487/929, 9.5 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 488/929, 9.5 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 489/929, 9.5 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 490/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 491/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 492/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 493/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 494/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 495/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 496/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.5 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 498/929, 9.5 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 499/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 500/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 501/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 502/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 503/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 504/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 505/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.5 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 508/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 509/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 510/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 511/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 512/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 513/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 514/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.5 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.5 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 519/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 520/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 521/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 522/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 523/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.5 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.5 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.5 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.5 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.5 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.5 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.5 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.5 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.5 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.5 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.5 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.5 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.5 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.5 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.5 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.5 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.5 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.5 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.5 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.5 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.5 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.5 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.5 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.5 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.5 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.5 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.5 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.5 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.5 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.5 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.5 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.5 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.5 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.5 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.5 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.5 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.5 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.5 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.5 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.5 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.5 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.4 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.4 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.4 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.4 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.4 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.4 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.4 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.4 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.4 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.4 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.4 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.4 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.4 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.4 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.3 task/s, elapsed: 100s, ETA:     0s2022-10-10 12:59:00,311 - mmseg - INFO - per class results:2022-10-10 12:59:00,311 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.92 | 96.02 || rigid_plastic | 15.87 | 18.36 ||   cardboard   | 57.77 | 72.23 ||     metal     |  34.2 | 42.68 ||  soft_plastic | 60.88 | 72.51 |+---------------+-------+-------+2022-10-10 12:59:00,311 - mmseg - INFO - Summary:2022-10-10 12:59:00,311 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.32 | 51.93 | 60.36 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:59:00,315 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 12:59:00,316 - mmseg - INFO - Iter [929/40000]	lr: 4.200e-05, eta: 9:29:13, time: 1.233, data_time: 0.013, memory: 67493, aAcc: 0.9132, mIoU: 0.5193, mAcc: 0.6036, IoU.background: 0.9092, IoU.rigid_plastic: 0.1587, IoU.cardboard: 0.5777, IoU.metal: 0.3420, IoU.soft_plastic: 0.6088, Acc.background: 0.9602, Acc.rigid_plastic: 0.1836, Acc.cardboard: 0.7223, Acc.metal: 0.4268, Acc.soft_plastic: 0.7251, src.decode.loss_seg: 0.1027, src.decode.acc_seg: 96.0792, src.loss: 0.1188, mix.decode.loss_seg: 0.0675, mix.decode.acc_seg: 97.0608, mix.loss: 0.0675, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:00:02,758 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 9:36:58, time: 5.757, data_time: 4.522, memory: 67493, src.decode.loss_seg: 0.1304, src.decode.acc_seg: 95.3611, src.loss: 0.1464, mix.decode.loss_seg: 0.0861, mix.decode.acc_seg: 96.7566, mix.loss: 0.0861, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:01:06,294 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 9:36:00, time: 1.271, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0866, src.decode.acc_seg: 96.9157, src.loss: 0.1027, mix.decode.loss_seg: 0.0581, mix.decode.acc_seg: 97.6297, mix.loss: 0.0581, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:02:08,474 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 9:34:59, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1067, src.decode.acc_seg: 96.2315, src.loss: 0.1227, mix.decode.loss_seg: 0.0735, mix.decode.acc_seg: 97.2670, mix.loss: 0.0735, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:03:10,232 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 9:33:56, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1086, src.decode.acc_seg: 96.0326, src.loss: 0.1247, mix.decode.loss_seg: 0.0765, mix.decode.acc_seg: 96.6116, mix.loss: 0.0765, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:04:12,162 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 9:32:54, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0962, src.decode.acc_seg: 96.5308, src.loss: 0.1123, mix.decode.loss_seg: 0.0593, mix.decode.acc_seg: 97.5515, mix.loss: 0.0593, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:05:14,002 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 9:31:52, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0981, src.decode.acc_seg: 96.4576, src.loss: 0.1141, mix.decode.loss_seg: 0.0651, mix.decode.acc_seg: 97.4116, mix.loss: 0.0651, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:06:15,952 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 9:30:50, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0816, src.decode.acc_seg: 97.0569, src.loss: 0.0976, mix.decode.loss_seg: 0.0532, mix.decode.acc_seg: 97.8676, mix.loss: 0.0532, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:07:17,685 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 9:29:48, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0981, src.decode.acc_seg: 96.4805, src.loss: 0.1141, mix.decode.loss_seg: 0.0535, mix.decode.acc_seg: 97.9753, mix.loss: 0.0535, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:08:19,174 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 9:28:45, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0932, src.decode.acc_seg: 96.6426, src.loss: 0.1092, mix.decode.loss_seg: 0.0618, mix.decode.acc_seg: 97.5321, mix.loss: 0.0618, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:09:20,977 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 9:27:43, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0905, src.decode.acc_seg: 96.6138, src.loss: 0.1065, mix.decode.loss_seg: 0.0532, mix.decode.acc_seg: 97.6904, mix.loss: 0.0532, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:10:22,863 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 9:26:41, time: 1.238, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1121, src.decode.acc_seg: 95.9343, src.loss: 0.1282, mix.decode.loss_seg: 0.0904, mix.decode.acc_seg: 96.5796, mix.loss: 0.0904, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:11:24,205 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 9:25:38, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1101, src.decode.acc_seg: 96.2089, src.loss: 0.1261, mix.decode.loss_seg: 0.0730, mix.decode.acc_seg: 97.3073, mix.loss: 0.0730, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:12:25,891 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 9:24:35, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0870, src.decode.acc_seg: 96.9970, src.loss: 0.1030, mix.decode.loss_seg: 0.0625, mix.decode.acc_seg: 97.5793, mix.loss: 0.0625, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:13:28,029 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 9:23:34, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0893, src.decode.acc_seg: 96.9807, src.loss: 0.1054, mix.decode.loss_seg: 0.0598, mix.decode.acc_seg: 97.6538, mix.loss: 0.0598, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:14:30,064 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 9:22:32, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0936, src.decode.acc_seg: 96.5225, src.loss: 0.1097, mix.decode.loss_seg: 0.0513, mix.decode.acc_seg: 97.8052, mix.loss: 0.0513, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:15:31,926 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 9:21:30, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0935, src.decode.acc_seg: 96.6836, src.loss: 0.1095, mix.decode.loss_seg: 0.0585, mix.decode.acc_seg: 97.6549, mix.loss: 0.0585, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:16:33,653 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 9:20:28, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1197, src.decode.acc_seg: 95.5693, src.loss: 0.1357, mix.decode.loss_seg: 0.0690, mix.decode.acc_seg: 97.1983, mix.loss: 0.0690, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:17:34,949 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 9:19:24, time: 1.226, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0875, src.decode.acc_seg: 96.8430, src.loss: 0.1036, mix.decode.loss_seg: 0.0636, mix.decode.acc_seg: 97.4388, mix.loss: 0.0636, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:18:36,778 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 9:18:22, time: 1.237, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.1040, src.decode.acc_seg: 96.4528, src.loss: 0.1201, mix.decode.loss_seg: 0.0650, mix.decode.acc_seg: 97.5769, mix.loss: 0.0650, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:19:38,833 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 13:19:38,834 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 9:17:20, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0869, src.decode.acc_seg: 97.1497, src.loss: 0.1030, mix.decode.loss_seg: 0.0543, mix.decode.acc_seg: 97.9107, mix.loss: 0.0543, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:20:41,084 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 9:16:19, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0794, src.decode.acc_seg: 97.1663, src.loss: 0.0954, mix.decode.loss_seg: 0.0568, mix.decode.acc_seg: 97.5984, mix.loss: 0.0568, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:21:42,752 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 9:15:17, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0996, src.decode.acc_seg: 96.2968, src.loss: 0.1157, mix.decode.loss_seg: 0.0625, mix.decode.acc_seg: 97.3976, mix.loss: 0.0625, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:22:44,855 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 9:14:15, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0937, src.decode.acc_seg: 96.5315, src.loss: 0.1098, mix.decode.loss_seg: 0.0595, mix.decode.acc_seg: 97.5998, mix.loss: 0.0595, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:23:46,573 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 9:13:13, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0958, src.decode.acc_seg: 96.3689, src.loss: 0.1119, mix.decode.loss_seg: 0.0650, mix.decode.acc_seg: 97.4430, mix.loss: 0.0650, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:24:48,196 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 9:12:10, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1012, src.decode.acc_seg: 96.1233, src.loss: 0.1172, mix.decode.loss_seg: 0.0749, mix.decode.acc_seg: 96.9781, mix.loss: 0.0749, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:25:49,779 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 9:11:08, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1166, src.decode.acc_seg: 95.6993, src.loss: 0.1326, mix.decode.loss_seg: 0.0714, mix.decode.acc_seg: 96.8668, mix.loss: 0.0714, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:26:51,739 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 9:10:06, time: 1.239, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0974, src.decode.acc_seg: 96.5211, src.loss: 0.1135, mix.decode.loss_seg: 0.0540, mix.decode.acc_seg: 97.8086, mix.loss: 0.0540, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:27:53,239 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 9:09:03, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1053, src.decode.acc_seg: 96.4276, src.loss: 0.1214, mix.decode.loss_seg: 0.0615, mix.decode.acc_seg: 97.6945, mix.loss: 0.0615, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:28:55,221 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 9:08:01, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0900, src.decode.acc_seg: 96.9003, src.loss: 0.1061, mix.decode.loss_seg: 0.0628, mix.decode.acc_seg: 97.4034, mix.loss: 0.0628, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:29:57,222 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 9:06:59, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0736, src.decode.acc_seg: 97.4298, src.loss: 0.0896, mix.decode.loss_seg: 0.0583, mix.decode.acc_seg: 97.5680, mix.loss: 0.0583, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:30:58,816 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 9:05:57, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0991, src.decode.acc_seg: 96.6556, src.loss: 0.1152, mix.decode.loss_seg: 0.0643, mix.decode.acc_seg: 97.4620, mix.loss: 0.0643, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:32:00,796 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 9:04:55, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1072, src.decode.acc_seg: 96.1551, src.loss: 0.1233, mix.decode.loss_seg: 0.0678, mix.decode.acc_seg: 97.4869, mix.loss: 0.0678, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:33:02,870 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 9:03:53, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0858, src.decode.acc_seg: 97.0644, src.loss: 0.1018, mix.decode.loss_seg: 0.0579, mix.decode.acc_seg: 97.6446, mix.loss: 0.0579, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:34:05,117 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 9:02:52, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1124, src.decode.acc_seg: 96.1956, src.loss: 0.1285, mix.decode.loss_seg: 0.0627, mix.decode.acc_seg: 97.3335, mix.loss: 0.0627, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:35:06,945 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 9:01:50, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1084, src.decode.acc_seg: 96.2798, src.loss: 0.1244, mix.decode.loss_seg: 0.0692, mix.decode.acc_seg: 97.0117, mix.loss: 0.0692, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:36:08,505 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 9:00:47, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0958, src.decode.acc_seg: 96.5069, src.loss: 0.1119, mix.decode.loss_seg: 0.0582, mix.decode.acc_seg: 97.6403, mix.loss: 0.0582, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:37:10,122 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 8:59:45, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0897, src.decode.acc_seg: 96.6002, src.loss: 0.1057, mix.decode.loss_seg: 0.0539, mix.decode.acc_seg: 97.5940, mix.loss: 0.0539, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:38:11,681 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 8:58:42, time: 1.231, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0941, src.decode.acc_seg: 96.8525, src.loss: 0.1101, mix.decode.loss_seg: 0.0627, mix.decode.acc_seg: 97.3219, mix.loss: 0.0627, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:39:14,013 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 8:57:41, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0717, src.decode.acc_seg: 97.4004, src.loss: 0.0877, mix.decode.loss_seg: 0.0488, mix.decode.acc_seg: 97.9837, mix.loss: 0.0488, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:40:15,883 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 13:40:15,883 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 8:56:39, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0867, src.decode.acc_seg: 96.6963, src.loss: 0.1027, mix.decode.loss_seg: 0.0557, mix.decode.acc_seg: 97.8444, mix.loss: 0.0557, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:41:17,268 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 8:55:36, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0893, src.decode.acc_seg: 96.6514, src.loss: 0.1054, mix.decode.loss_seg: 0.0599, mix.decode.acc_seg: 97.6901, mix.loss: 0.0599, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:42:18,671 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 8:54:33, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0730, src.decode.acc_seg: 97.5056, src.loss: 0.0891, mix.decode.loss_seg: 0.0462, mix.decode.acc_seg: 98.1430, mix.loss: 0.0462, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:43:20,796 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 8:53:32, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1048, src.decode.acc_seg: 96.1271, src.loss: 0.1209, mix.decode.loss_seg: 0.0558, mix.decode.acc_seg: 97.7270, mix.loss: 0.0558, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:44:22,607 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 8:52:30, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1098, src.decode.acc_seg: 96.1548, src.loss: 0.1259, mix.decode.loss_seg: 0.0632, mix.decode.acc_seg: 97.3554, mix.loss: 0.0632, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:45:24,422 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 8:51:28, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0825, src.decode.acc_seg: 97.0403, src.loss: 0.0985, mix.decode.loss_seg: 0.0555, mix.decode.acc_seg: 97.7570, mix.loss: 0.0555, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:46:26,664 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 8:50:26, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0733, src.decode.acc_seg: 97.3804, src.loss: 0.0894, mix.decode.loss_seg: 0.0520, mix.decode.acc_seg: 97.9673, mix.loss: 0.0520, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:47:28,600 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 8:49:24, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0825, src.decode.acc_seg: 97.0189, src.loss: 0.0985, mix.decode.loss_seg: 0.0495, mix.decode.acc_seg: 97.9307, mix.loss: 0.0495, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:48:30,457 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 8:48:22, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0690, src.decode.acc_seg: 97.4592, src.loss: 0.0850, mix.decode.loss_seg: 0.0525, mix.decode.acc_seg: 97.8619, mix.loss: 0.0525, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:49:31,873 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 8:47:19, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0949, src.decode.acc_seg: 96.4800, src.loss: 0.1109, mix.decode.loss_seg: 0.0604, mix.decode.acc_seg: 97.4147, mix.loss: 0.0604, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:50:34,079 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 8:46:18, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0762, src.decode.acc_seg: 97.1480, src.loss: 0.0922, mix.decode.loss_seg: 0.0560, mix.decode.acc_seg: 97.6246, mix.loss: 0.0560, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:51:35,747 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 8:45:16, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0867, src.decode.acc_seg: 96.8733, src.loss: 0.1027, mix.decode.loss_seg: 0.0547, mix.decode.acc_seg: 97.6743, mix.loss: 0.0547, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:52:37,610 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 8:44:14, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0921, src.decode.acc_seg: 96.8720, src.loss: 0.1081, mix.decode.loss_seg: 0.0489, mix.decode.acc_seg: 97.9000, mix.loss: 0.0489, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:53:38,671 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 8:43:10, time: 1.221, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0781, src.decode.acc_seg: 97.2377, src.loss: 0.0941, mix.decode.loss_seg: 0.0509, mix.decode.acc_seg: 98.0019, mix.loss: 0.0509, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:54:40,342 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 8:42:08, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0944, src.decode.acc_seg: 96.8123, src.loss: 0.1104, mix.decode.loss_seg: 0.0562, mix.decode.acc_seg: 97.6447, mix.loss: 0.0562, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:55:42,047 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 8:41:06, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1093, src.decode.acc_seg: 96.5300, src.loss: 0.1253, mix.decode.loss_seg: 0.0796, mix.decode.acc_seg: 97.4162, mix.loss: 0.0796, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:56:43,177 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 8:40:02, time: 1.223, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0988, src.decode.acc_seg: 96.3666, src.loss: 0.1148, mix.decode.loss_seg: 0.0652, mix.decode.acc_seg: 97.3579, mix.loss: 0.0652, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:57:45,139 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 8:39:01, time: 1.239, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0879, src.decode.acc_seg: 96.9482, src.loss: 0.1039, mix.decode.loss_seg: 0.0543, mix.decode.acc_seg: 97.6919, mix.loss: 0.0543, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:58:46,635 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 8:37:58, time: 1.230, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0903, src.decode.acc_seg: 96.9176, src.loss: 0.1064, mix.decode.loss_seg: 0.0613, mix.decode.acc_seg: 97.6678, mix.loss: 0.0613, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:59:48,278 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 8:36:56, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0862, src.decode.acc_seg: 96.7106, src.loss: 0.1022, mix.decode.loss_seg: 0.0532, mix.decode.acc_seg: 97.8067, mix.loss: 0.0532, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:00:49,713 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 14:00:49,714 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 8:35:53, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0922, src.decode.acc_seg: 96.6295, src.loss: 0.1083, mix.decode.loss_seg: 0.0570, mix.decode.acc_seg: 97.7796, mix.loss: 0.0570, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:01:51,147 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 8:34:50, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0790, src.decode.acc_seg: 97.1574, src.loss: 0.0950, mix.decode.loss_seg: 0.0541, mix.decode.acc_seg: 97.8789, mix.loss: 0.0541, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:02:52,745 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 8:33:48, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0877, src.decode.acc_seg: 96.9464, src.loss: 0.1038, mix.decode.loss_seg: 0.0582, mix.decode.acc_seg: 97.9867, mix.loss: 0.0582, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:03:54,271 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 8:32:45, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0960, src.decode.acc_seg: 96.5942, src.loss: 0.1121, mix.decode.loss_seg: 0.0664, mix.decode.acc_seg: 97.4307, mix.loss: 0.0664, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:04:55,397 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 8:31:42, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0920, src.decode.acc_seg: 96.7415, src.loss: 0.1080, mix.decode.loss_seg: 0.0597, mix.decode.acc_seg: 97.5421, mix.loss: 0.0597, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:05:56,761 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 8:30:39, time: 1.227, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0882, src.decode.acc_seg: 96.7959, src.loss: 0.1042, mix.decode.loss_seg: 0.0523, mix.decode.acc_seg: 97.6315, mix.loss: 0.0523, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:06:58,152 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 8:29:37, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1030, src.decode.acc_seg: 96.2792, src.loss: 0.1190, mix.decode.loss_seg: 0.0736, mix.decode.acc_seg: 96.9511, mix.loss: 0.0736, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:08:00,194 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 8:28:35, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1024, src.decode.acc_seg: 96.4791, src.loss: 0.1185, mix.decode.loss_seg: 0.0744, mix.decode.acc_seg: 97.0979, mix.loss: 0.0744, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:09:01,295 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 8:27:32, time: 1.222, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1002, src.decode.acc_seg: 96.4282, src.loss: 0.1162, mix.decode.loss_seg: 0.0686, mix.decode.acc_seg: 97.3934, mix.loss: 0.0686, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:10:02,934 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 8:26:30, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1068, src.decode.acc_seg: 96.1424, src.loss: 0.1229, mix.decode.loss_seg: 0.0627, mix.decode.acc_seg: 97.4516, mix.loss: 0.0627, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:11:04,283 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 8:25:27, time: 1.227, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0934, src.decode.acc_seg: 96.5990, src.loss: 0.1094, mix.decode.loss_seg: 0.0545, mix.decode.acc_seg: 97.9393, mix.loss: 0.0545, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:12:05,259 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 8:24:23, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0874, src.decode.acc_seg: 96.7940, src.loss: 0.1035, mix.decode.loss_seg: 0.0613, mix.decode.acc_seg: 97.6042, mix.loss: 0.0613, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:13:07,208 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 8:23:22, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0778, src.decode.acc_seg: 97.2884, src.loss: 0.0939, mix.decode.loss_seg: 0.0515, mix.decode.acc_seg: 97.8663, mix.loss: 0.0515, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:14:08,141 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 8:22:18, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0881, src.decode.acc_seg: 96.7935, src.loss: 0.1041, mix.decode.loss_seg: 0.0619, mix.decode.acc_seg: 97.7056, mix.loss: 0.0619, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:15:09,615 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 8:21:16, time: 1.229, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0772, src.decode.acc_seg: 97.2283, src.loss: 0.0932, mix.decode.loss_seg: 0.0521, mix.decode.acc_seg: 97.8466, mix.loss: 0.0521, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:16:11,207 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 8:20:13, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0868, src.decode.acc_seg: 96.8823, src.loss: 0.1028, mix.decode.loss_seg: 0.0533, mix.decode.acc_seg: 97.7332, mix.loss: 0.0533, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:17:12,531 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 8:19:11, time: 1.226, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1006, src.decode.acc_seg: 96.6488, src.loss: 0.1166, mix.decode.loss_seg: 0.0652, mix.decode.acc_seg: 97.3036, mix.loss: 0.0652, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:18:14,135 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 8:18:08, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0791, src.decode.acc_seg: 97.0662, src.loss: 0.0952, mix.decode.loss_seg: 0.0526, mix.decode.acc_seg: 97.7673, mix.loss: 0.0526, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:19:15,220 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 8:17:05, time: 1.222, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0958, src.decode.acc_seg: 96.5159, src.loss: 0.1118, mix.decode.loss_seg: 0.0576, mix.decode.acc_seg: 97.6013, mix.loss: 0.0576, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:20:16,855 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 8:16:03, time: 1.233, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0840, src.decode.acc_seg: 96.9955, src.loss: 0.1001, mix.decode.loss_seg: 0.0510, mix.decode.acc_seg: 97.9097, mix.loss: 0.0510, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1002s[                                 ] 2/929, 1.7 task/s, elapsed: 1s, ETA:   547s[                                 ] 3/929, 2.2 task/s, elapsed: 1s, ETA:   414s[                                 ] 4/929, 2.8 task/s, elapsed: 1s, ETA:   332s[                                 ] 5/929, 3.3 task/s, elapsed: 2s, ETA:   283s[                                 ] 6/929, 3.7 task/s, elapsed: 2s, ETA:   251s[                                 ] 7/929, 4.1 task/s, elapsed: 2s, ETA:   227s[                                 ] 8/929, 4.4 task/s, elapsed: 2s, ETA:   210s[                                 ] 9/929, 4.7 task/s, elapsed: 2s, ETA:   196s[                                ] 10/929, 5.0 task/s, elapsed: 2s, ETA:   185s[                                ] 11/929, 5.2 task/s, elapsed: 2s, ETA:   176s[                                ] 12/929, 5.4 task/s, elapsed: 2s, ETA:   169s[                                ] 13/929, 5.6 task/s, elapsed: 2s, ETA:   163s[                                ] 14/929, 5.8 task/s, elapsed: 2s, ETA:   158s[                                ] 15/929, 6.0 task/s, elapsed: 3s, ETA:   153s[                                ] 16/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 17/929, 6.3 task/s, elapsed: 3s, ETA:   145s[                                ] 18/929, 6.4 task/s, elapsed: 3s, ETA:   142s[                                ] 19/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 20/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 21/929, 6.8 task/s, elapsed: 3s, ETA:   134s[                                ] 22/929, 6.9 task/s, elapsed: 3s, ETA:   132s[                                ] 23/929, 6.9 task/s, elapsed: 3s, ETA:   132s[                                ] 24/929, 7.0 task/s, elapsed: 3s, ETA:   130s[                                ] 25/929, 7.0 task/s, elapsed: 4s, ETA:   129s[                                ] 26/929, 7.1 task/s, elapsed: 4s, ETA:   127s[                                ] 27/929, 7.2 task/s, elapsed: 4s, ETA:   125s[                                ] 28/929, 7.3 task/s, elapsed: 4s, ETA:   124s[                                ] 29/929, 7.3 task/s, elapsed: 4s, ETA:   123s[>                               ] 30/929, 7.4 task/s, elapsed: 4s, ETA:   121s[>                               ] 31/929, 7.5 task/s, elapsed: 4s, ETA:   120s[>                               ] 32/929, 7.5 task/s, elapsed: 4s, ETA:   119s[>                               ] 33/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 34/929, 7.6 task/s, elapsed: 4s, ETA:   118s[>                               ] 35/929, 7.7 task/s, elapsed: 5s, ETA:   117s[>                               ] 36/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 37/929, 7.7 task/s, elapsed: 5s, ETA:   115s[>                               ] 38/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 39/929, 7.8 task/s, elapsed: 5s, ETA:   114s[>                               ] 40/929, 7.9 task/s, elapsed: 5s, ETA:   113s[>                               ] 41/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 42/929, 7.9 task/s, elapsed: 5s, ETA:   112s[>                               ] 43/929, 8.0 task/s, elapsed: 5s, ETA:   111s[>                               ] 44/929, 8.0 task/s, elapsed: 5s, ETA:   110s[>                               ] 45/929, 8.1 task/s, elapsed: 6s, ETA:   110s[>                               ] 46/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 47/929, 8.1 task/s, elapsed: 6s, ETA:   109s[>                               ] 48/929, 8.1 task/s, elapsed: 6s, ETA:   108s[>                               ] 49/929, 8.2 task/s, elapsed: 6s, ETA:   108s[>                               ] 50/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 51/929, 8.2 task/s, elapsed: 6s, ETA:   107s[>                               ] 52/929, 8.2 task/s, elapsed: 6s, ETA:   106s[>                               ] 53/929, 8.3 task/s, elapsed: 6s, ETA:   106s[>                               ] 54/929, 8.3 task/s, elapsed: 7s, ETA:   106s[>                               ] 55/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 56/929, 8.3 task/s, elapsed: 7s, ETA:   105s[>                               ] 57/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>                               ] 58/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>>                              ] 59/929, 8.4 task/s, elapsed: 7s, ETA:   104s[>>                              ] 60/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 61/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 62/929, 8.4 task/s, elapsed: 7s, ETA:   103s[>>                              ] 63/929, 8.5 task/s, elapsed: 7s, ETA:   102s[>>                              ] 64/929, 8.5 task/s, elapsed: 8s, ETA:   102s[>>                              ] 65/929, 8.5 task/s, elapsed: 8s, ETA:   102s[>>                              ] 66/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 67/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 68/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 69/929, 8.5 task/s, elapsed: 8s, ETA:   101s[>>                              ] 70/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 71/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 72/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 73/929, 8.6 task/s, elapsed: 8s, ETA:   100s[>>                              ] 74/929, 8.6 task/s, elapsed: 9s, ETA:   100s[>>                              ] 75/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 76/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 77/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 78/929, 8.6 task/s, elapsed: 9s, ETA:    99s[>>                              ] 79/929, 8.6 task/s, elapsed: 9s, ETA:    98s[>>                              ] 80/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 81/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                              ] 82/929, 8.7 task/s, elapsed: 9s, ETA:    98s[>>                             ] 83/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 84/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 85/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 86/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 87/929, 8.7 task/s, elapsed: 10s, ETA:    97s[>>                             ] 88/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>                             ] 89/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 90/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 91/929, 8.7 task/s, elapsed: 10s, ETA:    96s[>>>                            ] 92/929, 8.8 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 93/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 94/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 95/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 96/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 97/929, 8.8 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 98/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                            ] 99/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 100/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 101/929, 8.8 task/s, elapsed: 11s, ETA:    94s[>>>                           ] 102/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 103/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 104/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 105/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 106/929, 8.9 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 107/929, 8.9 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 108/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 109/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 110/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 111/929, 8.9 task/s, elapsed: 12s, ETA:    92s[>>>                           ] 112/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 113/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 114/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 115/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 116/929, 9.0 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 117/929, 9.0 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 118/929, 9.0 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 119/929, 9.0 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 120/929, 9.0 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 121/929, 9.0 task/s, elapsed: 13s, ETA:    90s[>>>                           ] 122/929, 9.0 task/s, elapsed: 14s, ETA:    90s[>>>                           ] 123/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 124/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 125/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 126/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 127/929, 9.1 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 128/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 129/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 130/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 131/929, 9.1 task/s, elapsed: 14s, ETA:    88s[>>>>                          ] 132/929, 9.1 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 133/929, 9.1 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 134/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 135/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 136/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 137/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 138/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 139/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 140/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 141/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 142/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 143/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 144/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 145/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 146/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 147/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 148/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 149/929, 9.1 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 150/929, 9.1 task/s, elapsed: 16s, ETA:    85s[>>>>                          ] 151/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 152/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 153/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 154/929, 9.2 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 155/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 156/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 157/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 158/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 159/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 160/929, 9.2 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 161/929, 9.2 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 162/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 163/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 164/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 165/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 166/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 167/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 168/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 169/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 170/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 171/929, 9.2 task/s, elapsed: 18s, ETA:    82s[>>>>>                         ] 172/929, 9.3 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 173/929, 9.3 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 174/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 175/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 176/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 177/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 178/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 179/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 180/929, 9.2 task/s, elapsed: 19s, ETA:    81s[>>>>>                         ] 181/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 182/929, 9.3 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 183/929, 9.3 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 184/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>                         ] 185/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 186/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 187/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 188/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 189/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 190/929, 9.3 task/s, elapsed: 20s, ETA:    80s[>>>>>>                        ] 191/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 192/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 193/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 194/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 195/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 196/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 197/929, 9.3 task/s, elapsed: 21s, ETA:    79s[>>>>>>                        ] 198/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 199/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 200/929, 9.3 task/s, elapsed: 21s, ETA:    78s[>>>>>>                        ] 201/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 202/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 203/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 204/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 205/929, 9.3 task/s, elapsed: 22s, ETA:    78s[>>>>>>                        ] 206/929, 9.3 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 207/929, 9.3 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 208/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 209/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 210/929, 9.4 task/s, elapsed: 22s, ETA:    77s[>>>>>>                        ] 211/929, 9.4 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 212/929, 9.4 task/s, elapsed: 23s, ETA:    77s[>>>>>>                        ] 213/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 214/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 215/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>                        ] 216/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 217/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 218/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 219/929, 9.4 task/s, elapsed: 23s, ETA:    76s[>>>>>>>                       ] 220/929, 9.4 task/s, elapsed: 23s, ETA:    75s[>>>>>>>                       ] 221/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 222/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 223/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 224/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 225/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 226/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 227/929, 9.4 task/s, elapsed: 24s, ETA:    75s[>>>>>>>                       ] 228/929, 9.4 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 229/929, 9.4 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 230/929, 9.4 task/s, elapsed: 24s, ETA:    74s[>>>>>>>                       ] 231/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 232/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 233/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 234/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 235/929, 9.4 task/s, elapsed: 25s, ETA:    74s[>>>>>>>                       ] 236/929, 9.4 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 237/929, 9.4 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 238/929, 9.4 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 239/929, 9.4 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 240/929, 9.4 task/s, elapsed: 25s, ETA:    73s[>>>>>>>                       ] 241/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 242/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 243/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 244/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 245/929, 9.4 task/s, elapsed: 26s, ETA:    73s[>>>>>>>                       ] 246/929, 9.4 task/s, elapsed: 26s, ETA:    72s[>>>>>>>                       ] 247/929, 9.4 task/s, elapsed: 26s, ETA:    72s[>>>>>>>>                      ] 248/929, 9.4 task/s, elapsed: 26s, ETA:    72s[>>>>>>>>                      ] 249/929, 9.4 task/s, elapsed: 26s, ETA:    72s[>>>>>>>>                      ] 250/929, 9.4 task/s, elapsed: 26s, ETA:    72s[>>>>>>>>                      ] 251/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 252/929, 9.4 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 253/929, 9.5 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 254/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 255/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 256/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 257/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 258/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 259/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 260/929, 9.5 task/s, elapsed: 27s, ETA:    71s[>>>>>>>>                      ] 261/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 262/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 263/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 264/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 265/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 266/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 267/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 268/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 269/929, 9.5 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 270/929, 9.5 task/s, elapsed: 28s, ETA:    69s[>>>>>>>>                      ] 271/929, 9.5 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 272/929, 9.5 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 273/929, 9.5 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 274/929, 9.5 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 275/929, 9.5 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 276/929, 9.5 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 277/929, 9.5 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 278/929, 9.5 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 279/929, 9.5 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 280/929, 9.5 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 281/929, 9.5 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 282/929, 9.5 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 283/929, 9.5 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 284/929, 9.5 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 285/929, 9.5 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 286/929, 9.5 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 287/929, 9.5 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 288/929, 9.5 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 289/929, 9.5 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 290/929, 9.5 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 291/929, 9.5 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 292/929, 9.5 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 293/929, 9.5 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 294/929, 9.5 task/s, elapsed: 31s, ETA:    67s[>>>>>>>>>                     ] 295/929, 9.5 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 296/929, 9.5 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 297/929, 9.5 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 298/929, 9.5 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 299/929, 9.5 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 300/929, 9.5 task/s, elapsed: 31s, ETA:    66s[>>>>>>>>>                     ] 301/929, 9.5 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 302/929, 9.5 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 303/929, 9.5 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 304/929, 9.5 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 305/929, 9.5 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 306/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 307/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 308/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>                     ] 309/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>>                    ] 310/929, 9.6 task/s, elapsed: 32s, ETA:    65s[>>>>>>>>>>                    ] 311/929, 9.6 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 312/929, 9.6 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 313/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 314/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 315/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 316/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 317/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 318/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 319/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 320/929, 9.6 task/s, elapsed: 33s, ETA:    64s[>>>>>>>>>>                    ] 321/929, 9.6 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 322/929, 9.6 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 323/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 324/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 325/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 326/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 327/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 328/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 329/929, 9.6 task/s, elapsed: 34s, ETA:    63s[>>>>>>>>>>                    ] 330/929, 9.6 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 331/929, 9.6 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 332/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 333/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 334/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 335/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 336/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 337/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 338/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 339/929, 9.6 task/s, elapsed: 35s, ETA:    62s[>>>>>>>>>>                    ] 340/929, 9.6 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 341/929, 9.6 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 342/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 343/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 344/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 345/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 346/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 347/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 348/929, 9.6 task/s, elapsed: 36s, ETA:    61s[>>>>>>>>>>>                   ] 349/929, 9.6 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 350/929, 9.6 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 351/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 352/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 353/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 354/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 355/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 356/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 357/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 358/929, 9.6 task/s, elapsed: 37s, ETA:    60s[>>>>>>>>>>>                   ] 359/929, 9.6 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 360/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 361/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 362/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 363/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 364/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 365/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 366/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 367/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 368/929, 9.6 task/s, elapsed: 38s, ETA:    59s[>>>>>>>>>>>                   ] 369/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>                   ] 370/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>                   ] 371/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 372/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 373/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 374/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 375/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 376/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 377/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 378/929, 9.6 task/s, elapsed: 39s, ETA:    58s[>>>>>>>>>>>>                  ] 379/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 380/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 381/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 382/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 383/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 384/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 385/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 386/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 387/929, 9.6 task/s, elapsed: 40s, ETA:    57s[>>>>>>>>>>>>                  ] 388/929, 9.6 task/s, elapsed: 40s, ETA:    56s[>>>>>>>>>>>>                  ] 389/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 390/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 391/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 392/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 393/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 394/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 395/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 396/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 397/929, 9.6 task/s, elapsed: 41s, ETA:    56s[>>>>>>>>>>>>                  ] 398/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>                  ] 399/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>                  ] 400/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>                  ] 401/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>                  ] 402/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>>                 ] 403/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>>                 ] 404/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>>                 ] 405/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>>                 ] 406/929, 9.6 task/s, elapsed: 42s, ETA:    55s[>>>>>>>>>>>>>                 ] 407/929, 9.6 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 408/929, 9.6 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 409/929, 9.6 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 410/929, 9.6 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 411/929, 9.6 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 412/929, 9.5 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 413/929, 9.5 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 414/929, 9.5 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 415/929, 9.5 task/s, elapsed: 43s, ETA:    54s[>>>>>>>>>>>>>                 ] 416/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 417/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 418/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 419/929, 9.5 task/s, elapsed: 44s, ETA:    53s[>>>>>>>>>>>>>                 ] 420/929, 9.5 task/s, elapsed: 44s, ETA:    53s[>>>>>>>>>>>>>                 ] 421/929, 9.5 task/s, elapsed: 44s, ETA:    53s[>>>>>>>>>>>>>                 ] 422/929, 9.5 task/s, elapsed: 44s, ETA:    53s[>>>>>>>>>>>>>                 ] 423/929, 9.5 task/s, elapsed: 44s, ETA:    53s[>>>>>>>>>>>>>                 ] 424/929, 9.5 task/s, elapsed: 44s, ETA:    53s[>>>>>>>>>>>>>                 ] 425/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 426/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 427/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 428/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 429/929, 9.5 task/s, elapsed: 45s, ETA:    52s[>>>>>>>>>>>>>                 ] 430/929, 9.5 task/s, elapsed: 45s, ETA:    52s[>>>>>>>>>>>>>                 ] 431/929, 9.5 task/s, elapsed: 45s, ETA:    52s[>>>>>>>>>>>>>                 ] 432/929, 9.5 task/s, elapsed: 45s, ETA:    52s[>>>>>>>>>>>>>                 ] 433/929, 9.5 task/s, elapsed: 45s, ETA:    52s[>>>>>>>>>>>>>>                ] 434/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 435/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 436/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 437/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 438/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 439/929, 9.5 task/s, elapsed: 46s, ETA:    51s[>>>>>>>>>>>>>>                ] 440/929, 9.5 task/s, elapsed: 46s, ETA:    51s[>>>>>>>>>>>>>>                ] 441/929, 9.5 task/s, elapsed: 46s, ETA:    51s[>>>>>>>>>>>>>>                ] 442/929, 9.5 task/s, elapsed: 46s, ETA:    51s[>>>>>>>>>>>>>>                ] 443/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 444/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 445/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 446/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 447/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 448/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 449/929, 9.5 task/s, elapsed: 47s, ETA:    50s[>>>>>>>>>>>>>>                ] 450/929, 9.5 task/s, elapsed: 47s, ETA:    50s[>>>>>>>>>>>>>>                ] 451/929, 9.5 task/s, elapsed: 47s, ETA:    50s[>>>>>>>>>>>>>>                ] 452/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 453/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 454/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 455/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 456/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 457/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 458/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 459/929, 9.5 task/s, elapsed: 48s, ETA:    49s[>>>>>>>>>>>>>>                ] 460/929, 9.5 task/s, elapsed: 48s, ETA:    49s[>>>>>>>>>>>>>>                ] 461/929, 9.5 task/s, elapsed: 48s, ETA:    49s[>>>>>>>>>>>>>>                ] 462/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 463/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 464/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 465/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 466/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 467/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 468/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 469/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 470/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 471/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 472/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 473/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 474/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 475/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 476/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 477/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 478/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 479/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 480/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 481/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 482/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 483/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 484/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 485/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 486/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 487/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 488/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 489/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 490/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 491/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 492/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 493/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 494/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 495/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 496/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 498/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 499/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 500/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 501/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 502/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 503/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 504/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 505/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 508/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 509/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 510/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 511/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 512/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 513/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 514/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 518/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 519/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 520/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 521/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 522/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 523/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.5 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.5 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.5 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.5 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.5 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.5 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.5 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.5 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.5 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.5 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.5 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.4 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.4 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.4 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.4 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.5 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.5 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.4 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.4 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.4 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.4 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.4 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.4 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.4 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.4 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.4 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.4 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.4 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.4 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.4 task/s, elapsed: 68s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.4 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.4 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.4 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.4 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.4 task/s, elapsed: 69s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.4 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.4 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.4 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.4 task/s, elapsed: 70s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.4 task/s, elapsed: 76s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.4 task/s, elapsed: 77s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.4 task/s, elapsed: 78s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.4 task/s, elapsed: 79s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.4 task/s, elapsed: 80s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.4 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.4 task/s, elapsed: 81s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.4 task/s, elapsed: 82s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.4 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.4 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.4 task/s, elapsed: 99s, ETA:     0s2022-10-10 14:24:37,607 - mmseg - INFO - per class results:2022-10-10 14:24:37,608 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.09 | 95.69 || rigid_plastic | 25.25 | 29.88 ||   cardboard   | 57.99 | 73.46 ||     metal     | 26.06 |  28.2 ||  soft_plastic | 61.03 | 74.71 |+---------------+-------+-------+2022-10-10 14:24:37,608 - mmseg - INFO - Summary:2022-10-10 14:24:37,608 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.39 | 52.29 | 60.39 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:24:37,612 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 14:24:37,612 - mmseg - INFO - Iter [929/40000]	lr: 3.600e-05, eta: 8:15:00, time: 1.226, data_time: 0.013, memory: 67493, aAcc: 0.9139, mIoU: 0.5229, mAcc: 0.6039, IoU.background: 0.9109, IoU.rigid_plastic: 0.2525, IoU.cardboard: 0.5799, IoU.metal: 0.2606, IoU.soft_plastic: 0.6103, Acc.background: 0.9569, Acc.rigid_plastic: 0.2988, Acc.cardboard: 0.7346, Acc.metal: 0.2820, Acc.soft_plastic: 0.7471, src.decode.loss_seg: 0.0789, src.decode.acc_seg: 97.1044, src.loss: 0.0950, mix.decode.loss_seg: 0.0460, mix.decode.acc_seg: 98.2743, mix.loss: 0.0460, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:25:38,870 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 8:18:55, time: 5.215, data_time: 4.003, memory: 67493, src.decode.loss_seg: 0.0814, src.decode.acc_seg: 97.1016, src.loss: 0.0974, mix.decode.loss_seg: 0.0502, mix.decode.acc_seg: 97.8971, mix.loss: 0.0502, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:26:40,210 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 8:17:51, time: 1.227, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0693, src.decode.acc_seg: 97.4328, src.loss: 0.0853, mix.decode.loss_seg: 0.0436, mix.decode.acc_seg: 98.0786, mix.loss: 0.0436, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:27:43,371 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 8:16:49, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0668, src.decode.acc_seg: 97.6598, src.loss: 0.0829, mix.decode.loss_seg: 0.0428, mix.decode.acc_seg: 98.0205, mix.loss: 0.0428, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:28:45,174 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 8:15:46, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0716, src.decode.acc_seg: 97.4253, src.loss: 0.0877, mix.decode.loss_seg: 0.0486, mix.decode.acc_seg: 98.0602, mix.loss: 0.0486, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:29:46,325 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 8:14:41, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0850, src.decode.acc_seg: 97.0478, src.loss: 0.1011, mix.decode.loss_seg: 0.0607, mix.decode.acc_seg: 97.7116, mix.loss: 0.0607, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:30:48,055 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 8:13:38, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0863, src.decode.acc_seg: 96.9977, src.loss: 0.1023, mix.decode.loss_seg: 0.0622, mix.decode.acc_seg: 97.5571, mix.loss: 0.0622, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:31:49,559 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 8:12:34, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0758, src.decode.acc_seg: 97.2987, src.loss: 0.0918, mix.decode.loss_seg: 0.0563, mix.decode.acc_seg: 97.8819, mix.loss: 0.0563, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:32:50,848 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 8:11:30, time: 1.226, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0693, src.decode.acc_seg: 97.5957, src.loss: 0.0853, mix.decode.loss_seg: 0.0505, mix.decode.acc_seg: 97.8614, mix.loss: 0.0505, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:33:52,200 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 8:10:26, time: 1.227, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.1057, src.decode.acc_seg: 96.2199, src.loss: 0.1217, mix.decode.loss_seg: 0.0580, mix.decode.acc_seg: 97.6513, mix.loss: 0.0580, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:34:53,563 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 8:09:22, time: 1.227, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0855, src.decode.acc_seg: 97.0619, src.loss: 0.1015, mix.decode.loss_seg: 0.0540, mix.decode.acc_seg: 97.8166, mix.loss: 0.0540, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:35:54,970 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 8:08:18, time: 1.228, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0692, src.decode.acc_seg: 97.4754, src.loss: 0.0853, mix.decode.loss_seg: 0.0477, mix.decode.acc_seg: 98.1674, mix.loss: 0.0477, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:36:56,489 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 8:07:14, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0692, src.decode.acc_seg: 97.5162, src.loss: 0.0852, mix.decode.loss_seg: 0.0450, mix.decode.acc_seg: 98.0579, mix.loss: 0.0450, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:37:57,555 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 8:06:09, time: 1.221, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0762, src.decode.acc_seg: 97.1808, src.loss: 0.0923, mix.decode.loss_seg: 0.0561, mix.decode.acc_seg: 97.8119, mix.loss: 0.0561, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:38:59,699 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 8:05:06, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0756, src.decode.acc_seg: 97.1474, src.loss: 0.0916, mix.decode.loss_seg: 0.0656, mix.decode.acc_seg: 97.3798, mix.loss: 0.0656, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:40:01,410 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 8:04:03, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0848, src.decode.acc_seg: 96.7550, src.loss: 0.1008, mix.decode.loss_seg: 0.0538, mix.decode.acc_seg: 97.9003, mix.loss: 0.0538, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:41:02,835 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 8:02:59, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0642, src.decode.acc_seg: 97.7133, src.loss: 0.0803, mix.decode.loss_seg: 0.0430, mix.decode.acc_seg: 98.1860, mix.loss: 0.0430, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:42:04,335 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 8:01:55, time: 1.230, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0910, src.decode.acc_seg: 97.0120, src.loss: 0.1070, mix.decode.loss_seg: 0.0533, mix.decode.acc_seg: 97.8206, mix.loss: 0.0533, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:43:05,435 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 8:00:51, time: 1.222, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0915, src.decode.acc_seg: 96.6357, src.loss: 0.1075, mix.decode.loss_seg: 0.0664, mix.decode.acc_seg: 97.6299, mix.loss: 0.0664, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:44:06,753 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 7:59:47, time: 1.226, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0854, src.decode.acc_seg: 96.8440, src.loss: 0.1014, mix.decode.loss_seg: 0.0557, mix.decode.acc_seg: 97.9537, mix.loss: 0.0557, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:45:07,670 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 14:45:07,671 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 7:58:42, time: 1.218, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0893, src.decode.acc_seg: 96.9281, src.loss: 0.1053, mix.decode.loss_seg: 0.0508, mix.decode.acc_seg: 97.8547, mix.loss: 0.0508, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:46:09,257 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 7:57:39, time: 1.232, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0860, src.decode.acc_seg: 96.9313, src.loss: 0.1020, mix.decode.loss_seg: 0.0534, mix.decode.acc_seg: 97.7314, mix.loss: 0.0534, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:47:10,879 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 7:56:35, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0730, src.decode.acc_seg: 97.3935, src.loss: 0.0891, mix.decode.loss_seg: 0.0539, mix.decode.acc_seg: 97.6229, mix.loss: 0.0539, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:48:12,057 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 7:55:31, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0800, src.decode.acc_seg: 97.2710, src.loss: 0.0961, mix.decode.loss_seg: 0.0566, mix.decode.acc_seg: 97.8874, mix.loss: 0.0566, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:49:13,090 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 7:54:27, time: 1.221, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0647, src.decode.acc_seg: 97.6233, src.loss: 0.0807, mix.decode.loss_seg: 0.0449, mix.decode.acc_seg: 98.1189, mix.loss: 0.0449, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:50:14,115 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 7:53:23, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.1044, src.decode.acc_seg: 96.1241, src.loss: 0.1205, mix.decode.loss_seg: 0.0663, mix.decode.acc_seg: 97.3822, mix.loss: 0.0663, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:51:15,011 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 7:52:18, time: 1.218, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0699, src.decode.acc_seg: 97.4804, src.loss: 0.0860, mix.decode.loss_seg: 0.0475, mix.decode.acc_seg: 97.9147, mix.loss: 0.0475, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:52:15,364 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 7:51:13, time: 1.207, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0623, src.decode.acc_seg: 97.6641, src.loss: 0.0783, mix.decode.loss_seg: 0.0367, mix.decode.acc_seg: 98.4557, mix.loss: 0.0367, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:53:16,311 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 7:50:09, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0610, src.decode.acc_seg: 97.8359, src.loss: 0.0770, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.3628, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:54:16,774 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 7:49:04, time: 1.209, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0886, src.decode.acc_seg: 96.9149, src.loss: 0.1047, mix.decode.loss_seg: 0.0523, mix.decode.acc_seg: 97.7811, mix.loss: 0.0523, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:55:17,775 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 7:48:00, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0651, src.decode.acc_seg: 97.5969, src.loss: 0.0812, mix.decode.loss_seg: 0.0431, mix.decode.acc_seg: 98.1025, mix.loss: 0.0431, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:56:18,536 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 7:46:55, time: 1.215, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0651, src.decode.acc_seg: 97.6314, src.loss: 0.0811, mix.decode.loss_seg: 0.0497, mix.decode.acc_seg: 97.8014, mix.loss: 0.0497, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:57:19,748 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 7:45:51, time: 1.224, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0688, src.decode.acc_seg: 97.5089, src.loss: 0.0848, mix.decode.loss_seg: 0.0439, mix.decode.acc_seg: 98.1242, mix.loss: 0.0439, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:58:20,163 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 7:44:46, time: 1.208, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0662, src.decode.acc_seg: 97.4968, src.loss: 0.0823, mix.decode.loss_seg: 0.0434, mix.decode.acc_seg: 98.0935, mix.loss: 0.0434, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:59:21,339 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 7:43:42, time: 1.224, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0790, src.decode.acc_seg: 97.1377, src.loss: 0.0950, mix.decode.loss_seg: 0.0481, mix.decode.acc_seg: 98.1207, mix.loss: 0.0481, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:00:23,140 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 7:42:39, time: 1.236, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0763, src.decode.acc_seg: 97.4041, src.loss: 0.0923, mix.decode.loss_seg: 0.0489, mix.decode.acc_seg: 97.8293, mix.loss: 0.0489, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:01:24,413 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 7:41:36, time: 1.225, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0692, src.decode.acc_seg: 97.5517, src.loss: 0.0852, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.3777, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:02:25,316 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 7:40:31, time: 1.218, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0655, src.decode.acc_seg: 97.5518, src.loss: 0.0815, mix.decode.loss_seg: 0.0394, mix.decode.acc_seg: 98.2458, mix.loss: 0.0394, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:03:26,448 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 7:39:27, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0836, src.decode.acc_seg: 97.1010, src.loss: 0.0996, mix.decode.loss_seg: 0.0523, mix.decode.acc_seg: 97.7573, mix.loss: 0.0523, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:04:27,193 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 7:38:23, time: 1.215, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0753, src.decode.acc_seg: 97.3215, src.loss: 0.0914, mix.decode.loss_seg: 0.0547, mix.decode.acc_seg: 97.7365, mix.loss: 0.0547, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:05:27,825 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 15:05:27,825 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 7:37:19, time: 1.213, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0903, src.decode.acc_seg: 96.6736, src.loss: 0.1064, mix.decode.loss_seg: 0.0500, mix.decode.acc_seg: 97.9142, mix.loss: 0.0500, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:06:29,020 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 7:36:15, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0756, src.decode.acc_seg: 97.3763, src.loss: 0.0916, mix.decode.loss_seg: 0.0506, mix.decode.acc_seg: 97.8889, mix.loss: 0.0506, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:07:29,631 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 7:35:10, time: 1.212, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0909, src.decode.acc_seg: 96.8146, src.loss: 0.1069, mix.decode.loss_seg: 0.0557, mix.decode.acc_seg: 97.6562, mix.loss: 0.0557, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:08:31,366 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 7:34:07, time: 1.235, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0786, src.decode.acc_seg: 97.0528, src.loss: 0.0946, mix.decode.loss_seg: 0.0476, mix.decode.acc_seg: 98.1026, mix.loss: 0.0476, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:09:32,517 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 7:33:03, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0893, src.decode.acc_seg: 96.7905, src.loss: 0.1053, mix.decode.loss_seg: 0.0597, mix.decode.acc_seg: 97.7137, mix.loss: 0.0597, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:10:33,528 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 7:32:00, time: 1.220, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0720, src.decode.acc_seg: 97.4549, src.loss: 0.0881, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.1021, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:11:34,678 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 7:30:56, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0664, src.decode.acc_seg: 97.5558, src.loss: 0.0824, mix.decode.loss_seg: 0.0550, mix.decode.acc_seg: 97.7460, mix.loss: 0.0550, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:12:34,873 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 7:29:51, time: 1.204, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0673, src.decode.acc_seg: 97.3850, src.loss: 0.0834, mix.decode.loss_seg: 0.0496, mix.decode.acc_seg: 97.9080, mix.loss: 0.0496, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:13:35,711 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 7:28:47, time: 1.217, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0671, src.decode.acc_seg: 97.5311, src.loss: 0.0832, mix.decode.loss_seg: 0.0407, mix.decode.acc_seg: 98.0755, mix.loss: 0.0407, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:14:36,514 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 7:27:43, time: 1.216, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0700, src.decode.acc_seg: 97.4507, src.loss: 0.0860, mix.decode.loss_seg: 0.0587, mix.decode.acc_seg: 97.5996, mix.loss: 0.0587, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:15:37,036 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 7:26:38, time: 1.210, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0682, src.decode.acc_seg: 97.6142, src.loss: 0.0843, mix.decode.loss_seg: 0.0425, mix.decode.acc_seg: 98.1374, mix.loss: 0.0425, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:16:38,429 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 7:25:35, time: 1.228, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0645, src.decode.acc_seg: 97.6876, src.loss: 0.0806, mix.decode.loss_seg: 0.0384, mix.decode.acc_seg: 98.3267, mix.loss: 0.0384, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:17:39,068 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 7:24:31, time: 1.213, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0781, src.decode.acc_seg: 97.0103, src.loss: 0.0942, mix.decode.loss_seg: 0.0504, mix.decode.acc_seg: 97.7965, mix.loss: 0.0504, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:18:39,469 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 7:23:26, time: 1.208, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0848, src.decode.acc_seg: 96.8690, src.loss: 0.1009, mix.decode.loss_seg: 0.0526, mix.decode.acc_seg: 97.6045, mix.loss: 0.0526, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:19:40,068 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 7:22:22, time: 1.212, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0717, src.decode.acc_seg: 97.4643, src.loss: 0.0878, mix.decode.loss_seg: 0.0572, mix.decode.acc_seg: 97.7507, mix.loss: 0.0572, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:20:40,564 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 7:21:17, time: 1.210, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0783, src.decode.acc_seg: 97.2569, src.loss: 0.0944, mix.decode.loss_seg: 0.0533, mix.decode.acc_seg: 97.7625, mix.loss: 0.0533, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:21:41,515 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 7:20:14, time: 1.219, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0603, src.decode.acc_seg: 97.8552, src.loss: 0.0763, mix.decode.loss_seg: 0.0493, mix.decode.acc_seg: 97.9350, mix.loss: 0.0493, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:22:42,116 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 7:19:09, time: 1.212, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0731, src.decode.acc_seg: 97.2440, src.loss: 0.0891, mix.decode.loss_seg: 0.0516, mix.decode.acc_seg: 97.7448, mix.loss: 0.0516, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:23:43,328 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 7:18:06, time: 1.224, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0577, src.decode.acc_seg: 97.8569, src.loss: 0.0738, mix.decode.loss_seg: 0.0451, mix.decode.acc_seg: 98.0316, mix.loss: 0.0451, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:24:43,642 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 7:17:01, time: 1.206, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0696, src.decode.acc_seg: 97.5126, src.loss: 0.0857, mix.decode.loss_seg: 0.0516, mix.decode.acc_seg: 98.0377, mix.loss: 0.0516, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:25:44,773 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 15:25:44,773 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 7:15:58, time: 1.223, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0743, src.decode.acc_seg: 97.2616, src.loss: 0.0904, mix.decode.loss_seg: 0.0435, mix.decode.acc_seg: 98.2427, mix.loss: 0.0435, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:26:45,060 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 7:14:53, time: 1.206, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0655, src.decode.acc_seg: 97.5750, src.loss: 0.0816, mix.decode.loss_seg: 0.0445, mix.decode.acc_seg: 98.1328, mix.loss: 0.0445, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:27:46,492 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 7:13:50, time: 1.229, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0702, src.decode.acc_seg: 97.4834, src.loss: 0.0863, mix.decode.loss_seg: 0.0497, mix.decode.acc_seg: 97.8699, mix.loss: 0.0497, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:28:48,608 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 7:12:48, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0635, src.decode.acc_seg: 97.7600, src.loss: 0.0796, mix.decode.loss_seg: 0.0464, mix.decode.acc_seg: 98.0945, mix.loss: 0.0464, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:29:51,507 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 7:11:46, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0680, src.decode.acc_seg: 97.5664, src.loss: 0.0840, mix.decode.loss_seg: 0.0492, mix.decode.acc_seg: 98.0136, mix.loss: 0.0492, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:30:53,994 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 7:10:44, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0822, src.decode.acc_seg: 97.1598, src.loss: 0.0982, mix.decode.loss_seg: 0.0531, mix.decode.acc_seg: 97.7684, mix.loss: 0.0531, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:31:56,279 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 7:09:42, time: 1.246, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0687, src.decode.acc_seg: 97.4759, src.loss: 0.0848, mix.decode.loss_seg: 0.0454, mix.decode.acc_seg: 98.1614, mix.loss: 0.0454, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:32:58,205 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 7:08:39, time: 1.239, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0807, src.decode.acc_seg: 96.9810, src.loss: 0.0968, mix.decode.loss_seg: 0.0512, mix.decode.acc_seg: 97.8114, mix.loss: 0.0512, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:34:00,437 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 7:07:37, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0751, src.decode.acc_seg: 97.1659, src.loss: 0.0911, mix.decode.loss_seg: 0.0473, mix.decode.acc_seg: 98.2050, mix.loss: 0.0473, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:35:02,817 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 7:06:35, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0699, src.decode.acc_seg: 97.4280, src.loss: 0.0859, mix.decode.loss_seg: 0.0454, mix.decode.acc_seg: 98.0402, mix.loss: 0.0454, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:36:05,885 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 7:05:33, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0831, src.decode.acc_seg: 97.1744, src.loss: 0.0991, mix.decode.loss_seg: 0.0476, mix.decode.acc_seg: 97.9969, mix.loss: 0.0476, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:37:08,136 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 7:04:31, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0660, src.decode.acc_seg: 97.6402, src.loss: 0.0821, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.1115, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:38:10,131 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 7:03:28, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0698, src.decode.acc_seg: 97.4646, src.loss: 0.0858, mix.decode.loss_seg: 0.0462, mix.decode.acc_seg: 98.0138, mix.loss: 0.0462, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:39:12,572 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 7:02:26, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0697, src.decode.acc_seg: 97.4044, src.loss: 0.0857, mix.decode.loss_seg: 0.0429, mix.decode.acc_seg: 98.1332, mix.loss: 0.0429, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:40:14,681 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 7:01:24, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0624, src.decode.acc_seg: 97.6792, src.loss: 0.0785, mix.decode.loss_seg: 0.0438, mix.decode.acc_seg: 98.3006, mix.loss: 0.0438, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:41:17,394 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 7:00:22, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0668, src.decode.acc_seg: 97.5542, src.loss: 0.0828, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.3019, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:42:19,982 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 6:59:20, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0653, src.decode.acc_seg: 97.6061, src.loss: 0.0813, mix.decode.loss_seg: 0.0437, mix.decode.acc_seg: 98.0015, mix.loss: 0.0437, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:43:22,472 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 6:58:18, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0667, src.decode.acc_seg: 97.6498, src.loss: 0.0827, mix.decode.loss_seg: 0.0429, mix.decode.acc_seg: 98.1699, mix.loss: 0.0429, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:44:24,948 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 6:57:16, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0984, src.decode.acc_seg: 96.8039, src.loss: 0.1144, mix.decode.loss_seg: 0.0632, mix.decode.acc_seg: 97.3715, mix.loss: 0.0632, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:45:27,422 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 6:56:14, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0690, src.decode.acc_seg: 97.4888, src.loss: 0.0850, mix.decode.loss_seg: 0.0489, mix.decode.acc_seg: 98.0727, mix.loss: 0.0489, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1159s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   632s[                                 ] 3/929, 2.0 task/s, elapsed: 1s, ETA:   454s[                                 ] 4/929, 2.5 task/s, elapsed: 2s, ETA:   367s[                                 ] 5/929, 3.0 task/s, elapsed: 2s, ETA:   313s[                                 ] 6/929, 3.3 task/s, elapsed: 2s, ETA:   277s[                                 ] 7/929, 3.7 task/s, elapsed: 2s, ETA:   253s[                                 ] 8/929, 3.9 task/s, elapsed: 2s, ETA:   234s[                                 ] 9/929, 4.2 task/s, elapsed: 2s, ETA:   219s[                                ] 10/929, 4.4 task/s, elapsed: 2s, ETA:   208s[                                ] 11/929, 4.6 task/s, elapsed: 2s, ETA:   198s[                                ] 12/929, 4.8 task/s, elapsed: 2s, ETA:   190s[                                ] 13/929, 5.0 task/s, elapsed: 3s, ETA:   184s[                                ] 14/929, 5.2 task/s, elapsed: 3s, ETA:   178s[                                ] 15/929, 5.3 task/s, elapsed: 3s, ETA:   172s[                                ] 16/929, 5.4 task/s, elapsed: 3s, ETA:   168s[                                ] 17/929, 5.6 task/s, elapsed: 3s, ETA:   163s[                                ] 18/929, 5.7 task/s, elapsed: 3s, ETA:   159s[                                ] 19/929, 5.8 task/s, elapsed: 3s, ETA:   156s[                                ] 20/929, 5.9 task/s, elapsed: 3s, ETA:   154s[                                ] 21/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 22/929, 6.1 task/s, elapsed: 4s, ETA:   148s[                                ] 23/929, 6.2 task/s, elapsed: 4s, ETA:   146s[                                ] 24/929, 6.3 task/s, elapsed: 4s, ETA:   143s[                                ] 25/929, 6.4 task/s, elapsed: 4s, ETA:   141s[                                ] 26/929, 6.5 task/s, elapsed: 4s, ETA:   140s[                                ] 27/929, 6.5 task/s, elapsed: 4s, ETA:   138s[                                ] 28/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 29/929, 6.7 task/s, elapsed: 4s, ETA:   135s[>                               ] 30/929, 6.7 task/s, elapsed: 4s, ETA:   133s[>                               ] 31/929, 6.8 task/s, elapsed: 5s, ETA:   132s[>                               ] 32/929, 6.9 task/s, elapsed: 5s, ETA:   131s[>                               ] 33/929, 6.9 task/s, elapsed: 5s, ETA:   130s[>                               ] 34/929, 6.9 task/s, elapsed: 5s, ETA:   129s[>                               ] 35/929, 7.0 task/s, elapsed: 5s, ETA:   128s[>                               ] 36/929, 7.1 task/s, elapsed: 5s, ETA:   127s[>                               ] 37/929, 7.1 task/s, elapsed: 5s, ETA:   126s[>                               ] 38/929, 7.1 task/s, elapsed: 5s, ETA:   125s[>                               ] 39/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 40/929, 7.2 task/s, elapsed: 6s, ETA:   124s[>                               ] 41/929, 7.2 task/s, elapsed: 6s, ETA:   123s[>                               ] 42/929, 7.3 task/s, elapsed: 6s, ETA:   122s[>                               ] 43/929, 7.3 task/s, elapsed: 6s, ETA:   121s[>                               ] 44/929, 7.4 task/s, elapsed: 6s, ETA:   120s[>                               ] 45/929, 7.4 task/s, elapsed: 6s, ETA:   120s[>                               ] 46/929, 7.4 task/s, elapsed: 6s, ETA:   119s[>                               ] 47/929, 7.4 task/s, elapsed: 6s, ETA:   118s[>                               ] 48/929, 7.4 task/s, elapsed: 6s, ETA:   119s[>                               ] 49/929, 7.5 task/s, elapsed: 7s, ETA:   118s[>                               ] 50/929, 7.5 task/s, elapsed: 7s, ETA:   118s[>                               ] 51/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 52/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 53/929, 7.5 task/s, elapsed: 7s, ETA:   116s[>                               ] 54/929, 7.5 task/s, elapsed: 7s, ETA:   116s[>                               ] 55/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 56/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 57/929, 7.6 task/s, elapsed: 7s, ETA:   114s[>                               ] 58/929, 7.6 task/s, elapsed: 8s, ETA:   114s[>>                              ] 59/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 60/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 61/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 62/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 63/929, 7.8 task/s, elapsed: 8s, ETA:   112s[>>                              ] 64/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 65/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 66/929, 7.8 task/s, elapsed: 8s, ETA:   110s[>>                              ] 67/929, 7.8 task/s, elapsed: 9s, ETA:   110s[>>                              ] 68/929, 7.9 task/s, elapsed: 9s, ETA:   110s[>>                              ] 69/929, 7.9 task/s, elapsed: 9s, ETA:   109s[>>                              ] 70/929, 7.9 task/s, elapsed: 9s, ETA:   109s[>>                              ] 71/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 72/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 73/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 74/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 75/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                             ] 76/929, 8.0 task/s, elapsed: 10s, ETA:   107s[>>                             ] 77/929, 8.0 task/s, elapsed: 10s, ETA:   107s[>>                             ] 78/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 79/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 80/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 81/929, 8.0 task/s, elapsed: 10s, ETA:   105s[>>                             ] 82/929, 8.1 task/s, elapsed: 10s, ETA:   105s[>>                             ] 83/929, 8.1 task/s, elapsed: 10s, ETA:   105s[>>                             ] 84/929, 8.1 task/s, elapsed: 10s, ETA:   105s[>>                             ] 85/929, 8.1 task/s, elapsed: 11s, ETA:   105s[>>                             ] 86/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>                             ] 87/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>                             ] 88/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>                             ] 89/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>>                            ] 90/929, 8.1 task/s, elapsed: 11s, ETA:   103s[>>>                            ] 91/929, 8.1 task/s, elapsed: 11s, ETA:   103s[>>>                            ] 92/929, 8.1 task/s, elapsed: 11s, ETA:   103s[>>>                            ] 93/929, 8.1 task/s, elapsed: 11s, ETA:   103s[>>>                            ] 94/929, 8.1 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 95/929, 8.2 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 96/929, 8.2 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 97/929, 8.2 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 98/929, 8.2 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 99/929, 8.2 task/s, elapsed: 12s, ETA:   102s[>>>                           ] 100/929, 8.2 task/s, elapsed: 12s, ETA:   101s[>>>                           ] 101/929, 8.2 task/s, elapsed: 12s, ETA:   101s[>>>                           ] 102/929, 8.2 task/s, elapsed: 12s, ETA:   101s[>>>                           ] 103/929, 8.2 task/s, elapsed: 13s, ETA:   101s[>>>                           ] 104/929, 8.2 task/s, elapsed: 13s, ETA:   100s[>>>                           ] 105/929, 8.2 task/s, elapsed: 13s, ETA:   100s[>>>                           ] 106/929, 8.3 task/s, elapsed: 13s, ETA:   100s[>>>                           ] 107/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 108/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 109/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 110/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 111/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 112/929, 8.3 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 113/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 114/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 115/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 116/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 117/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 118/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 119/929, 8.3 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 120/929, 8.3 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 121/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>                           ] 122/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>                           ] 123/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>>                          ] 124/929, 8.3 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 125/929, 8.3 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 126/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 127/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 128/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 129/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 130/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 131/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 132/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 133/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 134/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 135/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 136/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 137/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 138/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 139/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 140/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 141/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 142/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 143/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 144/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 145/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 146/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 147/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 148/929, 8.4 task/s, elapsed: 18s, ETA:    93s[>>>>                          ] 149/929, 8.4 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 150/929, 8.4 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 151/929, 8.4 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 152/929, 8.4 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 153/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 154/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>>                         ] 155/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>>                         ] 156/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 157/929, 8.5 task/s, elapsed: 19s, ETA:    91s[>>>>>                         ] 158/929, 8.5 task/s, elapsed: 19s, ETA:    91s[>>>>>                         ] 159/929, 8.5 task/s, elapsed: 19s, ETA:    91s[>>>>>                         ] 160/929, 8.5 task/s, elapsed: 19s, ETA:    91s[>>>>>                         ] 161/929, 8.5 task/s, elapsed: 19s, ETA:    91s[>>>>>                         ] 162/929, 8.5 task/s, elapsed: 19s, ETA:    91s[>>>>>                         ] 163/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 164/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 165/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 166/929, 8.5 task/s, elapsed: 20s, ETA:    90s[>>>>>                         ] 167/929, 8.5 task/s, elapsed: 20s, ETA:    90s[>>>>>                         ] 168/929, 8.5 task/s, elapsed: 20s, ETA:    90s[>>>>>                         ] 169/929, 8.5 task/s, elapsed: 20s, ETA:    90s[>>>>>                         ] 170/929, 8.5 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 171/929, 8.5 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 172/929, 8.5 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 173/929, 8.5 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 174/929, 8.5 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 175/929, 8.5 task/s, elapsed: 21s, ETA:    89s[>>>>>                         ] 176/929, 8.5 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 177/929, 8.5 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 178/929, 8.5 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 179/929, 8.5 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 180/929, 8.5 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 181/929, 8.5 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 182/929, 8.5 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 183/929, 8.5 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 184/929, 8.6 task/s, elapsed: 22s, ETA:    87s[>>>>>                         ] 185/929, 8.6 task/s, elapsed: 22s, ETA:    87s[>>>>>>                        ] 186/929, 8.6 task/s, elapsed: 22s, ETA:    87s[>>>>>>                        ] 187/929, 8.6 task/s, elapsed: 22s, ETA:    87s[>>>>>>                        ] 188/929, 8.6 task/s, elapsed: 22s, ETA:    87s[>>>>>>                        ] 189/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 190/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 191/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 192/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 193/929, 8.6 task/s, elapsed: 23s, ETA:    86s[>>>>>>                        ] 194/929, 8.6 task/s, elapsed: 23s, ETA:    86s[>>>>>>                        ] 195/929, 8.6 task/s, elapsed: 23s, ETA:    86s[>>>>>>                        ] 196/929, 8.6 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 197/929, 8.6 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 198/929, 8.6 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 199/929, 8.6 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 200/929, 8.6 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 201/929, 8.6 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 202/929, 8.6 task/s, elapsed: 24s, ETA:    85s[>>>>>>                        ] 203/929, 8.6 task/s, elapsed: 24s, ETA:    85s[>>>>>>                        ] 204/929, 8.6 task/s, elapsed: 24s, ETA:    85s[>>>>>>                        ] 205/929, 8.6 task/s, elapsed: 24s, ETA:    84s[>>>>>>                        ] 206/929, 8.6 task/s, elapsed: 24s, ETA:    84s[>>>>>>                        ] 207/929, 8.6 task/s, elapsed: 24s, ETA:    84s[>>>>>>                        ] 208/929, 8.6 task/s, elapsed: 24s, ETA:    84s[>>>>>>                        ] 209/929, 8.6 task/s, elapsed: 24s, ETA:    84s[>>>>>>                        ] 210/929, 8.6 task/s, elapsed: 24s, ETA:    84s[>>>>>>                        ] 211/929, 8.6 task/s, elapsed: 25s, ETA:    84s[>>>>>>                        ] 212/929, 8.6 task/s, elapsed: 25s, ETA:    84s[>>>>>>                        ] 213/929, 8.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>                        ] 214/929, 8.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>                        ] 215/929, 8.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>                        ] 216/929, 8.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>>                       ] 217/929, 8.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>>                       ] 218/929, 8.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>>                       ] 219/929, 8.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>>                       ] 220/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 221/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 222/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 223/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 224/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 225/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 226/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 227/929, 8.6 task/s, elapsed: 26s, ETA:    82s[>>>>>>>                       ] 228/929, 8.6 task/s, elapsed: 26s, ETA:    81s[>>>>>>>                       ] 229/929, 8.6 task/s, elapsed: 27s, ETA:    81s[>>>>>>>                       ] 230/929, 8.6 task/s, elapsed: 27s, ETA:    81s[>>>>>>>                       ] 231/929, 8.6 task/s, elapsed: 27s, ETA:    81s[>>>>>>>                       ] 232/929, 8.6 task/s, elapsed: 27s, ETA:    81s[>>>>>>>                       ] 233/929, 8.6 task/s, elapsed: 27s, ETA:    81s[>>>>>>>                       ] 234/929, 8.6 task/s, elapsed: 27s, ETA:    81s[>>>>>>>                       ] 235/929, 8.6 task/s, elapsed: 27s, ETA:    80s[>>>>>>>                       ] 236/929, 8.6 task/s, elapsed: 27s, ETA:    80s[>>>>>>>                       ] 237/929, 8.6 task/s, elapsed: 27s, ETA:    80s[>>>>>>>                       ] 238/929, 8.6 task/s, elapsed: 28s, ETA:    80s[>>>>>>>                       ] 239/929, 8.6 task/s, elapsed: 28s, ETA:    80s[>>>>>>>                       ] 240/929, 8.6 task/s, elapsed: 28s, ETA:    80s[>>>>>>>                       ] 241/929, 8.6 task/s, elapsed: 28s, ETA:    80s[>>>>>>>                       ] 242/929, 8.6 task/s, elapsed: 28s, ETA:    80s[>>>>>>>                       ] 243/929, 8.6 task/s, elapsed: 28s, ETA:    80s[>>>>>>>                       ] 244/929, 8.6 task/s, elapsed: 28s, ETA:    79s[>>>>>>>                       ] 245/929, 8.6 task/s, elapsed: 28s, ETA:    79s[>>>>>>>                       ] 246/929, 8.6 task/s, elapsed: 29s, ETA:    79s[>>>>>>>                       ] 247/929, 8.6 task/s, elapsed: 29s, ETA:    79s[>>>>>>>>                      ] 248/929, 8.6 task/s, elapsed: 29s, ETA:    79s[>>>>>>>>                      ] 249/929, 8.6 task/s, elapsed: 29s, ETA:    79s[>>>>>>>>                      ] 250/929, 8.6 task/s, elapsed: 29s, ETA:    79s[>>>>>>>>                      ] 251/929, 8.6 task/s, elapsed: 29s, ETA:    79s[>>>>>>>>                      ] 252/929, 8.6 task/s, elapsed: 29s, ETA:    78s[>>>>>>>>                      ] 253/929, 8.6 task/s, elapsed: 29s, ETA:    78s[>>>>>>>>                      ] 254/929, 8.6 task/s, elapsed: 29s, ETA:    78s[>>>>>>>>                      ] 255/929, 8.6 task/s, elapsed: 30s, ETA:    78s[>>>>>>>>                      ] 256/929, 8.6 task/s, elapsed: 30s, ETA:    78s[>>>>>>>>                      ] 257/929, 8.6 task/s, elapsed: 30s, ETA:    78s[>>>>>>>>                      ] 258/929, 8.6 task/s, elapsed: 30s, ETA:    78s[>>>>>>>>                      ] 259/929, 8.6 task/s, elapsed: 30s, ETA:    78s[>>>>>>>>                      ] 260/929, 8.6 task/s, elapsed: 30s, ETA:    77s[>>>>>>>>                      ] 261/929, 8.6 task/s, elapsed: 30s, ETA:    77s[>>>>>>>>                      ] 262/929, 8.6 task/s, elapsed: 30s, ETA:    77s[>>>>>>>>                      ] 263/929, 8.6 task/s, elapsed: 30s, ETA:    77s[>>>>>>>>                      ] 264/929, 8.6 task/s, elapsed: 31s, ETA:    77s[>>>>>>>>                      ] 265/929, 8.6 task/s, elapsed: 31s, ETA:    77s[>>>>>>>>                      ] 266/929, 8.6 task/s, elapsed: 31s, ETA:    77s[>>>>>>>>                      ] 267/929, 8.7 task/s, elapsed: 31s, ETA:    77s[>>>>>>>>                      ] 268/929, 8.6 task/s, elapsed: 31s, ETA:    77s[>>>>>>>>                      ] 269/929, 8.6 task/s, elapsed: 31s, ETA:    76s[>>>>>>>>                      ] 270/929, 8.6 task/s, elapsed: 31s, ETA:    76s[>>>>>>>>                      ] 271/929, 8.6 task/s, elapsed: 31s, ETA:    76s[>>>>>>>>                      ] 272/929, 8.6 task/s, elapsed: 31s, ETA:    76s[>>>>>>>>                      ] 273/929, 8.6 task/s, elapsed: 32s, ETA:    76s[>>>>>>>>                      ] 274/929, 8.6 task/s, elapsed: 32s, ETA:    76s[>>>>>>>>                      ] 275/929, 8.6 task/s, elapsed: 32s, ETA:    76s[>>>>>>>>                      ] 276/929, 8.6 task/s, elapsed: 32s, ETA:    76s[>>>>>>>>                      ] 277/929, 8.6 task/s, elapsed: 32s, ETA:    75s[>>>>>>>>                      ] 278/929, 8.6 task/s, elapsed: 32s, ETA:    75s[>>>>>>>>>                     ] 279/929, 8.6 task/s, elapsed: 32s, ETA:    75s[>>>>>>>>>                     ] 280/929, 8.6 task/s, elapsed: 32s, ETA:    75s[>>>>>>>>>                     ] 281/929, 8.6 task/s, elapsed: 33s, ETA:    75s[>>>>>>>>>                     ] 282/929, 8.6 task/s, elapsed: 33s, ETA:    75s[>>>>>>>>>                     ] 283/929, 8.6 task/s, elapsed: 33s, ETA:    75s[>>>>>>>>>                     ] 284/929, 8.6 task/s, elapsed: 33s, ETA:    75s[>>>>>>>>>                     ] 285/929, 8.6 task/s, elapsed: 33s, ETA:    75s[>>>>>>>>>                     ] 286/929, 8.6 task/s, elapsed: 33s, ETA:    74s[>>>>>>>>>                     ] 287/929, 8.6 task/s, elapsed: 33s, ETA:    74s[>>>>>>>>>                     ] 288/929, 8.6 task/s, elapsed: 33s, ETA:    74s[>>>>>>>>>                     ] 289/929, 8.6 task/s, elapsed: 33s, ETA:    74s[>>>>>>>>>                     ] 290/929, 8.6 task/s, elapsed: 34s, ETA:    74s[>>>>>>>>>                     ] 291/929, 8.7 task/s, elapsed: 34s, ETA:    74s[>>>>>>>>>                     ] 292/929, 8.6 task/s, elapsed: 34s, ETA:    74s[>>>>>>>>>                     ] 293/929, 8.7 task/s, elapsed: 34s, ETA:    74s[>>>>>>>>>                     ] 294/929, 8.7 task/s, elapsed: 34s, ETA:    73s[>>>>>>>>>                     ] 295/929, 8.7 task/s, elapsed: 34s, ETA:    73s[>>>>>>>>>                     ] 296/929, 8.7 task/s, elapsed: 34s, ETA:    73s[>>>>>>>>>                     ] 297/929, 8.7 task/s, elapsed: 34s, ETA:    73s[>>>>>>>>>                     ] 298/929, 8.7 task/s, elapsed: 34s, ETA:    73s[>>>>>>>>>                     ] 299/929, 8.7 task/s, elapsed: 34s, ETA:    73s[>>>>>>>>>                     ] 300/929, 8.7 task/s, elapsed: 35s, ETA:    72s[>>>>>>>>>                     ] 301/929, 8.7 task/s, elapsed: 35s, ETA:    72s[>>>>>>>>>                     ] 302/929, 8.7 task/s, elapsed: 35s, ETA:    72s[>>>>>>>>>                     ] 303/929, 8.7 task/s, elapsed: 35s, ETA:    72s[>>>>>>>>>                     ] 304/929, 8.7 task/s, elapsed: 35s, ETA:    72s[>>>>>>>>>                     ] 305/929, 8.7 task/s, elapsed: 35s, ETA:    72s[>>>>>>>>>                     ] 306/929, 8.7 task/s, elapsed: 35s, ETA:    72s[>>>>>>>>>                     ] 307/929, 8.7 task/s, elapsed: 35s, ETA:    71s[>>>>>>>>>                     ] 308/929, 8.7 task/s, elapsed: 35s, ETA:    71s[>>>>>>>>>                     ] 309/929, 8.7 task/s, elapsed: 35s, ETA:    71s[>>>>>>>>>>                    ] 310/929, 8.7 task/s, elapsed: 36s, ETA:    71s[>>>>>>>>>>                    ] 311/929, 8.7 task/s, elapsed: 36s, ETA:    71s[>>>>>>>>>>                    ] 312/929, 8.7 task/s, elapsed: 36s, ETA:    71s[>>>>>>>>>>                    ] 313/929, 8.7 task/s, elapsed: 36s, ETA:    71s[>>>>>>>>>>                    ] 314/929, 8.7 task/s, elapsed: 36s, ETA:    71s[>>>>>>>>>>                    ] 315/929, 8.7 task/s, elapsed: 36s, ETA:    70s[>>>>>>>>>>                    ] 316/929, 8.7 task/s, elapsed: 36s, ETA:    70s[>>>>>>>>>>                    ] 317/929, 8.7 task/s, elapsed: 36s, ETA:    70s[>>>>>>>>>>                    ] 318/929, 8.7 task/s, elapsed: 36s, ETA:    70s[>>>>>>>>>>                    ] 319/929, 8.7 task/s, elapsed: 37s, ETA:    70s[>>>>>>>>>>                    ] 320/929, 8.7 task/s, elapsed: 37s, ETA:    70s[>>>>>>>>>>                    ] 321/929, 8.7 task/s, elapsed: 37s, ETA:    70s[>>>>>>>>>>                    ] 322/929, 8.7 task/s, elapsed: 37s, ETA:    69s[>>>>>>>>>>                    ] 323/929, 8.7 task/s, elapsed: 37s, ETA:    69s[>>>>>>>>>>                    ] 324/929, 8.7 task/s, elapsed: 37s, ETA:    69s[>>>>>>>>>>                    ] 325/929, 8.8 task/s, elapsed: 37s, ETA:    69s[>>>>>>>>>>                    ] 326/929, 8.8 task/s, elapsed: 37s, ETA:    69s[>>>>>>>>>>                    ] 327/929, 8.8 task/s, elapsed: 37s, ETA:    69s[>>>>>>>>>>                    ] 328/929, 8.8 task/s, elapsed: 37s, ETA:    69s[>>>>>>>>>>                    ] 329/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 330/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 331/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 332/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 333/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 334/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 335/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 336/929, 8.8 task/s, elapsed: 38s, ETA:    68s[>>>>>>>>>>                    ] 337/929, 8.8 task/s, elapsed: 38s, ETA:    67s[>>>>>>>>>>                    ] 338/929, 8.8 task/s, elapsed: 38s, ETA:    67s[>>>>>>>>>>                    ] 339/929, 8.8 task/s, elapsed: 39s, ETA:    67s[>>>>>>>>>>                    ] 340/929, 8.8 task/s, elapsed: 39s, ETA:    67s[>>>>>>>>>>>                   ] 341/929, 8.8 task/s, elapsed: 39s, ETA:    67s[>>>>>>>>>>>                   ] 342/929, 8.8 task/s, elapsed: 39s, ETA:    67s[>>>>>>>>>>>                   ] 343/929, 8.8 task/s, elapsed: 39s, ETA:    67s[>>>>>>>>>>>                   ] 344/929, 8.8 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 345/929, 8.8 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 346/929, 8.8 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 347/929, 8.8 task/s, elapsed: 39s, ETA:    66s[>>>>>>>>>>>                   ] 348/929, 8.8 task/s, elapsed: 40s, ETA:    66s[>>>>>>>>>>>                   ] 349/929, 8.8 task/s, elapsed: 40s, ETA:    66s[>>>>>>>>>>>                   ] 350/929, 8.8 task/s, elapsed: 40s, ETA:    66s[>>>>>>>>>>>                   ] 351/929, 8.8 task/s, elapsed: 40s, ETA:    66s[>>>>>>>>>>>                   ] 352/929, 8.8 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 353/929, 8.8 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 354/929, 8.8 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 355/929, 8.8 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 356/929, 8.8 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 357/929, 8.8 task/s, elapsed: 40s, ETA:    65s[>>>>>>>>>>>                   ] 358/929, 8.8 task/s, elapsed: 41s, ETA:    65s[>>>>>>>>>>>                   ] 359/929, 8.8 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 360/929, 8.8 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 361/929, 8.8 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 362/929, 8.8 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 363/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 364/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 365/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 366/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 367/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 368/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>                   ] 369/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>                   ] 370/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>                   ] 371/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>>                  ] 372/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>>                  ] 373/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>>                  ] 374/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 375/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 376/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 377/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 378/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 379/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 380/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 381/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 382/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 383/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 384/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 385/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 386/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 387/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 388/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 389/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 390/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 391/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 392/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 393/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 394/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 395/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 396/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 397/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 398/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 399/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 400/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 401/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 402/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 403/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 404/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 405/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 406/929, 8.9 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 407/929, 8.9 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 408/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 409/929, 9.0 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 410/929, 9.0 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 411/929, 9.0 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 412/929, 9.0 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 413/929, 9.0 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 414/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 415/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 416/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 417/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 418/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 419/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 420/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 421/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 422/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 423/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 424/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 425/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 426/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 427/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 428/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 429/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 430/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 431/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 432/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 433/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 434/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 435/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 436/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 437/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 438/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 441/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 442/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 443/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 444/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 445/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 446/929, 9.0 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.0 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 450/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 451/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 452/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 453/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 454/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 455/929, 9.0 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.0 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 460/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 461/929, 9.0 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 462/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 463/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.0 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.0 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.0 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 468/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 469/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 470/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 471/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 472/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 477/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 478/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 479/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 480/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 481/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.1 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 487/929, 9.1 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 488/929, 9.1 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 489/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 496/929, 9.1 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 497/929, 9.1 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 498/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 505/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 506/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 514/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 523/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.2 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.2 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.2 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.2 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.2 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.2 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.2 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.2 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.2 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.2 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.2 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.2 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.2 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.2 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.2 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.2 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.2 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.2 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.2 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.2 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.2 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.3 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.3 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.3 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.3 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.3 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.3 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.3 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.3 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.3 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.3 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.3 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.3 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.3 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.3 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.2 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.2 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.2 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.2 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.2 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.2 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.2 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.2 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.2 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.2 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.2 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.2 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.2 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.2 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.2 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.2 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.2 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.2 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.2 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.2 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.2 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.3 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.3 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.3 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.3 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.3 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.3 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.3 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.3 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.3 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.3 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.3 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.3 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.3 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.3 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.3 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.3 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.3 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.3 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.3 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.3 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.3 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.3 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.3 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.3 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.3 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.2 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.2 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.2 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.2 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.2 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.2 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.2 task/s, elapsed: 101s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.2 task/s, elapsed: 101s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.2 task/s, elapsed: 101s, ETA:     0s2022-10-10 15:49:55,827 - mmseg - INFO - per class results:2022-10-10 15:49:55,827 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.83 | 95.08 || rigid_plastic | 25.01 | 29.72 ||   cardboard   | 58.42 | 75.74 ||     metal     | 38.44 | 48.59 ||  soft_plastic | 61.88 | 76.51 |+---------------+-------+-------+2022-10-10 15:49:55,828 - mmseg - INFO - Summary:2022-10-10 15:49:55,828 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.27 | 54.92 | 65.13 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:49:55,832 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 15:49:55,832 - mmseg - INFO - Iter [929/40000]	lr: 3.000e-05, eta: 6:55:13, time: 1.274, data_time: 0.014, memory: 67493, aAcc: 0.9127, mIoU: 0.5492, mAcc: 0.6513, IoU.background: 0.9083, IoU.rigid_plastic: 0.2501, IoU.cardboard: 0.5842, IoU.metal: 0.3844, IoU.soft_plastic: 0.6188, Acc.background: 0.9508, Acc.rigid_plastic: 0.2972, Acc.cardboard: 0.7574, Acc.metal: 0.4859, Acc.soft_plastic: 0.7651, src.decode.loss_seg: 0.0686, src.decode.acc_seg: 97.5411, src.loss: 0.0846, mix.decode.loss_seg: 0.0469, mix.decode.acc_seg: 98.1247, mix.loss: 0.0469, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:50:58,234 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 6:57:34, time: 5.342, data_time: 4.108, memory: 67493, src.decode.loss_seg: 0.0652, src.decode.acc_seg: 97.5245, src.loss: 0.0812, mix.decode.loss_seg: 0.0524, mix.decode.acc_seg: 97.9923, mix.loss: 0.0524, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:52:00,414 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 6:56:31, time: 1.244, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0612, src.decode.acc_seg: 97.7564, src.loss: 0.0772, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.2806, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:53:02,908 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 6:55:28, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0852, src.decode.acc_seg: 96.9463, src.loss: 0.1012, mix.decode.loss_seg: 0.0586, mix.decode.acc_seg: 97.8816, mix.loss: 0.0586, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:54:07,617 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 6:54:27, time: 1.294, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0731, src.decode.acc_seg: 97.3234, src.loss: 0.0892, mix.decode.loss_seg: 0.0545, mix.decode.acc_seg: 97.7028, mix.loss: 0.0545, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:55:10,671 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 6:53:25, time: 1.261, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0627, src.decode.acc_seg: 97.8074, src.loss: 0.0787, mix.decode.loss_seg: 0.0460, mix.decode.acc_seg: 98.1819, mix.loss: 0.0460, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:56:13,356 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 6:52:22, time: 1.254, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0717, src.decode.acc_seg: 97.3812, src.loss: 0.0877, mix.decode.loss_seg: 0.0473, mix.decode.acc_seg: 98.0694, mix.loss: 0.0473, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:57:16,163 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 6:51:19, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0695, src.decode.acc_seg: 97.5059, src.loss: 0.0855, mix.decode.loss_seg: 0.0496, mix.decode.acc_seg: 97.8338, mix.loss: 0.0496, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:58:18,374 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 6:50:15, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0748, src.decode.acc_seg: 97.4391, src.loss: 0.0908, mix.decode.loss_seg: 0.0528, mix.decode.acc_seg: 97.9006, mix.loss: 0.0528, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:59:21,269 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 6:49:13, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0749, src.decode.acc_seg: 97.5156, src.loss: 0.0909, mix.decode.loss_seg: 0.0517, mix.decode.acc_seg: 98.0007, mix.loss: 0.0517, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:00:24,161 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 6:48:10, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0658, src.decode.acc_seg: 97.5137, src.loss: 0.0819, mix.decode.loss_seg: 0.0499, mix.decode.acc_seg: 97.9901, mix.loss: 0.0499, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:01:27,088 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 6:47:07, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0615, src.decode.acc_seg: 97.7972, src.loss: 0.0776, mix.decode.loss_seg: 0.0479, mix.decode.acc_seg: 98.1320, mix.loss: 0.0479, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:02:30,892 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 6:46:06, time: 1.276, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0689, src.decode.acc_seg: 97.5732, src.loss: 0.0849, mix.decode.loss_seg: 0.0510, mix.decode.acc_seg: 98.1811, mix.loss: 0.0510, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:03:33,843 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 6:45:03, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0634, src.decode.acc_seg: 97.7153, src.loss: 0.0794, mix.decode.loss_seg: 0.0529, mix.decode.acc_seg: 97.7796, mix.loss: 0.0529, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:04:36,747 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 6:44:00, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0647, src.decode.acc_seg: 97.6844, src.loss: 0.0807, mix.decode.loss_seg: 0.0390, mix.decode.acc_seg: 98.4666, mix.loss: 0.0390, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:05:39,154 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 6:42:57, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0591, src.decode.acc_seg: 97.7936, src.loss: 0.0751, mix.decode.loss_seg: 0.0463, mix.decode.acc_seg: 98.0098, mix.loss: 0.0463, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:06:41,899 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 6:41:54, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0769, src.decode.acc_seg: 97.1695, src.loss: 0.0929, mix.decode.loss_seg: 0.0563, mix.decode.acc_seg: 97.5660, mix.loss: 0.0563, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:07:44,542 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 6:40:51, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0667, src.decode.acc_seg: 97.5488, src.loss: 0.0827, mix.decode.loss_seg: 0.0478, mix.decode.acc_seg: 98.0622, mix.loss: 0.0478, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:08:47,159 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 6:39:48, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0809, src.decode.acc_seg: 97.2139, src.loss: 0.0969, mix.decode.loss_seg: 0.0436, mix.decode.acc_seg: 98.0172, mix.loss: 0.0436, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:09:49,837 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 6:38:45, time: 1.254, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0663, src.decode.acc_seg: 97.4621, src.loss: 0.0823, mix.decode.loss_seg: 0.0506, mix.decode.acc_seg: 97.7819, mix.loss: 0.0506, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:10:52,803 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 16:10:52,804 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 6:37:43, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0629, src.decode.acc_seg: 97.7646, src.loss: 0.0789, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.0152, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:11:55,089 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 6:36:39, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0721, src.decode.acc_seg: 97.3956, src.loss: 0.0881, mix.decode.loss_seg: 0.0517, mix.decode.acc_seg: 97.9336, mix.loss: 0.0517, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:12:57,634 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 6:35:36, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0673, src.decode.acc_seg: 97.6814, src.loss: 0.0833, mix.decode.loss_seg: 0.0555, mix.decode.acc_seg: 97.8042, mix.loss: 0.0555, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:14:00,674 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 6:34:34, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0654, src.decode.acc_seg: 97.8059, src.loss: 0.0814, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.2332, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:15:03,354 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 6:33:31, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0629, src.decode.acc_seg: 97.8462, src.loss: 0.0789, mix.decode.loss_seg: 0.0468, mix.decode.acc_seg: 98.3389, mix.loss: 0.0468, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:16:05,537 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 6:32:28, time: 1.244, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0590, src.decode.acc_seg: 97.8241, src.loss: 0.0750, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.3454, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:17:07,667 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 6:31:24, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0543, src.decode.acc_seg: 97.9598, src.loss: 0.0704, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.3091, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:18:09,771 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 6:30:21, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0787, src.decode.acc_seg: 97.4484, src.loss: 0.0948, mix.decode.loss_seg: 0.0540, mix.decode.acc_seg: 97.7329, mix.loss: 0.0540, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:19:12,244 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 6:29:18, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0677, src.decode.acc_seg: 97.5398, src.loss: 0.0837, mix.decode.loss_seg: 0.0472, mix.decode.acc_seg: 98.1225, mix.loss: 0.0472, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:20:14,457 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 6:28:14, time: 1.244, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0695, src.decode.acc_seg: 97.3772, src.loss: 0.0855, mix.decode.loss_seg: 0.0601, mix.decode.acc_seg: 97.6463, mix.loss: 0.0601, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:21:17,533 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 6:27:12, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0706, src.decode.acc_seg: 97.5573, src.loss: 0.0867, mix.decode.loss_seg: 0.0495, mix.decode.acc_seg: 98.0236, mix.loss: 0.0495, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:22:20,760 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 6:26:10, time: 1.265, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0711, src.decode.acc_seg: 97.3674, src.loss: 0.0872, mix.decode.loss_seg: 0.0479, mix.decode.acc_seg: 98.1109, mix.loss: 0.0479, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:23:23,626 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 6:25:07, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0538, src.decode.acc_seg: 98.0297, src.loss: 0.0698, mix.decode.loss_seg: 0.0379, mix.decode.acc_seg: 98.3442, mix.loss: 0.0379, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:24:25,485 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 6:24:03, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0675, src.decode.acc_seg: 97.6901, src.loss: 0.0835, mix.decode.loss_seg: 0.0509, mix.decode.acc_seg: 97.9676, mix.loss: 0.0509, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:25:27,981 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 6:23:00, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0578, src.decode.acc_seg: 97.8940, src.loss: 0.0738, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.2846, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:26:30,285 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 6:21:57, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0694, src.decode.acc_seg: 97.4995, src.loss: 0.0854, mix.decode.loss_seg: 0.0449, mix.decode.acc_seg: 98.0273, mix.loss: 0.0449, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:27:32,423 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 6:20:54, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0608, src.decode.acc_seg: 97.7457, src.loss: 0.0768, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.0783, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:28:34,604 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 6:19:50, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0534, src.decode.acc_seg: 98.0677, src.loss: 0.0695, mix.decode.loss_seg: 0.0441, mix.decode.acc_seg: 98.1245, mix.loss: 0.0441, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:29:36,736 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 6:18:47, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0617, src.decode.acc_seg: 97.8152, src.loss: 0.0777, mix.decode.loss_seg: 0.0440, mix.decode.acc_seg: 98.2949, mix.loss: 0.0440, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:30:38,982 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 6:17:44, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0772, src.decode.acc_seg: 97.2272, src.loss: 0.0932, mix.decode.loss_seg: 0.0556, mix.decode.acc_seg: 97.7072, mix.loss: 0.0556, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:31:41,705 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 16:31:41,706 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 6:16:41, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0638, src.decode.acc_seg: 97.6691, src.loss: 0.0798, mix.decode.loss_seg: 0.0461, mix.decode.acc_seg: 98.1099, mix.loss: 0.0461, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:32:43,794 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 6:15:38, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0641, src.decode.acc_seg: 97.7259, src.loss: 0.0801, mix.decode.loss_seg: 0.0461, mix.decode.acc_seg: 98.2730, mix.loss: 0.0461, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:33:45,865 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 6:14:34, time: 1.241, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0578, src.decode.acc_seg: 97.9422, src.loss: 0.0739, mix.decode.loss_seg: 0.0411, mix.decode.acc_seg: 98.1803, mix.loss: 0.0411, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:34:48,414 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 6:13:31, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0692, src.decode.acc_seg: 97.4924, src.loss: 0.0852, mix.decode.loss_seg: 0.0452, mix.decode.acc_seg: 98.1542, mix.loss: 0.0452, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:35:50,333 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 6:12:28, time: 1.238, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0586, src.decode.acc_seg: 97.8198, src.loss: 0.0746, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.2832, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:36:52,858 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 6:11:25, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0788, src.decode.acc_seg: 97.1167, src.loss: 0.0949, mix.decode.loss_seg: 0.0515, mix.decode.acc_seg: 97.9927, mix.loss: 0.0515, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:37:55,173 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 6:10:22, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0626, src.decode.acc_seg: 97.6189, src.loss: 0.0787, mix.decode.loss_seg: 0.0465, mix.decode.acc_seg: 97.9241, mix.loss: 0.0465, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:38:57,529 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 6:09:19, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0744, src.decode.acc_seg: 97.2777, src.loss: 0.0904, mix.decode.loss_seg: 0.0471, mix.decode.acc_seg: 97.9091, mix.loss: 0.0471, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:39:59,236 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 6:08:15, time: 1.234, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0680, src.decode.acc_seg: 97.4878, src.loss: 0.0841, mix.decode.loss_seg: 0.0421, mix.decode.acc_seg: 98.1625, mix.loss: 0.0421, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:41:00,815 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 6:07:11, time: 1.232, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0599, src.decode.acc_seg: 97.8076, src.loss: 0.0759, mix.decode.loss_seg: 0.0441, mix.decode.acc_seg: 98.2480, mix.loss: 0.0441, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:42:02,689 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 6:06:08, time: 1.237, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0526, src.decode.acc_seg: 98.0648, src.loss: 0.0686, mix.decode.loss_seg: 0.0418, mix.decode.acc_seg: 98.3125, mix.loss: 0.0418, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:43:04,622 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 6:05:04, time: 1.239, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0619, src.decode.acc_seg: 97.8697, src.loss: 0.0779, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.6018, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:44:06,600 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 6:04:01, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0560, src.decode.acc_seg: 97.9091, src.loss: 0.0720, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.6980, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:45:08,295 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 6:02:57, time: 1.234, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0539, src.decode.acc_seg: 98.1391, src.loss: 0.0699, mix.decode.loss_seg: 0.0403, mix.decode.acc_seg: 98.2193, mix.loss: 0.0403, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:46:11,009 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 6:01:55, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0570, src.decode.acc_seg: 97.9081, src.loss: 0.0730, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.1796, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:47:13,413 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 6:00:52, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0656, src.decode.acc_seg: 97.5645, src.loss: 0.0816, mix.decode.loss_seg: 0.0420, mix.decode.acc_seg: 98.2270, mix.loss: 0.0420, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:48:15,757 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 5:59:49, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0606, src.decode.acc_seg: 97.8937, src.loss: 0.0766, mix.decode.loss_seg: 0.0426, mix.decode.acc_seg: 98.2926, mix.loss: 0.0426, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:49:18,013 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 5:58:45, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0491, src.decode.acc_seg: 98.1693, src.loss: 0.0652, mix.decode.loss_seg: 0.0358, mix.decode.acc_seg: 98.5039, mix.loss: 0.0358, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:50:20,076 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 5:57:42, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0604, src.decode.acc_seg: 97.7874, src.loss: 0.0764, mix.decode.loss_seg: 0.0488, mix.decode.acc_seg: 98.2686, mix.loss: 0.0488, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:51:23,382 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 5:56:40, time: 1.266, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0643, src.decode.acc_seg: 97.7644, src.loss: 0.0803, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 98.0748, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:52:25,531 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 16:52:25,531 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 5:55:37, time: 1.243, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0620, src.decode.acc_seg: 97.6148, src.loss: 0.0780, mix.decode.loss_seg: 0.0456, mix.decode.acc_seg: 98.1347, mix.loss: 0.0456, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:53:28,154 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 5:54:34, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0563, src.decode.acc_seg: 97.8607, src.loss: 0.0723, mix.decode.loss_seg: 0.0458, mix.decode.acc_seg: 98.1361, mix.loss: 0.0458, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:54:30,520 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 5:53:31, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0546, src.decode.acc_seg: 98.0501, src.loss: 0.0706, mix.decode.loss_seg: 0.0431, mix.decode.acc_seg: 98.0977, mix.loss: 0.0431, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:55:33,308 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 5:52:28, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0509, src.decode.acc_seg: 98.0855, src.loss: 0.0669, mix.decode.loss_seg: 0.0366, mix.decode.acc_seg: 98.5152, mix.loss: 0.0366, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:56:35,309 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 5:51:25, time: 1.240, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0512, src.decode.acc_seg: 98.0971, src.loss: 0.0672, mix.decode.loss_seg: 0.0380, mix.decode.acc_seg: 98.3966, mix.loss: 0.0380, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:57:37,461 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 5:50:22, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0517, src.decode.acc_seg: 98.1434, src.loss: 0.0678, mix.decode.loss_seg: 0.0366, mix.decode.acc_seg: 98.4812, mix.loss: 0.0366, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:58:39,548 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 5:49:18, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0540, src.decode.acc_seg: 98.1080, src.loss: 0.0700, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.6047, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:59:41,798 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 5:48:15, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0579, src.decode.acc_seg: 97.9084, src.loss: 0.0740, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.3348, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:00:44,541 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 5:47:12, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0679, src.decode.acc_seg: 97.6084, src.loss: 0.0840, mix.decode.loss_seg: 0.0438, mix.decode.acc_seg: 98.1558, mix.loss: 0.0438, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:01:47,144 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 5:46:10, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0718, src.decode.acc_seg: 97.2734, src.loss: 0.0878, mix.decode.loss_seg: 0.0473, mix.decode.acc_seg: 97.9323, mix.loss: 0.0473, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:02:49,829 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 5:45:07, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0626, src.decode.acc_seg: 97.7214, src.loss: 0.0786, mix.decode.loss_seg: 0.0431, mix.decode.acc_seg: 98.3700, mix.loss: 0.0431, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:03:51,882 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 5:44:04, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0748, src.decode.acc_seg: 97.4543, src.loss: 0.0908, mix.decode.loss_seg: 0.0462, mix.decode.acc_seg: 97.9970, mix.loss: 0.0462, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:04:54,314 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 5:43:01, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0579, src.decode.acc_seg: 97.7375, src.loss: 0.0739, mix.decode.loss_seg: 0.0369, mix.decode.acc_seg: 98.3413, mix.loss: 0.0369, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:05:56,499 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 5:41:57, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0565, src.decode.acc_seg: 97.9601, src.loss: 0.0726, mix.decode.loss_seg: 0.0375, mix.decode.acc_seg: 98.4367, mix.loss: 0.0375, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:06:58,902 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 5:40:54, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0543, src.decode.acc_seg: 98.1474, src.loss: 0.0703, mix.decode.loss_seg: 0.0427, mix.decode.acc_seg: 98.2652, mix.loss: 0.0427, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:08:01,773 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 5:39:52, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0646, src.decode.acc_seg: 97.6676, src.loss: 0.0806, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.1699, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:09:04,128 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 5:38:49, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0546, src.decode.acc_seg: 98.0174, src.loss: 0.0707, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.4676, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:10:06,239 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 5:37:46, time: 1.242, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0600, src.decode.acc_seg: 97.8293, src.loss: 0.0760, mix.decode.loss_seg: 0.0425, mix.decode.acc_seg: 98.1984, mix.loss: 0.0425, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:11:09,042 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 5:36:43, time: 1.256, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0590, src.decode.acc_seg: 97.8442, src.loss: 0.0751, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.2559, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:12:11,422 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 5:35:40, time: 1.248, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0622, src.decode.acc_seg: 97.7536, src.loss: 0.0783, mix.decode.loss_seg: 0.0457, mix.decode.acc_seg: 98.2511, mix.loss: 0.0457, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1157s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   626s[                                 ] 3/929, 2.1 task/s, elapsed: 1s, ETA:   448s[                                 ] 4/929, 2.6 task/s, elapsed: 2s, ETA:   360s[                                 ] 5/929, 3.0 task/s, elapsed: 2s, ETA:   306s[                                 ] 6/929, 3.4 task/s, elapsed: 2s, ETA:   270s[                                 ] 7/929, 3.8 task/s, elapsed: 2s, ETA:   244s[                                 ] 8/929, 4.1 task/s, elapsed: 2s, ETA:   225s[                                 ] 9/929, 4.4 task/s, elapsed: 2s, ETA:   210s[                                ] 10/929, 4.6 task/s, elapsed: 2s, ETA:   198s[                                ] 11/929, 4.9 task/s, elapsed: 2s, ETA:   188s[                                ] 12/929, 5.1 task/s, elapsed: 2s, ETA:   180s[                                ] 13/929, 5.3 task/s, elapsed: 2s, ETA:   173s[                                ] 14/929, 5.5 task/s, elapsed: 3s, ETA:   167s[                                ] 15/929, 5.6 task/s, elapsed: 3s, ETA:   162s[                                ] 16/929, 5.8 task/s, elapsed: 3s, ETA:   157s[                                ] 17/929, 6.0 task/s, elapsed: 3s, ETA:   153s[                                ] 18/929, 6.1 task/s, elapsed: 3s, ETA:   150s[                                ] 19/929, 6.2 task/s, elapsed: 3s, ETA:   146s[                                ] 20/929, 6.3 task/s, elapsed: 3s, ETA:   143s[                                ] 21/929, 6.4 task/s, elapsed: 3s, ETA:   141s[                                ] 22/929, 6.5 task/s, elapsed: 3s, ETA:   139s[                                ] 23/929, 6.6 task/s, elapsed: 3s, ETA:   137s[                                ] 24/929, 6.7 task/s, elapsed: 4s, ETA:   136s[                                ] 25/929, 6.8 task/s, elapsed: 4s, ETA:   134s[                                ] 26/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 27/929, 6.9 task/s, elapsed: 4s, ETA:   130s[                                ] 28/929, 7.0 task/s, elapsed: 4s, ETA:   129s[                                ] 29/929, 7.1 task/s, elapsed: 4s, ETA:   128s[>                               ] 30/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 31/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 32/929, 7.2 task/s, elapsed: 4s, ETA:   124s[>                               ] 33/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 34/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 35/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 36/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 37/929, 7.5 task/s, elapsed: 5s, ETA:   120s[>                               ] 38/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 39/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 40/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 41/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 42/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 43/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 44/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 45/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 46/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 47/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 48/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 49/929, 7.8 task/s, elapsed: 6s, ETA:   112s[>                               ] 50/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 51/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 53/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 54/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 55/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 56/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 57/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 60/929, 8.2 task/s, elapsed: 7s, ETA:   107s[>>                              ] 61/929, 8.2 task/s, elapsed: 7s, ETA:   106s[>>                              ] 62/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 63/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 64/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 65/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 66/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 68/929, 8.2 task/s, elapsed: 8s, ETA:   104s[>>                              ] 69/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 70/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 71/929, 8.2 task/s, elapsed: 9s, ETA:   104s[>>                              ] 72/929, 8.3 task/s, elapsed: 9s, ETA:   104s[>>                              ] 73/929, 8.3 task/s, elapsed: 9s, ETA:   104s[>>                              ] 74/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 75/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 76/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 77/929, 8.3 task/s, elapsed: 9s, ETA:   102s[>>                              ] 78/929, 8.3 task/s, elapsed: 9s, ETA:   102s[>>                              ] 79/929, 8.3 task/s, elapsed: 9s, ETA:   102s[>>                             ] 80/929, 8.3 task/s, elapsed: 10s, ETA:   102s[>>                             ] 81/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 82/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 83/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 84/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 85/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 86/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 87/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 88/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 89/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 90/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 91/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 92/929, 8.4 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 93/929, 8.4 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 94/929, 8.5 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 95/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 96/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 97/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 98/929, 8.5 task/s, elapsed: 12s, ETA:    98s[>>>                            ] 99/929, 8.5 task/s, elapsed: 12s, ETA:    97s[>>>                           ] 100/929, 8.5 task/s, elapsed: 12s, ETA:    97s[>>>                           ] 101/929, 8.5 task/s, elapsed: 12s, ETA:    97s[>>>                           ] 102/929, 8.6 task/s, elapsed: 12s, ETA:    97s[>>>                           ] 103/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 104/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 105/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 106/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 107/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 108/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 109/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 110/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 111/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 112/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 113/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 114/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 115/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 116/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 117/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 118/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 119/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 120/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 121/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 122/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 123/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>>                          ] 124/929, 8.7 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 125/929, 8.7 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 126/929, 8.7 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 127/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 128/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 129/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 130/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 131/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 132/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 133/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 134/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 135/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 136/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 137/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 138/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 139/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 140/929, 8.8 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 141/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 142/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 143/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 144/929, 8.8 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 145/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 146/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 147/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 148/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 149/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 150/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 151/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 152/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 153/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 154/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 155/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 156/929, 8.9 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 157/929, 8.9 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 158/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 159/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 160/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 161/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 162/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 163/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 164/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 165/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 166/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 167/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 168/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 169/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 170/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 171/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 172/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 173/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 174/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 175/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 176/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 177/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 178/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 180/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 181/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 183/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 184/929, 9.0 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 185/929, 9.0 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 186/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 187/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 188/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 191/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 192/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 193/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 194/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 195/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 196/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 198/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 199/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 200/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 222/929, 9.1 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 223/929, 9.1 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 224/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 225/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 230/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 231/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 232/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 234/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 239/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 240/929, 9.1 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 241/929, 9.1 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 242/929, 9.1 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 243/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 247/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 248/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 249/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 255/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 256/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 257/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 258/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 264/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 290/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 293/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 297/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 298/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 299/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 306/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 307/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 308/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 309/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>>                    ] 310/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 315/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 316/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 317/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 318/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 319/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 323/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 324/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 325/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 326/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 327/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 332/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 333/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 334/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 335/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 336/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 337/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 340/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 341/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 342/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.2 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 345/929, 9.2 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 346/929, 9.2 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 348/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 349/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 350/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 354/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 355/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 356/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 357/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 358/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 359/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 363/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 364/929, 9.2 task/s, elapsed: 39s, ETA:    61s[>>>>>>>>>>>                   ] 365/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 366/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 367/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 40s, ETA:    60s[>>>>>>>>>>>>                  ] 375/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.2 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 381/929, 9.2 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 382/929, 9.2 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 383/929, 9.2 task/s, elapsed: 41s, ETA:    59s[>>>>>>>>>>>>                  ] 384/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 385/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.2 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 390/929, 9.2 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 391/929, 9.2 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 392/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 393/929, 9.3 task/s, elapsed: 42s, ETA:    58s[>>>>>>>>>>>>                  ] 394/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.3 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 398/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 399/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 400/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 401/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 402/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.3 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.3 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.3 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 407/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 408/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 409/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 410/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 411/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 412/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.3 task/s, elapsed: 44s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 415/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 416/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 417/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 418/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 419/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 420/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 421/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.3 task/s, elapsed: 45s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 424/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 425/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 426/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 427/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 428/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 429/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 430/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.3 task/s, elapsed: 46s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.3 task/s, elapsed: 46s, ETA:    53s[>>>>>>>>>>>>>                 ] 433/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 434/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 435/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 436/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 437/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 438/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 439/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 440/929, 9.3 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.3 task/s, elapsed: 47s, ETA:    52s[>>>>>>>>>>>>>>                ] 442/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 443/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 444/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 445/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 446/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 447/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 448/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 449/929, 9.3 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.3 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 451/929, 9.3 task/s, elapsed: 48s, ETA:    51s[>>>>>>>>>>>>>>                ] 452/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 453/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 454/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 455/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 456/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 457/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 458/929, 9.3 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.3 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 460/929, 9.3 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 461/929, 9.3 task/s, elapsed: 49s, ETA:    50s[>>>>>>>>>>>>>>                ] 462/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 463/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 464/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 465/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 466/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 467/929, 9.3 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.3 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 469/929, 9.3 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 470/929, 9.3 task/s, elapsed: 50s, ETA:    49s[>>>>>>>>>>>>>>>               ] 471/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 472/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 473/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 474/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 475/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 476/929, 9.3 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.3 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 478/929, 9.3 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 479/929, 9.3 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 480/929, 9.3 task/s, elapsed: 51s, ETA:    48s[>>>>>>>>>>>>>>>               ] 481/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 482/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 483/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 484/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 485/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.3 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 488/929, 9.3 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 489/929, 9.3 task/s, elapsed: 52s, ETA:    47s[>>>>>>>>>>>>>>>               ] 490/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 492/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 493/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 494/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 498/929, 9.3 task/s, elapsed: 53s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 499/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 501/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 502/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 503/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 508/929, 9.3 task/s, elapsed: 54s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 511/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 512/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 513/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 517/929, 9.3 task/s, elapsed: 55s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 520/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 521/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 522/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 526/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.3 task/s, elapsed: 56s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.3 task/s, elapsed: 57s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.3 task/s, elapsed: 58s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.4 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.4 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.4 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.4 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.4 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.4 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.4 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.4 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.4 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.4 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.4 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.4 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.4 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.4 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.4 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.3 task/s, elapsed: 62s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.4 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.4 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.4 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.4 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.4 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.4 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.4 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.4 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.4 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.4 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.4 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.4 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.4 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.4 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.4 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.4 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.4 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.4 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.4 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.4 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.4 task/s, elapsed: 71s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.4 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.4 task/s, elapsed: 72s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.4 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.4 task/s, elapsed: 73s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.4 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.4 task/s, elapsed: 74s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.4 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.4 task/s, elapsed: 75s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.4 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.4 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.4 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.4 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.4 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.4 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.4 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.3 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.3 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.3 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.3 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.3 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.3 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.3 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.3 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.3 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.3 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.3 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.3 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.3 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.3 task/s, elapsed: 100s, ETA:     0s2022-10-10 17:16:51,056 - mmseg - INFO - per class results:2022-10-10 17:16:51,057 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.08 | 95.28 || rigid_plastic | 30.11 | 36.95 ||   cardboard   | 59.02 | 77.68 ||     metal     | 32.64 |  37.4 ||  soft_plastic | 63.16 | 73.24 |+---------------+-------+-------+2022-10-10 17:16:51,057 - mmseg - INFO - Summary:2022-10-10 17:16:51,057 - mmseg - INFO - +-------+------+-------+|  aAcc | mIoU |  mAcc |+-------+------+-------+| 91.52 | 55.2 | 64.11 |+-------+------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:16:51,061 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 17:16:51,061 - mmseg - INFO - Iter [929/40000]	lr: 2.400e-05, eta: 5:34:39, time: 1.297, data_time: 0.015, memory: 67493, aAcc: 0.9152, mIoU: 0.5520, mAcc: 0.6411, IoU.background: 0.9108, IoU.rigid_plastic: 0.3011, IoU.cardboard: 0.5902, IoU.metal: 0.3264, IoU.soft_plastic: 0.6316, Acc.background: 0.9528, Acc.rigid_plastic: 0.3695, Acc.cardboard: 0.7768, Acc.metal: 0.3740, Acc.soft_plastic: 0.7324, src.decode.loss_seg: 0.0591, src.decode.acc_seg: 98.0117, src.loss: 0.0751, mix.decode.loss_seg: 0.0494, mix.decode.acc_seg: 97.9266, mix.loss: 0.0494, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:17:53,740 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 5:35:58, time: 5.549, data_time: 4.310, memory: 67493, src.decode.loss_seg: 0.0575, src.decode.acc_seg: 97.9930, src.loss: 0.0735, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.6533, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:18:56,275 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 5:34:55, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0587, src.decode.acc_seg: 97.9173, src.loss: 0.0748, mix.decode.loss_seg: 0.0385, mix.decode.acc_seg: 98.3022, mix.loss: 0.0385, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:19:58,489 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 5:33:51, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0590, src.decode.acc_seg: 97.6930, src.loss: 0.0751, mix.decode.loss_seg: 0.0389, mix.decode.acc_seg: 98.3301, mix.loss: 0.0389, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:21:01,574 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 5:32:48, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0654, src.decode.acc_seg: 97.5212, src.loss: 0.0814, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.2886, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:22:06,217 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 5:31:45, time: 1.293, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0596, src.decode.acc_seg: 97.8132, src.loss: 0.0757, mix.decode.loss_seg: 0.0467, mix.decode.acc_seg: 97.9128, mix.loss: 0.0467, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:23:09,356 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 5:30:42, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0555, src.decode.acc_seg: 97.9011, src.loss: 0.0715, mix.decode.loss_seg: 0.0390, mix.decode.acc_seg: 98.3924, mix.loss: 0.0390, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:24:11,596 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 5:29:38, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0598, src.decode.acc_seg: 97.8255, src.loss: 0.0758, mix.decode.loss_seg: 0.0458, mix.decode.acc_seg: 98.0611, mix.loss: 0.0458, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:25:14,351 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 5:28:35, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0516, src.decode.acc_seg: 98.1057, src.loss: 0.0676, mix.decode.loss_seg: 0.0335, mix.decode.acc_seg: 98.5715, mix.loss: 0.0335, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:26:16,882 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 5:27:31, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0523, src.decode.acc_seg: 98.0689, src.loss: 0.0684, mix.decode.loss_seg: 0.0416, mix.decode.acc_seg: 98.2003, mix.loss: 0.0416, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:27:19,256 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 5:26:27, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0672, src.decode.acc_seg: 97.7480, src.loss: 0.0833, mix.decode.loss_seg: 0.0469, mix.decode.acc_seg: 98.1866, mix.loss: 0.0469, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:28:22,420 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 5:25:24, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0599, src.decode.acc_seg: 97.9386, src.loss: 0.0759, mix.decode.loss_seg: 0.0447, mix.decode.acc_seg: 98.0878, mix.loss: 0.0447, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:29:25,187 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 5:24:21, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0699, src.decode.acc_seg: 97.5627, src.loss: 0.0859, mix.decode.loss_seg: 0.0410, mix.decode.acc_seg: 98.1330, mix.loss: 0.0410, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:30:27,974 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 5:23:17, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0464, src.decode.acc_seg: 98.2933, src.loss: 0.0625, mix.decode.loss_seg: 0.0412, mix.decode.acc_seg: 98.3233, mix.loss: 0.0412, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:31:30,433 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 5:22:14, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0565, src.decode.acc_seg: 97.9217, src.loss: 0.0726, mix.decode.loss_seg: 0.0389, mix.decode.acc_seg: 98.3826, mix.loss: 0.0389, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:32:33,391 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 5:21:10, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0424, src.decode.acc_seg: 98.3997, src.loss: 0.0584, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.4806, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:33:35,799 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 5:20:07, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0562, src.decode.acc_seg: 97.9187, src.loss: 0.0722, mix.decode.loss_seg: 0.0375, mix.decode.acc_seg: 98.4420, mix.loss: 0.0375, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:34:38,326 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 5:19:03, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0657, src.decode.acc_seg: 97.5361, src.loss: 0.0817, mix.decode.loss_seg: 0.0468, mix.decode.acc_seg: 97.9676, mix.loss: 0.0468, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:35:41,204 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 5:18:00, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0541, src.decode.acc_seg: 97.9336, src.loss: 0.0702, mix.decode.loss_seg: 0.0393, mix.decode.acc_seg: 98.3100, mix.loss: 0.0393, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:36:43,682 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 5:16:56, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0542, src.decode.acc_seg: 98.0016, src.loss: 0.0702, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.3951, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:37:46,804 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 17:37:46,804 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 5:15:53, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0577, src.decode.acc_seg: 97.9710, src.loss: 0.0737, mix.decode.loss_seg: 0.0386, mix.decode.acc_seg: 98.5496, mix.loss: 0.0386, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:38:49,340 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 5:14:49, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0527, src.decode.acc_seg: 98.0325, src.loss: 0.0687, mix.decode.loss_seg: 0.0389, mix.decode.acc_seg: 98.3885, mix.loss: 0.0389, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:39:51,877 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 5:13:46, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0656, src.decode.acc_seg: 97.6655, src.loss: 0.0817, mix.decode.loss_seg: 0.0444, mix.decode.acc_seg: 98.3178, mix.loss: 0.0444, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:40:54,278 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 5:12:42, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0559, src.decode.acc_seg: 97.9199, src.loss: 0.0719, mix.decode.loss_seg: 0.0441, mix.decode.acc_seg: 98.1844, mix.loss: 0.0441, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:41:57,363 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 5:11:39, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0545, src.decode.acc_seg: 97.9037, src.loss: 0.0705, mix.decode.loss_seg: 0.0394, mix.decode.acc_seg: 98.3153, mix.loss: 0.0394, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:43:00,127 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 5:10:36, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0583, src.decode.acc_seg: 97.8037, src.loss: 0.0744, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.1330, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:44:03,057 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 5:09:32, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0507, src.decode.acc_seg: 98.1223, src.loss: 0.0668, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.5093, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:45:05,556 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 5:08:29, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0589, src.decode.acc_seg: 97.8233, src.loss: 0.0750, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.3334, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:46:07,917 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 5:07:25, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0572, src.decode.acc_seg: 97.9675, src.loss: 0.0732, mix.decode.loss_seg: 0.0400, mix.decode.acc_seg: 98.3104, mix.loss: 0.0400, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:47:10,400 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 5:06:22, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0594, src.decode.acc_seg: 97.9476, src.loss: 0.0754, mix.decode.loss_seg: 0.0411, mix.decode.acc_seg: 98.2733, mix.loss: 0.0411, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:48:13,124 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 5:05:18, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0600, src.decode.acc_seg: 97.9131, src.loss: 0.0760, mix.decode.loss_seg: 0.0490, mix.decode.acc_seg: 98.0236, mix.loss: 0.0490, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:49:15,198 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 5:04:14, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0501, src.decode.acc_seg: 98.0775, src.loss: 0.0662, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.3546, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:50:17,345 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 5:03:11, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0530, src.decode.acc_seg: 98.0762, src.loss: 0.0690, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.4902, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:51:20,132 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 5:02:07, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0692, src.decode.acc_seg: 97.4795, src.loss: 0.0852, mix.decode.loss_seg: 0.0369, mix.decode.acc_seg: 98.4153, mix.loss: 0.0369, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:52:22,662 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 5:01:04, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0539, src.decode.acc_seg: 97.9829, src.loss: 0.0700, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.4761, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:53:25,697 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 5:00:00, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0616, src.decode.acc_seg: 97.7691, src.loss: 0.0777, mix.decode.loss_seg: 0.0401, mix.decode.acc_seg: 98.2208, mix.loss: 0.0401, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:54:27,961 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 4:58:57, time: 1.245, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0603, src.decode.acc_seg: 97.8284, src.loss: 0.0763, mix.decode.loss_seg: 0.0418, mix.decode.acc_seg: 98.1496, mix.loss: 0.0418, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:55:31,152 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 4:57:54, time: 1.264, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0531, src.decode.acc_seg: 98.1340, src.loss: 0.0692, mix.decode.loss_seg: 0.0374, mix.decode.acc_seg: 98.4664, mix.loss: 0.0374, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:56:33,553 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 4:56:50, time: 1.248, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0464, src.decode.acc_seg: 98.2917, src.loss: 0.0624, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.2302, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:57:36,310 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 4:55:47, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0618, src.decode.acc_seg: 97.7549, src.loss: 0.0779, mix.decode.loss_seg: 0.0420, mix.decode.acc_seg: 98.2985, mix.loss: 0.0420, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:58:39,453 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 17:58:39,453 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 4:54:44, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0604, src.decode.acc_seg: 97.8401, src.loss: 0.0764, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.3647, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:59:41,650 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 4:53:40, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0544, src.decode.acc_seg: 97.9984, src.loss: 0.0704, mix.decode.loss_seg: 0.0324, mix.decode.acc_seg: 98.5891, mix.loss: 0.0324, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:00:44,726 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 4:52:37, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0627, src.decode.acc_seg: 97.7980, src.loss: 0.0787, mix.decode.loss_seg: 0.0431, mix.decode.acc_seg: 98.3495, mix.loss: 0.0431, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:01:47,622 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 4:51:33, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0559, src.decode.acc_seg: 97.8819, src.loss: 0.0719, mix.decode.loss_seg: 0.0387, mix.decode.acc_seg: 98.4187, mix.loss: 0.0387, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:02:49,959 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 4:50:30, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0503, src.decode.acc_seg: 98.1495, src.loss: 0.0663, mix.decode.loss_seg: 0.0399, mix.decode.acc_seg: 98.3805, mix.loss: 0.0399, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:03:52,349 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 4:49:26, time: 1.248, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0492, src.decode.acc_seg: 98.1931, src.loss: 0.0652, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.5357, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:04:54,528 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 4:48:23, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0514, src.decode.acc_seg: 98.0881, src.loss: 0.0674, mix.decode.loss_seg: 0.0348, mix.decode.acc_seg: 98.4657, mix.loss: 0.0348, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:05:57,504 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 4:47:19, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0536, src.decode.acc_seg: 98.0743, src.loss: 0.0697, mix.decode.loss_seg: 0.0388, mix.decode.acc_seg: 98.3341, mix.loss: 0.0388, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:07:00,263 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 4:46:16, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0610, src.decode.acc_seg: 97.7515, src.loss: 0.0770, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.4837, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:08:02,712 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 4:45:12, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0501, src.decode.acc_seg: 98.1895, src.loss: 0.0662, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.4993, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:09:04,980 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 4:44:09, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.4098, src.loss: 0.0601, mix.decode.loss_seg: 0.0326, mix.decode.acc_seg: 98.6445, mix.loss: 0.0326, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:10:08,281 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 4:43:06, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0515, src.decode.acc_seg: 98.2732, src.loss: 0.0675, mix.decode.loss_seg: 0.0426, mix.decode.acc_seg: 98.2904, mix.loss: 0.0426, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:11:11,063 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 4:42:02, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0533, src.decode.acc_seg: 98.0053, src.loss: 0.0693, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.2659, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:12:13,537 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 4:40:59, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0589, src.decode.acc_seg: 97.8452, src.loss: 0.0750, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.2984, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:13:16,358 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 4:39:56, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0476, src.decode.acc_seg: 98.1534, src.loss: 0.0636, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.1943, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:14:18,975 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 4:38:52, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0486, src.decode.acc_seg: 98.2189, src.loss: 0.0647, mix.decode.loss_seg: 0.0408, mix.decode.acc_seg: 98.2196, mix.loss: 0.0408, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:15:21,805 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 4:37:49, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0503, src.decode.acc_seg: 98.1406, src.loss: 0.0663, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.3167, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:16:23,972 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 4:36:45, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0558, src.decode.acc_seg: 97.8699, src.loss: 0.0718, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.5155, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:17:26,328 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 4:35:42, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0594, src.decode.acc_seg: 97.9230, src.loss: 0.0755, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.5151, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:18:28,895 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 4:34:38, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0541, src.decode.acc_seg: 97.9048, src.loss: 0.0701, mix.decode.loss_seg: 0.0406, mix.decode.acc_seg: 98.2697, mix.loss: 0.0406, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:19:31,555 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 18:19:31,555 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 4:33:35, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0564, src.decode.acc_seg: 98.0963, src.loss: 0.0724, mix.decode.loss_seg: 0.0433, mix.decode.acc_seg: 98.3133, mix.loss: 0.0433, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:20:34,674 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 4:32:32, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0553, src.decode.acc_seg: 97.9700, src.loss: 0.0713, mix.decode.loss_seg: 0.0421, mix.decode.acc_seg: 98.1726, mix.loss: 0.0421, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:21:37,221 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 4:31:29, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0526, src.decode.acc_seg: 98.1070, src.loss: 0.0686, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.2934, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:22:40,363 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 4:30:25, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0532, src.decode.acc_seg: 97.9877, src.loss: 0.0693, mix.decode.loss_seg: 0.0503, mix.decode.acc_seg: 97.8393, mix.loss: 0.0503, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:23:42,968 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 4:29:22, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0519, src.decode.acc_seg: 98.0059, src.loss: 0.0679, mix.decode.loss_seg: 0.0350, mix.decode.acc_seg: 98.4858, mix.loss: 0.0350, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:24:45,679 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 4:28:19, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0523, src.decode.acc_seg: 98.0977, src.loss: 0.0683, mix.decode.loss_seg: 0.0373, mix.decode.acc_seg: 98.4548, mix.loss: 0.0373, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:25:47,961 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 4:27:15, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0560, src.decode.acc_seg: 97.9840, src.loss: 0.0721, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.1629, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:26:50,552 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 4:26:12, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0555, src.decode.acc_seg: 97.9966, src.loss: 0.0715, mix.decode.loss_seg: 0.0383, mix.decode.acc_seg: 98.3791, mix.loss: 0.0383, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:27:53,570 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 4:25:09, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0512, src.decode.acc_seg: 98.1612, src.loss: 0.0672, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.6750, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:28:56,062 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 4:24:05, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.3853, src.loss: 0.0594, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.4907, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:29:58,682 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 4:23:02, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0532, src.decode.acc_seg: 97.9220, src.loss: 0.0692, mix.decode.loss_seg: 0.0373, mix.decode.acc_seg: 98.4315, mix.loss: 0.0373, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:31:00,969 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 4:21:58, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0500, src.decode.acc_seg: 98.2227, src.loss: 0.0660, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.5375, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:32:04,208 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 4:20:55, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0624, src.decode.acc_seg: 97.7085, src.loss: 0.0784, mix.decode.loss_seg: 0.0412, mix.decode.acc_seg: 98.2883, mix.loss: 0.0412, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:33:07,232 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 4:19:52, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0510, src.decode.acc_seg: 98.0709, src.loss: 0.0670, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.4812, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:34:09,949 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 4:18:49, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0533, src.decode.acc_seg: 97.9921, src.loss: 0.0694, mix.decode.loss_seg: 0.0457, mix.decode.acc_seg: 98.2474, mix.loss: 0.0457, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:35:12,636 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 4:17:45, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0514, src.decode.acc_seg: 98.1395, src.loss: 0.0674, mix.decode.loss_seg: 0.0394, mix.decode.acc_seg: 98.3185, mix.loss: 0.0394, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:36:14,508 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 4:16:42, time: 1.237, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0517, src.decode.acc_seg: 98.0989, src.loss: 0.0677, mix.decode.loss_seg: 0.0438, mix.decode.acc_seg: 98.1761, mix.loss: 0.0438, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:37:17,442 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 4:15:39, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0531, src.decode.acc_seg: 98.1192, src.loss: 0.0691, mix.decode.loss_seg: 0.0450, mix.decode.acc_seg: 98.0901, mix.loss: 0.0450, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:38:19,752 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 4:14:35, time: 1.246, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0402, src.decode.acc_seg: 98.5430, src.loss: 0.0562, mix.decode.loss_seg: 0.0273, mix.decode.acc_seg: 98.7639, mix.loss: 0.0273, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:39:24,137 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 4:13:32, time: 1.288, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0556, src.decode.acc_seg: 98.0781, src.loss: 0.0717, mix.decode.loss_seg: 0.0454, mix.decode.acc_seg: 98.0628, mix.loss: 0.0454, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1040s[                                 ] 2/929, 1.6 task/s, elapsed: 1s, ETA:   568s[                                 ] 3/929, 2.3 task/s, elapsed: 1s, ETA:   411s[                                 ] 4/929, 2.8 task/s, elapsed: 1s, ETA:   332s[                                 ] 5/929, 3.2 task/s, elapsed: 2s, ETA:   284s[                                 ] 6/929, 3.6 task/s, elapsed: 2s, ETA:   253s[                                 ] 7/929, 4.0 task/s, elapsed: 2s, ETA:   231s[                                 ] 8/929, 4.3 task/s, elapsed: 2s, ETA:   214s[                                 ] 9/929, 4.6 task/s, elapsed: 2s, ETA:   201s[                                ] 10/929, 4.8 task/s, elapsed: 2s, ETA:   190s[                                ] 11/929, 5.1 task/s, elapsed: 2s, ETA:   181s[                                ] 12/929, 5.3 task/s, elapsed: 2s, ETA:   174s[                                ] 13/929, 5.5 task/s, elapsed: 2s, ETA:   168s[                                ] 14/929, 5.6 task/s, elapsed: 2s, ETA:   162s[                                ] 15/929, 5.8 task/s, elapsed: 3s, ETA:   158s[                                ] 16/929, 5.9 task/s, elapsed: 3s, ETA:   154s[                                ] 17/929, 6.1 task/s, elapsed: 3s, ETA:   150s[                                ] 18/929, 6.2 task/s, elapsed: 3s, ETA:   148s[                                ] 19/929, 6.3 task/s, elapsed: 3s, ETA:   145s[                                ] 20/929, 6.4 task/s, elapsed: 3s, ETA:   143s[                                ] 21/929, 6.5 task/s, elapsed: 3s, ETA:   140s[                                ] 22/929, 6.6 task/s, elapsed: 3s, ETA:   138s[                                ] 23/929, 6.7 task/s, elapsed: 3s, ETA:   136s[                                ] 24/929, 6.7 task/s, elapsed: 4s, ETA:   134s[                                ] 25/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 26/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 27/929, 7.0 task/s, elapsed: 4s, ETA:   129s[                                ] 28/929, 7.0 task/s, elapsed: 4s, ETA:   128s[                                ] 29/929, 7.1 task/s, elapsed: 4s, ETA:   127s[>                               ] 30/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 31/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 32/929, 7.3 task/s, elapsed: 4s, ETA:   124s[>                               ] 33/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 34/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 35/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 36/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 37/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 38/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 39/929, 7.6 task/s, elapsed: 5s, ETA:   118s[>                               ] 40/929, 7.6 task/s, elapsed: 5s, ETA:   117s[>                               ] 41/929, 7.6 task/s, elapsed: 5s, ETA:   116s[>                               ] 42/929, 7.7 task/s, elapsed: 5s, ETA:   116s[>                               ] 43/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 44/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 45/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 46/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 47/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 48/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 49/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 50/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 51/929, 8.0 task/s, elapsed: 6s, ETA:   110s[>                               ] 52/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 53/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 54/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 55/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 56/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 57/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 61/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 62/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 63/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 64/929, 8.1 task/s, elapsed: 8s, ETA:   106s[>>                              ] 65/929, 8.1 task/s, elapsed: 8s, ETA:   106s[>>                              ] 66/929, 8.1 task/s, elapsed: 8s, ETA:   106s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 68/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 69/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 70/929, 8.2 task/s, elapsed: 9s, ETA:   105s[>>                              ] 71/929, 8.2 task/s, elapsed: 9s, ETA:   105s[>>                              ] 72/929, 8.2 task/s, elapsed: 9s, ETA:   105s[>>                              ] 73/929, 8.2 task/s, elapsed: 9s, ETA:   105s[>>                              ] 74/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 75/929, 8.2 task/s, elapsed: 9s, ETA:   105s[>>                              ] 76/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 77/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                             ] 78/929, 8.1 task/s, elapsed: 10s, ETA:   104s[>>                             ] 79/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 80/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 81/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 82/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 83/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 84/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 85/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 86/929, 8.2 task/s, elapsed: 10s, ETA:   102s[>>                             ] 87/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>                             ] 88/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>                             ] 89/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 90/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 91/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 92/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 93/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 94/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 95/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 96/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                            ] 97/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                            ] 98/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                            ] 99/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                           ] 100/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                           ] 101/929, 8.3 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 102/929, 8.3 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 103/929, 8.3 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 104/929, 8.3 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 105/929, 8.4 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 106/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 107/929, 8.3 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 108/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 109/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 110/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 111/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 112/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 113/929, 8.4 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 114/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 115/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 116/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 117/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 118/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 119/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 120/929, 8.4 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 121/929, 8.4 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 122/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>                           ] 123/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 124/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 125/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 126/929, 8.4 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 127/929, 8.4 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 128/929, 8.4 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 129/929, 8.4 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 130/929, 8.4 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 131/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 132/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 133/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 134/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 135/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 136/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 137/929, 8.5 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 138/929, 8.5 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 139/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 140/929, 8.5 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 141/929, 8.5 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 142/929, 8.5 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 143/929, 8.5 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 144/929, 8.5 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 145/929, 8.5 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 146/929, 8.5 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 147/929, 8.5 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 148/929, 8.5 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 149/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 150/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 151/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>                          ] 152/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>                          ] 153/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>                          ] 154/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 155/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 156/929, 8.5 task/s, elapsed: 18s, ETA:    90s[>>>>>                         ] 157/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>>                         ] 158/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>>                         ] 159/929, 8.6 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 160/929, 8.6 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 161/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 162/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 163/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 164/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 165/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 166/929, 8.6 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 167/929, 8.6 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 168/929, 8.6 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 169/929, 8.7 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 170/929, 8.7 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 171/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 172/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 173/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 174/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 175/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 176/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 177/929, 8.7 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 178/929, 8.7 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 179/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 180/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 181/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 182/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 183/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 184/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 185/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>>                        ] 186/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>>                        ] 187/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>>                        ] 188/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 189/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 190/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 191/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 192/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 193/929, 8.8 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 194/929, 8.8 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 195/929, 8.8 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 196/929, 8.8 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 197/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 198/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 199/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 200/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 201/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 202/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 203/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 204/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 205/929, 8.8 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 206/929, 8.8 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 207/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 208/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 209/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 210/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 211/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 212/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 213/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 214/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 215/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 216/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>>                       ] 217/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 218/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 219/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 220/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 221/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 222/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 223/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 224/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 225/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 226/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 227/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 228/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 229/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 230/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 231/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 232/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 233/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 234/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 235/929, 8.8 task/s, elapsed: 27s, ETA:    79s[>>>>>>>                       ] 236/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 237/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 239/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 240/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 241/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 242/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 243/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 244/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 245/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 246/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 247/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 248/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 249/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 250/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 251/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 252/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 254/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 255/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 256/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 257/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 258/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 259/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 260/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 261/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 262/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 263/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 264/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 265/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 266/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 267/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 268/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 269/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 270/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 271/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 272/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 273/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 274/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 275/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 276/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 277/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 278/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 279/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 280/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 281/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 282/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 283/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 284/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 285/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 286/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 287/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 288/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 289/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 290/929, 8.9 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 292/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 293/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 294/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 295/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 296/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 297/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 298/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 299/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 300/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 301/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 302/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 303/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 304/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 305/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 306/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 307/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 308/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 309/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 310/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 311/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 312/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 313/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 314/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 315/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 316/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 317/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 318/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 319/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 320/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 321/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 322/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 323/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 324/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 325/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 326/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 327/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 328/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 329/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 330/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 331/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 332/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 333/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 334/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 335/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 336/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 337/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 338/929, 9.0 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 339/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>                    ] 340/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 341/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 342/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 343/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 344/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 345/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 346/929, 9.0 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 347/929, 9.0 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 348/929, 9.0 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 349/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 350/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 351/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 352/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 353/929, 9.1 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 354/929, 9.1 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 355/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 356/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 357/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 358/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 359/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 360/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 361/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 362/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 363/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 366/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 367/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 368/929, 9.1 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 369/929, 9.1 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 370/929, 9.1 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 371/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 376/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 377/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 378/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 379/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 380/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 384/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 385/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 386/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 387/929, 9.1 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 388/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 394/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 395/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 396/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 397/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 398/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 403/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 404/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 405/929, 9.1 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 412/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 413/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 414/929, 9.1 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.1 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 422/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 423/929, 9.1 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.1 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 430/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 431/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 432/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 441/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 450/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.2 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.1 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.1 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.1 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.1 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.1 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.1 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.0 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.0 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.0 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.0 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.0 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.0 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.0 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.0 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.0 task/s, elapsed: 87s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.0 task/s, elapsed: 88s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.0 task/s, elapsed: 88s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.0 task/s, elapsed: 89s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.0 task/s, elapsed: 89s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.0 task/s, elapsed: 90s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.0 task/s, elapsed: 90s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.0 task/s, elapsed: 90s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.0 task/s, elapsed: 91s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.0 task/s, elapsed: 91s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.0 task/s, elapsed: 91s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.0 task/s, elapsed: 91s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.0 task/s, elapsed: 92s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.0 task/s, elapsed: 92s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.0 task/s, elapsed: 92s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.0 task/s, elapsed: 92s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.0 task/s, elapsed: 92s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 8.9 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 8.9 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 8.9 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 8.9 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 8.9 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 8.9 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 8.9 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 8.9 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 8.9 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 8.9 task/s, elapsed: 100s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 8.9 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 8.9 task/s, elapsed: 101s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 8.9 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 8.9 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 8.9 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 8.9 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 8.9 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 8.9 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 8.9 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 8.9 task/s, elapsed: 102s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 8.9 task/s, elapsed: 102s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 8.9 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 8.9 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 8.9 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 8.9 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 8.9 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 8.9 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 8.9 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 8.9 task/s, elapsed: 103s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 8.9 task/s, elapsed: 103s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 8.9 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 8.9 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 8.9 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 8.9 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 8.9 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 8.9 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 8.9 task/s, elapsed: 104s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 8.9 task/s, elapsed: 104s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 8.9 task/s, elapsed: 104s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 8.9 task/s, elapsed: 104s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 8.9 task/s, elapsed: 104s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 8.9 task/s, elapsed: 104s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 8.9 task/s, elapsed: 104s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 8.9 task/s, elapsed: 104s, ETA:     0s2022-10-10 18:43:27,621 - mmseg - INFO - per class results:2022-10-10 18:43:27,622 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.12 | 96.76 || rigid_plastic | 37.03 | 45.69 ||   cardboard   | 56.16 | 68.39 ||     metal     | 31.65 | 39.02 ||  soft_plastic | 61.73 |  69.5 |+---------------+-------+-------+2022-10-10 18:43:27,622 - mmseg - INFO - Summary:2022-10-10 18:43:27,622 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.52 | 55.54 | 63.87 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:43:27,626 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 18:43:27,626 - mmseg - INFO - Iter [929/40000]	lr: 1.800e-05, eta: 4:12:29, time: 1.264, data_time: 0.015, memory: 67493, aAcc: 0.9152, mIoU: 0.5554, mAcc: 0.6387, IoU.background: 0.9112, IoU.rigid_plastic: 0.3703, IoU.cardboard: 0.5616, IoU.metal: 0.3165, IoU.soft_plastic: 0.6173, Acc.background: 0.9676, Acc.rigid_plastic: 0.4569, Acc.cardboard: 0.6839, Acc.metal: 0.3902, Acc.soft_plastic: 0.6950, src.decode.loss_seg: 0.0541, src.decode.acc_seg: 97.9046, src.loss: 0.0702, mix.decode.loss_seg: 0.0428, mix.decode.acc_seg: 98.1358, mix.loss: 0.0428, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:44:30,431 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 4:12:43, time: 4.861, data_time: 3.619, memory: 67493, src.decode.loss_seg: 0.0450, src.decode.acc_seg: 98.2901, src.loss: 0.0611, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.5904, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:45:33,212 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 4:11:39, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0520, src.decode.acc_seg: 98.1284, src.loss: 0.0681, mix.decode.loss_seg: 0.0384, mix.decode.acc_seg: 98.3820, mix.loss: 0.0384, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:46:35,728 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 4:10:35, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0490, src.decode.acc_seg: 98.2414, src.loss: 0.0650, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.4086, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:47:38,099 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 4:09:31, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0561, src.decode.acc_seg: 97.9954, src.loss: 0.0722, mix.decode.loss_seg: 0.0415, mix.decode.acc_seg: 98.3313, mix.loss: 0.0415, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:48:40,607 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 4:08:28, time: 1.250, data_time: 0.013, memory: 67493, src.decode.loss_seg: 0.0473, src.decode.acc_seg: 98.2090, src.loss: 0.0633, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.5927, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:49:44,851 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 4:07:25, time: 1.285, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0485, src.decode.acc_seg: 98.1996, src.loss: 0.0645, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.3975, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:50:48,056 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 4:06:21, time: 1.264, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0531, src.decode.acc_seg: 97.9395, src.loss: 0.0691, mix.decode.loss_seg: 0.0467, mix.decode.acc_seg: 98.1791, mix.loss: 0.0467, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:51:50,628 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 4:05:17, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0421, src.decode.acc_seg: 98.4285, src.loss: 0.0581, mix.decode.loss_seg: 0.0347, mix.decode.acc_seg: 98.3877, mix.loss: 0.0347, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:52:53,249 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 4:04:13, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0469, src.decode.acc_seg: 98.2216, src.loss: 0.0630, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.5121, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:53:56,133 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 4:03:10, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0464, src.decode.acc_seg: 98.3135, src.loss: 0.0624, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.4233, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:54:59,379 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 4:02:06, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0467, src.decode.acc_seg: 98.2239, src.loss: 0.0628, mix.decode.loss_seg: 0.0358, mix.decode.acc_seg: 98.3563, mix.loss: 0.0358, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:56:01,372 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 4:01:02, time: 1.240, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0548, src.decode.acc_seg: 97.8892, src.loss: 0.0708, mix.decode.loss_seg: 0.0306, mix.decode.acc_seg: 98.6395, mix.loss: 0.0306, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:57:04,550 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 3:59:59, time: 1.264, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0469, src.decode.acc_seg: 98.1900, src.loss: 0.0630, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.4357, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:58:07,222 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 3:58:55, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0539, src.decode.acc_seg: 98.0772, src.loss: 0.0699, mix.decode.loss_seg: 0.0398, mix.decode.acc_seg: 98.2939, mix.loss: 0.0398, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:59:09,575 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 3:57:51, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0402, src.decode.acc_seg: 98.5162, src.loss: 0.0563, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.4448, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:00:11,880 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 3:56:47, time: 1.246, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0489, src.decode.acc_seg: 98.1859, src.loss: 0.0649, mix.decode.loss_seg: 0.0359, mix.decode.acc_seg: 98.5162, mix.loss: 0.0359, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:01:14,349 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 3:55:43, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0498, src.decode.acc_seg: 98.0138, src.loss: 0.0658, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4241, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:02:17,249 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 3:54:40, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.5079, src.loss: 0.0564, mix.decode.loss_seg: 0.0335, mix.decode.acc_seg: 98.6487, mix.loss: 0.0335, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:03:20,180 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 3:53:36, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0559, src.decode.acc_seg: 97.8378, src.loss: 0.0719, mix.decode.loss_seg: 0.0435, mix.decode.acc_seg: 98.2389, mix.loss: 0.0435, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:04:23,348 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 19:04:23,348 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 3:52:33, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0473, src.decode.acc_seg: 98.1535, src.loss: 0.0634, mix.decode.loss_seg: 0.0380, mix.decode.acc_seg: 98.3491, mix.loss: 0.0380, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:05:25,678 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 3:51:29, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0444, src.decode.acc_seg: 98.3715, src.loss: 0.0604, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.4244, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:06:28,386 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 3:50:25, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.3374, src.loss: 0.0601, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.5948, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:07:30,700 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 3:49:21, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0491, src.decode.acc_seg: 98.3083, src.loss: 0.0652, mix.decode.loss_seg: 0.0374, mix.decode.acc_seg: 98.4461, mix.loss: 0.0374, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:08:33,217 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 3:48:18, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0500, src.decode.acc_seg: 98.1684, src.loss: 0.0660, mix.decode.loss_seg: 0.0450, mix.decode.acc_seg: 98.1461, mix.loss: 0.0450, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:09:35,577 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 3:47:14, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0477, src.decode.acc_seg: 98.1735, src.loss: 0.0637, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.5454, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:10:38,856 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 3:46:10, time: 1.266, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0428, src.decode.acc_seg: 98.3930, src.loss: 0.0588, mix.decode.loss_seg: 0.0380, mix.decode.acc_seg: 98.5183, mix.loss: 0.0380, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:11:41,548 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 3:45:07, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0564, src.decode.acc_seg: 97.9499, src.loss: 0.0725, mix.decode.loss_seg: 0.0354, mix.decode.acc_seg: 98.5054, mix.loss: 0.0354, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:12:44,273 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 3:44:03, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0486, src.decode.acc_seg: 98.1121, src.loss: 0.0646, mix.decode.loss_seg: 0.0423, mix.decode.acc_seg: 98.3716, mix.loss: 0.0423, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:13:47,087 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 3:42:59, time: 1.256, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0431, src.decode.acc_seg: 98.4618, src.loss: 0.0591, mix.decode.loss_seg: 0.0283, mix.decode.acc_seg: 98.8421, mix.loss: 0.0283, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:14:49,949 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 3:41:56, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0482, src.decode.acc_seg: 98.1941, src.loss: 0.0642, mix.decode.loss_seg: 0.0364, mix.decode.acc_seg: 98.2488, mix.loss: 0.0364, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:15:52,533 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 3:40:52, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0535, src.decode.acc_seg: 98.0591, src.loss: 0.0695, mix.decode.loss_seg: 0.0351, mix.decode.acc_seg: 98.5694, mix.loss: 0.0351, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:16:55,530 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 3:39:48, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0448, src.decode.acc_seg: 98.3358, src.loss: 0.0608, mix.decode.loss_seg: 0.0348, mix.decode.acc_seg: 98.4325, mix.loss: 0.0348, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:17:57,931 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 3:38:45, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0479, src.decode.acc_seg: 98.1652, src.loss: 0.0639, mix.decode.loss_seg: 0.0358, mix.decode.acc_seg: 98.3989, mix.loss: 0.0358, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:19:00,498 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 3:37:41, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0504, src.decode.acc_seg: 98.0393, src.loss: 0.0664, mix.decode.loss_seg: 0.0398, mix.decode.acc_seg: 98.3777, mix.loss: 0.0398, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:20:03,511 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 3:36:37, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0471, src.decode.acc_seg: 98.1747, src.loss: 0.0631, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.5804, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:21:06,117 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 3:35:34, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.5058, src.loss: 0.0568, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.5624, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:22:09,317 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 3:34:30, time: 1.264, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0440, src.decode.acc_seg: 98.3912, src.loss: 0.0600, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.5470, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:23:11,840 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 3:33:27, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0461, src.decode.acc_seg: 98.2510, src.loss: 0.0621, mix.decode.loss_seg: 0.0381, mix.decode.acc_seg: 98.4257, mix.loss: 0.0381, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:24:14,479 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 3:32:23, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0440, src.decode.acc_seg: 98.3081, src.loss: 0.0601, mix.decode.loss_seg: 0.0289, mix.decode.acc_seg: 98.7406, mix.loss: 0.0289, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:25:17,053 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 19:25:17,054 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 3:31:19, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0406, src.decode.acc_seg: 98.4306, src.loss: 0.0566, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4113, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:26:19,764 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 3:30:16, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0572, src.decode.acc_seg: 97.9560, src.loss: 0.0733, mix.decode.loss_seg: 0.0435, mix.decode.acc_seg: 98.1422, mix.loss: 0.0435, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:27:22,224 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 3:29:12, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0514, src.decode.acc_seg: 98.0488, src.loss: 0.0674, mix.decode.loss_seg: 0.0337, mix.decode.acc_seg: 98.6133, mix.loss: 0.0337, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:28:25,313 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 3:28:08, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0477, src.decode.acc_seg: 98.3215, src.loss: 0.0637, mix.decode.loss_seg: 0.0337, mix.decode.acc_seg: 98.6105, mix.loss: 0.0337, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:29:28,966 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 3:27:05, time: 1.273, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0481, src.decode.acc_seg: 98.1842, src.loss: 0.0642, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5910, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:30:31,269 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 3:26:01, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0466, src.decode.acc_seg: 98.2481, src.loss: 0.0626, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.5417, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:31:33,727 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 3:24:58, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.4209, src.loss: 0.0586, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.7466, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:32:35,957 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 3:23:54, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.5327, src.loss: 0.0550, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.5773, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:33:38,632 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 3:22:50, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0454, src.decode.acc_seg: 98.3356, src.loss: 0.0614, mix.decode.loss_seg: 0.0326, mix.decode.acc_seg: 98.6912, mix.loss: 0.0326, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:34:40,726 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 3:21:47, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0498, src.decode.acc_seg: 98.1510, src.loss: 0.0658, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.4332, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:35:43,899 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 3:20:43, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0515, src.decode.acc_seg: 98.1030, src.loss: 0.0675, mix.decode.loss_seg: 0.0385, mix.decode.acc_seg: 98.4614, mix.loss: 0.0385, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:36:46,146 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 3:19:39, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0467, src.decode.acc_seg: 98.2392, src.loss: 0.0627, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.3680, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:37:48,722 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 3:18:36, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0457, src.decode.acc_seg: 98.2580, src.loss: 0.0617, mix.decode.loss_seg: 0.0372, mix.decode.acc_seg: 98.4559, mix.loss: 0.0372, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:38:51,311 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 3:17:32, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0385, src.decode.acc_seg: 98.5349, src.loss: 0.0546, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.7117, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:39:54,026 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 3:16:28, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0430, src.decode.acc_seg: 98.3263, src.loss: 0.0590, mix.decode.loss_seg: 0.0355, mix.decode.acc_seg: 98.5792, mix.loss: 0.0355, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:40:57,181 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 3:15:25, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.4428, src.loss: 0.0602, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.6037, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:41:59,665 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 3:14:21, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.4720, src.loss: 0.0569, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.6188, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:43:02,580 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 3:13:18, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0456, src.decode.acc_seg: 98.2268, src.loss: 0.0616, mix.decode.loss_seg: 0.0284, mix.decode.acc_seg: 98.7221, mix.loss: 0.0284, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:44:05,150 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 3:12:14, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.3413, src.loss: 0.0607, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.6794, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:45:07,630 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 3:11:11, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0462, src.decode.acc_seg: 98.2233, src.loss: 0.0622, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.5310, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:46:10,186 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 19:46:10,187 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 3:10:07, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0422, src.decode.acc_seg: 98.4892, src.loss: 0.0583, mix.decode.loss_seg: 0.0313, mix.decode.acc_seg: 98.6592, mix.loss: 0.0313, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:47:12,707 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 3:09:03, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0460, src.decode.acc_seg: 98.2380, src.loss: 0.0620, mix.decode.loss_seg: 0.0356, mix.decode.acc_seg: 98.4648, mix.loss: 0.0356, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:48:15,077 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 3:08:00, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0527, src.decode.acc_seg: 98.0273, src.loss: 0.0687, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6328, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:49:17,938 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 3:06:56, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0563, src.decode.acc_seg: 97.8735, src.loss: 0.0723, mix.decode.loss_seg: 0.0423, mix.decode.acc_seg: 98.1290, mix.loss: 0.0423, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:50:21,257 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 3:05:53, time: 1.266, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0460, src.decode.acc_seg: 98.3186, src.loss: 0.0621, mix.decode.loss_seg: 0.0331, mix.decode.acc_seg: 98.5252, mix.loss: 0.0331, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:51:24,049 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 3:04:49, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0456, src.decode.acc_seg: 98.2561, src.loss: 0.0616, mix.decode.loss_seg: 0.0340, mix.decode.acc_seg: 98.5469, mix.loss: 0.0340, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:52:26,533 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 3:03:46, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.4359, src.loss: 0.0593, mix.decode.loss_seg: 0.0287, mix.decode.acc_seg: 98.7913, mix.loss: 0.0287, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:53:29,360 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 3:02:42, time: 1.257, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0456, src.decode.acc_seg: 98.2738, src.loss: 0.0616, mix.decode.loss_seg: 0.0406, mix.decode.acc_seg: 98.3525, mix.loss: 0.0406, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:54:31,924 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 3:01:39, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0498, src.decode.acc_seg: 98.2709, src.loss: 0.0658, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.4195, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:55:34,347 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 3:00:35, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0381, src.decode.acc_seg: 98.5931, src.loss: 0.0542, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.6769, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:56:37,147 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 2:59:31, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0455, src.decode.acc_seg: 98.2644, src.loss: 0.0615, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.5589, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:57:39,754 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 2:58:28, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.3778, src.loss: 0.0607, mix.decode.loss_seg: 0.0397, mix.decode.acc_seg: 98.3392, mix.loss: 0.0397, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:58:42,020 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 2:57:24, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0443, src.decode.acc_seg: 98.2891, src.loss: 0.0603, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.4193, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:59:44,721 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 2:56:21, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0422, src.decode.acc_seg: 98.5068, src.loss: 0.0583, mix.decode.loss_seg: 0.0430, mix.decode.acc_seg: 98.2100, mix.loss: 0.0430, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:00:47,537 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 2:55:17, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4454, src.loss: 0.0567, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.5942, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:01:50,239 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 2:54:14, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0503, src.decode.acc_seg: 98.2040, src.loss: 0.0663, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.3787, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:02:53,217 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 2:53:10, time: 1.260, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0460, src.decode.acc_seg: 98.4027, src.loss: 0.0620, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.7570, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:03:56,015 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 2:52:07, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0385, src.decode.acc_seg: 98.5213, src.loss: 0.0545, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.7135, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:05:00,683 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 2:51:04, time: 1.293, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0465, src.decode.acc_seg: 98.3046, src.loss: 0.0626, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.7366, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:06:03,937 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 2:50:00, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0394, src.decode.acc_seg: 98.5677, src.loss: 0.0554, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.6628, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1161s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   630s[                                 ] 3/929, 2.0 task/s, elapsed: 1s, ETA:   453s[                                 ] 4/929, 2.5 task/s, elapsed: 2s, ETA:   364s[                                 ] 5/929, 3.0 task/s, elapsed: 2s, ETA:   311s[                                 ] 6/929, 3.3 task/s, elapsed: 2s, ETA:   276s[                                 ] 7/929, 3.7 task/s, elapsed: 2s, ETA:   250s[                                 ] 8/929, 4.0 task/s, elapsed: 2s, ETA:   232s[                                 ] 9/929, 4.3 task/s, elapsed: 2s, ETA:   216s[                                ] 10/929, 4.5 task/s, elapsed: 2s, ETA:   204s[                                ] 11/929, 4.7 task/s, elapsed: 2s, ETA:   194s[                                ] 12/929, 4.9 task/s, elapsed: 2s, ETA:   187s[                                ] 13/929, 5.1 task/s, elapsed: 3s, ETA:   180s[                                ] 14/929, 5.3 task/s, elapsed: 3s, ETA:   174s[                                ] 15/929, 5.4 task/s, elapsed: 3s, ETA:   169s[                                ] 16/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 17/929, 5.7 task/s, elapsed: 3s, ETA:   160s[                                ] 18/929, 5.8 task/s, elapsed: 3s, ETA:   156s[                                ] 19/929, 6.0 task/s, elapsed: 3s, ETA:   152s[                                ] 20/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 21/929, 6.2 task/s, elapsed: 3s, ETA:   146s[                                ] 22/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 23/929, 6.4 task/s, elapsed: 4s, ETA:   141s[                                ] 24/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 25/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 26/929, 6.7 task/s, elapsed: 4s, ETA:   136s[                                ] 27/929, 6.7 task/s, elapsed: 4s, ETA:   134s[                                ] 28/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 29/929, 6.9 task/s, elapsed: 4s, ETA:   131s[>                               ] 30/929, 7.0 task/s, elapsed: 4s, ETA:   129s[>                               ] 31/929, 7.0 task/s, elapsed: 4s, ETA:   128s[>                               ] 32/929, 7.1 task/s, elapsed: 5s, ETA:   126s[>                               ] 33/929, 7.2 task/s, elapsed: 5s, ETA:   125s[>                               ] 34/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 35/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 36/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 37/929, 7.3 task/s, elapsed: 5s, ETA:   121s[>                               ] 38/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 39/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 40/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 41/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 42/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 43/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 44/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 45/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 46/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 47/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 48/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 49/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 50/929, 7.8 task/s, elapsed: 6s, ETA:   112s[>                               ] 51/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 53/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 54/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 55/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 56/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 57/929, 8.0 task/s, elapsed: 7s, ETA:   108s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 61/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 62/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 63/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 64/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 65/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 66/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 68/929, 8.2 task/s, elapsed: 8s, ETA:   104s[>>                              ] 69/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 70/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 71/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 72/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 73/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 74/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 75/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 76/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 78/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 79/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 80/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                             ] 81/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 82/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 83/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 85/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 86/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 87/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 88/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 89/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 90/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 91/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 92/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 93/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 94/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 95/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 96/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 97/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 98/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 99/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                           ] 100/929, 8.7 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 101/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 102/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 103/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 106/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 107/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 108/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 109/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 110/929, 8.8 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 111/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 112/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 113/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 114/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 115/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 116/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 117/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 118/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 119/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 120/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 121/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 122/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>                           ] 123/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 124/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 125/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 126/929, 8.9 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 127/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 128/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 129/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 130/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 131/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 132/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 133/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 134/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 135/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 136/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 137/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 138/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 139/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 140/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 141/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 142/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 143/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 144/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 145/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 146/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 147/929, 8.9 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 148/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 149/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 150/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 151/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 152/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 153/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 154/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 155/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 156/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 157/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 158/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 159/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 160/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 161/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 162/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 163/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 164/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 165/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 166/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 167/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 168/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 169/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 170/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 171/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 172/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 173/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 174/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 175/929, 9.0 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 176/929, 9.0 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 177/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 178/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 180/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 181/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 183/929, 9.0 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 184/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 185/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 186/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 187/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 188/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 191/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 192/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 193/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 194/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 195/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 196/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 198/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 199/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 200/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 222/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 223/929, 9.1 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 224/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 225/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 230/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 231/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 232/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 234/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 239/929, 9.1 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 240/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 241/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 242/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 243/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>                       ] 247/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 248/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 249/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 255/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 256/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 257/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 258/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 264/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 290/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 293/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 297/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 298/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 299/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 306/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 307/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 308/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>                     ] 309/929, 9.2 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 310/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 315/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 316/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 317/929, 9.2 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 318/929, 9.2 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 319/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 323/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 324/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 325/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 326/929, 9.2 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 327/929, 9.2 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 328/929, 9.2 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 329/929, 9.2 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 330/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 332/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 333/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.2 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 336/929, 9.2 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 337/929, 9.2 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 338/929, 9.2 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 339/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 340/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 341/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 342/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.2 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.2 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 346/929, 9.2 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 347/929, 9.2 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 348/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 349/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 350/929, 9.1 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.1 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.1 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 355/929, 9.2 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 356/929, 9.2 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 357/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 358/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 359/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.2 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.2 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.2 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.2 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 366/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 367/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 384/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 385/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 393/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 394/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 398/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.2 task/s, elapsed: 43s, ETA:    57s[>>>>>>>>>>>>                  ] 401/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>                  ] 402/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 411/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 412/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 420/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 421/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 430/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 439/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 440/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.2 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.2 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 449/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.2 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.2 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.2 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.2 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 523/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.1 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.1 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.1 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.1 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.1 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.1 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.1 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.1 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.1 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.1 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.1 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.1 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.1 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.1 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.1 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.1 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.1 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.1 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.1 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.0 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.0 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.0 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.0 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.0 task/s, elapsed: 92s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.0 task/s, elapsed: 93s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.0 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.0 task/s, elapsed: 94s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.0 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.0 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.0 task/s, elapsed: 95s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.0 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.0 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.0 task/s, elapsed: 96s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.0 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.0 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.0 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.0 task/s, elapsed: 97s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.0 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.0 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.0 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.0 task/s, elapsed: 98s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.0 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.0 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.0 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.0 task/s, elapsed: 99s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.0 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.0 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.0 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 9.0 task/s, elapsed: 100s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.0 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.0 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.0 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.0 task/s, elapsed: 101s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.0 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.0 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.0 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.0 task/s, elapsed: 102s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.0 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.0 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.0 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.0 task/s, elapsed: 103s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.0 task/s, elapsed: 103s, ETA:     0s2022-10-10 20:09:59,851 - mmseg - INFO - per class results:2022-10-10 20:09:59,851 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.16 | 95.68 || rigid_plastic | 37.88 | 47.84 ||   cardboard   | 58.84 | 76.09 ||     metal     | 32.09 | 36.35 ||  soft_plastic |  62.9 | 71.18 |+---------------+-------+-------+2022-10-10 20:09:59,852 - mmseg - INFO - Summary:2022-10-10 20:09:59,852 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.63 | 56.57 | 65.43 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:09:59,855 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 20:09:59,855 - mmseg - INFO - Iter [929/40000]	lr: 1.200e-05, eta: 2:48:57, time: 1.254, data_time: 0.015, memory: 67493, aAcc: 0.9163, mIoU: 0.5657, mAcc: 0.6543, IoU.background: 0.9116, IoU.rigid_plastic: 0.3788, IoU.cardboard: 0.5884, IoU.metal: 0.3209, IoU.soft_plastic: 0.6290, Acc.background: 0.9568, Acc.rigid_plastic: 0.4784, Acc.cardboard: 0.7609, Acc.metal: 0.3635, Acc.soft_plastic: 0.7118, src.decode.loss_seg: 0.0411, src.decode.acc_seg: 98.4366, src.loss: 0.0571, mix.decode.loss_seg: 0.0374, mix.decode.acc_seg: 98.2234, mix.loss: 0.0374, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:11:02,461 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 2:48:36, time: 4.716, data_time: 3.478, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.4684, src.loss: 0.0568, mix.decode.loss_seg: 0.0335, mix.decode.acc_seg: 98.5365, mix.loss: 0.0335, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:12:05,387 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 2:47:32, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0413, src.decode.acc_seg: 98.3975, src.loss: 0.0573, mix.decode.loss_seg: 0.0349, mix.decode.acc_seg: 98.3951, mix.loss: 0.0349, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:13:08,475 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 2:46:29, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0478, src.decode.acc_seg: 98.2304, src.loss: 0.0638, mix.decode.loss_seg: 0.0372, mix.decode.acc_seg: 98.3422, mix.loss: 0.0372, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:14:10,982 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 2:45:25, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.1801, src.loss: 0.0648, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4665, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:15:14,047 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 2:44:21, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0437, src.decode.acc_seg: 98.3811, src.loss: 0.0598, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.5991, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:16:17,463 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 2:43:17, time: 1.268, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0482, src.decode.acc_seg: 98.1479, src.loss: 0.0642, mix.decode.loss_seg: 0.0327, mix.decode.acc_seg: 98.4501, mix.loss: 0.0327, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:17:20,967 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 2:42:14, time: 1.270, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0478, src.decode.acc_seg: 98.2675, src.loss: 0.0638, mix.decode.loss_seg: 0.0382, mix.decode.acc_seg: 98.2716, mix.loss: 0.0382, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:18:24,777 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 2:41:10, time: 1.276, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0500, src.decode.acc_seg: 98.1041, src.loss: 0.0660, mix.decode.loss_seg: 0.0354, mix.decode.acc_seg: 98.6138, mix.loss: 0.0354, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:19:27,339 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 2:40:06, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0400, src.decode.acc_seg: 98.5079, src.loss: 0.0560, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.3591, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:20:30,402 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 2:39:02, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0496, src.decode.acc_seg: 98.1609, src.loss: 0.0656, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.5026, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:21:33,988 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 2:37:59, time: 1.272, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0460, src.decode.acc_seg: 98.3322, src.loss: 0.0620, mix.decode.loss_seg: 0.0321, mix.decode.acc_seg: 98.5881, mix.loss: 0.0321, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:22:36,817 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 2:36:55, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.4708, src.loss: 0.0593, mix.decode.loss_seg: 0.0266, mix.decode.acc_seg: 98.9566, mix.loss: 0.0266, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:23:39,706 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 2:35:51, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0459, src.decode.acc_seg: 98.2228, src.loss: 0.0619, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.6474, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:24:42,267 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 2:34:47, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0484, src.decode.acc_seg: 98.1808, src.loss: 0.0644, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.5598, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:25:44,691 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 2:33:43, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0397, src.decode.acc_seg: 98.4898, src.loss: 0.0557, mix.decode.loss_seg: 0.0273, mix.decode.acc_seg: 98.7631, mix.loss: 0.0273, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:26:46,997 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 2:32:40, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.3353, src.loss: 0.0594, mix.decode.loss_seg: 0.0286, mix.decode.acc_seg: 98.7513, mix.loss: 0.0286, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:27:49,584 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 2:31:36, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0422, src.decode.acc_seg: 98.4342, src.loss: 0.0582, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.7555, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:28:52,604 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 2:30:32, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.3557, src.loss: 0.0593, mix.decode.loss_seg: 0.0275, mix.decode.acc_seg: 98.8134, mix.loss: 0.0275, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:29:55,593 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 2:29:28, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0396, src.decode.acc_seg: 98.5127, src.loss: 0.0556, mix.decode.loss_seg: 0.0284, mix.decode.acc_seg: 98.7877, mix.loss: 0.0284, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:30:57,884 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 20:30:57,884 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 2:28:24, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0432, src.decode.acc_seg: 98.3340, src.loss: 0.0592, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.7228, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:32:00,614 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 2:27:21, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4186, src.loss: 0.0577, mix.decode.loss_seg: 0.0348, mix.decode.acc_seg: 98.4756, mix.loss: 0.0348, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:33:02,935 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 2:26:17, time: 1.246, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4695, src.loss: 0.0567, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.5830, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:34:06,070 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 2:25:13, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0380, src.decode.acc_seg: 98.5781, src.loss: 0.0541, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.6155, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:35:08,477 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 2:24:09, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.6027, src.loss: 0.0569, mix.decode.loss_seg: 0.0270, mix.decode.acc_seg: 98.7603, mix.loss: 0.0270, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:36:11,414 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 2:23:05, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.3399, src.loss: 0.0586, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6143, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:37:14,520 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 2:22:02, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4180, src.loss: 0.0567, mix.decode.loss_seg: 0.0313, mix.decode.acc_seg: 98.6712, mix.loss: 0.0313, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:38:17,208 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 2:20:58, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0482, src.decode.acc_seg: 98.2433, src.loss: 0.0642, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.3962, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:39:19,953 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 2:19:54, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0380, src.decode.acc_seg: 98.5435, src.loss: 0.0540, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.6527, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:40:22,567 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 2:18:50, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0423, src.decode.acc_seg: 98.4573, src.loss: 0.0583, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.6788, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:41:25,298 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 2:17:47, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0483, src.decode.acc_seg: 98.1934, src.loss: 0.0643, mix.decode.loss_seg: 0.0385, mix.decode.acc_seg: 98.3305, mix.loss: 0.0385, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:42:28,089 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 2:16:43, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0448, src.decode.acc_seg: 98.3037, src.loss: 0.0609, mix.decode.loss_seg: 0.0411, mix.decode.acc_seg: 98.1899, mix.loss: 0.0411, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:43:30,875 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 2:15:39, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0446, src.decode.acc_seg: 98.3820, src.loss: 0.0606, mix.decode.loss_seg: 0.0350, mix.decode.acc_seg: 98.5454, mix.loss: 0.0350, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:44:34,008 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 2:14:35, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.4439, src.loss: 0.0607, mix.decode.loss_seg: 0.0276, mix.decode.acc_seg: 98.8494, mix.loss: 0.0276, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:45:36,604 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 2:13:32, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.4032, src.loss: 0.0586, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.6946, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:46:39,361 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 2:12:28, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0367, src.decode.acc_seg: 98.6405, src.loss: 0.0527, mix.decode.loss_seg: 0.0347, mix.decode.acc_seg: 98.7358, mix.loss: 0.0347, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:47:42,041 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 2:11:24, time: 1.254, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0428, src.decode.acc_seg: 98.4168, src.loss: 0.0588, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.4932, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:48:44,628 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 2:10:20, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0382, src.decode.acc_seg: 98.5405, src.loss: 0.0542, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.6514, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:49:47,703 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 2:09:17, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4199, src.loss: 0.0567, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.6105, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:50:50,442 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 2:08:13, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0389, src.decode.acc_seg: 98.5352, src.loss: 0.0549, mix.decode.loss_seg: 0.0297, mix.decode.acc_seg: 98.7950, mix.loss: 0.0297, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:51:54,306 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 20:51:54,306 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 2:07:09, time: 1.277, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0438, src.decode.acc_seg: 98.3648, src.loss: 0.0598, mix.decode.loss_seg: 0.0351, mix.decode.acc_seg: 98.5082, mix.loss: 0.0351, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:52:56,751 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 2:06:06, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0406, src.decode.acc_seg: 98.4874, src.loss: 0.0567, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.6811, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:53:59,422 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 2:05:02, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0400, src.decode.acc_seg: 98.5811, src.loss: 0.0560, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.7053, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:55:02,755 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 2:03:58, time: 1.267, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0421, src.decode.acc_seg: 98.3922, src.loss: 0.0581, mix.decode.loss_seg: 0.0291, mix.decode.acc_seg: 98.7669, mix.loss: 0.0291, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:56:05,682 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 2:02:55, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0452, src.decode.acc_seg: 98.2714, src.loss: 0.0612, mix.decode.loss_seg: 0.0319, mix.decode.acc_seg: 98.5973, mix.loss: 0.0319, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:57:08,292 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 2:01:51, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0472, src.decode.acc_seg: 98.2604, src.loss: 0.0632, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.6142, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:58:11,521 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 2:00:47, time: 1.265, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0430, src.decode.acc_seg: 98.3466, src.loss: 0.0590, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.5894, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:59:14,869 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 1:59:44, time: 1.267, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0468, src.decode.acc_seg: 98.1964, src.loss: 0.0628, mix.decode.loss_seg: 0.0372, mix.decode.acc_seg: 98.3964, mix.loss: 0.0372, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:00:17,456 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 1:58:40, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0461, src.decode.acc_seg: 98.2651, src.loss: 0.0621, mix.decode.loss_seg: 0.0351, mix.decode.acc_seg: 98.5358, mix.loss: 0.0351, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:01:20,078 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 1:57:36, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0427, src.decode.acc_seg: 98.4018, src.loss: 0.0587, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6600, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:02:23,111 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 1:56:33, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0388, src.decode.acc_seg: 98.5509, src.loss: 0.0548, mix.decode.loss_seg: 0.0348, mix.decode.acc_seg: 98.5183, mix.loss: 0.0348, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:03:25,202 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 1:55:29, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0356, src.decode.acc_seg: 98.6479, src.loss: 0.0516, mix.decode.loss_seg: 0.0300, mix.decode.acc_seg: 98.7578, mix.loss: 0.0300, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:04:27,889 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 1:54:25, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0420, src.decode.acc_seg: 98.4108, src.loss: 0.0581, mix.decode.loss_seg: 0.0367, mix.decode.acc_seg: 98.5084, mix.loss: 0.0367, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:05:30,752 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 1:53:21, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0445, src.decode.acc_seg: 98.2712, src.loss: 0.0605, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.3553, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:06:33,375 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 1:52:18, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0439, src.decode.acc_seg: 98.2707, src.loss: 0.0600, mix.decode.loss_seg: 0.0368, mix.decode.acc_seg: 98.4210, mix.loss: 0.0368, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:07:35,638 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 1:51:14, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0547, src.decode.acc_seg: 98.0599, src.loss: 0.0707, mix.decode.loss_seg: 0.0356, mix.decode.acc_seg: 98.4396, mix.loss: 0.0356, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:08:38,199 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 1:50:10, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0388, src.decode.acc_seg: 98.5231, src.loss: 0.0548, mix.decode.loss_seg: 0.0297, mix.decode.acc_seg: 98.7304, mix.loss: 0.0297, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:09:40,784 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 1:49:06, time: 1.252, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0465, src.decode.acc_seg: 98.2036, src.loss: 0.0626, mix.decode.loss_seg: 0.0317, mix.decode.acc_seg: 98.6743, mix.loss: 0.0317, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:10:43,307 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 1:48:03, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0413, src.decode.acc_seg: 98.4724, src.loss: 0.0573, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.7049, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:11:45,472 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 1:46:59, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0375, src.decode.acc_seg: 98.5563, src.loss: 0.0535, mix.decode.loss_seg: 0.0287, mix.decode.acc_seg: 98.7898, mix.loss: 0.0287, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:12:47,976 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 21:12:47,976 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 1:45:55, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.3935, src.loss: 0.0586, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.3679, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:13:50,673 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 1:44:52, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.4995, src.loss: 0.0564, mix.decode.loss_seg: 0.0267, mix.decode.acc_seg: 98.8255, mix.loss: 0.0267, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:14:52,754 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 1:43:48, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0485, src.decode.acc_seg: 98.2534, src.loss: 0.0646, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.6927, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:15:55,193 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 1:42:44, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.4102, src.loss: 0.0564, mix.decode.loss_seg: 0.0328, mix.decode.acc_seg: 98.5504, mix.loss: 0.0328, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:16:58,008 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 1:41:40, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0424, src.decode.acc_seg: 98.4026, src.loss: 0.0585, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.6289, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:18:00,875 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 1:40:37, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0478, src.decode.acc_seg: 98.2544, src.loss: 0.0638, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.3022, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:19:03,428 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 1:39:33, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0332, src.decode.acc_seg: 98.7752, src.loss: 0.0492, mix.decode.loss_seg: 0.0291, mix.decode.acc_seg: 98.6578, mix.loss: 0.0291, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:20:06,321 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 1:38:29, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0467, src.decode.acc_seg: 98.2090, src.loss: 0.0627, mix.decode.loss_seg: 0.0327, mix.decode.acc_seg: 98.5825, mix.loss: 0.0327, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:21:08,952 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 1:37:26, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0415, src.decode.acc_seg: 98.4646, src.loss: 0.0575, mix.decode.loss_seg: 0.0340, mix.decode.acc_seg: 98.6059, mix.loss: 0.0340, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:22:11,378 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 1:36:22, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0378, src.decode.acc_seg: 98.5976, src.loss: 0.0538, mix.decode.loss_seg: 0.0352, mix.decode.acc_seg: 98.5693, mix.loss: 0.0352, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:23:14,456 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 1:35:19, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4403, src.loss: 0.0578, mix.decode.loss_seg: 0.0331, mix.decode.acc_seg: 98.6097, mix.loss: 0.0331, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:24:17,050 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 1:34:15, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0357, src.decode.acc_seg: 98.6017, src.loss: 0.0518, mix.decode.loss_seg: 0.0296, mix.decode.acc_seg: 98.7289, mix.loss: 0.0296, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:25:19,099 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 1:33:11, time: 1.241, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0350, src.decode.acc_seg: 98.6468, src.loss: 0.0510, mix.decode.loss_seg: 0.0249, mix.decode.acc_seg: 98.9542, mix.loss: 0.0249, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:26:22,253 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 1:32:08, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0360, src.decode.acc_seg: 98.6309, src.loss: 0.0521, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.8326, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:27:25,221 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 1:31:04, time: 1.259, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0451, src.decode.acc_seg: 98.3326, src.loss: 0.0611, mix.decode.loss_seg: 0.0356, mix.decode.acc_seg: 98.5322, mix.loss: 0.0356, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:28:28,208 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 1:30:00, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.5151, src.loss: 0.0564, mix.decode.loss_seg: 0.0242, mix.decode.acc_seg: 98.9775, mix.loss: 0.0242, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:29:30,370 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 1:28:57, time: 1.243, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.4505, src.loss: 0.0594, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.6796, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:30:32,921 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 1:27:53, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0337, src.decode.acc_seg: 98.7149, src.loss: 0.0498, mix.decode.loss_seg: 0.0280, mix.decode.acc_seg: 98.8444, mix.loss: 0.0280, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:31:37,774 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 1:26:50, time: 1.297, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0369, src.decode.acc_seg: 98.6047, src.loss: 0.0529, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.5733, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:32:40,179 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 1:25:46, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0358, src.decode.acc_seg: 98.6353, src.loss: 0.0518, mix.decode.loss_seg: 0.0268, mix.decode.acc_seg: 98.8242, mix.loss: 0.0268, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1226s[                                 ] 2/929, 1.4 task/s, elapsed: 1s, ETA:   660s[                                 ] 3/929, 2.0 task/s, elapsed: 2s, ETA:   471s[                                 ] 4/929, 2.5 task/s, elapsed: 2s, ETA:   377s[                                 ] 5/929, 2.9 task/s, elapsed: 2s, ETA:   323s[                                 ] 6/929, 3.2 task/s, elapsed: 2s, ETA:   285s[                                 ] 7/929, 3.6 task/s, elapsed: 2s, ETA:   258s[                                 ] 8/929, 3.9 task/s, elapsed: 2s, ETA:   237s[                                 ] 9/929, 4.2 task/s, elapsed: 2s, ETA:   221s[                                ] 10/929, 4.4 task/s, elapsed: 2s, ETA:   208s[                                ] 11/929, 4.6 task/s, elapsed: 2s, ETA:   200s[                                ] 12/929, 4.8 task/s, elapsed: 2s, ETA:   191s[                                ] 13/929, 5.0 task/s, elapsed: 3s, ETA:   183s[                                ] 14/929, 5.2 task/s, elapsed: 3s, ETA:   176s[                                ] 15/929, 5.4 task/s, elapsed: 3s, ETA:   170s[                                ] 16/929, 5.5 task/s, elapsed: 3s, ETA:   165s[                                ] 17/929, 5.7 task/s, elapsed: 3s, ETA:   160s[                                ] 18/929, 5.8 task/s, elapsed: 3s, ETA:   156s[                                ] 19/929, 6.0 task/s, elapsed: 3s, ETA:   153s[                                ] 20/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 21/929, 6.2 task/s, elapsed: 3s, ETA:   146s[                                ] 22/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 23/929, 6.4 task/s, elapsed: 4s, ETA:   141s[                                ] 24/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 25/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 26/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 27/929, 6.7 task/s, elapsed: 4s, ETA:   134s[                                ] 28/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 29/929, 6.8 task/s, elapsed: 4s, ETA:   132s[>                               ] 30/929, 6.9 task/s, elapsed: 4s, ETA:   130s[>                               ] 31/929, 7.0 task/s, elapsed: 4s, ETA:   129s[>                               ] 32/929, 7.0 task/s, elapsed: 5s, ETA:   128s[>                               ] 33/929, 7.1 task/s, elapsed: 5s, ETA:   127s[>                               ] 34/929, 7.1 task/s, elapsed: 5s, ETA:   125s[>                               ] 35/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 36/929, 7.2 task/s, elapsed: 5s, ETA:   123s[>                               ] 37/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 38/929, 7.3 task/s, elapsed: 5s, ETA:   121s[>                               ] 39/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 40/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 41/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 42/929, 7.5 task/s, elapsed: 6s, ETA:   118s[>                               ] 43/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 44/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 45/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 46/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 47/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 48/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 49/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 50/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 51/929, 7.8 task/s, elapsed: 7s, ETA:   113s[>                               ] 52/929, 7.8 task/s, elapsed: 7s, ETA:   112s[>                               ] 53/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 54/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 55/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 56/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 57/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 58/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>>                              ] 59/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>>                              ] 60/929, 8.0 task/s, elapsed: 7s, ETA:   108s[>>                              ] 61/929, 8.0 task/s, elapsed: 8s, ETA:   108s[>>                              ] 62/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 63/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 64/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 65/929, 8.1 task/s, elapsed: 8s, ETA:   106s[>>                              ] 66/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 68/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 69/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 70/929, 8.2 task/s, elapsed: 9s, ETA:   104s[>>                              ] 71/929, 8.3 task/s, elapsed: 9s, ETA:   104s[>>                              ] 72/929, 8.3 task/s, elapsed: 9s, ETA:   104s[>>                              ] 73/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 74/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 75/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 76/929, 8.3 task/s, elapsed: 9s, ETA:   102s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 78/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 79/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                             ] 80/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 81/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 82/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 83/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 85/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 86/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 87/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 88/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 89/929, 8.5 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 90/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 91/929, 8.6 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 92/929, 8.6 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 93/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 94/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 95/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 96/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 97/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 98/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 99/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                           ] 100/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 101/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 102/929, 8.7 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 103/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 106/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 107/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 108/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 109/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 110/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 111/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 112/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 113/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 114/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 115/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 116/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 117/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 118/929, 8.8 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 119/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 120/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 121/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 122/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 123/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 124/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 125/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 126/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 127/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 128/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 129/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 130/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 131/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 132/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 133/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 134/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 135/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 136/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 137/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 138/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 139/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 140/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 141/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 142/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 143/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 144/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 145/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 146/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 147/929, 8.9 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 148/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 149/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 150/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 151/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 152/929, 9.0 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 153/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>                          ] 154/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 155/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 156/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 157/929, 9.0 task/s, elapsed: 17s, ETA:    86s[>>>>>                         ] 158/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 159/929, 9.0 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 160/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 161/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 162/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 163/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 164/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 165/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 166/929, 9.0 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 167/929, 9.0 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 168/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 169/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 170/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 171/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 172/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 173/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 174/929, 9.0 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 175/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 176/929, 9.1 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 177/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 178/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 180/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 181/929, 9.1 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 183/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 184/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 185/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 186/929, 9.1 task/s, elapsed: 20s, ETA:    82s[>>>>>>                        ] 187/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 188/929, 9.1 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 190/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 191/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 192/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 193/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 194/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 195/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 196/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 198/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 199/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 200/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.2 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 221/929, 9.1 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 222/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 223/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 224/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 225/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.2 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 229/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 230/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 231/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 232/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 234/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 235/929, 9.2 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 237/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 238/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 239/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 240/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 241/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 242/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 243/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 244/929, 9.2 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>                       ] 246/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>                       ] 247/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 248/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 249/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.2 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 254/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 255/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 256/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 257/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 258/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.2 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 263/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 264/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 290/929, 9.2 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 293/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 297/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 298/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 299/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 306/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 307/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 308/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 309/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>>                    ] 310/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 315/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 316/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 317/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 318/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 319/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 323/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 324/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 325/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 326/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 327/929, 9.2 task/s, elapsed: 35s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 332/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 333/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 336/929, 9.2 task/s, elapsed: 36s, ETA:    64s[>>>>>>>>>>                    ] 337/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 340/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 341/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 342/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.2 task/s, elapsed: 37s, ETA:    63s[>>>>>>>>>>>                   ] 346/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 348/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 349/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 350/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.2 task/s, elapsed: 38s, ETA:    62s[>>>>>>>>>>>                   ] 355/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 356/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 357/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 358/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 359/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 365/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 366/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 367/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 375/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 384/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 385/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 394/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 398/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 412/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 430/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 468/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 477/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 478/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 487/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 496/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 505/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 514/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 515/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 523/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 524/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.1 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.1 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.1 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.1 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.1 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.1 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.1 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.1 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.1 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.1 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.1 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.1 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.1 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.1 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.1 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.1 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.1 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.1 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.1 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.1 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.1 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.1 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.1 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.1 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.1 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.1 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.1 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.1 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.1 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.1 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.1 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.1 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.1 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.1 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.1 task/s, elapsed: 102s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.1 task/s, elapsed: 102s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.1 task/s, elapsed: 102s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.1 task/s, elapsed: 102s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.1 task/s, elapsed: 102s, ETA:     0s2022-10-10 21:36:32,519 - mmseg - INFO - per class results:2022-10-10 21:36:32,520 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.21 | 96.36 || rigid_plastic | 32.06 | 37.11 ||   cardboard   | 58.13 | 72.56 ||     metal     | 30.67 | 37.72 ||  soft_plastic | 62.65 | 70.64 |+---------------+-------+-------+2022-10-10 21:36:32,520 - mmseg - INFO - Summary:2022-10-10 21:36:32,520 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.67 | 54.95 | 62.88 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:36:32,524 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 21:36:32,524 - mmseg - INFO - Iter [929/40000]	lr: 6.002e-06, eta: 1:24:42, time: 1.253, data_time: 0.015, memory: 67493, aAcc: 0.9167, mIoU: 0.5495, mAcc: 0.6288, IoU.background: 0.9121, IoU.rigid_plastic: 0.3206, IoU.cardboard: 0.5813, IoU.metal: 0.3067, IoU.soft_plastic: 0.6265, Acc.background: 0.9636, Acc.rigid_plastic: 0.3711, Acc.cardboard: 0.7256, Acc.metal: 0.3772, Acc.soft_plastic: 0.7064, src.decode.loss_seg: 0.0430, src.decode.acc_seg: 98.3728, src.loss: 0.0590, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6014, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:37:35,254 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 1:23:57, time: 4.648, data_time: 3.408, memory: 67493, src.decode.loss_seg: 0.0375, src.decode.acc_seg: 98.5533, src.loss: 0.0536, mix.decode.loss_seg: 0.0293, mix.decode.acc_seg: 98.7126, mix.loss: 0.0293, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:38:38,237 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 1:22:53, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0391, src.decode.acc_seg: 98.5886, src.loss: 0.0552, mix.decode.loss_seg: 0.0287, mix.decode.acc_seg: 98.7988, mix.loss: 0.0287, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:39:41,219 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 1:21:50, time: 1.260, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0435, src.decode.acc_seg: 98.4209, src.loss: 0.0595, mix.decode.loss_seg: 0.0313, mix.decode.acc_seg: 98.6477, mix.loss: 0.0313, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:40:43,852 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 1:20:46, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0367, src.decode.acc_seg: 98.5712, src.loss: 0.0527, mix.decode.loss_seg: 0.0278, mix.decode.acc_seg: 98.8025, mix.loss: 0.0278, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:41:46,757 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 1:19:42, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0324, src.decode.acc_seg: 98.8028, src.loss: 0.0484, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.8180, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:42:49,493 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 1:18:38, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.4423, src.loss: 0.0576, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.8475, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:43:51,927 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 1:17:34, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0377, src.decode.acc_seg: 98.5927, src.loss: 0.0537, mix.decode.loss_seg: 0.0298, mix.decode.acc_seg: 98.6921, mix.loss: 0.0298, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:44:54,830 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 1:16:30, time: 1.258, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0335, src.decode.acc_seg: 98.6919, src.loss: 0.0495, mix.decode.loss_seg: 0.0306, mix.decode.acc_seg: 98.7471, mix.loss: 0.0306, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:45:59,131 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 1:15:26, time: 1.286, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0391, src.decode.acc_seg: 98.5754, src.loss: 0.0551, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.7108, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:47:02,256 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 1:14:23, time: 1.263, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.5425, src.loss: 0.0550, mix.decode.loss_seg: 0.0298, mix.decode.acc_seg: 98.7502, mix.loss: 0.0298, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:48:04,766 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 1:13:19, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0381, src.decode.acc_seg: 98.5712, src.loss: 0.0542, mix.decode.loss_seg: 0.0292, mix.decode.acc_seg: 98.6855, mix.loss: 0.0292, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:49:07,429 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 1:12:15, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0413, src.decode.acc_seg: 98.4535, src.loss: 0.0573, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6310, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:50:09,854 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 1:11:11, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0437, src.decode.acc_seg: 98.3930, src.loss: 0.0598, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6458, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:51:12,405 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 1:10:07, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0362, src.decode.acc_seg: 98.6576, src.loss: 0.0522, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.6726, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:52:14,987 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 1:09:03, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0534, src.decode.acc_seg: 98.3243, src.loss: 0.0695, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.5666, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:53:18,008 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 1:08:00, time: 1.260, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0395, src.decode.acc_seg: 98.5274, src.loss: 0.0555, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.7674, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:54:20,919 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 1:06:56, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0418, src.decode.acc_seg: 98.3973, src.loss: 0.0579, mix.decode.loss_seg: 0.0355, mix.decode.acc_seg: 98.5213, mix.loss: 0.0355, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:55:23,603 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 1:05:52, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.4661, src.loss: 0.0568, mix.decode.loss_seg: 0.0324, mix.decode.acc_seg: 98.6129, mix.loss: 0.0324, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:56:26,390 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 1:04:48, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0350, src.decode.acc_seg: 98.6392, src.loss: 0.0510, mix.decode.loss_seg: 0.0301, mix.decode.acc_seg: 98.6866, mix.loss: 0.0301, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:57:29,434 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 21:57:29,434 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 1:03:44, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.5252, src.loss: 0.0550, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.8598, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:58:31,644 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 1:02:40, time: 1.244, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.5044, src.loss: 0.0569, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.6043, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:59:34,027 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 1:01:37, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0389, src.decode.acc_seg: 98.5060, src.loss: 0.0550, mix.decode.loss_seg: 0.0284, mix.decode.acc_seg: 98.8156, mix.loss: 0.0284, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:00:37,060 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 1:00:33, time: 1.261, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0412, src.decode.acc_seg: 98.3671, src.loss: 0.0572, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6629, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:01:39,495 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 0:59:29, time: 1.249, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0412, src.decode.acc_seg: 98.4695, src.loss: 0.0572, mix.decode.loss_seg: 0.0297, mix.decode.acc_seg: 98.8385, mix.loss: 0.0297, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:02:42,135 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:58:25, time: 1.253, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.4608, src.loss: 0.0576, mix.decode.loss_seg: 0.0321, mix.decode.acc_seg: 98.5730, mix.loss: 0.0321, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:03:44,753 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:57:21, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0342, src.decode.acc_seg: 98.6750, src.loss: 0.0502, mix.decode.loss_seg: 0.0279, mix.decode.acc_seg: 98.7278, mix.loss: 0.0279, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:04:47,172 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:56:17, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0379, src.decode.acc_seg: 98.5114, src.loss: 0.0539, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.6916, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:05:50,428 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:55:14, time: 1.265, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0428, src.decode.acc_seg: 98.4176, src.loss: 0.0588, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.7439, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:06:53,215 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:54:10, time: 1.256, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0467, src.decode.acc_seg: 98.2231, src.loss: 0.0627, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.3649, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:07:56,574 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:53:06, time: 1.267, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0374, src.decode.acc_seg: 98.6466, src.loss: 0.0534, mix.decode.loss_seg: 0.0268, mix.decode.acc_seg: 98.8326, mix.loss: 0.0268, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:08:59,255 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:52:02, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0458, src.decode.acc_seg: 98.2723, src.loss: 0.0618, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.7059, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:10:01,761 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:50:58, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0451, src.decode.acc_seg: 98.2969, src.loss: 0.0611, mix.decode.loss_seg: 0.0337, mix.decode.acc_seg: 98.5531, mix.loss: 0.0337, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:11:04,378 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:49:55, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0456, src.decode.acc_seg: 98.2686, src.loss: 0.0616, mix.decode.loss_seg: 0.0331, mix.decode.acc_seg: 98.5210, mix.loss: 0.0331, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:12:07,498 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:48:51, time: 1.262, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0429, src.decode.acc_seg: 98.4523, src.loss: 0.0589, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.6317, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:13:10,420 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:47:47, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0349, src.decode.acc_seg: 98.7088, src.loss: 0.0510, mix.decode.loss_seg: 0.0233, mix.decode.acc_seg: 98.9451, mix.loss: 0.0233, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:14:12,906 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:46:43, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0378, src.decode.acc_seg: 98.5616, src.loss: 0.0539, mix.decode.loss_seg: 0.0275, mix.decode.acc_seg: 98.7813, mix.loss: 0.0275, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:15:15,221 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:45:40, time: 1.246, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0406, src.decode.acc_seg: 98.4209, src.loss: 0.0566, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.5555, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:16:18,394 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:44:36, time: 1.263, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0366, src.decode.acc_seg: 98.6160, src.loss: 0.0526, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.4964, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:17:21,396 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:43:32, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0375, src.decode.acc_seg: 98.5567, src.loss: 0.0535, mix.decode.loss_seg: 0.0268, mix.decode.acc_seg: 98.8966, mix.loss: 0.0268, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:18:24,178 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 22:18:24,178 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:42:28, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0395, src.decode.acc_seg: 98.5905, src.loss: 0.0555, mix.decode.loss_seg: 0.0328, mix.decode.acc_seg: 98.6921, mix.loss: 0.0328, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:19:27,076 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:41:25, time: 1.258, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0403, src.decode.acc_seg: 98.5043, src.loss: 0.0563, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.7963, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:20:29,561 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:40:21, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0361, src.decode.acc_seg: 98.6071, src.loss: 0.0521, mix.decode.loss_seg: 0.0282, mix.decode.acc_seg: 98.7869, mix.loss: 0.0282, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:21:32,884 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:39:17, time: 1.266, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0396, src.decode.acc_seg: 98.5019, src.loss: 0.0557, mix.decode.loss_seg: 0.0259, mix.decode.acc_seg: 98.9186, mix.loss: 0.0259, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:22:34,986 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:38:13, time: 1.242, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0375, src.decode.acc_seg: 98.5489, src.loss: 0.0535, mix.decode.loss_seg: 0.0288, mix.decode.acc_seg: 98.7148, mix.loss: 0.0288, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:23:37,524 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:37:09, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0358, src.decode.acc_seg: 98.5791, src.loss: 0.0518, mix.decode.loss_seg: 0.0286, mix.decode.acc_seg: 98.7390, mix.loss: 0.0286, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:24:40,616 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:36:06, time: 1.262, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0399, src.decode.acc_seg: 98.5616, src.loss: 0.0559, mix.decode.loss_seg: 0.0309, mix.decode.acc_seg: 98.5515, mix.loss: 0.0309, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:25:43,118 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:35:02, time: 1.250, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0378, src.decode.acc_seg: 98.5416, src.loss: 0.0538, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.7917, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:26:45,576 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:33:58, time: 1.249, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0362, src.decode.acc_seg: 98.6199, src.loss: 0.0522, mix.decode.loss_seg: 0.0281, mix.decode.acc_seg: 98.7949, mix.loss: 0.0281, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:27:48,277 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:32:54, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0369, src.decode.acc_seg: 98.6090, src.loss: 0.0529, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.6322, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:28:51,030 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:31:51, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0372, src.decode.acc_seg: 98.5722, src.loss: 0.0533, mix.decode.loss_seg: 0.0264, mix.decode.acc_seg: 98.7311, mix.loss: 0.0264, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:29:53,763 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:30:47, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0400, src.decode.acc_seg: 98.4805, src.loss: 0.0561, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.6573, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:30:56,744 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:29:43, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0388, src.decode.acc_seg: 98.6317, src.loss: 0.0548, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.7402, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:31:59,288 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:28:39, time: 1.251, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0448, src.decode.acc_seg: 98.2315, src.loss: 0.0608, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.4926, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:33:02,054 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:27:36, time: 1.255, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0358, src.decode.acc_seg: 98.6226, src.loss: 0.0518, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6734, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:34:05,234 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:26:32, time: 1.264, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0333, src.decode.acc_seg: 98.7448, src.loss: 0.0493, mix.decode.loss_seg: 0.0269, mix.decode.acc_seg: 98.9137, mix.loss: 0.0269, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:35:08,246 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:25:28, time: 1.260, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0425, src.decode.acc_seg: 98.3832, src.loss: 0.0586, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.6969, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:36:11,178 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:24:25, time: 1.259, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0394, src.decode.acc_seg: 98.5317, src.loss: 0.0554, mix.decode.loss_seg: 0.0334, mix.decode.acc_seg: 98.5745, mix.loss: 0.0334, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:37:14,214 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:23:21, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0342, src.decode.acc_seg: 98.7225, src.loss: 0.0502, mix.decode.loss_seg: 0.0276, mix.decode.acc_seg: 98.8639, mix.loss: 0.0276, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:38:16,793 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:22:17, time: 1.252, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0314, src.decode.acc_seg: 98.7848, src.loss: 0.0474, mix.decode.loss_seg: 0.0272, mix.decode.acc_seg: 98.8214, mix.loss: 0.0272, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:39:19,593 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed6926_e8d232022-10-10 22:39:19,593 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:21:13, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0337, src.decode.acc_seg: 98.6808, src.loss: 0.0497, mix.decode.loss_seg: 0.0295, mix.decode.acc_seg: 98.8886, mix.loss: 0.0295, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:40:22,382 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:20:10, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0331, src.decode.acc_seg: 98.7220, src.loss: 0.0492, mix.decode.loss_seg: 0.0283, mix.decode.acc_seg: 98.6917, mix.loss: 0.0283, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:41:24,465 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:19:06, time: 1.242, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0383, src.decode.acc_seg: 98.6849, src.loss: 0.0543, mix.decode.loss_seg: 0.0263, mix.decode.acc_seg: 98.9394, mix.loss: 0.0263, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:42:27,304 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:18:02, time: 1.257, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0400, src.decode.acc_seg: 98.4539, src.loss: 0.0561, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.6771, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:43:29,666 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:16:59, time: 1.247, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.5469, src.loss: 0.0550, mix.decode.loss_seg: 0.0277, mix.decode.acc_seg: 98.8129, mix.loss: 0.0277, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:44:32,360 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:15:55, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0358, src.decode.acc_seg: 98.6912, src.loss: 0.0519, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.5433, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:45:34,749 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:14:51, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0427, src.decode.acc_seg: 98.3754, src.loss: 0.0587, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.6654, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:46:37,421 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:13:47, time: 1.253, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0398, src.decode.acc_seg: 98.4873, src.loss: 0.0558, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5699, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:47:40,692 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:12:44, time: 1.265, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0341, src.decode.acc_seg: 98.6696, src.loss: 0.0501, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.7445, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:48:43,378 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:11:40, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0369, src.decode.acc_seg: 98.5423, src.loss: 0.0529, mix.decode.loss_seg: 0.0276, mix.decode.acc_seg: 98.7899, mix.loss: 0.0276, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:49:46,089 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:10:36, time: 1.254, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0378, src.decode.acc_seg: 98.5213, src.loss: 0.0538, mix.decode.loss_seg: 0.0289, mix.decode.acc_seg: 98.7741, mix.loss: 0.0289, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:50:48,841 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:09:33, time: 1.255, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.4956, src.loss: 0.0550, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.6676, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:51:51,221 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:08:29, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0397, src.decode.acc_seg: 98.4879, src.loss: 0.0557, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.5831, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:52:54,274 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:07:25, time: 1.261, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0384, src.decode.acc_seg: 98.5523, src.loss: 0.0544, mix.decode.loss_seg: 0.0249, mix.decode.acc_seg: 98.9137, mix.loss: 0.0249, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:53:57,096 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:06:22, time: 1.256, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0435, src.decode.acc_seg: 98.3934, src.loss: 0.0595, mix.decode.loss_seg: 0.0300, mix.decode.acc_seg: 98.8287, mix.loss: 0.0300, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:54:59,574 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:05:18, time: 1.250, data_time: 0.015, memory: 67493, src.decode.loss_seg: 0.0389, src.decode.acc_seg: 98.5176, src.loss: 0.0549, mix.decode.loss_seg: 0.0296, mix.decode.acc_seg: 98.7742, mix.loss: 0.0296, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:56:02,139 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:04:14, time: 1.251, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0353, src.decode.acc_seg: 98.6452, src.loss: 0.0514, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.6248, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:57:04,537 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:03:11, time: 1.248, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0346, src.decode.acc_seg: 98.6610, src.loss: 0.0506, mix.decode.loss_seg: 0.0289, mix.decode.acc_seg: 98.6130, mix.loss: 0.0289, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:58:09,145 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:02:07, time: 1.292, data_time: 0.016, memory: 67493, src.decode.loss_seg: 0.0322, src.decode.acc_seg: 98.7562, src.loss: 0.0482, mix.decode.loss_seg: 0.0301, mix.decode.acc_seg: 98.7376, mix.loss: 0.0301, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:59:11,385 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:01:03, time: 1.245, data_time: 0.014, memory: 67493, src.decode.loss_seg: 0.0384, src.decode.acc_seg: 98.5870, src.loss: 0.0544, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.6159, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1205s[                                 ] 2/929, 1.4 task/s, elapsed: 1s, ETA:   649s[                                 ] 3/929, 2.0 task/s, elapsed: 2s, ETA:   464s[                                 ] 4/929, 2.5 task/s, elapsed: 2s, ETA:   372s[                                 ] 5/929, 2.9 task/s, elapsed: 2s, ETA:   316s[                                 ] 6/929, 3.3 task/s, elapsed: 2s, ETA:   280s[                                 ] 7/929, 3.6 task/s, elapsed: 2s, ETA:   253s[                                 ] 8/929, 3.9 task/s, elapsed: 2s, ETA:   233s[                                 ] 9/929, 4.2 task/s, elapsed: 2s, ETA:   218s[                                ] 10/929, 4.5 task/s, elapsed: 2s, ETA:   205s[                                ] 11/929, 4.7 task/s, elapsed: 2s, ETA:   195s[                                ] 12/929, 4.9 task/s, elapsed: 2s, ETA:   187s[                                ] 13/929, 5.1 task/s, elapsed: 3s, ETA:   180s[                                ] 14/929, 5.3 task/s, elapsed: 3s, ETA:   173s[                                ] 15/929, 5.4 task/s, elapsed: 3s, ETA:   168s[                                ] 16/929, 5.6 task/s, elapsed: 3s, ETA:   163s[                                ] 17/929, 5.7 task/s, elapsed: 3s, ETA:   159s[                                ] 18/929, 5.9 task/s, elapsed: 3s, ETA:   155s[                                ] 19/929, 6.0 task/s, elapsed: 3s, ETA:   152s[                                ] 20/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 21/929, 6.2 task/s, elapsed: 3s, ETA:   146s[                                ] 22/929, 6.3 task/s, elapsed: 3s, ETA:   143s[                                ] 23/929, 6.4 task/s, elapsed: 4s, ETA:   141s[                                ] 24/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 25/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 26/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 27/929, 6.7 task/s, elapsed: 4s, ETA:   134s[                                ] 28/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 29/929, 6.9 task/s, elapsed: 4s, ETA:   131s[>                               ] 30/929, 6.9 task/s, elapsed: 4s, ETA:   130s[>                               ] 31/929, 7.0 task/s, elapsed: 4s, ETA:   129s[>                               ] 32/929, 7.0 task/s, elapsed: 5s, ETA:   128s[>                               ] 33/929, 7.1 task/s, elapsed: 5s, ETA:   127s[>                               ] 34/929, 7.1 task/s, elapsed: 5s, ETA:   125s[>                               ] 35/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 36/929, 7.2 task/s, elapsed: 5s, ETA:   123s[>                               ] 37/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 38/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 39/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 40/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 41/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 42/929, 7.5 task/s, elapsed: 6s, ETA:   118s[>                               ] 43/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 44/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 45/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 46/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 47/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 48/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 49/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 50/929, 7.8 task/s, elapsed: 6s, ETA:   112s[>                               ] 51/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 53/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 54/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 55/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 56/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 57/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 58/929, 8.0 task/s, elapsed: 7s, ETA:   108s[>>                              ] 59/929, 8.0 task/s, elapsed: 7s, ETA:   108s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 61/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 62/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 63/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 64/929, 8.1 task/s, elapsed: 8s, ETA:   106s[>>                              ] 65/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 66/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 68/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 69/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 70/929, 8.2 task/s, elapsed: 9s, ETA:   104s[>>                              ] 71/929, 8.2 task/s, elapsed: 9s, ETA:   104s[>>                              ] 72/929, 8.3 task/s, elapsed: 9s, ETA:   104s[>>                              ] 73/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 74/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 75/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 76/929, 8.3 task/s, elapsed: 9s, ETA:   102s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 78/929, 8.3 task/s, elapsed: 9s, ETA:   102s[>>                              ] 79/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                             ] 80/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 81/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 82/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 83/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 84/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 85/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 86/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 87/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 88/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 89/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>>                            ] 90/929, 8.5 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 91/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 92/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 93/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 94/929, 8.6 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 95/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 96/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 97/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 98/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 99/929, 8.6 task/s, elapsed: 11s, ETA:    96s[>>>                           ] 100/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 101/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 102/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 103/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 104/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 105/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 106/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 107/929, 8.7 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 108/929, 8.7 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 109/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 110/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 111/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 112/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 113/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 114/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 115/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 116/929, 8.7 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 117/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 118/929, 8.8 task/s, elapsed: 13s, ETA:    93s[>>>                           ] 119/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 120/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 121/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 122/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>                           ] 123/929, 8.8 task/s, elapsed: 14s, ETA:    92s[>>>>                          ] 124/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 125/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 126/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 127/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 128/929, 8.8 task/s, elapsed: 14s, ETA:    91s[>>>>                          ] 129/929, 8.8 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 130/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 131/929, 8.8 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 132/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 133/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 134/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 135/929, 8.9 task/s, elapsed: 15s, ETA:    90s[>>>>                          ] 136/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 137/929, 8.9 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 138/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 139/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 140/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 141/929, 8.9 task/s, elapsed: 16s, ETA:    89s[>>>>                          ] 142/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 143/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 144/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 145/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 146/929, 8.9 task/s, elapsed: 16s, ETA:    88s[>>>>                          ] 147/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 148/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 149/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 150/929, 8.9 task/s, elapsed: 17s, ETA:    88s[>>>>                          ] 151/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 152/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 153/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>                          ] 154/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 155/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 156/929, 8.9 task/s, elapsed: 17s, ETA:    87s[>>>>>                         ] 157/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 158/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 159/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 160/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 161/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 162/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 163/929, 8.9 task/s, elapsed: 18s, ETA:    86s[>>>>>                         ] 164/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 165/929, 9.0 task/s, elapsed: 18s, ETA:    85s[>>>>>                         ] 166/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 167/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 168/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 169/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 170/929, 9.0 task/s, elapsed: 19s, ETA:    85s[>>>>>                         ] 171/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 172/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 173/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 174/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 175/929, 9.0 task/s, elapsed: 19s, ETA:    84s[>>>>>                         ] 176/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 177/929, 9.0 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 178/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 179/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 180/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 181/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 182/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 183/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 184/929, 9.0 task/s, elapsed: 20s, ETA:    83s[>>>>>                         ] 185/929, 9.0 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 186/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 187/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 188/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 189/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 190/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 191/929, 9.0 task/s, elapsed: 21s, ETA:    82s[>>>>>>                        ] 192/929, 9.0 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 193/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 194/929, 9.1 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 195/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 196/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 197/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 198/929, 9.1 task/s, elapsed: 22s, ETA:    81s[>>>>>>                        ] 199/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 200/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 201/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 202/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 203/929, 9.1 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 204/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 205/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 206/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 207/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 208/929, 9.1 task/s, elapsed: 23s, ETA:    80s[>>>>>>                        ] 209/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 210/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 211/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 212/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 213/929, 9.1 task/s, elapsed: 23s, ETA:    79s[>>>>>>                        ] 214/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 215/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>                        ] 216/929, 9.1 task/s, elapsed: 24s, ETA:    79s[>>>>>>>                       ] 217/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 219/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 220/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 221/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 222/929, 9.1 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 223/929, 9.1 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 224/929, 9.1 task/s, elapsed: 25s, ETA:    78s[>>>>>>>                       ] 225/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 226/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 227/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 228/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 229/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 230/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 231/929, 9.1 task/s, elapsed: 25s, ETA:    77s[>>>>>>>                       ] 232/929, 9.1 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 234/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 235/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 236/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 237/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 238/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 239/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 240/929, 9.1 task/s, elapsed: 26s, ETA:    76s[>>>>>>>                       ] 241/929, 9.1 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 242/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 243/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 244/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 245/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 246/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 247/929, 9.1 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 248/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 249/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 250/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 251/929, 9.1 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 252/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 253/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 254/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 255/929, 9.2 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 256/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 257/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 258/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 259/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 260/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 261/929, 9.2 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 262/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 263/929, 9.2 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 264/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 265/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 266/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 267/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 268/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 269/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 270/929, 9.2 task/s, elapsed: 29s, ETA:    72s[>>>>>>>>                      ] 271/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 272/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 273/929, 9.2 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 274/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 275/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 276/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 277/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>                      ] 278/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 279/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 280/929, 9.2 task/s, elapsed: 30s, ETA:    71s[>>>>>>>>>                     ] 281/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 282/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 283/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 284/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 285/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 286/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 287/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 288/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 289/929, 9.2 task/s, elapsed: 31s, ETA:    70s[>>>>>>>>>                     ] 290/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 291/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 292/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 293/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 294/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 295/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 296/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 297/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 298/929, 9.2 task/s, elapsed: 32s, ETA:    69s[>>>>>>>>>                     ] 299/929, 9.2 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 300/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 301/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 302/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 303/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 304/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 305/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 306/929, 9.2 task/s, elapsed: 33s, ETA:    68s[>>>>>>>>>                     ] 307/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 308/929, 9.2 task/s, elapsed: 33s, ETA:    67s[>>>>>>>>>                     ] 309/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 310/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 311/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 312/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 313/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 314/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 315/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 316/929, 9.2 task/s, elapsed: 34s, ETA:    67s[>>>>>>>>>>                    ] 317/929, 9.2 task/s, elapsed: 34s, ETA:    66s[>>>>>>>>>>                    ] 318/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 319/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 320/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 321/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 322/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 323/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 324/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 325/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 326/929, 9.2 task/s, elapsed: 35s, ETA:    66s[>>>>>>>>>>                    ] 327/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 328/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 329/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 330/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 331/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 332/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 333/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.2 task/s, elapsed: 36s, ETA:    65s[>>>>>>>>>>                    ] 336/929, 9.2 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 337/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 338/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 339/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>                    ] 340/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 341/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 342/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.2 task/s, elapsed: 37s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.2 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 346/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 347/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 348/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 349/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 350/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 351/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.2 task/s, elapsed: 38s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.2 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 355/929, 9.2 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 356/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 357/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 358/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 359/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.2 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.2 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.2 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 366/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 367/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 368/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.2 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.2 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 376/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 377/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.2 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.2 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 384/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 385/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 394/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 398/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 403/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 412/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 422/929, 9.1 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.1 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.1 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.1 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 430/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 431/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 441/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 450/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 451/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 460/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 468/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 469/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 477/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 478/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 487/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 496/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 497/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 505/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 514/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 515/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 523/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 524/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.1 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.1 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.1 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.0 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.0 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.0 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.0 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.0 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.0 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.0 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.0 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.0 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.0 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.0 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.0 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.0 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.0 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.0 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.0 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.0 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.0 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.0 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.0 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.0 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.0 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.0 task/s, elapsed: 86s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.0 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.0 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.0 task/s, elapsed: 87s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.0 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.0 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.0 task/s, elapsed: 88s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.0 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.0 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.0 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.0 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.0 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.0 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.0 task/s, elapsed: 91s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.0 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.0 task/s, elapsed: 92s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.0 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.0 task/s, elapsed: 93s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.0 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.0 task/s, elapsed: 94s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.0 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.0 task/s, elapsed: 95s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.0 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.0 task/s, elapsed: 96s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.0 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.0 task/s, elapsed: 97s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.0 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.0 task/s, elapsed: 98s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.0 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.0 task/s, elapsed: 99s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.0 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.0 task/s, elapsed: 100s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.0 task/s, elapsed: 101s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.0 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.0 task/s, elapsed: 102s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.0 task/s, elapsed: 103s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.0 task/s, elapsed: 103s, ETA:     0s2022-10-10 23:03:19,537 - mmseg - INFO - per class results:2022-10-10 23:03:19,537 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.26 | 96.13 || rigid_plastic | 36.08 | 43.12 ||   cardboard   |  58.7 |  74.0 ||     metal     | 32.17 |  36.9 ||  soft_plastic | 62.62 | 71.12 |+---------------+-------+-------+2022-10-10 23:03:19,537 - mmseg - INFO - Summary:2022-10-10 23:03:19,537 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.72 | 56.17 | 64.25 |+-------+-------+-------+2022-10-10 23:03:19,540 - mmseg - INFO - Saving checkpoint at 40000 iterations