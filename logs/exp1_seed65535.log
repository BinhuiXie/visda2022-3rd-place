2022-10-10 08:51:18,198 - mmseg - INFO - Environment info:------------------------------------------------------------sys.platform: linuxPython: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]CUDA available: TrueGPU 0: NVIDIA A100-SXM4-80GBCUDA_HOME: /usr/local/cudaNVCC: Build cuda_11.3.r11.3/compiler.29745058_0GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0PyTorch: 1.7.1+cu110PyTorch compiling details: PyTorch built with:  - GCC 7.3  - C++ Version: 201402  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)  - OpenMP 201511 (a.k.a. OpenMP 4.5)  - NNPACK is enabled  - CPU capability usage: AVX2  - CUDA Runtime 11.0  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80  - CuDNN 8.0.5  - Magma 2.5.2  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, TorchVision: 0.8.2+cu110OpenCV: 4.4.0MMCV: 1.3.7MMCV Compiler: GCC 7.3MMCV CUDA Compiler: 11.0MMSegmentation: 0.16.0+e6a2fe4------------------------------------------------------------2022-10-10 08:51:18,198 - mmseg - INFO - Distributed training: False2022-10-10 08:51:19,007 - mmseg - INFO - Config:log_config = dict(    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])dist_params = dict(backend='nccl')log_level = 'INFO'load_from = Noneresume_from = Noneworkflow = [('train', 1)]cudnn_benchmark = Truenorm_cfg = dict(type='BN', requires_grad=True)find_unused_parameters = Truemodel = dict(    type='EncoderDecoderProjector',    pretrained='pretrained/mit_b5.pth',    backbone=dict(type='mit_b5', style='pytorch'),    decode_head=dict(        type='DAFormerHead',        in_channels=[64, 128, 320, 512],        in_index=[0, 1, 2, 3],        channels=256,        dropout_ratio=0.1,        num_classes=5,        norm_cfg=dict(type='BN', requires_grad=True),        align_corners=False,        decoder_params=dict(            embed_dims=256,            embed_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),            embed_neck_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),            fusion_cfg=dict(                type='aspp',                sep=True,                dilations=(1, 6, 12, 18),                pool=False,                act_cfg=dict(type='ReLU'),                norm_cfg=dict(type='BN', requires_grad=True))),        loss_decode=dict(            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),    auxiliary_head=dict(        type='ProjHead',        in_channels=[64, 128, 320, 512],        in_index=[0, 1, 2, 3],        input_transform='resize_concat',        channels=512,        num_convs=2,        dropout_ratio=0.1,        num_classes=5,        norm_cfg=dict(type='BN', requires_grad=True),        align_corners=False,        loss_decode=dict(            type='ContrastiveLoss',            use_dist=True,            use_bank=False,            use_reg=True,            use_avg_pool=True,            scale_min_ratio=0.75,            num_classes=5,            contrast_temp=100.0,            loss_weight=0.01,            reg_relative_weight=0.001)),    train_cfg=dict(        work_dir=        'work_dirs_test/local-exp11/221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e4'    ),    test_cfg=dict(mode='whole'))img_norm_cfg = dict(    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)crop_size = (640, 640)source_train_pipeline = [    dict(type='LoadImageFromFile'),    dict(type='LoadAnnotations'),    dict(type='Resize', img_scale=(1138, 640)),    dict(type='RandomCrop', crop_size=(640, 640), cat_max_ratio=0.75),    dict(type='RandomFlip', prob=0.5),    dict(        type='Normalize',        mean=[123.675, 116.28, 103.53],        std=[58.395, 57.12, 57.375],        to_rgb=True),    dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),    dict(type='DefaultFormatBundle'),    dict(type='Collect', keys=['img', 'gt_semantic_seg'])]target_train_pipeline = [    dict(type='LoadImageFromFile'),    dict(type='LoadAnnotations'),    dict(type='Resize', img_scale=(1138, 640)),    dict(type='RandomCrop', crop_size=(640, 640)),    dict(type='RandomFlip', prob=0.5),    dict(        type='Normalize',        mean=[123.675, 116.28, 103.53],        std=[58.395, 57.12, 57.375],        to_rgb=True),    dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),    dict(type='DefaultFormatBundle'),    dict(type='Collect', keys=['img', 'gt_semantic_seg'])]test_pipeline = [    dict(type='LoadImageFromFile'),    dict(        type='MultiScaleFlipAug',        img_scale=(1138, 640),        flip=False,        transforms=[            dict(type='Resize', keep_ratio=True),            dict(type='RandomFlip'),            dict(                type='Normalize',                mean=[123.675, 116.28, 103.53],                std=[58.395, 57.12, 57.375],                to_rgb=True),            dict(type='ImageToTensor', keys=['img']),            dict(type='Collect', keys=['img'])        ])]data = dict(    samples_per_gpu=2,    workers_per_gpu=4,    train=dict(        type='UDADataset',        source=dict(            type='ZeroWasteDataset',            data_root='data/zerowaste-f/train',            img_dir='data',            ann_dir='sem_seg',            pipeline=[                dict(type='LoadImageFromFile'),                dict(type='LoadAnnotations'),                dict(type='Resize', img_scale=(1138, 640)),                dict(                    type='RandomCrop',                    crop_size=(640, 640),                    cat_max_ratio=0.75),                dict(type='RandomFlip', prob=0.5),                dict(                    type='Normalize',                    mean=[123.675, 116.28, 103.53],                    std=[58.395, 57.12, 57.375],                    to_rgb=True),                dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),                dict(type='DefaultFormatBundle'),                dict(type='Collect', keys=['img', 'gt_semantic_seg'])            ]),        target=dict(            type='ZeroWasteV2Dataset',            data_root='data/zerowaste-v2-splits/train',            img_dir='data',            ann_dir='sem_seg',            pipeline=[                dict(type='LoadImageFromFile'),                dict(type='LoadAnnotations'),                dict(type='Resize', img_scale=(1138, 640)),                dict(type='RandomCrop', crop_size=(640, 640)),                dict(type='RandomFlip', prob=0.5),                dict(                    type='Normalize',                    mean=[123.675, 116.28, 103.53],                    std=[58.395, 57.12, 57.375],                    to_rgb=True),                dict(type='Pad', size=(640, 640), pad_val=0, seg_pad_val=255),                dict(type='DefaultFormatBundle'),                dict(type='Collect', keys=['img', 'gt_semantic_seg'])            ])),    val=dict(        type='ZeroWasteDataset',        data_root='data/zerowaste-f/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]),    test=dict(        type='ZeroWasteV2Dataset',        data_root='data/zerowaste-v2-splits/test',        img_dir='data',        ann_dir='sem_seg',        pipeline=[            dict(type='LoadImageFromFile'),            dict(                type='MultiScaleFlipAug',                img_scale=(1138, 640),                flip=False,                transforms=[                    dict(type='Resize', keep_ratio=True),                    dict(type='RandomFlip'),                    dict(                        type='Normalize',                        mean=[123.675, 116.28, 103.53],                        std=[58.395, 57.12, 57.375],                        to_rgb=True),                    dict(type='ImageToTensor', keys=['img']),                    dict(type='Collect', keys=['img'])                ])        ]))uda = dict(    type='SePiCo',    alpha=0.999,    pseudo_threshold=0.968,    pseudo_weight_ignore_top=15,    pseudo_weight_ignore_bottom=120,    imnet_feature_dist_lambda=0,    imnet_feature_dist_classes=None,    imnet_feature_dist_scale_min_ratio=None,    mix='class',    blur=True,    color_jitter_strength=0.2,    color_jitter_probability=0.2,    debug_img_interval=1000,    print_grad_magnitude=False,    enable_self_training=True,    enable_strong_aug=True,    start_distribution_iter=3000)use_ddp_wrapper = Trueoptimizer = dict(    type='AdamW',    lr=6e-05,    betas=(0.9, 0.999),    weight_decay=0.01,    paramwise_cfg=dict(        custom_keys=dict(            head=dict(lr_mult=10.0),            pos_block=dict(decay_mult=0.0),            norm=dict(decay_mult=0.0))))optimizer_config = Nonelr_config = dict(    policy='poly',    warmup='linear',    warmup_iters=1500,    warmup_ratio=1e-06,    power=1.0,    min_lr=0.0,    by_epoch=False)n_gpus = 1seed = 65535runner = dict(type='IterBasedRunner', max_iters=40000)checkpoint_config = dict(by_epoch=False, interval=40000, max_keep_ckpts=1)evaluation = dict(interval=4000, metric='mIoU')exp = 11name_dataset = 'zerov12zerov2'name_architecture = 'daformer_sepaspp_proj_mitb5'name_encoder = 'mitb5'name_decoder = 'daformer_sepaspp_proj'name_uda = 'dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self'name_opt = 'adamw_6e-05_pmTrue_poly10warm_1x2_40k'name = '221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e4'work_dir = 'work_dirs_test/local-exp11/221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e4'git_rev = 'e6a2fe470f8338b6aa4778416c9ec54b3fdf2542'gpu_ids = range(0, 1)2022-10-10 08:51:19,008 - mmseg - INFO - Set random seed to 65535, deterministic: False/mnt/data/bit/xbh/_visda2022/visda2022-ours/mmseg/models/backbones/mix_transformer.py:214: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead  warnings.warn('DeprecationWarning: pretrained is a deprecated, '2022-10-10 08:51:20,509 - mmseg - INFO - Load mit checkpoint.2022-10-10 08:51:20,509 - mmseg - INFO - Use load_from_local loader/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/cnn/utils/weight_init.py:118: UserWarning: init_cfg without layer key, if you do not define override key either, this init_cfg will do nothing  warnings.warn(2022-10-10 08:51:20,829 - mmseg - INFO - Load mit checkpoint.2022-10-10 08:51:20,829 - mmseg - INFO - Use load_from_local loader2022-10-10 08:51:21,077 - mmseg - INFO - SePiCo(  (model): EncoderDecoderProjector(    (backbone): mit_b5(      (patch_embed1): OverlapPatchEmbed(        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)      )      (patch_embed2): OverlapPatchEmbed(        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)      )      (patch_embed3): OverlapPatchEmbed(        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)      )      (patch_embed4): OverlapPatchEmbed(        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)      )      (block1): ModuleList(        (0): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): Identity()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)      (block2): ModuleList(        (0): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)      (block3): ModuleList(        (0): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (6): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (7): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (8): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (9): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (10): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (11): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (12): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (13): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (14): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (15): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (16): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (17): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (18): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (19): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (20): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (21): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (22): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (23): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (24): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (25): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (26): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (27): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (28): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (29): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (30): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (31): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (32): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (33): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (34): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (35): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (36): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (37): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (38): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (39): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)      (block4): ModuleList(        (0): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)    )    (decode_head): DAFormerHead(      input_transform=multiple_select, ignore_index=255, align_corners=False      (loss_decode): CrossEntropyLoss()      (conv_seg): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))      (dropout): Dropout2d(p=0.1, inplace=False)      (embed_layers): ModuleDict(        (0): MLP(          (proj): Linear(in_features=64, out_features=256, bias=True)        )        (1): MLP(          (proj): Linear(in_features=128, out_features=256, bias=True)        )        (2): MLP(          (proj): Linear(in_features=320, out_features=256, bias=True)        )        (3): MLP(          (proj): Linear(in_features=512, out_features=256, bias=True)        )      )      (fuse_layer): ASPPWrapper(        (aspp_modules): DepthwiseSeparableASPPModule(          (0): ConvModule(            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)            (activate): ReLU(inplace=True)          )          (1): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (2): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (3): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )        )        (bottleneck): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}    (auxiliary_head): ProjHead(      input_transform=resize_concat, ignore_index=255, align_corners=False      (loss_decode): ContrastiveLoss()      (dropout): Dropout2d(p=0.1, inplace=False)      (convs): Sequential(        (0): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )        (1): ConvModule(          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )  )  (ema_model): EncoderDecoderProjector(    (backbone): mit_b5(      (patch_embed1): OverlapPatchEmbed(        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)      )      (patch_embed2): OverlapPatchEmbed(        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)      )      (patch_embed3): OverlapPatchEmbed(        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)      )      (patch_embed4): OverlapPatchEmbed(        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)      )      (block1): ModuleList(        (0): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): Identity()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=64, out_features=64, bias=True)            (kv): Linear(in_features=64, out_features=128, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=64, out_features=64, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=64, out_features=256, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)            )            (act): GELU()            (fc2): Linear(in_features=256, out_features=64, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)      (block2): ModuleList(        (0): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=128, out_features=128, bias=True)            (kv): Linear(in_features=128, out_features=256, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=128, out_features=128, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=128, out_features=512, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)            )            (act): GELU()            (fc2): Linear(in_features=512, out_features=128, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)      (block3): ModuleList(        (0): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (3): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (4): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (5): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (6): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (7): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (8): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (9): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (10): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (11): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (12): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (13): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (14): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (15): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (16): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (17): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (18): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (19): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (20): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (21): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (22): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (23): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (24): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (25): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (26): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (27): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (28): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (29): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (30): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (31): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (32): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (33): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (34): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (35): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (36): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (37): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (38): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (39): Block(          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=320, out_features=320, bias=True)            (kv): Linear(in_features=320, out_features=640, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=320, out_features=320, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)          )          (drop_path): DropPath()          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=320, out_features=1280, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)            )            (act): GELU()            (fc2): Linear(in_features=1280, out_features=320, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)      (block4): ModuleList(        (0): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (1): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )        (2): Block(          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (attn): Attention(            (q): Linear(in_features=512, out_features=512, bias=True)            (kv): Linear(in_features=512, out_features=1024, bias=True)            (attn_drop): Dropout(p=0.0, inplace=False)            (proj): Linear(in_features=512, out_features=512, bias=True)            (proj_drop): Dropout(p=0.0, inplace=False)          )          (drop_path): DropPath()          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)          (mlp): Mlp(            (fc1): Linear(in_features=512, out_features=2048, bias=True)            (dwconv): DWConv(              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)            )            (act): GELU()            (fc2): Linear(in_features=2048, out_features=512, bias=True)            (drop): Dropout(p=0.0, inplace=False)          )        )      )      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)    )    (decode_head): DAFormerHead(      input_transform=multiple_select, ignore_index=255, align_corners=False      (loss_decode): CrossEntropyLoss()      (conv_seg): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))      (dropout): Dropout2d(p=0.1, inplace=False)      (embed_layers): ModuleDict(        (0): MLP(          (proj): Linear(in_features=64, out_features=256, bias=True)        )        (1): MLP(          (proj): Linear(in_features=128, out_features=256, bias=True)        )        (2): MLP(          (proj): Linear(in_features=320, out_features=256, bias=True)        )        (3): MLP(          (proj): Linear(in_features=512, out_features=256, bias=True)        )      )      (fuse_layer): ASPPWrapper(        (aspp_modules): DepthwiseSeparableASPPModule(          (0): ConvModule(            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)            (activate): ReLU(inplace=True)          )          (1): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (2): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )          (3): DepthwiseSeparableConvModule(            (depthwise_conv): ConvModule(              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )            (pointwise_conv): ConvModule(              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)              (activate): ReLU(inplace=True)            )          )        )        (bottleneck): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}    (auxiliary_head): ProjHead(      input_transform=resize_concat, ignore_index=255, align_corners=False      (loss_decode): ContrastiveLoss()      (dropout): Dropout2d(p=0.1, inplace=False)      (convs): Sequential(        (0): ConvModule(          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )        (1): ConvModule(          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (activate): ReLU(inplace=True)        )      )    )  ))2022-10-10 08:51:21,162 - mmseg - INFO - Loaded 3002 images from data/zerowaste-f/train/data2022-10-10 08:51:21,256 - mmseg - INFO - Loaded 6216 images from data/zerowaste-v2-splits/train/data2022-10-10 08:51:27,280 - mmseg - INFO - Loaded 929 images from data/zerowaste-f/test/data2022-10-10 08:51:27,280 - mmseg - INFO - Start running, host: root@perception-jupyter, work_dir: /mnt/data/bit/xbh/_visda2022/visda2022-ours/work_dirs_test/local-exp11/221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 08:51:27,281 - mmseg - INFO - workflow: [('train', 1)], max: 40000 itersRun job 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e4/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:52:22,072 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 11:52:39, time: 1.070, data_time: 0.020, memory: 67494, src.decode.loss_seg: 1.5979, src.decode.acc_seg: 24.9336, src.loss: 1.5979, mix.decode.loss_seg: 0.9385, mix.decode.acc_seg: 32.7529, mix.loss: 0.9385/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:53:12,717 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 11:32:39, time: 1.013, data_time: 0.013, memory: 67494, src.decode.loss_seg: 1.4552, src.decode.acc_seg: 63.1996, src.loss: 1.4552, mix.decode.loss_seg: 0.8395, mix.decode.acc_seg: 58.2661, mix.loss: 0.8395/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:54:03,318 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 11:25:15, time: 1.012, data_time: 0.013, memory: 67494, src.decode.loss_seg: 1.2033, src.decode.acc_seg: 78.3746, src.loss: 1.2033, mix.decode.loss_seg: 0.7050, mix.decode.acc_seg: 76.9226, mix.loss: 0.7050/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:54:53,736 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 11:20:30, time: 1.008, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.9356, src.decode.acc_seg: 83.9462, src.loss: 0.9356, mix.decode.loss_seg: 0.5281, mix.decode.acc_seg: 82.7499, mix.loss: 0.5281/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:55:43,669 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 11:16:02, time: 0.999, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.7383, src.decode.acc_seg: 85.7432, src.loss: 0.7383, mix.decode.loss_seg: 0.3359, mix.decode.acc_seg: 84.1621, mix.loss: 0.3359/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:56:34,759 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 11:15:20, time: 1.022, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.6037, src.decode.acc_seg: 85.9018, src.loss: 0.6037, mix.decode.loss_seg: 0.2980, mix.decode.acc_seg: 85.9975, mix.loss: 0.2980/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:57:25,566 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 11:14:04, time: 1.016, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.5408, src.decode.acc_seg: 85.0430, src.loss: 0.5408, mix.decode.loss_seg: 0.2650, mix.decode.acc_seg: 86.4203, mix.loss: 0.2650/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:58:16,520 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 11:13:08, time: 1.019, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.4473, src.decode.acc_seg: 86.9709, src.loss: 0.4473, mix.decode.loss_seg: 0.2358, mix.decode.acc_seg: 88.3001, mix.loss: 0.2358/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:59:07,461 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 11:12:12, time: 1.019, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.4206, src.decode.acc_seg: 87.4780, src.loss: 0.4206, mix.decode.loss_seg: 0.2234, mix.decode.acc_seg: 88.6784, mix.loss: 0.2234/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 08:59:58,247 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 11:11:05, time: 1.016, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.4226, src.decode.acc_seg: 86.1221, src.loss: 0.4226, mix.decode.loss_seg: 0.2182, mix.decode.acc_seg: 87.5318, mix.loss: 0.2182/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:00:49,486 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 11:10:33, time: 1.025, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3779, src.decode.acc_seg: 88.0153, src.loss: 0.3779, mix.decode.loss_seg: 0.1740, mix.decode.acc_seg: 88.9528, mix.loss: 0.1740/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:01:40,479 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 11:09:42, time: 1.020, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3770, src.decode.acc_seg: 87.6733, src.loss: 0.3770, mix.decode.loss_seg: 0.2058, mix.decode.acc_seg: 88.2263, mix.loss: 0.2058/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:02:31,247 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 11:08:38, time: 1.015, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.4087, src.decode.acc_seg: 86.1994, src.loss: 0.4087, mix.decode.loss_seg: 0.2354, mix.decode.acc_seg: 87.9869, mix.loss: 0.2354/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:03:21,953 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 11:07:32, time: 1.014, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3539, src.decode.acc_seg: 87.9995, src.loss: 0.3539, mix.decode.loss_seg: 0.1794, mix.decode.acc_seg: 89.9272, mix.loss: 0.1794/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:04:12,266 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 11:06:07, time: 1.006, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3784, src.decode.acc_seg: 87.2276, src.loss: 0.3784, mix.decode.loss_seg: 0.1851, mix.decode.acc_seg: 88.8563, mix.loss: 0.1851/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:05:03,134 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 11:05:14, time: 1.017, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3469, src.decode.acc_seg: 87.8389, src.loss: 0.3469, mix.decode.loss_seg: 0.1498, mix.decode.acc_seg: 89.1855, mix.loss: 0.1498/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:05:53,891 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 11:04:16, time: 1.015, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3020, src.decode.acc_seg: 89.7195, src.loss: 0.3020, mix.decode.loss_seg: 0.1435, mix.decode.acc_seg: 90.0833, mix.loss: 0.1435/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:06:44,535 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 11:03:14, time: 1.013, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3572, src.decode.acc_seg: 86.6644, src.loss: 0.3572, mix.decode.loss_seg: 0.1962, mix.decode.acc_seg: 88.8080, mix.loss: 0.1962/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:07:35,078 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 11:02:08, time: 1.011, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3458, src.decode.acc_seg: 87.1553, src.loss: 0.3458, mix.decode.loss_seg: 0.1784, mix.decode.acc_seg: 88.7935, mix.loss: 0.1784/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:08:26,085 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 09:08:26,085 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 11:01:23, time: 1.020, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3077, src.decode.acc_seg: 89.2133, src.loss: 0.3077, mix.decode.loss_seg: 0.1670, mix.decode.acc_seg: 91.0935, mix.loss: 0.1670/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:09:16,852 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 11:00:28, time: 1.015, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3005, src.decode.acc_seg: 89.8121, src.loss: 0.3005, mix.decode.loss_seg: 0.1709, mix.decode.acc_seg: 90.9909, mix.loss: 0.1709/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:10:07,168 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 10:59:18, time: 1.006, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3205, src.decode.acc_seg: 88.2057, src.loss: 0.3205, mix.decode.loss_seg: 0.1735, mix.decode.acc_seg: 88.5779, mix.loss: 0.1735/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:10:57,538 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 10:58:11, time: 1.007, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3308, src.decode.acc_seg: 88.6442, src.loss: 0.3308, mix.decode.loss_seg: 0.1825, mix.decode.acc_seg: 90.8712, mix.loss: 0.1825/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:11:48,239 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 10:57:16, time: 1.014, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3651, src.decode.acc_seg: 86.8252, src.loss: 0.3651, mix.decode.loss_seg: 0.1924, mix.decode.acc_seg: 89.5691, mix.loss: 0.1924/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:12:38,093 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 10:55:55, time: 0.997, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3139, src.decode.acc_seg: 88.7373, src.loss: 0.3139, mix.decode.loss_seg: 0.1489, mix.decode.acc_seg: 90.8008, mix.loss: 0.1489/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:13:28,829 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 10:55:03, time: 1.015, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3049, src.decode.acc_seg: 88.4736, src.loss: 0.3049, mix.decode.loss_seg: 0.1622, mix.decode.acc_seg: 89.7517, mix.loss: 0.1622/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:14:19,662 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 10:54:14, time: 1.017, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2561, src.decode.acc_seg: 90.8870, src.loss: 0.2561, mix.decode.loss_seg: 0.1262, mix.decode.acc_seg: 93.1613, mix.loss: 0.1262/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:15:09,829 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 10:53:06, time: 1.003, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.2561, src.decode.acc_seg: 90.8514, src.loss: 0.2561, mix.decode.loss_seg: 0.1422, mix.decode.acc_seg: 92.0220, mix.loss: 0.1422/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:16:00,755 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 10:52:20, time: 1.018, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3062, src.decode.acc_seg: 89.1707, src.loss: 0.3062, mix.decode.loss_seg: 0.1694, mix.decode.acc_seg: 91.4105, mix.loss: 0.1694/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:16:51,305 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 10:51:23, time: 1.011, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2974, src.decode.acc_seg: 89.0427, src.loss: 0.2974, mix.decode.loss_seg: 0.1543, mix.decode.acc_seg: 92.2201, mix.loss: 0.1543/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:17:41,500 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 10:50:19, time: 1.004, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.2750, src.decode.acc_seg: 90.3376, src.loss: 0.2750, mix.decode.loss_seg: 0.1585, mix.decode.acc_seg: 92.0248, mix.loss: 0.1585/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:18:31,841 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 10:49:18, time: 1.007, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.3361, src.decode.acc_seg: 87.8913, src.loss: 0.3361, mix.decode.loss_seg: 0.1923, mix.decode.acc_seg: 91.1396, mix.loss: 0.1923/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:19:22,429 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 10:48:24, time: 1.012, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3305, src.decode.acc_seg: 87.9351, src.loss: 0.3305, mix.decode.loss_seg: 0.1821, mix.decode.acc_seg: 90.4388, mix.loss: 0.1821/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:20:12,971 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 10:47:29, time: 1.011, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2826, src.decode.acc_seg: 89.7636, src.loss: 0.2826, mix.decode.loss_seg: 0.1401, mix.decode.acc_seg: 92.3538, mix.loss: 0.1401/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:21:03,867 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 10:46:43, time: 1.018, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3037, src.decode.acc_seg: 90.1422, src.loss: 0.3037, mix.decode.loss_seg: 0.1604, mix.decode.acc_seg: 92.5519, mix.loss: 0.1604/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:21:54,700 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 10:45:54, time: 1.017, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2776, src.decode.acc_seg: 90.2491, src.loss: 0.2776, mix.decode.loss_seg: 0.1479, mix.decode.acc_seg: 93.0265, mix.loss: 0.1479/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:22:45,868 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 10:45:13, time: 1.023, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2670, src.decode.acc_seg: 90.2957, src.loss: 0.2670, mix.decode.loss_seg: 0.1608, mix.decode.acc_seg: 92.2360, mix.loss: 0.1608/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:23:36,976 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 10:44:29, time: 1.022, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2530, src.decode.acc_seg: 91.0468, src.loss: 0.2530, mix.decode.loss_seg: 0.1363, mix.decode.acc_seg: 93.3764, mix.loss: 0.1363/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:24:28,216 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 10:43:48, time: 1.025, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.3261, src.decode.acc_seg: 88.9347, src.loss: 0.3261, mix.decode.loss_seg: 0.1753, mix.decode.acc_seg: 91.7382, mix.loss: 0.1753/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:25:19,024 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 09:25:19,024 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 10:42:58, time: 1.016, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2778, src.decode.acc_seg: 90.1407, src.loss: 0.2778, mix.decode.loss_seg: 0.1585, mix.decode.acc_seg: 91.9294, mix.loss: 0.1585/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:26:10,184 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 10:42:15, time: 1.023, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2476, src.decode.acc_seg: 91.3020, src.loss: 0.2476, mix.decode.loss_seg: 0.1312, mix.decode.acc_seg: 93.1417, mix.loss: 0.1312/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:27:00,542 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 10:41:17, time: 1.007, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2648, src.decode.acc_seg: 90.4761, src.loss: 0.2648, mix.decode.loss_seg: 0.1522, mix.decode.acc_seg: 92.5707, mix.loss: 0.1522/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:27:51,654 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 10:40:32, time: 1.022, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2567, src.decode.acc_seg: 91.0364, src.loss: 0.2567, mix.decode.loss_seg: 0.1500, mix.decode.acc_seg: 93.2675, mix.loss: 0.1500/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:28:42,621 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 10:39:45, time: 1.019, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2621, src.decode.acc_seg: 90.8852, src.loss: 0.2621, mix.decode.loss_seg: 0.1581, mix.decode.acc_seg: 92.2414, mix.loss: 0.1581/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:29:33,184 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 10:38:50, time: 1.011, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2674, src.decode.acc_seg: 90.2883, src.loss: 0.2674, mix.decode.loss_seg: 0.1513, mix.decode.acc_seg: 93.0202, mix.loss: 0.1513/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:30:23,878 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 10:37:58, time: 1.014, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.2531, src.decode.acc_seg: 90.9229, src.loss: 0.2531, mix.decode.loss_seg: 0.1451, mix.decode.acc_seg: 93.1626, mix.loss: 0.1451/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:31:14,908 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 10:37:12, time: 1.021, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2739, src.decode.acc_seg: 90.0283, src.loss: 0.2739, mix.decode.loss_seg: 0.1538, mix.decode.acc_seg: 92.3995, mix.loss: 0.1538/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:32:05,252 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 10:36:14, time: 1.007, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.2579, src.decode.acc_seg: 91.1196, src.loss: 0.2579, mix.decode.loss_seg: 0.1408, mix.decode.acc_seg: 93.0979, mix.loss: 0.1408/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:32:56,205 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 10:35:26, time: 1.019, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2600, src.decode.acc_seg: 90.9036, src.loss: 0.2600, mix.decode.loss_seg: 0.1496, mix.decode.acc_seg: 93.3502, mix.loss: 0.1496/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:33:46,688 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 10:34:31, time: 1.010, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2835, src.decode.acc_seg: 90.2045, src.loss: 0.2835, mix.decode.loss_seg: 0.1470, mix.decode.acc_seg: 93.1168, mix.loss: 0.1470/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:34:37,595 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 10:33:43, time: 1.018, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2592, src.decode.acc_seg: 90.4491, src.loss: 0.2592, mix.decode.loss_seg: 0.1386, mix.decode.acc_seg: 93.7697, mix.loss: 0.1386/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:35:28,560 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 10:32:55, time: 1.019, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2438, src.decode.acc_seg: 91.9340, src.loss: 0.2438, mix.decode.loss_seg: 0.1244, mix.decode.acc_seg: 94.3975, mix.loss: 0.1244/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:36:19,238 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 10:32:03, time: 1.014, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2595, src.decode.acc_seg: 90.7960, src.loss: 0.2595, mix.decode.loss_seg: 0.1539, mix.decode.acc_seg: 93.0669, mix.loss: 0.1539/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:37:09,652 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 10:31:07, time: 1.008, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2618, src.decode.acc_seg: 90.7514, src.loss: 0.2618, mix.decode.loss_seg: 0.1420, mix.decode.acc_seg: 93.5377, mix.loss: 0.1420/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:38:00,178 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 10:30:13, time: 1.011, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2568, src.decode.acc_seg: 90.6408, src.loss: 0.2568, mix.decode.loss_seg: 0.1640, mix.decode.acc_seg: 92.9246, mix.loss: 0.1640/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:38:50,716 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 10:29:20, time: 1.011, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.2444, src.decode.acc_seg: 91.1024, src.loss: 0.2444, mix.decode.loss_seg: 0.1209, mix.decode.acc_seg: 94.4609, mix.loss: 0.1209/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:39:41,156 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 10:28:25, time: 1.009, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2139, src.decode.acc_seg: 92.2463, src.loss: 0.2139, mix.decode.loss_seg: 0.1277, mix.decode.acc_seg: 94.3283, mix.loss: 0.1277/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:40:32,080 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 10:27:36, time: 1.018, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2453, src.decode.acc_seg: 91.8478, src.loss: 0.2453, mix.decode.loss_seg: 0.1108, mix.decode.acc_seg: 95.0430, mix.loss: 0.1108/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:41:22,837 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 10:26:46, time: 1.015, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2720, src.decode.acc_seg: 89.9242, src.loss: 0.2720, mix.decode.loss_seg: 0.1590, mix.decode.acc_seg: 92.7027, mix.loss: 0.1590/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:42:12,569 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 09:42:12,569 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 10:25:42, time: 0.995, data_time: 0.012, memory: 67494, src.decode.loss_seg: 0.2506, src.decode.acc_seg: 91.0066, src.loss: 0.2506, mix.decode.loss_seg: 0.1474, mix.decode.acc_seg: 93.5608, mix.loss: 0.1474/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:43:15,550 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 10:27:20, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.2628, src.decode.acc_seg: 90.7005, src.loss: 0.2789, mix.decode.loss_seg: 0.1480, mix.decode.acc_seg: 93.9478, mix.loss: 0.1480, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:44:18,279 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 10:28:49, time: 1.255, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2412, src.decode.acc_seg: 91.7495, src.loss: 0.2572, mix.decode.loss_seg: 0.1505, mix.decode.acc_seg: 93.2316, mix.loss: 0.1505, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:45:21,327 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 10:30:18, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2279, src.decode.acc_seg: 91.8241, src.loss: 0.2440, mix.decode.loss_seg: 0.1401, mix.decode.acc_seg: 93.8100, mix.loss: 0.1401, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:46:24,432 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 10:31:42, time: 1.262, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2323, src.decode.acc_seg: 91.9493, src.loss: 0.2484, mix.decode.loss_seg: 0.1322, mix.decode.acc_seg: 94.3951, mix.loss: 0.1322, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:47:27,995 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 10:33:07, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1783, src.decode.acc_seg: 93.6540, src.loss: 0.1944, mix.decode.loss_seg: 0.1147, mix.decode.acc_seg: 94.7603, mix.loss: 0.1147, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:48:30,504 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 10:34:16, time: 1.250, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2041, src.decode.acc_seg: 92.5245, src.loss: 0.2202, mix.decode.loss_seg: 0.1101, mix.decode.acc_seg: 94.9209, mix.loss: 0.1101, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:49:33,526 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 10:35:26, time: 1.260, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2419, src.decode.acc_seg: 90.9933, src.loss: 0.2580, mix.decode.loss_seg: 0.1314, mix.decode.acc_seg: 94.2938, mix.loss: 0.1314, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:50:36,128 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 10:36:28, time: 1.252, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2372, src.decode.acc_seg: 91.7315, src.loss: 0.2533, mix.decode.loss_seg: 0.1328, mix.decode.acc_seg: 94.3822, mix.loss: 0.1328, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:51:39,048 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 10:37:30, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2274, src.decode.acc_seg: 91.8281, src.loss: 0.2434, mix.decode.loss_seg: 0.1177, mix.decode.acc_seg: 94.8023, mix.loss: 0.1177, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:52:42,323 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 10:38:32, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.2202, src.decode.acc_seg: 92.2723, src.loss: 0.2362, mix.decode.loss_seg: 0.1211, mix.decode.acc_seg: 95.0038, mix.loss: 0.1211, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:53:45,609 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 10:39:30, time: 1.266, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2168, src.decode.acc_seg: 92.1714, src.loss: 0.2329, mix.decode.loss_seg: 0.1312, mix.decode.acc_seg: 94.0067, mix.loss: 0.1312, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:54:48,730 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 10:40:23, time: 1.262, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2900, src.decode.acc_seg: 89.6254, src.loss: 0.3061, mix.decode.loss_seg: 0.1636, mix.decode.acc_seg: 93.5884, mix.loss: 0.1636, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:55:51,668 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 10:41:12, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1891, src.decode.acc_seg: 93.4767, src.loss: 0.2052, mix.decode.loss_seg: 0.1127, mix.decode.acc_seg: 94.9936, mix.loss: 0.1127, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:56:54,464 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 10:41:56, time: 1.256, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2037, src.decode.acc_seg: 92.1004, src.loss: 0.2198, mix.decode.loss_seg: 0.1086, mix.decode.acc_seg: 94.8825, mix.loss: 0.1086, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:57:57,340 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 10:42:38, time: 1.258, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.2064, src.decode.acc_seg: 92.3246, src.loss: 0.2225, mix.decode.loss_seg: 0.1071, mix.decode.acc_seg: 95.0493, mix.loss: 0.1071, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 09:59:00,372 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 10:43:18, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1812, src.decode.acc_seg: 93.5330, src.loss: 0.1972, mix.decode.loss_seg: 0.1097, mix.decode.acc_seg: 95.4628, mix.loss: 0.1097, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:00:03,744 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 10:43:59, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.2393, src.decode.acc_seg: 91.5404, src.loss: 0.2553, mix.decode.loss_seg: 0.1484, mix.decode.acc_seg: 94.2785, mix.loss: 0.1484, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:01:07,041 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 10:44:37, time: 1.266, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2180, src.decode.acc_seg: 92.1448, src.loss: 0.2341, mix.decode.loss_seg: 0.1233, mix.decode.acc_seg: 94.9803, mix.loss: 0.1233, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:02:10,648 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 10:45:15, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.2288, src.decode.acc_seg: 91.9816, src.loss: 0.2449, mix.decode.loss_seg: 0.1362, mix.decode.acc_seg: 94.3674, mix.loss: 0.1362, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 1.1 task/s, elapsed: 1s, ETA:   819s[                                 ] 2/929, 2.0 task/s, elapsed: 1s, ETA:   462s[                                 ] 3/929, 2.7 task/s, elapsed: 1s, ETA:   345s[                                 ] 4/929, 3.2 task/s, elapsed: 1s, ETA:   286s[                                 ] 5/929, 3.6 task/s, elapsed: 1s, ETA:   253s[                                 ] 6/929, 4.0 task/s, elapsed: 2s, ETA:   232s[                                 ] 7/929, 4.3 task/s, elapsed: 2s, ETA:   214s[                                 ] 8/929, 4.6 task/s, elapsed: 2s, ETA:   202s[                                 ] 9/929, 4.8 task/s, elapsed: 2s, ETA:   191s[                                ] 10/929, 5.0 task/s, elapsed: 2s, ETA:   183s[                                ] 11/929, 5.2 task/s, elapsed: 2s, ETA:   177s[                                ] 12/929, 5.3 task/s, elapsed: 2s, ETA:   172s[                                ] 13/929, 5.5 task/s, elapsed: 2s, ETA:   168s[                                ] 14/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 15/929, 5.7 task/s, elapsed: 3s, ETA:   161s[                                ] 16/929, 5.8 task/s, elapsed: 3s, ETA:   158s[                                ] 17/929, 5.8 task/s, elapsed: 3s, ETA:   156s[                                ] 18/929, 6.0 task/s, elapsed: 3s, ETA:   153s[                                ] 19/929, 6.0 task/s, elapsed: 3s, ETA:   150s[                                ] 20/929, 6.1 task/s, elapsed: 3s, ETA:   149s[                                ] 21/929, 6.1 task/s, elapsed: 3s, ETA:   148s[                                ] 22/929, 6.2 task/s, elapsed: 4s, ETA:   146s[                                ] 23/929, 6.3 task/s, elapsed: 4s, ETA:   144s[                                ] 24/929, 6.3 task/s, elapsed: 4s, ETA:   143s[                                ] 25/929, 6.4 task/s, elapsed: 4s, ETA:   141s[                                ] 26/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 27/929, 6.5 task/s, elapsed: 4s, ETA:   138s[                                ] 28/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 29/929, 6.6 task/s, elapsed: 4s, ETA:   136s[>                               ] 30/929, 6.7 task/s, elapsed: 5s, ETA:   135s[>                               ] 31/929, 6.7 task/s, elapsed: 5s, ETA:   134s[>                               ] 32/929, 6.7 task/s, elapsed: 5s, ETA:   134s[>                               ] 33/929, 6.7 task/s, elapsed: 5s, ETA:   133s[>                               ] 34/929, 6.8 task/s, elapsed: 5s, ETA:   132s[>                               ] 35/929, 6.8 task/s, elapsed: 5s, ETA:   131s[>                               ] 36/929, 6.8 task/s, elapsed: 5s, ETA:   131s[>                               ] 37/929, 6.9 task/s, elapsed: 5s, ETA:   130s[>                               ] 38/929, 6.9 task/s, elapsed: 6s, ETA:   129s[>                               ] 39/929, 6.9 task/s, elapsed: 6s, ETA:   129s[>                               ] 40/929, 6.9 task/s, elapsed: 6s, ETA:   128s[>                               ] 41/929, 7.0 task/s, elapsed: 6s, ETA:   128s[>                               ] 42/929, 7.0 task/s, elapsed: 6s, ETA:   127s[>                               ] 43/929, 7.0 task/s, elapsed: 6s, ETA:   126s[>                               ] 44/929, 7.0 task/s, elapsed: 6s, ETA:   126s[>                               ] 45/929, 7.0 task/s, elapsed: 6s, ETA:   126s[>                               ] 46/929, 7.1 task/s, elapsed: 7s, ETA:   125s[>                               ] 47/929, 7.0 task/s, elapsed: 7s, ETA:   125s[>                               ] 48/929, 7.1 task/s, elapsed: 7s, ETA:   125s[>                               ] 49/929, 7.1 task/s, elapsed: 7s, ETA:   124s[>                               ] 50/929, 7.1 task/s, elapsed: 7s, ETA:   124s[>                               ] 51/929, 7.1 task/s, elapsed: 7s, ETA:   124s[>                               ] 52/929, 7.1 task/s, elapsed: 7s, ETA:   123s[>                               ] 53/929, 7.1 task/s, elapsed: 7s, ETA:   123s[>                               ] 54/929, 7.1 task/s, elapsed: 8s, ETA:   122s[>                               ] 55/929, 7.2 task/s, elapsed: 8s, ETA:   122s[>                               ] 56/929, 7.2 task/s, elapsed: 8s, ETA:   122s[>                               ] 57/929, 7.2 task/s, elapsed: 8s, ETA:   121s[>                               ] 58/929, 7.2 task/s, elapsed: 8s, ETA:   121s[>>                              ] 59/929, 7.2 task/s, elapsed: 8s, ETA:   120s[>>                              ] 60/929, 7.2 task/s, elapsed: 8s, ETA:   120s[>>                              ] 61/929, 7.3 task/s, elapsed: 8s, ETA:   120s[>>                              ] 62/929, 7.3 task/s, elapsed: 9s, ETA:   119s[>>                              ] 63/929, 7.3 task/s, elapsed: 9s, ETA:   119s[>>                              ] 64/929, 7.3 task/s, elapsed: 9s, ETA:   119s[>>                              ] 65/929, 7.3 task/s, elapsed: 9s, ETA:   118s[>>                              ] 66/929, 7.3 task/s, elapsed: 9s, ETA:   118s[>>                              ] 67/929, 7.3 task/s, elapsed: 9s, ETA:   118s[>>                              ] 68/929, 7.4 task/s, elapsed: 9s, ETA:   117s[>>                              ] 69/929, 7.4 task/s, elapsed: 9s, ETA:   117s[>>                             ] 70/929, 7.4 task/s, elapsed: 10s, ETA:   117s[>>                             ] 71/929, 7.4 task/s, elapsed: 10s, ETA:   116s[>>                             ] 72/929, 7.4 task/s, elapsed: 10s, ETA:   116s[>>                             ] 73/929, 7.4 task/s, elapsed: 10s, ETA:   116s[>>                             ] 74/929, 7.4 task/s, elapsed: 10s, ETA:   116s[>>                             ] 75/929, 7.4 task/s, elapsed: 10s, ETA:   115s[>>                             ] 76/929, 7.4 task/s, elapsed: 10s, ETA:   115s[>>                             ] 77/929, 7.4 task/s, elapsed: 10s, ETA:   115s[>>                             ] 78/929, 7.4 task/s, elapsed: 11s, ETA:   115s[>>                             ] 79/929, 7.4 task/s, elapsed: 11s, ETA:   114s[>>                             ] 80/929, 7.4 task/s, elapsed: 11s, ETA:   114s[>>                             ] 81/929, 7.5 task/s, elapsed: 11s, ETA:   114s[>>                             ] 82/929, 7.5 task/s, elapsed: 11s, ETA:   113s[>>                             ] 83/929, 7.5 task/s, elapsed: 11s, ETA:   113s[>>                             ] 84/929, 7.5 task/s, elapsed: 11s, ETA:   113s[>>                             ] 85/929, 7.5 task/s, elapsed: 11s, ETA:   113s[>>                             ] 86/929, 7.5 task/s, elapsed: 11s, ETA:   112s[>>                             ] 87/929, 7.5 task/s, elapsed: 12s, ETA:   112s[>>                             ] 88/929, 7.5 task/s, elapsed: 12s, ETA:   112s[>>                             ] 89/929, 7.5 task/s, elapsed: 12s, ETA:   112s[>>>                            ] 90/929, 7.5 task/s, elapsed: 12s, ETA:   111s[>>>                            ] 91/929, 7.5 task/s, elapsed: 12s, ETA:   111s[>>>                            ] 92/929, 7.5 task/s, elapsed: 12s, ETA:   111s[>>>                            ] 93/929, 7.6 task/s, elapsed: 12s, ETA:   111s[>>>                            ] 94/929, 7.6 task/s, elapsed: 12s, ETA:   110s[>>>                            ] 95/929, 7.6 task/s, elapsed: 13s, ETA:   110s[>>>                            ] 96/929, 7.6 task/s, elapsed: 13s, ETA:   110s[>>>                            ] 97/929, 7.6 task/s, elapsed: 13s, ETA:   110s[>>>                            ] 98/929, 7.6 task/s, elapsed: 13s, ETA:   109s[>>>                            ] 99/929, 7.6 task/s, elapsed: 13s, ETA:   109s[>>>                           ] 100/929, 7.6 task/s, elapsed: 13s, ETA:   109s[>>>                           ] 101/929, 7.6 task/s, elapsed: 13s, ETA:   109s[>>>                           ] 102/929, 7.6 task/s, elapsed: 13s, ETA:   109s[>>>                           ] 103/929, 7.6 task/s, elapsed: 14s, ETA:   109s[>>>                           ] 104/929, 7.6 task/s, elapsed: 14s, ETA:   108s[>>>                           ] 105/929, 7.6 task/s, elapsed: 14s, ETA:   108s[>>>                           ] 106/929, 7.6 task/s, elapsed: 14s, ETA:   108s[>>>                           ] 107/929, 7.6 task/s, elapsed: 14s, ETA:   108s[>>>                           ] 108/929, 7.6 task/s, elapsed: 14s, ETA:   108s[>>>                           ] 109/929, 7.6 task/s, elapsed: 14s, ETA:   107s[>>>                           ] 110/929, 7.6 task/s, elapsed: 14s, ETA:   107s[>>>                           ] 111/929, 7.6 task/s, elapsed: 15s, ETA:   107s[>>>                           ] 112/929, 7.6 task/s, elapsed: 15s, ETA:   107s[>>>                           ] 113/929, 7.6 task/s, elapsed: 15s, ETA:   107s[>>>                           ] 114/929, 7.7 task/s, elapsed: 15s, ETA:   106s[>>>                           ] 115/929, 7.7 task/s, elapsed: 15s, ETA:   106s[>>>                           ] 116/929, 7.7 task/s, elapsed: 15s, ETA:   106s[>>>                           ] 117/929, 7.7 task/s, elapsed: 15s, ETA:   106s[>>>                           ] 118/929, 7.7 task/s, elapsed: 15s, ETA:   106s[>>>                           ] 119/929, 7.7 task/s, elapsed: 15s, ETA:   105s[>>>                           ] 120/929, 7.7 task/s, elapsed: 16s, ETA:   105s[>>>                           ] 121/929, 7.7 task/s, elapsed: 16s, ETA:   105s[>>>                           ] 122/929, 7.7 task/s, elapsed: 16s, ETA:   105s[>>>                           ] 123/929, 7.7 task/s, elapsed: 16s, ETA:   105s[>>>>                          ] 124/929, 7.7 task/s, elapsed: 16s, ETA:   104s[>>>>                          ] 125/929, 7.7 task/s, elapsed: 16s, ETA:   104s[>>>>                          ] 126/929, 7.7 task/s, elapsed: 16s, ETA:   104s[>>>>                          ] 127/929, 7.7 task/s, elapsed: 16s, ETA:   104s[>>>>                          ] 128/929, 7.7 task/s, elapsed: 17s, ETA:   104s[>>>>                          ] 129/929, 7.7 task/s, elapsed: 17s, ETA:   103s[>>>>                          ] 130/929, 7.7 task/s, elapsed: 17s, ETA:   103s[>>>>                          ] 131/929, 7.7 task/s, elapsed: 17s, ETA:   103s[>>>>                          ] 132/929, 7.7 task/s, elapsed: 17s, ETA:   103s[>>>>                          ] 133/929, 7.7 task/s, elapsed: 17s, ETA:   103s[>>>>                          ] 134/929, 7.7 task/s, elapsed: 17s, ETA:   103s[>>>>                          ] 135/929, 7.8 task/s, elapsed: 17s, ETA:   102s[>>>>                          ] 136/929, 7.8 task/s, elapsed: 18s, ETA:   102s[>>>>                          ] 137/929, 7.8 task/s, elapsed: 18s, ETA:   102s[>>>>                          ] 138/929, 7.8 task/s, elapsed: 18s, ETA:   102s[>>>>                          ] 139/929, 7.8 task/s, elapsed: 18s, ETA:   102s[>>>>                          ] 140/929, 7.8 task/s, elapsed: 18s, ETA:   102s[>>>>                          ] 141/929, 7.8 task/s, elapsed: 18s, ETA:   101s[>>>>                          ] 142/929, 7.8 task/s, elapsed: 18s, ETA:   101s[>>>>                          ] 143/929, 7.8 task/s, elapsed: 18s, ETA:   101s[>>>>                          ] 144/929, 7.8 task/s, elapsed: 19s, ETA:   101s[>>>>                          ] 145/929, 7.8 task/s, elapsed: 19s, ETA:   101s[>>>>                          ] 146/929, 7.8 task/s, elapsed: 19s, ETA:   101s[>>>>                          ] 147/929, 7.8 task/s, elapsed: 19s, ETA:   100s[>>>>                          ] 148/929, 7.8 task/s, elapsed: 19s, ETA:   100s[>>>>                          ] 149/929, 7.8 task/s, elapsed: 19s, ETA:   100s[>>>>                          ] 150/929, 7.8 task/s, elapsed: 19s, ETA:   100s[>>>>                          ] 151/929, 7.8 task/s, elapsed: 19s, ETA:   100s[>>>>                          ] 152/929, 7.8 task/s, elapsed: 19s, ETA:   100s[>>>>                          ] 153/929, 7.8 task/s, elapsed: 20s, ETA:    99s[>>>>                          ] 154/929, 7.8 task/s, elapsed: 20s, ETA:    99s[>>>>>                         ] 155/929, 7.8 task/s, elapsed: 20s, ETA:    99s[>>>>>                         ] 156/929, 7.8 task/s, elapsed: 20s, ETA:    99s[>>>>>                         ] 157/929, 7.8 task/s, elapsed: 20s, ETA:    99s[>>>>>                         ] 158/929, 7.8 task/s, elapsed: 20s, ETA:    99s[>>>>>                         ] 159/929, 7.8 task/s, elapsed: 20s, ETA:    98s[>>>>>                         ] 160/929, 7.8 task/s, elapsed: 20s, ETA:    98s[>>>>>                         ] 161/929, 7.8 task/s, elapsed: 21s, ETA:    98s[>>>>>                         ] 162/929, 7.8 task/s, elapsed: 21s, ETA:    98s[>>>>>                         ] 163/929, 7.8 task/s, elapsed: 21s, ETA:    98s[>>>>>                         ] 164/929, 7.8 task/s, elapsed: 21s, ETA:    98s[>>>>>                         ] 165/929, 7.8 task/s, elapsed: 21s, ETA:    98s[>>>>>                         ] 166/929, 7.8 task/s, elapsed: 21s, ETA:    98s[>>>>>                         ] 167/929, 7.8 task/s, elapsed: 21s, ETA:    98s[>>>>>                         ] 168/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 169/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 170/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 171/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 172/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 173/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 174/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 175/929, 7.8 task/s, elapsed: 22s, ETA:    97s[>>>>>                         ] 176/929, 7.8 task/s, elapsed: 23s, ETA:    96s[>>>>>                         ] 177/929, 7.8 task/s, elapsed: 23s, ETA:    96s[>>>>>                         ] 178/929, 7.8 task/s, elapsed: 23s, ETA:    96s[>>>>>                         ] 179/929, 7.8 task/s, elapsed: 23s, ETA:    96s[>>>>>                         ] 180/929, 7.8 task/s, elapsed: 23s, ETA:    96s[>>>>>                         ] 181/929, 7.8 task/s, elapsed: 23s, ETA:    96s[>>>>>                         ] 182/929, 7.8 task/s, elapsed: 23s, ETA:    95s[>>>>>                         ] 183/929, 7.8 task/s, elapsed: 23s, ETA:    95s[>>>>>                         ] 184/929, 7.8 task/s, elapsed: 23s, ETA:    95s[>>>>>                         ] 185/929, 7.8 task/s, elapsed: 24s, ETA:    95s[>>>>>>                        ] 186/929, 7.8 task/s, elapsed: 24s, ETA:    95s[>>>>>>                        ] 187/929, 7.8 task/s, elapsed: 24s, ETA:    95s[>>>>>>                        ] 188/929, 7.8 task/s, elapsed: 24s, ETA:    95s[>>>>>>                        ] 189/929, 7.8 task/s, elapsed: 24s, ETA:    94s[>>>>>>                        ] 190/929, 7.8 task/s, elapsed: 24s, ETA:    94s[>>>>>>                        ] 191/929, 7.8 task/s, elapsed: 24s, ETA:    94s[>>>>>>                        ] 192/929, 7.8 task/s, elapsed: 25s, ETA:    94s[>>>>>>                        ] 193/929, 7.8 task/s, elapsed: 25s, ETA:    94s[>>>>>>                        ] 194/929, 7.8 task/s, elapsed: 25s, ETA:    94s[>>>>>>                        ] 195/929, 7.8 task/s, elapsed: 25s, ETA:    94s[>>>>>>                        ] 196/929, 7.8 task/s, elapsed: 25s, ETA:    94s[>>>>>>                        ] 197/929, 7.8 task/s, elapsed: 25s, ETA:    94s[>>>>>>                        ] 198/929, 7.8 task/s, elapsed: 25s, ETA:    94s[>>>>>>                        ] 199/929, 7.8 task/s, elapsed: 25s, ETA:    93s[>>>>>>                        ] 200/929, 7.8 task/s, elapsed: 26s, ETA:    93s[>>>>>>                        ] 201/929, 7.8 task/s, elapsed: 26s, ETA:    93s[>>>>>>                        ] 202/929, 7.8 task/s, elapsed: 26s, ETA:    93s[>>>>>>                        ] 203/929, 7.8 task/s, elapsed: 26s, ETA:    93s[>>>>>>                        ] 204/929, 7.8 task/s, elapsed: 26s, ETA:    93s[>>>>>>                        ] 205/929, 7.8 task/s, elapsed: 26s, ETA:    93s[>>>>>>                        ] 206/929, 7.8 task/s, elapsed: 26s, ETA:    92s[>>>>>>                        ] 207/929, 7.8 task/s, elapsed: 26s, ETA:    92s[>>>>>>                        ] 208/929, 7.8 task/s, elapsed: 27s, ETA:    92s[>>>>>>                        ] 209/929, 7.8 task/s, elapsed: 27s, ETA:    92s[>>>>>>                        ] 210/929, 7.8 task/s, elapsed: 27s, ETA:    92s[>>>>>>                        ] 211/929, 7.8 task/s, elapsed: 27s, ETA:    92s[>>>>>>                        ] 212/929, 7.8 task/s, elapsed: 27s, ETA:    92s[>>>>>>                        ] 213/929, 7.8 task/s, elapsed: 27s, ETA:    91s[>>>>>>                        ] 214/929, 7.8 task/s, elapsed: 27s, ETA:    91s[>>>>>>                        ] 215/929, 7.8 task/s, elapsed: 27s, ETA:    91s[>>>>>>                        ] 216/929, 7.8 task/s, elapsed: 28s, ETA:    91s[>>>>>>>                       ] 217/929, 7.8 task/s, elapsed: 28s, ETA:    91s[>>>>>>>                       ] 218/929, 7.8 task/s, elapsed: 28s, ETA:    91s[>>>>>>>                       ] 219/929, 7.8 task/s, elapsed: 28s, ETA:    91s[>>>>>>>                       ] 220/929, 7.8 task/s, elapsed: 28s, ETA:    91s[>>>>>>>                       ] 221/929, 7.8 task/s, elapsed: 28s, ETA:    90s[>>>>>>>                       ] 222/929, 7.8 task/s, elapsed: 28s, ETA:    90s[>>>>>>>                       ] 223/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 224/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 225/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 226/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 227/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 228/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 229/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 230/929, 7.8 task/s, elapsed: 29s, ETA:    90s[>>>>>>>                       ] 231/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 232/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 233/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 234/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 235/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 236/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 237/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 238/929, 7.8 task/s, elapsed: 30s, ETA:    89s[>>>>>>>                       ] 239/929, 7.8 task/s, elapsed: 31s, ETA:    88s[>>>>>>>                       ] 240/929, 7.8 task/s, elapsed: 31s, ETA:    88s[>>>>>>>                       ] 241/929, 7.8 task/s, elapsed: 31s, ETA:    88s[>>>>>>>                       ] 242/929, 7.8 task/s, elapsed: 31s, ETA:    88s[>>>>>>>                       ] 243/929, 7.8 task/s, elapsed: 31s, ETA:    88s[>>>>>>>                       ] 244/929, 7.8 task/s, elapsed: 31s, ETA:    88s[>>>>>>>                       ] 245/929, 7.8 task/s, elapsed: 31s, ETA:    88s[>>>>>>>                       ] 246/929, 7.8 task/s, elapsed: 32s, ETA:    88s[>>>>>>>                       ] 247/929, 7.8 task/s, elapsed: 32s, ETA:    88s[>>>>>>>>                      ] 248/929, 7.8 task/s, elapsed: 32s, ETA:    88s[>>>>>>>>                      ] 249/929, 7.8 task/s, elapsed: 32s, ETA:    87s[>>>>>>>>                      ] 250/929, 7.8 task/s, elapsed: 32s, ETA:    87s[>>>>>>>>                      ] 251/929, 7.8 task/s, elapsed: 32s, ETA:    87s[>>>>>>>>                      ] 252/929, 7.8 task/s, elapsed: 32s, ETA:    87s[>>>>>>>>                      ] 253/929, 7.8 task/s, elapsed: 33s, ETA:    87s[>>>>>>>>                      ] 254/929, 7.8 task/s, elapsed: 33s, ETA:    87s[>>>>>>>>                      ] 255/929, 7.8 task/s, elapsed: 33s, ETA:    87s[>>>>>>>>                      ] 256/929, 7.8 task/s, elapsed: 33s, ETA:    86s[>>>>>>>>                      ] 257/929, 7.8 task/s, elapsed: 33s, ETA:    86s[>>>>>>>>                      ] 258/929, 7.8 task/s, elapsed: 33s, ETA:    86s[>>>>>>>>                      ] 259/929, 7.8 task/s, elapsed: 33s, ETA:    86s[>>>>>>>>                      ] 260/929, 7.8 task/s, elapsed: 34s, ETA:    86s[>>>>>>>>                      ] 261/929, 7.8 task/s, elapsed: 34s, ETA:    86s[>>>>>>>>                      ] 262/929, 7.7 task/s, elapsed: 34s, ETA:    86s[>>>>>>>>                      ] 263/929, 7.8 task/s, elapsed: 34s, ETA:    86s[>>>>>>>>                      ] 264/929, 7.7 task/s, elapsed: 34s, ETA:    86s[>>>>>>>>                      ] 265/929, 7.7 task/s, elapsed: 34s, ETA:    86s[>>>>>>>>                      ] 266/929, 7.7 task/s, elapsed: 34s, ETA:    86s[>>>>>>>>                      ] 267/929, 7.7 task/s, elapsed: 34s, ETA:    85s[>>>>>>>>                      ] 268/929, 7.7 task/s, elapsed: 35s, ETA:    85s[>>>>>>>>                      ] 269/929, 7.7 task/s, elapsed: 35s, ETA:    85s[>>>>>>>>                      ] 270/929, 7.7 task/s, elapsed: 35s, ETA:    85s[>>>>>>>>                      ] 271/929, 7.8 task/s, elapsed: 35s, ETA:    85s[>>>>>>>>                      ] 272/929, 7.8 task/s, elapsed: 35s, ETA:    85s[>>>>>>>>                      ] 273/929, 7.7 task/s, elapsed: 35s, ETA:    85s[>>>>>>>>                      ] 274/929, 7.7 task/s, elapsed: 35s, ETA:    85s[>>>>>>>>                      ] 275/929, 7.7 task/s, elapsed: 35s, ETA:    84s[>>>>>>>>                      ] 276/929, 7.8 task/s, elapsed: 36s, ETA:    84s[>>>>>>>>                      ] 277/929, 7.8 task/s, elapsed: 36s, ETA:    84s[>>>>>>>>                      ] 278/929, 7.7 task/s, elapsed: 36s, ETA:    84s[>>>>>>>>>                     ] 279/929, 7.7 task/s, elapsed: 36s, ETA:    84s[>>>>>>>>>                     ] 280/929, 7.7 task/s, elapsed: 36s, ETA:    84s[>>>>>>>>>                     ] 281/929, 7.8 task/s, elapsed: 36s, ETA:    84s[>>>>>>>>>                     ] 282/929, 7.8 task/s, elapsed: 36s, ETA:    83s[>>>>>>>>>                     ] 283/929, 7.8 task/s, elapsed: 37s, ETA:    83s[>>>>>>>>>                     ] 284/929, 7.8 task/s, elapsed: 37s, ETA:    83s[>>>>>>>>>                     ] 285/929, 7.8 task/s, elapsed: 37s, ETA:    83s[>>>>>>>>>                     ] 286/929, 7.8 task/s, elapsed: 37s, ETA:    83s[>>>>>>>>>                     ] 287/929, 7.8 task/s, elapsed: 37s, ETA:    83s[>>>>>>>>>                     ] 288/929, 7.8 task/s, elapsed: 37s, ETA:    83s[>>>>>>>>>                     ] 289/929, 7.8 task/s, elapsed: 37s, ETA:    83s[>>>>>>>>>                     ] 290/929, 7.7 task/s, elapsed: 37s, ETA:    82s[>>>>>>>>>                     ] 291/929, 7.7 task/s, elapsed: 38s, ETA:    82s[>>>>>>>>>                     ] 292/929, 7.8 task/s, elapsed: 38s, ETA:    82s[>>>>>>>>>                     ] 293/929, 7.7 task/s, elapsed: 38s, ETA:    82s[>>>>>>>>>                     ] 294/929, 7.8 task/s, elapsed: 38s, ETA:    82s[>>>>>>>>>                     ] 295/929, 7.8 task/s, elapsed: 38s, ETA:    82s[>>>>>>>>>                     ] 296/929, 7.8 task/s, elapsed: 38s, ETA:    82s[>>>>>>>>>                     ] 297/929, 7.8 task/s, elapsed: 38s, ETA:    82s[>>>>>>>>>                     ] 298/929, 7.8 task/s, elapsed: 38s, ETA:    81s[>>>>>>>>>                     ] 299/929, 7.8 task/s, elapsed: 39s, ETA:    81s[>>>>>>>>>                     ] 300/929, 7.8 task/s, elapsed: 39s, ETA:    81s[>>>>>>>>>                     ] 301/929, 7.8 task/s, elapsed: 39s, ETA:    81s[>>>>>>>>>                     ] 302/929, 7.8 task/s, elapsed: 39s, ETA:    81s[>>>>>>>>>                     ] 303/929, 7.8 task/s, elapsed: 39s, ETA:    81s[>>>>>>>>>                     ] 304/929, 7.8 task/s, elapsed: 39s, ETA:    81s[>>>>>>>>>                     ] 305/929, 7.8 task/s, elapsed: 39s, ETA:    80s[>>>>>>>>>                     ] 306/929, 7.8 task/s, elapsed: 39s, ETA:    80s[>>>>>>>>>                     ] 307/929, 7.8 task/s, elapsed: 40s, ETA:    80s[>>>>>>>>>                     ] 308/929, 7.8 task/s, elapsed: 40s, ETA:    80s[>>>>>>>>>                     ] 309/929, 7.8 task/s, elapsed: 40s, ETA:    80s[>>>>>>>>>>                    ] 310/929, 7.8 task/s, elapsed: 40s, ETA:    80s[>>>>>>>>>>                    ] 311/929, 7.8 task/s, elapsed: 40s, ETA:    79s[>>>>>>>>>>                    ] 312/929, 7.8 task/s, elapsed: 40s, ETA:    79s[>>>>>>>>>>                    ] 313/929, 7.8 task/s, elapsed: 40s, ETA:    79s[>>>>>>>>>>                    ] 314/929, 7.8 task/s, elapsed: 40s, ETA:    79s[>>>>>>>>>>                    ] 315/929, 7.8 task/s, elapsed: 40s, ETA:    79s[>>>>>>>>>>                    ] 316/929, 7.8 task/s, elapsed: 41s, ETA:    79s[>>>>>>>>>>                    ] 317/929, 7.8 task/s, elapsed: 41s, ETA:    79s[>>>>>>>>>>                    ] 318/929, 7.8 task/s, elapsed: 41s, ETA:    78s[>>>>>>>>>>                    ] 319/929, 7.8 task/s, elapsed: 41s, ETA:    78s[>>>>>>>>>>                    ] 320/929, 7.8 task/s, elapsed: 41s, ETA:    78s[>>>>>>>>>>                    ] 321/929, 7.8 task/s, elapsed: 41s, ETA:    78s[>>>>>>>>>>                    ] 322/929, 7.8 task/s, elapsed: 41s, ETA:    78s[>>>>>>>>>>                    ] 323/929, 7.8 task/s, elapsed: 42s, ETA:    78s[>>>>>>>>>>                    ] 324/929, 7.8 task/s, elapsed: 42s, ETA:    78s[>>>>>>>>>>                    ] 325/929, 7.8 task/s, elapsed: 42s, ETA:    78s[>>>>>>>>>>                    ] 326/929, 7.8 task/s, elapsed: 42s, ETA:    78s[>>>>>>>>>>                    ] 327/929, 7.8 task/s, elapsed: 42s, ETA:    77s[>>>>>>>>>>                    ] 328/929, 7.8 task/s, elapsed: 42s, ETA:    77s[>>>>>>>>>>                    ] 329/929, 7.8 task/s, elapsed: 42s, ETA:    77s[>>>>>>>>>>                    ] 330/929, 7.8 task/s, elapsed: 42s, ETA:    77s[>>>>>>>>>>                    ] 331/929, 7.8 task/s, elapsed: 43s, ETA:    77s[>>>>>>>>>>                    ] 332/929, 7.8 task/s, elapsed: 43s, ETA:    77s[>>>>>>>>>>                    ] 333/929, 7.8 task/s, elapsed: 43s, ETA:    77s[>>>>>>>>>>                    ] 334/929, 7.8 task/s, elapsed: 43s, ETA:    76s[>>>>>>>>>>                    ] 335/929, 7.8 task/s, elapsed: 43s, ETA:    76s[>>>>>>>>>>                    ] 336/929, 7.8 task/s, elapsed: 43s, ETA:    76s[>>>>>>>>>>                    ] 337/929, 7.8 task/s, elapsed: 43s, ETA:    76s[>>>>>>>>>>                    ] 338/929, 7.8 task/s, elapsed: 44s, ETA:    76s[>>>>>>>>>>                    ] 339/929, 7.8 task/s, elapsed: 44s, ETA:    76s[>>>>>>>>>>                    ] 340/929, 7.8 task/s, elapsed: 44s, ETA:    76s[>>>>>>>>>>>                   ] 341/929, 7.8 task/s, elapsed: 44s, ETA:    76s[>>>>>>>>>>>                   ] 342/929, 7.8 task/s, elapsed: 44s, ETA:    76s[>>>>>>>>>>>                   ] 343/929, 7.8 task/s, elapsed: 44s, ETA:    75s[>>>>>>>>>>>                   ] 344/929, 7.8 task/s, elapsed: 44s, ETA:    75s[>>>>>>>>>>>                   ] 345/929, 7.8 task/s, elapsed: 44s, ETA:    75s[>>>>>>>>>>>                   ] 346/929, 7.8 task/s, elapsed: 45s, ETA:    75s[>>>>>>>>>>>                   ] 347/929, 7.8 task/s, elapsed: 45s, ETA:    75s[>>>>>>>>>>>                   ] 348/929, 7.8 task/s, elapsed: 45s, ETA:    75s[>>>>>>>>>>>                   ] 349/929, 7.8 task/s, elapsed: 45s, ETA:    75s[>>>>>>>>>>>                   ] 350/929, 7.8 task/s, elapsed: 45s, ETA:    75s[>>>>>>>>>>>                   ] 351/929, 7.8 task/s, elapsed: 45s, ETA:    74s[>>>>>>>>>>>                   ] 352/929, 7.8 task/s, elapsed: 45s, ETA:    74s[>>>>>>>>>>>                   ] 353/929, 7.8 task/s, elapsed: 45s, ETA:    74s[>>>>>>>>>>>                   ] 354/929, 7.8 task/s, elapsed: 46s, ETA:    74s[>>>>>>>>>>>                   ] 355/929, 7.8 task/s, elapsed: 46s, ETA:    74s[>>>>>>>>>>>                   ] 356/929, 7.8 task/s, elapsed: 46s, ETA:    74s[>>>>>>>>>>>                   ] 357/929, 7.8 task/s, elapsed: 46s, ETA:    74s[>>>>>>>>>>>                   ] 358/929, 7.8 task/s, elapsed: 46s, ETA:    73s[>>>>>>>>>>>                   ] 359/929, 7.8 task/s, elapsed: 46s, ETA:    73s[>>>>>>>>>>>                   ] 360/929, 7.8 task/s, elapsed: 46s, ETA:    73s[>>>>>>>>>>>                   ] 361/929, 7.8 task/s, elapsed: 46s, ETA:    73s[>>>>>>>>>>>                   ] 362/929, 7.8 task/s, elapsed: 47s, ETA:    73s[>>>>>>>>>>>                   ] 363/929, 7.8 task/s, elapsed: 47s, ETA:    73s[>>>>>>>>>>>                   ] 364/929, 7.8 task/s, elapsed: 47s, ETA:    73s[>>>>>>>>>>>                   ] 365/929, 7.8 task/s, elapsed: 47s, ETA:    73s[>>>>>>>>>>>                   ] 366/929, 7.8 task/s, elapsed: 47s, ETA:    72s[>>>>>>>>>>>                   ] 367/929, 7.8 task/s, elapsed: 47s, ETA:    72s[>>>>>>>>>>>                   ] 368/929, 7.8 task/s, elapsed: 47s, ETA:    72s[>>>>>>>>>>>                   ] 369/929, 7.8 task/s, elapsed: 48s, ETA:    72s[>>>>>>>>>>>                   ] 370/929, 7.8 task/s, elapsed: 48s, ETA:    72s[>>>>>>>>>>>                   ] 371/929, 7.8 task/s, elapsed: 48s, ETA:    72s[>>>>>>>>>>>>                  ] 372/929, 7.8 task/s, elapsed: 48s, ETA:    72s[>>>>>>>>>>>>                  ] 373/929, 7.8 task/s, elapsed: 48s, ETA:    72s[>>>>>>>>>>>>                  ] 374/929, 7.8 task/s, elapsed: 48s, ETA:    71s[>>>>>>>>>>>>                  ] 375/929, 7.8 task/s, elapsed: 48s, ETA:    71s[>>>>>>>>>>>>                  ] 376/929, 7.8 task/s, elapsed: 48s, ETA:    71s[>>>>>>>>>>>>                  ] 377/929, 7.8 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 378/929, 7.8 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 379/929, 7.7 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 380/929, 7.8 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 381/929, 7.8 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 382/929, 7.8 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 383/929, 7.8 task/s, elapsed: 49s, ETA:    70s[>>>>>>>>>>>>                  ] 384/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 385/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 386/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 387/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 388/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 389/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 390/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 391/929, 7.7 task/s, elapsed: 50s, ETA:    69s[>>>>>>>>>>>>                  ] 392/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 393/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 394/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 395/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 396/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 397/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 398/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 399/929, 7.7 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>                  ] 400/929, 7.7 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>                  ] 401/929, 7.7 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>                  ] 402/929, 7.7 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>>                 ] 403/929, 7.7 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>>                 ] 404/929, 7.7 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>>                 ] 405/929, 7.7 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>>                 ] 406/929, 7.7 task/s, elapsed: 53s, ETA:    68s[>>>>>>>>>>>>>                 ] 407/929, 7.7 task/s, elapsed: 53s, ETA:    68s[>>>>>>>>>>>>>                 ] 408/929, 7.7 task/s, elapsed: 53s, ETA:    67s[>>>>>>>>>>>>>                 ] 409/929, 7.7 task/s, elapsed: 53s, ETA:    67s[>>>>>>>>>>>>>                 ] 410/929, 7.7 task/s, elapsed: 53s, ETA:    67s[>>>>>>>>>>>>>                 ] 411/929, 7.7 task/s, elapsed: 53s, ETA:    67s[>>>>>>>>>>>>>                 ] 412/929, 7.7 task/s, elapsed: 53s, ETA:    67s[>>>>>>>>>>>>>                 ] 413/929, 7.7 task/s, elapsed: 53s, ETA:    67s[>>>>>>>>>>>>>                 ] 414/929, 7.7 task/s, elapsed: 54s, ETA:    67s[>>>>>>>>>>>>>                 ] 415/929, 7.7 task/s, elapsed: 54s, ETA:    67s[>>>>>>>>>>>>>                 ] 416/929, 7.7 task/s, elapsed: 54s, ETA:    66s[>>>>>>>>>>>>>                 ] 417/929, 7.7 task/s, elapsed: 54s, ETA:    66s[>>>>>>>>>>>>>                 ] 418/929, 7.7 task/s, elapsed: 54s, ETA:    66s[>>>>>>>>>>>>>                 ] 419/929, 7.7 task/s, elapsed: 54s, ETA:    66s[>>>>>>>>>>>>>                 ] 420/929, 7.7 task/s, elapsed: 54s, ETA:    66s[>>>>>>>>>>>>>                 ] 421/929, 7.7 task/s, elapsed: 55s, ETA:    66s[>>>>>>>>>>>>>                 ] 422/929, 7.7 task/s, elapsed: 55s, ETA:    66s[>>>>>>>>>>>>>                 ] 423/929, 7.7 task/s, elapsed: 55s, ETA:    66s[>>>>>>>>>>>>>                 ] 424/929, 7.7 task/s, elapsed: 55s, ETA:    65s[>>>>>>>>>>>>>                 ] 425/929, 7.7 task/s, elapsed: 55s, ETA:    65s[>>>>>>>>>>>>>                 ] 426/929, 7.7 task/s, elapsed: 55s, ETA:    65s[>>>>>>>>>>>>>                 ] 427/929, 7.7 task/s, elapsed: 55s, ETA:    65s[>>>>>>>>>>>>>                 ] 428/929, 7.7 task/s, elapsed: 56s, ETA:    65s[>>>>>>>>>>>>>                 ] 429/929, 7.7 task/s, elapsed: 56s, ETA:    65s[>>>>>>>>>>>>>                 ] 430/929, 7.7 task/s, elapsed: 56s, ETA:    65s[>>>>>>>>>>>>>                 ] 431/929, 7.7 task/s, elapsed: 56s, ETA:    65s[>>>>>>>>>>>>>                 ] 432/929, 7.7 task/s, elapsed: 56s, ETA:    64s[>>>>>>>>>>>>>                 ] 433/929, 7.7 task/s, elapsed: 56s, ETA:    64s[>>>>>>>>>>>>>>                ] 434/929, 7.7 task/s, elapsed: 56s, ETA:    64s[>>>>>>>>>>>>>>                ] 435/929, 7.7 task/s, elapsed: 56s, ETA:    64s[>>>>>>>>>>>>>>                ] 436/929, 7.7 task/s, elapsed: 57s, ETA:    64s[>>>>>>>>>>>>>>                ] 437/929, 7.7 task/s, elapsed: 57s, ETA:    64s[>>>>>>>>>>>>>>                ] 438/929, 7.7 task/s, elapsed: 57s, ETA:    64s[>>>>>>>>>>>>>>                ] 439/929, 7.7 task/s, elapsed: 57s, ETA:    64s[>>>>>>>>>>>>>>                ] 440/929, 7.7 task/s, elapsed: 57s, ETA:    63s[>>>>>>>>>>>>>>                ] 441/929, 7.7 task/s, elapsed: 57s, ETA:    63s[>>>>>>>>>>>>>>                ] 442/929, 7.7 task/s, elapsed: 57s, ETA:    63s[>>>>>>>>>>>>>>                ] 443/929, 7.7 task/s, elapsed: 58s, ETA:    63s[>>>>>>>>>>>>>>                ] 444/929, 7.7 task/s, elapsed: 58s, ETA:    63s[>>>>>>>>>>>>>>                ] 445/929, 7.7 task/s, elapsed: 58s, ETA:    63s[>>>>>>>>>>>>>>                ] 446/929, 7.7 task/s, elapsed: 58s, ETA:    63s[>>>>>>>>>>>>>>                ] 447/929, 7.7 task/s, elapsed: 58s, ETA:    63s[>>>>>>>>>>>>>>                ] 448/929, 7.7 task/s, elapsed: 58s, ETA:    62s[>>>>>>>>>>>>>>                ] 449/929, 7.7 task/s, elapsed: 58s, ETA:    62s[>>>>>>>>>>>>>>                ] 450/929, 7.7 task/s, elapsed: 58s, ETA:    62s[>>>>>>>>>>>>>>                ] 451/929, 7.7 task/s, elapsed: 58s, ETA:    62s[>>>>>>>>>>>>>>                ] 452/929, 7.7 task/s, elapsed: 59s, ETA:    62s[>>>>>>>>>>>>>>                ] 453/929, 7.7 task/s, elapsed: 59s, ETA:    62s[>>>>>>>>>>>>>>                ] 454/929, 7.7 task/s, elapsed: 59s, ETA:    62s[>>>>>>>>>>>>>>                ] 455/929, 7.7 task/s, elapsed: 59s, ETA:    61s[>>>>>>>>>>>>>>                ] 456/929, 7.7 task/s, elapsed: 59s, ETA:    61s[>>>>>>>>>>>>>>                ] 457/929, 7.7 task/s, elapsed: 59s, ETA:    61s[>>>>>>>>>>>>>>                ] 458/929, 7.7 task/s, elapsed: 59s, ETA:    61s[>>>>>>>>>>>>>>                ] 459/929, 7.7 task/s, elapsed: 60s, ETA:    61s[>>>>>>>>>>>>>>                ] 460/929, 7.7 task/s, elapsed: 60s, ETA:    61s[>>>>>>>>>>>>>>                ] 461/929, 7.7 task/s, elapsed: 60s, ETA:    61s[>>>>>>>>>>>>>>                ] 462/929, 7.7 task/s, elapsed: 60s, ETA:    61s[>>>>>>>>>>>>>>                ] 463/929, 7.7 task/s, elapsed: 60s, ETA:    60s[>>>>>>>>>>>>>>                ] 464/929, 7.7 task/s, elapsed: 60s, ETA:    60s[>>>>>>>>>>>>>>>               ] 465/929, 7.7 task/s, elapsed: 60s, ETA:    60s[>>>>>>>>>>>>>>>               ] 466/929, 7.7 task/s, elapsed: 60s, ETA:    60s[>>>>>>>>>>>>>>>               ] 467/929, 7.7 task/s, elapsed: 61s, ETA:    60s[>>>>>>>>>>>>>>>               ] 468/929, 7.7 task/s, elapsed: 61s, ETA:    60s[>>>>>>>>>>>>>>>               ] 469/929, 7.7 task/s, elapsed: 61s, ETA:    60s[>>>>>>>>>>>>>>>               ] 470/929, 7.7 task/s, elapsed: 61s, ETA:    59s[>>>>>>>>>>>>>>>               ] 471/929, 7.7 task/s, elapsed: 61s, ETA:    59s[>>>>>>>>>>>>>>>               ] 472/929, 7.7 task/s, elapsed: 61s, ETA:    59s[>>>>>>>>>>>>>>>               ] 473/929, 7.7 task/s, elapsed: 61s, ETA:    59s[>>>>>>>>>>>>>>>               ] 474/929, 7.7 task/s, elapsed: 61s, ETA:    59s[>>>>>>>>>>>>>>>               ] 475/929, 7.7 task/s, elapsed: 62s, ETA:    59s[>>>>>>>>>>>>>>>               ] 476/929, 7.7 task/s, elapsed: 62s, ETA:    59s[>>>>>>>>>>>>>>>               ] 477/929, 7.7 task/s, elapsed: 62s, ETA:    59s[>>>>>>>>>>>>>>>               ] 478/929, 7.7 task/s, elapsed: 62s, ETA:    58s[>>>>>>>>>>>>>>>               ] 479/929, 7.7 task/s, elapsed: 62s, ETA:    58s[>>>>>>>>>>>>>>>               ] 480/929, 7.7 task/s, elapsed: 62s, ETA:    58s[>>>>>>>>>>>>>>>               ] 481/929, 7.7 task/s, elapsed: 62s, ETA:    58s[>>>>>>>>>>>>>>>               ] 482/929, 7.7 task/s, elapsed: 62s, ETA:    58s[>>>>>>>>>>>>>>>               ] 483/929, 7.7 task/s, elapsed: 63s, ETA:    58s[>>>>>>>>>>>>>>>               ] 484/929, 7.7 task/s, elapsed: 63s, ETA:    58s[>>>>>>>>>>>>>>>               ] 485/929, 7.7 task/s, elapsed: 63s, ETA:    58s[>>>>>>>>>>>>>>>               ] 486/929, 7.7 task/s, elapsed: 63s, ETA:    57s[>>>>>>>>>>>>>>>               ] 487/929, 7.7 task/s, elapsed: 63s, ETA:    57s[>>>>>>>>>>>>>>>               ] 488/929, 7.7 task/s, elapsed: 63s, ETA:    57s[>>>>>>>>>>>>>>>               ] 489/929, 7.7 task/s, elapsed: 63s, ETA:    57s[>>>>>>>>>>>>>>>               ] 490/929, 7.7 task/s, elapsed: 64s, ETA:    57s[>>>>>>>>>>>>>>>               ] 491/929, 7.7 task/s, elapsed: 64s, ETA:    57s[>>>>>>>>>>>>>>>               ] 492/929, 7.7 task/s, elapsed: 64s, ETA:    57s[>>>>>>>>>>>>>>>               ] 493/929, 7.7 task/s, elapsed: 64s, ETA:    57s[>>>>>>>>>>>>>>>               ] 494/929, 7.7 task/s, elapsed: 64s, ETA:    56s[>>>>>>>>>>>>>>>               ] 495/929, 7.7 task/s, elapsed: 64s, ETA:    56s[>>>>>>>>>>>>>>>>              ] 496/929, 7.7 task/s, elapsed: 64s, ETA:    56s[>>>>>>>>>>>>>>>>              ] 497/929, 7.7 task/s, elapsed: 64s, ETA:    56s[>>>>>>>>>>>>>>>>              ] 498/929, 7.7 task/s, elapsed: 65s, ETA:    56s[>>>>>>>>>>>>>>>>              ] 499/929, 7.7 task/s, elapsed: 65s, ETA:    56s[>>>>>>>>>>>>>>>>              ] 500/929, 7.7 task/s, elapsed: 65s, ETA:    56s[>>>>>>>>>>>>>>>>              ] 501/929, 7.7 task/s, elapsed: 65s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 502/929, 7.7 task/s, elapsed: 65s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 503/929, 7.7 task/s, elapsed: 65s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 504/929, 7.7 task/s, elapsed: 65s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 505/929, 7.7 task/s, elapsed: 65s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 506/929, 7.7 task/s, elapsed: 66s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 507/929, 7.7 task/s, elapsed: 66s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 508/929, 7.7 task/s, elapsed: 66s, ETA:    55s[>>>>>>>>>>>>>>>>              ] 509/929, 7.7 task/s, elapsed: 66s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 510/929, 7.7 task/s, elapsed: 66s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 511/929, 7.7 task/s, elapsed: 66s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 512/929, 7.7 task/s, elapsed: 66s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 513/929, 7.7 task/s, elapsed: 66s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 514/929, 7.7 task/s, elapsed: 67s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 515/929, 7.7 task/s, elapsed: 67s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 516/929, 7.7 task/s, elapsed: 67s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 517/929, 7.7 task/s, elapsed: 67s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 518/929, 7.7 task/s, elapsed: 67s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 519/929, 7.7 task/s, elapsed: 67s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 520/929, 7.7 task/s, elapsed: 67s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 521/929, 7.7 task/s, elapsed: 68s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 522/929, 7.7 task/s, elapsed: 68s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 523/929, 7.7 task/s, elapsed: 68s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 524/929, 7.7 task/s, elapsed: 68s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 525/929, 7.7 task/s, elapsed: 68s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 526/929, 7.7 task/s, elapsed: 68s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 527/929, 7.7 task/s, elapsed: 68s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 528/929, 7.7 task/s, elapsed: 69s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 529/929, 7.7 task/s, elapsed: 69s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 530/929, 7.7 task/s, elapsed: 69s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 531/929, 7.7 task/s, elapsed: 69s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 532/929, 7.7 task/s, elapsed: 69s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 533/929, 7.7 task/s, elapsed: 69s, ETA:    51s[>>>>>>>>>>>>>>>>>             ] 534/929, 7.7 task/s, elapsed: 69s, ETA:    51s[>>>>>>>>>>>>>>>>>             ] 535/929, 7.7 task/s, elapsed: 69s, ETA:    51s[>>>>>>>>>>>>>>>>>             ] 536/929, 7.7 task/s, elapsed: 70s, ETA:    51s[>>>>>>>>>>>>>>>>>             ] 537/929, 7.7 task/s, elapsed: 70s, ETA:    51s[>>>>>>>>>>>>>>>>>             ] 538/929, 7.7 task/s, elapsed: 70s, ETA:    51s[>>>>>>>>>>>>>>>>>             ] 539/929, 7.7 task/s, elapsed: 70s, ETA:    51s[>>>>>>>>>>>>>>>>>             ] 540/929, 7.7 task/s, elapsed: 70s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 541/929, 7.7 task/s, elapsed: 70s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 542/929, 7.7 task/s, elapsed: 70s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 543/929, 7.7 task/s, elapsed: 70s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 544/929, 7.7 task/s, elapsed: 71s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 545/929, 7.7 task/s, elapsed: 71s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 546/929, 7.7 task/s, elapsed: 71s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 547/929, 7.7 task/s, elapsed: 71s, ETA:    50s[>>>>>>>>>>>>>>>>>             ] 548/929, 7.7 task/s, elapsed: 71s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 549/929, 7.7 task/s, elapsed: 71s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 550/929, 7.7 task/s, elapsed: 71s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 551/929, 7.7 task/s, elapsed: 71s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 552/929, 7.7 task/s, elapsed: 72s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 553/929, 7.7 task/s, elapsed: 72s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 554/929, 7.7 task/s, elapsed: 72s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 555/929, 7.7 task/s, elapsed: 72s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 556/929, 7.7 task/s, elapsed: 72s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 557/929, 7.7 task/s, elapsed: 72s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 558/929, 7.7 task/s, elapsed: 72s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 559/929, 7.7 task/s, elapsed: 73s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 560/929, 7.7 task/s, elapsed: 73s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 561/929, 7.7 task/s, elapsed: 73s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 562/929, 7.7 task/s, elapsed: 73s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 563/929, 7.7 task/s, elapsed: 73s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 564/929, 7.7 task/s, elapsed: 73s, ETA:    47s[>>>>>>>>>>>>>>>>>>            ] 565/929, 7.7 task/s, elapsed: 73s, ETA:    47s[>>>>>>>>>>>>>>>>>>            ] 566/929, 7.7 task/s, elapsed: 73s, ETA:    47s[>>>>>>>>>>>>>>>>>>            ] 567/929, 7.7 task/s, elapsed: 74s, ETA:    47s[>>>>>>>>>>>>>>>>>>            ] 568/929, 7.7 task/s, elapsed: 74s, ETA:    47s[>>>>>>>>>>>>>>>>>>            ] 569/929, 7.7 task/s, elapsed: 74s, ETA:    47s[>>>>>>>>>>>>>>>>>>            ] 570/929, 7.7 task/s, elapsed: 74s, ETA:    47s[>>>>>>>>>>>>>>>>>>            ] 571/929, 7.7 task/s, elapsed: 74s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 572/929, 7.7 task/s, elapsed: 74s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 573/929, 7.7 task/s, elapsed: 74s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 574/929, 7.7 task/s, elapsed: 74s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 575/929, 7.7 task/s, elapsed: 75s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 576/929, 7.7 task/s, elapsed: 75s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 577/929, 7.7 task/s, elapsed: 75s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 578/929, 7.7 task/s, elapsed: 75s, ETA:    46s[>>>>>>>>>>>>>>>>>>            ] 579/929, 7.7 task/s, elapsed: 75s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 580/929, 7.7 task/s, elapsed: 75s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 581/929, 7.7 task/s, elapsed: 75s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 582/929, 7.7 task/s, elapsed: 75s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 583/929, 7.7 task/s, elapsed: 76s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 584/929, 7.7 task/s, elapsed: 76s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 585/929, 7.7 task/s, elapsed: 76s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 586/929, 7.7 task/s, elapsed: 76s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 587/929, 7.7 task/s, elapsed: 76s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 588/929, 7.7 task/s, elapsed: 76s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 7.7 task/s, elapsed: 76s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 7.7 task/s, elapsed: 76s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 7.7 task/s, elapsed: 77s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 7.7 task/s, elapsed: 77s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 7.7 task/s, elapsed: 77s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 7.7 task/s, elapsed: 77s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 7.7 task/s, elapsed: 77s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 7.7 task/s, elapsed: 77s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 7.7 task/s, elapsed: 78s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 7.7 task/s, elapsed: 78s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 7.7 task/s, elapsed: 78s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 7.7 task/s, elapsed: 78s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 7.7 task/s, elapsed: 78s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 7.7 task/s, elapsed: 78s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 7.7 task/s, elapsed: 78s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 7.7 task/s, elapsed: 78s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 7.7 task/s, elapsed: 78s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 7.7 task/s, elapsed: 79s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 7.7 task/s, elapsed: 79s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 7.7 task/s, elapsed: 79s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 7.7 task/s, elapsed: 79s, ETA:    42s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 7.7 task/s, elapsed: 79s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 7.7 task/s, elapsed: 79s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 7.7 task/s, elapsed: 79s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 7.7 task/s, elapsed: 79s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 7.7 task/s, elapsed: 80s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 7.7 task/s, elapsed: 80s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 7.7 task/s, elapsed: 80s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 7.7 task/s, elapsed: 80s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 7.7 task/s, elapsed: 80s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 7.7 task/s, elapsed: 80s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 7.7 task/s, elapsed: 80s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 7.7 task/s, elapsed: 81s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 7.7 task/s, elapsed: 81s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 7.7 task/s, elapsed: 81s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 7.7 task/s, elapsed: 81s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 7.7 task/s, elapsed: 81s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 7.7 task/s, elapsed: 81s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 7.7 task/s, elapsed: 81s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 7.7 task/s, elapsed: 82s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 7.7 task/s, elapsed: 82s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 7.7 task/s, elapsed: 82s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 7.7 task/s, elapsed: 82s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 7.7 task/s, elapsed: 82s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 7.7 task/s, elapsed: 82s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 7.7 task/s, elapsed: 82s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 7.7 task/s, elapsed: 82s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 7.7 task/s, elapsed: 83s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 7.7 task/s, elapsed: 83s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 7.7 task/s, elapsed: 83s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 7.7 task/s, elapsed: 83s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 7.7 task/s, elapsed: 83s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 7.7 task/s, elapsed: 83s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 7.7 task/s, elapsed: 83s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 7.7 task/s, elapsed: 84s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 7.7 task/s, elapsed: 84s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 7.7 task/s, elapsed: 84s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 7.7 task/s, elapsed: 84s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 7.7 task/s, elapsed: 84s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 7.7 task/s, elapsed: 84s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 7.7 task/s, elapsed: 84s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 7.7 task/s, elapsed: 84s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 7.7 task/s, elapsed: 85s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 7.7 task/s, elapsed: 85s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 7.7 task/s, elapsed: 85s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 7.7 task/s, elapsed: 85s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 7.7 task/s, elapsed: 85s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 7.7 task/s, elapsed: 85s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 7.7 task/s, elapsed: 85s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 7.7 task/s, elapsed: 85s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 7.7 task/s, elapsed: 86s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 7.7 task/s, elapsed: 86s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 7.7 task/s, elapsed: 86s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 7.7 task/s, elapsed: 86s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 7.7 task/s, elapsed: 86s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 7.7 task/s, elapsed: 86s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 7.7 task/s, elapsed: 86s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 7.7 task/s, elapsed: 86s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 7.7 task/s, elapsed: 87s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 7.7 task/s, elapsed: 87s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 7.7 task/s, elapsed: 87s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 7.7 task/s, elapsed: 87s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 7.7 task/s, elapsed: 87s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 7.7 task/s, elapsed: 87s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 7.7 task/s, elapsed: 87s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 7.7 task/s, elapsed: 87s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 7.7 task/s, elapsed: 88s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 7.7 task/s, elapsed: 88s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 7.7 task/s, elapsed: 88s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 7.7 task/s, elapsed: 88s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 7.7 task/s, elapsed: 88s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 7.7 task/s, elapsed: 88s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 7.7 task/s, elapsed: 88s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 7.7 task/s, elapsed: 88s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 7.7 task/s, elapsed: 89s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 7.7 task/s, elapsed: 89s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 7.7 task/s, elapsed: 89s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 7.7 task/s, elapsed: 89s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 7.7 task/s, elapsed: 89s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 7.7 task/s, elapsed: 89s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 7.7 task/s, elapsed: 89s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 7.7 task/s, elapsed: 90s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 7.7 task/s, elapsed: 90s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 7.7 task/s, elapsed: 90s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 7.7 task/s, elapsed: 90s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 7.7 task/s, elapsed: 90s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 7.7 task/s, elapsed: 90s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 7.7 task/s, elapsed: 90s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 7.7 task/s, elapsed: 91s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 7.7 task/s, elapsed: 91s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 7.7 task/s, elapsed: 91s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 7.7 task/s, elapsed: 91s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 7.7 task/s, elapsed: 91s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 7.7 task/s, elapsed: 91s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 7.7 task/s, elapsed: 91s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 7.7 task/s, elapsed: 91s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 7.7 task/s, elapsed: 92s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 7.7 task/s, elapsed: 92s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 7.7 task/s, elapsed: 92s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 7.7 task/s, elapsed: 92s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 7.7 task/s, elapsed: 92s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 7.7 task/s, elapsed: 92s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 7.7 task/s, elapsed: 92s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 7.7 task/s, elapsed: 92s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 7.7 task/s, elapsed: 93s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 7.7 task/s, elapsed: 93s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 7.7 task/s, elapsed: 93s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 7.7 task/s, elapsed: 93s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 7.7 task/s, elapsed: 93s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 7.7 task/s, elapsed: 93s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 7.7 task/s, elapsed: 93s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 7.7 task/s, elapsed: 94s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 7.7 task/s, elapsed: 94s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 7.7 task/s, elapsed: 94s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 7.7 task/s, elapsed: 94s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 7.7 task/s, elapsed: 94s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 7.7 task/s, elapsed: 94s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 7.7 task/s, elapsed: 94s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 7.7 task/s, elapsed: 94s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 7.7 task/s, elapsed: 95s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 7.7 task/s, elapsed: 95s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 7.7 task/s, elapsed: 95s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 7.7 task/s, elapsed: 95s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 7.7 task/s, elapsed: 95s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 7.7 task/s, elapsed: 95s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 7.7 task/s, elapsed: 95s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 7.7 task/s, elapsed: 95s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 7.7 task/s, elapsed: 96s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 7.7 task/s, elapsed: 96s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 7.7 task/s, elapsed: 96s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 7.7 task/s, elapsed: 96s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 7.7 task/s, elapsed: 96s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 7.7 task/s, elapsed: 96s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 7.7 task/s, elapsed: 96s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 7.7 task/s, elapsed: 97s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 7.7 task/s, elapsed: 97s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 7.7 task/s, elapsed: 97s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 7.7 task/s, elapsed: 97s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 7.7 task/s, elapsed: 97s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 7.7 task/s, elapsed: 97s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 7.7 task/s, elapsed: 97s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 7.7 task/s, elapsed: 97s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 7.7 task/s, elapsed: 98s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 7.7 task/s, elapsed: 98s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 7.7 task/s, elapsed: 98s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 7.7 task/s, elapsed: 98s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 7.7 task/s, elapsed: 98s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 7.7 task/s, elapsed: 98s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 7.7 task/s, elapsed: 98s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 7.7 task/s, elapsed: 98s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 7.7 task/s, elapsed: 99s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 7.7 task/s, elapsed: 99s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 7.7 task/s, elapsed: 99s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 7.7 task/s, elapsed: 99s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 7.7 task/s, elapsed: 99s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 7.7 task/s, elapsed: 99s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 7.7 task/s, elapsed: 99s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 7.7 task/s, elapsed: 99s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 7.7 task/s, elapsed: 100s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 7.7 task/s, elapsed: 100s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 7.7 task/s, elapsed: 100s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 7.7 task/s, elapsed: 100s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 7.7 task/s, elapsed: 100s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 7.7 task/s, elapsed: 100s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 7.7 task/s, elapsed: 100s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 7.7 task/s, elapsed: 101s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 7.7 task/s, elapsed: 101s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 7.7 task/s, elapsed: 101s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 7.7 task/s, elapsed: 101s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 7.7 task/s, elapsed: 101s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 7.7 task/s, elapsed: 101s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 7.7 task/s, elapsed: 101s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 7.7 task/s, elapsed: 101s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 7.7 task/s, elapsed: 102s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 7.7 task/s, elapsed: 102s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 7.7 task/s, elapsed: 102s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 7.7 task/s, elapsed: 102s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 7.7 task/s, elapsed: 102s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 7.7 task/s, elapsed: 102s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 7.7 task/s, elapsed: 102s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 7.7 task/s, elapsed: 103s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 7.7 task/s, elapsed: 103s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 7.7 task/s, elapsed: 103s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 7.7 task/s, elapsed: 103s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 7.7 task/s, elapsed: 103s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 7.7 task/s, elapsed: 103s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 7.7 task/s, elapsed: 103s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 7.7 task/s, elapsed: 103s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 7.7 task/s, elapsed: 104s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 7.7 task/s, elapsed: 104s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 7.7 task/s, elapsed: 104s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 7.7 task/s, elapsed: 104s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 7.7 task/s, elapsed: 104s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 7.7 task/s, elapsed: 104s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 7.7 task/s, elapsed: 104s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 7.7 task/s, elapsed: 105s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 7.7 task/s, elapsed: 105s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 7.7 task/s, elapsed: 105s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 7.7 task/s, elapsed: 105s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 7.7 task/s, elapsed: 105s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 7.7 task/s, elapsed: 105s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 7.7 task/s, elapsed: 105s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 7.7 task/s, elapsed: 105s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 7.7 task/s, elapsed: 106s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 7.7 task/s, elapsed: 106s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 7.7 task/s, elapsed: 106s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 7.7 task/s, elapsed: 106s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 7.7 task/s, elapsed: 106s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 7.7 task/s, elapsed: 106s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 7.7 task/s, elapsed: 106s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 7.7 task/s, elapsed: 106s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 7.7 task/s, elapsed: 107s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 7.7 task/s, elapsed: 107s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 7.7 task/s, elapsed: 107s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 7.7 task/s, elapsed: 107s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 7.7 task/s, elapsed: 107s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 7.7 task/s, elapsed: 107s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 7.7 task/s, elapsed: 107s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 7.7 task/s, elapsed: 108s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 7.7 task/s, elapsed: 108s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 7.7 task/s, elapsed: 108s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 7.7 task/s, elapsed: 108s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 7.7 task/s, elapsed: 108s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 7.7 task/s, elapsed: 108s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 7.7 task/s, elapsed: 108s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 7.7 task/s, elapsed: 108s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 7.7 task/s, elapsed: 109s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 7.7 task/s, elapsed: 109s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 7.7 task/s, elapsed: 109s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 7.7 task/s, elapsed: 109s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 7.7 task/s, elapsed: 109s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 7.7 task/s, elapsed: 109s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 7.7 task/s, elapsed: 109s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 7.7 task/s, elapsed: 109s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 7.7 task/s, elapsed: 110s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 7.7 task/s, elapsed: 110s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 7.7 task/s, elapsed: 110s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 7.7 task/s, elapsed: 110s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 7.7 task/s, elapsed: 110s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 7.7 task/s, elapsed: 110s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 7.7 task/s, elapsed: 110s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 7.7 task/s, elapsed: 110s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 7.7 task/s, elapsed: 111s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 7.7 task/s, elapsed: 111s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 7.7 task/s, elapsed: 111s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 7.7 task/s, elapsed: 111s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 7.7 task/s, elapsed: 111s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 7.7 task/s, elapsed: 111s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 7.7 task/s, elapsed: 111s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 7.7 task/s, elapsed: 112s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 7.7 task/s, elapsed: 112s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 7.7 task/s, elapsed: 112s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 7.7 task/s, elapsed: 112s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 7.7 task/s, elapsed: 112s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 7.7 task/s, elapsed: 112s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 7.7 task/s, elapsed: 112s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 7.7 task/s, elapsed: 112s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 7.7 task/s, elapsed: 113s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 7.7 task/s, elapsed: 113s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 7.7 task/s, elapsed: 113s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 7.7 task/s, elapsed: 113s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 7.7 task/s, elapsed: 113s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 7.7 task/s, elapsed: 113s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 7.7 task/s, elapsed: 113s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 7.7 task/s, elapsed: 113s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 7.7 task/s, elapsed: 114s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 7.7 task/s, elapsed: 114s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 7.7 task/s, elapsed: 114s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 7.7 task/s, elapsed: 114s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 7.7 task/s, elapsed: 114s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 7.7 task/s, elapsed: 114s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 7.7 task/s, elapsed: 114s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 7.7 task/s, elapsed: 115s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 7.7 task/s, elapsed: 115s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 7.7 task/s, elapsed: 115s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 7.7 task/s, elapsed: 115s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 7.7 task/s, elapsed: 115s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 7.7 task/s, elapsed: 115s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 7.7 task/s, elapsed: 115s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 7.7 task/s, elapsed: 115s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 7.7 task/s, elapsed: 116s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 7.7 task/s, elapsed: 116s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 7.7 task/s, elapsed: 116s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 7.7 task/s, elapsed: 116s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 7.7 task/s, elapsed: 116s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 7.7 task/s, elapsed: 116s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 7.7 task/s, elapsed: 116s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 7.7 task/s, elapsed: 116s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 7.7 task/s, elapsed: 117s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 7.7 task/s, elapsed: 117s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 7.7 task/s, elapsed: 117s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 7.7 task/s, elapsed: 117s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 7.7 task/s, elapsed: 117s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 7.7 task/s, elapsed: 117s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 7.7 task/s, elapsed: 117s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 7.7 task/s, elapsed: 117s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 7.7 task/s, elapsed: 118s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 7.7 task/s, elapsed: 118s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 7.7 task/s, elapsed: 118s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 7.7 task/s, elapsed: 118s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 7.7 task/s, elapsed: 118s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 7.7 task/s, elapsed: 118s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 7.7 task/s, elapsed: 118s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 7.7 task/s, elapsed: 118s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 7.7 task/s, elapsed: 119s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 7.7 task/s, elapsed: 119s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 7.7 task/s, elapsed: 119s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 7.7 task/s, elapsed: 119s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 7.7 task/s, elapsed: 119s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 7.7 task/s, elapsed: 119s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 7.7 task/s, elapsed: 119s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 7.7 task/s, elapsed: 119s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 7.7 task/s, elapsed: 120s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 7.7 task/s, elapsed: 120s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 7.7 task/s, elapsed: 120s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 7.7 task/s, elapsed: 120s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 7.7 task/s, elapsed: 120s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 7.7 task/s, elapsed: 120s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 7.7 task/s, elapsed: 120s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 7.7 task/s, elapsed: 120s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 7.7 task/s, elapsed: 121s, ETA:     0s2022-10-10 10:06:45,866 - mmseg - INFO - per class results:2022-10-10 10:06:45,868 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 89.36 |  95.0 || rigid_plastic | 18.01 | 22.79 ||   cardboard   | 50.23 | 66.27 ||     metal     |  0.0  |  0.0  ||  soft_plastic | 60.15 |  72.5 |+---------------+-------+-------+2022-10-10 10:06:45,868 - mmseg - INFO - Summary:2022-10-10 10:06:45,868 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 89.81 | 43.55 | 51.31 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:06:45,873 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 10:06:45,874 - mmseg - INFO - Iter [929/40000]	lr: 5.400e-05, eta: 10:45:55, time: 1.282, data_time: 0.014, memory: 67494, aAcc: 0.8981, mIoU: 0.4355, mAcc: 0.5131, IoU.background: 0.8936, IoU.rigid_plastic: 0.1801, IoU.cardboard: 0.5023, IoU.metal: 0.0000, IoU.soft_plastic: 0.6015, Acc.background: 0.9500, Acc.rigid_plastic: 0.2279, Acc.cardboard: 0.6627, Acc.metal: 0.0000, Acc.soft_plastic: 0.7250, src.decode.loss_seg: 0.2004, src.decode.acc_seg: 92.5496, src.loss: 0.2165, mix.decode.loss_seg: 0.1110, mix.decode.acc_seg: 95.1916, mix.loss: 0.1110, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:07:48,282 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 11:17:32, time: 5.471, data_time: 4.235, memory: 67494, src.decode.loss_seg: 0.1815, src.decode.acc_seg: 93.5768, src.loss: 0.1976, mix.decode.loss_seg: 0.1033, mix.decode.acc_seg: 95.3787, mix.loss: 0.1033, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:08:51,592 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 11:17:34, time: 1.266, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1862, src.decode.acc_seg: 93.6111, src.loss: 0.2023, mix.decode.loss_seg: 0.1046, mix.decode.acc_seg: 95.2877, mix.loss: 0.1046, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:09:54,784 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 11:17:34, time: 1.264, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2117, src.decode.acc_seg: 92.6722, src.loss: 0.2277, mix.decode.loss_seg: 0.1241, mix.decode.acc_seg: 94.8629, mix.loss: 0.1241, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:10:57,167 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 11:17:26, time: 1.248, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1808, src.decode.acc_seg: 93.5349, src.loss: 0.1969, mix.decode.loss_seg: 0.1107, mix.decode.acc_seg: 95.4380, mix.loss: 0.1107, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:11:59,802 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 11:17:19, time: 1.253, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1945, src.decode.acc_seg: 92.7650, src.loss: 0.2106, mix.decode.loss_seg: 0.1182, mix.decode.acc_seg: 94.9465, mix.loss: 0.1182, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:13:02,176 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 11:17:08, time: 1.247, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2172, src.decode.acc_seg: 92.4695, src.loss: 0.2332, mix.decode.loss_seg: 0.1486, mix.decode.acc_seg: 93.8695, mix.loss: 0.1486, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:14:04,747 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 11:16:57, time: 1.251, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1820, src.decode.acc_seg: 93.3844, src.loss: 0.1980, mix.decode.loss_seg: 0.0950, mix.decode.acc_seg: 95.8864, mix.loss: 0.0950, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:15:08,014 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 11:16:51, time: 1.265, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1894, src.decode.acc_seg: 93.3343, src.loss: 0.2054, mix.decode.loss_seg: 0.1046, mix.decode.acc_seg: 95.5117, mix.loss: 0.1046, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:16:11,243 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 11:16:44, time: 1.265, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1736, src.decode.acc_seg: 93.6015, src.loss: 0.1897, mix.decode.loss_seg: 0.1034, mix.decode.acc_seg: 95.4960, mix.loss: 0.1034, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:17:14,122 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 11:16:32, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1893, src.decode.acc_seg: 93.1190, src.loss: 0.2054, mix.decode.loss_seg: 0.1159, mix.decode.acc_seg: 95.2523, mix.loss: 0.1159, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:18:17,702 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 11:16:25, time: 1.272, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.1896, src.decode.acc_seg: 93.5312, src.loss: 0.2057, mix.decode.loss_seg: 0.1132, mix.decode.acc_seg: 95.2888, mix.loss: 0.1132, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:19:20,382 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 11:16:10, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1750, src.decode.acc_seg: 93.9043, src.loss: 0.1911, mix.decode.loss_seg: 0.0947, mix.decode.acc_seg: 95.8975, mix.loss: 0.0947, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:20:22,441 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 11:15:48, time: 1.241, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1805, src.decode.acc_seg: 93.5194, src.loss: 0.1966, mix.decode.loss_seg: 0.1010, mix.decode.acc_seg: 96.0904, mix.loss: 0.1010, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:21:25,490 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 11:15:34, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2080, src.decode.acc_seg: 92.6829, src.loss: 0.2240, mix.decode.loss_seg: 0.1190, mix.decode.acc_seg: 95.5953, mix.loss: 0.1190, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:22:28,965 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 11:15:21, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.2011, src.decode.acc_seg: 92.5886, src.loss: 0.2172, mix.decode.loss_seg: 0.1245, mix.decode.acc_seg: 94.7749, mix.loss: 0.1245, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:23:31,101 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 11:14:58, time: 1.243, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1706, src.decode.acc_seg: 93.7938, src.loss: 0.1866, mix.decode.loss_seg: 0.0976, mix.decode.acc_seg: 95.7871, mix.loss: 0.0976, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:24:33,557 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 11:14:36, time: 1.249, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1715, src.decode.acc_seg: 94.2662, src.loss: 0.1876, mix.decode.loss_seg: 0.1042, mix.decode.acc_seg: 95.8097, mix.loss: 0.1042, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:25:36,658 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 11:14:18, time: 1.262, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1785, src.decode.acc_seg: 93.9824, src.loss: 0.1945, mix.decode.loss_seg: 0.1233, mix.decode.acc_seg: 95.4593, mix.loss: 0.1233, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:26:39,609 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 11:13:58, time: 1.259, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1476, src.decode.acc_seg: 94.7877, src.loss: 0.1637, mix.decode.loss_seg: 0.0928, mix.decode.acc_seg: 96.0487, mix.loss: 0.0928, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:27:42,867 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 10:27:42,867 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 11:13:40, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.2366, src.decode.acc_seg: 91.9625, src.loss: 0.2526, mix.decode.loss_seg: 0.1417, mix.decode.acc_seg: 94.6095, mix.loss: 0.1417, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:28:45,614 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 11:13:16, time: 1.255, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2051, src.decode.acc_seg: 92.3884, src.loss: 0.2212, mix.decode.loss_seg: 0.1045, mix.decode.acc_seg: 95.5597, mix.loss: 0.1045, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:29:48,376 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 11:12:53, time: 1.255, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1749, src.decode.acc_seg: 93.4494, src.loss: 0.1909, mix.decode.loss_seg: 0.0976, mix.decode.acc_seg: 95.6485, mix.loss: 0.0976, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:30:50,827 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 11:12:26, time: 1.249, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1641, src.decode.acc_seg: 94.2617, src.loss: 0.1802, mix.decode.loss_seg: 0.0864, mix.decode.acc_seg: 96.0106, mix.loss: 0.0864, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:31:53,788 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 11:12:02, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1888, src.decode.acc_seg: 93.0827, src.loss: 0.2049, mix.decode.loss_seg: 0.1131, mix.decode.acc_seg: 95.2429, mix.loss: 0.1131, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:32:56,601 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 11:11:36, time: 1.256, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.2111, src.decode.acc_seg: 92.4017, src.loss: 0.2272, mix.decode.loss_seg: 0.1182, mix.decode.acc_seg: 94.9475, mix.loss: 0.1182, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:33:59,439 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 11:11:10, time: 1.257, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1822, src.decode.acc_seg: 93.5558, src.loss: 0.1982, mix.decode.loss_seg: 0.0868, mix.decode.acc_seg: 96.4936, mix.loss: 0.0868, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:35:02,272 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 11:10:43, time: 1.257, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1828, src.decode.acc_seg: 93.8305, src.loss: 0.1988, mix.decode.loss_seg: 0.1041, mix.decode.acc_seg: 95.6868, mix.loss: 0.1041, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:36:05,161 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 11:10:16, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1849, src.decode.acc_seg: 93.4721, src.loss: 0.2010, mix.decode.loss_seg: 0.1083, mix.decode.acc_seg: 95.4499, mix.loss: 0.1083, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:37:07,488 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 11:09:45, time: 1.247, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1967, src.decode.acc_seg: 93.0429, src.loss: 0.2128, mix.decode.loss_seg: 0.0995, mix.decode.acc_seg: 95.8261, mix.loss: 0.0995, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:38:11,186 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 11:09:21, time: 1.274, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1463, src.decode.acc_seg: 94.7996, src.loss: 0.1624, mix.decode.loss_seg: 0.0903, mix.decode.acc_seg: 96.2089, mix.loss: 0.0903, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:39:13,787 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 11:08:50, time: 1.252, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1740, src.decode.acc_seg: 94.2066, src.loss: 0.1901, mix.decode.loss_seg: 0.0967, mix.decode.acc_seg: 96.1636, mix.loss: 0.0967, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:40:16,677 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 11:08:21, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1732, src.decode.acc_seg: 93.6745, src.loss: 0.1893, mix.decode.loss_seg: 0.0896, mix.decode.acc_seg: 96.2887, mix.loss: 0.0896, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:41:18,608 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 11:07:45, time: 1.239, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1840, src.decode.acc_seg: 93.0788, src.loss: 0.2000, mix.decode.loss_seg: 0.1087, mix.decode.acc_seg: 95.4015, mix.loss: 0.1087, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:42:21,636 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 11:07:15, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1775, src.decode.acc_seg: 93.0481, src.loss: 0.1936, mix.decode.loss_seg: 0.1155, mix.decode.acc_seg: 95.1188, mix.loss: 0.1155, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:43:24,729 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 11:06:44, time: 1.262, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1856, src.decode.acc_seg: 93.4041, src.loss: 0.2016, mix.decode.loss_seg: 0.1082, mix.decode.acc_seg: 95.5277, mix.loss: 0.1082, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:44:27,604 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 11:06:12, time: 1.257, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1724, src.decode.acc_seg: 94.1743, src.loss: 0.1885, mix.decode.loss_seg: 0.0986, mix.decode.acc_seg: 96.0745, mix.loss: 0.0986, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:45:31,123 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 11:05:44, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1928, src.decode.acc_seg: 93.1314, src.loss: 0.2089, mix.decode.loss_seg: 0.1062, mix.decode.acc_seg: 95.3748, mix.loss: 0.1062, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:46:33,766 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 11:05:09, time: 1.253, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1433, src.decode.acc_seg: 94.6057, src.loss: 0.1594, mix.decode.loss_seg: 0.0920, mix.decode.acc_seg: 95.9797, mix.loss: 0.0920, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:47:36,649 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 11:04:36, time: 1.258, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1992, src.decode.acc_seg: 93.0552, src.loss: 0.2153, mix.decode.loss_seg: 0.1335, mix.decode.acc_seg: 95.2754, mix.loss: 0.1335, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:48:39,242 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 10:48:39,243 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 11:04:00, time: 1.252, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1732, src.decode.acc_seg: 93.8611, src.loss: 0.1892, mix.decode.loss_seg: 0.0962, mix.decode.acc_seg: 95.9891, mix.loss: 0.0962, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:49:42,729 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 11:03:29, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1421, src.decode.acc_seg: 94.6078, src.loss: 0.1582, mix.decode.loss_seg: 0.0845, mix.decode.acc_seg: 96.3551, mix.loss: 0.0845, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:50:46,035 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 11:02:56, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1598, src.decode.acc_seg: 94.3407, src.loss: 0.1758, mix.decode.loss_seg: 0.1002, mix.decode.acc_seg: 95.9514, mix.loss: 0.1002, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:51:49,038 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 11:02:21, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1693, src.decode.acc_seg: 93.6894, src.loss: 0.1853, mix.decode.loss_seg: 0.0872, mix.decode.acc_seg: 96.2537, mix.loss: 0.0872, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:52:51,823 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 11:01:45, time: 1.256, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1713, src.decode.acc_seg: 94.4188, src.loss: 0.1874, mix.decode.loss_seg: 0.1039, mix.decode.acc_seg: 96.2087, mix.loss: 0.1039, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:53:54,927 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 11:01:10, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1515, src.decode.acc_seg: 94.5833, src.loss: 0.1676, mix.decode.loss_seg: 0.0842, mix.decode.acc_seg: 96.7270, mix.loss: 0.0842, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:54:58,458 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 11:00:36, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1626, src.decode.acc_seg: 94.2584, src.loss: 0.1786, mix.decode.loss_seg: 0.1003, mix.decode.acc_seg: 96.2686, mix.loss: 0.1003, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:56:01,762 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 11:00:02, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1829, src.decode.acc_seg: 93.0724, src.loss: 0.1989, mix.decode.loss_seg: 0.0950, mix.decode.acc_seg: 96.3153, mix.loss: 0.0950, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:57:04,622 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 10:59:24, time: 1.257, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1782, src.decode.acc_seg: 93.9139, src.loss: 0.1943, mix.decode.loss_seg: 0.1163, mix.decode.acc_seg: 95.5854, mix.loss: 0.1163, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:58:06,982 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 10:58:43, time: 1.247, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1436, src.decode.acc_seg: 94.9347, src.loss: 0.1596, mix.decode.loss_seg: 0.0925, mix.decode.acc_seg: 96.0601, mix.loss: 0.0925, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 10:59:10,016 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 10:58:05, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1412, src.decode.acc_seg: 94.8387, src.loss: 0.1572, mix.decode.loss_seg: 0.0802, mix.decode.acc_seg: 96.7199, mix.loss: 0.0802, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:00:13,319 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 10:57:29, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1610, src.decode.acc_seg: 94.1120, src.loss: 0.1771, mix.decode.loss_seg: 0.0951, mix.decode.acc_seg: 96.1430, mix.loss: 0.0951, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:01:16,530 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 10:56:51, time: 1.264, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1434, src.decode.acc_seg: 95.2445, src.loss: 0.1594, mix.decode.loss_seg: 0.0814, mix.decode.acc_seg: 96.7191, mix.loss: 0.0814, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:02:19,464 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 10:56:12, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1489, src.decode.acc_seg: 94.7200, src.loss: 0.1650, mix.decode.loss_seg: 0.0881, mix.decode.acc_seg: 96.7241, mix.loss: 0.0881, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:03:22,543 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 10:55:33, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1562, src.decode.acc_seg: 94.2816, src.loss: 0.1722, mix.decode.loss_seg: 0.0797, mix.decode.acc_seg: 96.6230, mix.loss: 0.0797, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:04:25,548 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 10:54:53, time: 1.260, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1460, src.decode.acc_seg: 94.4504, src.loss: 0.1621, mix.decode.loss_seg: 0.1028, mix.decode.acc_seg: 95.7635, mix.loss: 0.1028, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:05:28,476 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 10:54:13, time: 1.259, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1337, src.decode.acc_seg: 95.2157, src.loss: 0.1498, mix.decode.loss_seg: 0.0818, mix.decode.acc_seg: 96.5301, mix.loss: 0.0818, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0161, tgt.loss: 0.0161/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:06:32,033 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 10:53:35, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1414, src.decode.acc_seg: 95.0508, src.loss: 0.1574, mix.decode.loss_seg: 0.0849, mix.decode.acc_seg: 96.2177, mix.loss: 0.0849, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:07:34,414 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 10:52:52, time: 1.248, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1466, src.decode.acc_seg: 94.9066, src.loss: 0.1627, mix.decode.loss_seg: 0.1062, mix.decode.acc_seg: 95.9107, mix.loss: 0.1062, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:08:37,439 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 10:52:11, time: 1.260, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1493, src.decode.acc_seg: 94.5847, src.loss: 0.1653, mix.decode.loss_seg: 0.0986, mix.decode.acc_seg: 95.8305, mix.loss: 0.0986, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:09:40,142 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 11:09:40,142 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 10:51:28, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1714, src.decode.acc_seg: 93.7747, src.loss: 0.1874, mix.decode.loss_seg: 0.0891, mix.decode.acc_seg: 96.2359, mix.loss: 0.0891, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:10:43,170 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 10:50:47, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1620, src.decode.acc_seg: 93.9656, src.loss: 0.1781, mix.decode.loss_seg: 0.0949, mix.decode.acc_seg: 96.4283, mix.loss: 0.0949, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:11:46,076 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 10:50:05, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1784, src.decode.acc_seg: 93.5099, src.loss: 0.1945, mix.decode.loss_seg: 0.1042, mix.decode.acc_seg: 95.9787, mix.loss: 0.1042, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:12:48,995 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 10:49:22, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1664, src.decode.acc_seg: 93.9568, src.loss: 0.1825, mix.decode.loss_seg: 0.0894, mix.decode.acc_seg: 96.1422, mix.loss: 0.0894, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:13:52,719 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 10:48:43, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1440, src.decode.acc_seg: 94.8492, src.loss: 0.1601, mix.decode.loss_seg: 0.0810, mix.decode.acc_seg: 96.5326, mix.loss: 0.0810, src.aux.loss_cl: 0.0161, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:14:55,440 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 10:47:59, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1458, src.decode.acc_seg: 94.9340, src.loss: 0.1619, mix.decode.loss_seg: 0.0788, mix.decode.acc_seg: 96.3854, mix.loss: 0.0788, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:15:58,388 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 10:47:16, time: 1.259, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1455, src.decode.acc_seg: 95.1148, src.loss: 0.1615, mix.decode.loss_seg: 0.0854, mix.decode.acc_seg: 96.5551, mix.loss: 0.0854, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:17:01,341 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 10:46:32, time: 1.259, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1706, src.decode.acc_seg: 93.8502, src.loss: 0.1867, mix.decode.loss_seg: 0.0832, mix.decode.acc_seg: 96.5119, mix.loss: 0.0832, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:18:04,242 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 10:45:48, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1632, src.decode.acc_seg: 93.8391, src.loss: 0.1792, mix.decode.loss_seg: 0.0911, mix.decode.acc_seg: 96.2105, mix.loss: 0.0911, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:19:07,723 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 10:45:06, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1247, src.decode.acc_seg: 95.3456, src.loss: 0.1408, mix.decode.loss_seg: 0.0700, mix.decode.acc_seg: 96.9886, mix.loss: 0.0700, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:20:10,860 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 10:44:23, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1321, src.decode.acc_seg: 95.4454, src.loss: 0.1482, mix.decode.loss_seg: 0.0713, mix.decode.acc_seg: 97.1388, mix.loss: 0.0713, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:21:13,166 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 10:43:35, time: 1.246, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1315, src.decode.acc_seg: 95.2328, src.loss: 0.1476, mix.decode.loss_seg: 0.0956, mix.decode.acc_seg: 96.2187, mix.loss: 0.0956, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:22:16,671 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 10:42:53, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1658, src.decode.acc_seg: 94.5363, src.loss: 0.1818, mix.decode.loss_seg: 0.0954, mix.decode.acc_seg: 96.2588, mix.loss: 0.0954, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:23:18,966 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 10:42:05, time: 1.246, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1422, src.decode.acc_seg: 94.7975, src.loss: 0.1582, mix.decode.loss_seg: 0.0852, mix.decode.acc_seg: 96.4768, mix.loss: 0.0852, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:24:22,134 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 10:41:21, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1278, src.decode.acc_seg: 95.3198, src.loss: 0.1439, mix.decode.loss_seg: 0.0815, mix.decode.acc_seg: 96.6336, mix.loss: 0.0815, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:25:25,766 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 10:40:38, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1614, src.decode.acc_seg: 94.4738, src.loss: 0.1775, mix.decode.loss_seg: 0.0792, mix.decode.acc_seg: 97.1944, mix.loss: 0.0792, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:26:29,212 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 10:39:54, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1449, src.decode.acc_seg: 94.5226, src.loss: 0.1610, mix.decode.loss_seg: 0.0781, mix.decode.acc_seg: 96.8868, mix.loss: 0.0781, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:27:31,475 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 10:39:06, time: 1.245, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1668, src.decode.acc_seg: 94.0534, src.loss: 0.1829, mix.decode.loss_seg: 0.0779, mix.decode.acc_seg: 97.0445, mix.loss: 0.0779, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:28:35,389 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 10:38:23, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1549, src.decode.acc_seg: 94.3587, src.loss: 0.1710, mix.decode.loss_seg: 0.0797, mix.decode.acc_seg: 97.0049, mix.loss: 0.0797, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:29:38,316 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 10:37:37, time: 1.259, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1553, src.decode.acc_seg: 94.6402, src.loss: 0.1714, mix.decode.loss_seg: 0.1022, mix.decode.acc_seg: 96.2248, mix.loss: 0.1022, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.7 task/s, elapsed: 1s, ETA:  1294s[                                 ] 2/929, 1.3 task/s, elapsed: 2s, ETA:   728s[                                 ] 3/929, 1.8 task/s, elapsed: 2s, ETA:   520s[                                 ] 4/929, 2.2 task/s, elapsed: 2s, ETA:   425s[                                 ] 5/929, 2.5 task/s, elapsed: 2s, ETA:   368s[                                 ] 6/929, 2.8 task/s, elapsed: 2s, ETA:   328s[                                 ] 7/929, 3.1 task/s, elapsed: 2s, ETA:   300s[                                 ] 8/929, 3.3 task/s, elapsed: 2s, ETA:   278s[                                 ] 9/929, 3.5 task/s, elapsed: 3s, ETA:   262s[                                ] 10/929, 3.7 task/s, elapsed: 3s, ETA:   246s[                                ] 11/929, 3.9 task/s, elapsed: 3s, ETA:   237s[                                ] 12/929, 4.0 task/s, elapsed: 3s, ETA:   228s[                                ] 13/929, 4.2 task/s, elapsed: 3s, ETA:   219s[                                ] 14/929, 4.3 task/s, elapsed: 3s, ETA:   212s[                                ] 15/929, 4.4 task/s, elapsed: 3s, ETA:   207s[                                ] 16/929, 4.5 task/s, elapsed: 4s, ETA:   202s[                                ] 17/929, 4.6 task/s, elapsed: 4s, ETA:   197s[                                ] 18/929, 4.7 task/s, elapsed: 4s, ETA:   192s[                                ] 19/929, 4.9 task/s, elapsed: 4s, ETA:   188s[                                ] 20/929, 5.0 task/s, elapsed: 4s, ETA:   184s[                                ] 21/929, 5.0 task/s, elapsed: 4s, ETA:   181s[                                ] 22/929, 5.1 task/s, elapsed: 4s, ETA:   179s[                                ] 23/929, 5.1 task/s, elapsed: 4s, ETA:   176s[                                ] 24/929, 5.2 task/s, elapsed: 5s, ETA:   175s[                                ] 25/929, 5.2 task/s, elapsed: 5s, ETA:   172s[                                ] 26/929, 5.3 task/s, elapsed: 5s, ETA:   170s[                                ] 27/929, 5.4 task/s, elapsed: 5s, ETA:   168s[                                ] 28/929, 5.4 task/s, elapsed: 5s, ETA:   167s[                                ] 29/929, 5.5 task/s, elapsed: 5s, ETA:   164s[>                               ] 30/929, 5.5 task/s, elapsed: 5s, ETA:   163s[>                               ] 31/929, 5.6 task/s, elapsed: 6s, ETA:   161s[>                               ] 32/929, 5.6 task/s, elapsed: 6s, ETA:   160s[>                               ] 33/929, 5.6 task/s, elapsed: 6s, ETA:   159s[>                               ] 34/929, 5.7 task/s, elapsed: 6s, ETA:   157s[>                               ] 35/929, 5.7 task/s, elapsed: 6s, ETA:   156s[>                               ] 36/929, 5.7 task/s, elapsed: 6s, ETA:   155s[>                               ] 37/929, 5.8 task/s, elapsed: 6s, ETA:   154s[>                               ] 38/929, 5.8 task/s, elapsed: 6s, ETA:   152s[>                               ] 39/929, 5.9 task/s, elapsed: 7s, ETA:   151s[>                               ] 40/929, 5.9 task/s, elapsed: 7s, ETA:   150s[>                               ] 41/929, 6.0 task/s, elapsed: 7s, ETA:   149s[>                               ] 42/929, 6.0 task/s, elapsed: 7s, ETA:   148s[>                               ] 43/929, 6.0 task/s, elapsed: 7s, ETA:   146s[>                               ] 44/929, 6.1 task/s, elapsed: 7s, ETA:   146s[>                               ] 45/929, 6.1 task/s, elapsed: 7s, ETA:   145s[>                               ] 46/929, 6.1 task/s, elapsed: 7s, ETA:   144s[>                               ] 47/929, 6.2 task/s, elapsed: 8s, ETA:   143s[>                               ] 48/929, 6.2 task/s, elapsed: 8s, ETA:   142s[>                               ] 49/929, 6.2 task/s, elapsed: 8s, ETA:   141s[>                               ] 50/929, 6.3 task/s, elapsed: 8s, ETA:   140s[>                               ] 51/929, 6.3 task/s, elapsed: 8s, ETA:   139s[>                               ] 52/929, 6.3 task/s, elapsed: 8s, ETA:   139s[>                               ] 53/929, 6.3 task/s, elapsed: 8s, ETA:   139s[>                               ] 54/929, 6.4 task/s, elapsed: 9s, ETA:   138s[>                               ] 55/929, 6.4 task/s, elapsed: 9s, ETA:   137s[>                               ] 56/929, 6.4 task/s, elapsed: 9s, ETA:   136s[>                               ] 57/929, 6.4 task/s, elapsed: 9s, ETA:   136s[>                               ] 58/929, 6.4 task/s, elapsed: 9s, ETA:   135s[>>                              ] 59/929, 6.4 task/s, elapsed: 9s, ETA:   135s[>>                              ] 60/929, 6.4 task/s, elapsed: 9s, ETA:   135s[>>                              ] 61/929, 6.5 task/s, elapsed: 9s, ETA:   134s[>>                             ] 62/929, 6.5 task/s, elapsed: 10s, ETA:   134s[>>                             ] 63/929, 6.5 task/s, elapsed: 10s, ETA:   134s[>>                             ] 64/929, 6.4 task/s, elapsed: 10s, ETA:   134s[>>                             ] 65/929, 6.5 task/s, elapsed: 10s, ETA:   134s[>>                             ] 66/929, 6.5 task/s, elapsed: 10s, ETA:   133s[>>                             ] 67/929, 6.5 task/s, elapsed: 10s, ETA:   133s[>>                             ] 68/929, 6.5 task/s, elapsed: 10s, ETA:   132s[>>                             ] 69/929, 6.5 task/s, elapsed: 11s, ETA:   133s[>>                             ] 70/929, 6.5 task/s, elapsed: 11s, ETA:   132s[>>                             ] 71/929, 6.5 task/s, elapsed: 11s, ETA:   132s[>>                             ] 72/929, 6.5 task/s, elapsed: 11s, ETA:   132s[>>                             ] 73/929, 6.5 task/s, elapsed: 11s, ETA:   131s[>>                             ] 74/929, 6.5 task/s, elapsed: 11s, ETA:   131s[>>                             ] 75/929, 6.5 task/s, elapsed: 11s, ETA:   130s[>>                             ] 76/929, 6.5 task/s, elapsed: 12s, ETA:   130s[>>                             ] 77/929, 6.6 task/s, elapsed: 12s, ETA:   130s[>>                             ] 78/929, 6.6 task/s, elapsed: 12s, ETA:   129s[>>                             ] 79/929, 6.6 task/s, elapsed: 12s, ETA:   129s[>>                             ] 80/929, 6.6 task/s, elapsed: 12s, ETA:   129s[>>                             ] 81/929, 6.6 task/s, elapsed: 12s, ETA:   128s[>>                             ] 82/929, 6.6 task/s, elapsed: 12s, ETA:   128s[>>                             ] 83/929, 6.6 task/s, elapsed: 13s, ETA:   128s[>>                             ] 84/929, 6.6 task/s, elapsed: 13s, ETA:   128s[>>                             ] 85/929, 6.6 task/s, elapsed: 13s, ETA:   127s[>>                             ] 86/929, 6.6 task/s, elapsed: 13s, ETA:   127s[>>                             ] 87/929, 6.6 task/s, elapsed: 13s, ETA:   127s[>>                             ] 88/929, 6.7 task/s, elapsed: 13s, ETA:   126s[>>                             ] 89/929, 6.7 task/s, elapsed: 13s, ETA:   126s[>>>                            ] 90/929, 6.7 task/s, elapsed: 13s, ETA:   126s[>>>                            ] 91/929, 6.7 task/s, elapsed: 14s, ETA:   125s[>>>                            ] 92/929, 6.7 task/s, elapsed: 14s, ETA:   125s[>>>                            ] 93/929, 6.7 task/s, elapsed: 14s, ETA:   125s[>>>                            ] 94/929, 6.7 task/s, elapsed: 14s, ETA:   124s[>>>                            ] 95/929, 6.7 task/s, elapsed: 14s, ETA:   124s[>>>                            ] 96/929, 6.7 task/s, elapsed: 14s, ETA:   124s[>>>                            ] 97/929, 6.7 task/s, elapsed: 14s, ETA:   123s[>>>                            ] 98/929, 6.8 task/s, elapsed: 14s, ETA:   123s[>>>                            ] 99/929, 6.7 task/s, elapsed: 15s, ETA:   123s[>>>                           ] 100/929, 6.8 task/s, elapsed: 15s, ETA:   123s[>>>                           ] 101/929, 6.8 task/s, elapsed: 15s, ETA:   122s[>>>                           ] 102/929, 6.8 task/s, elapsed: 15s, ETA:   122s[>>>                           ] 103/929, 6.8 task/s, elapsed: 15s, ETA:   122s[>>>                           ] 104/929, 6.8 task/s, elapsed: 15s, ETA:   122s[>>>                           ] 105/929, 6.8 task/s, elapsed: 15s, ETA:   122s[>>>                           ] 106/929, 6.8 task/s, elapsed: 16s, ETA:   121s[>>>                           ] 107/929, 6.8 task/s, elapsed: 16s, ETA:   121s[>>>                           ] 108/929, 6.8 task/s, elapsed: 16s, ETA:   121s[>>>                           ] 109/929, 6.8 task/s, elapsed: 16s, ETA:   121s[>>>                           ] 110/929, 6.8 task/s, elapsed: 16s, ETA:   121s[>>>                           ] 111/929, 6.8 task/s, elapsed: 16s, ETA:   120s[>>>                           ] 112/929, 6.8 task/s, elapsed: 16s, ETA:   120s[>>>                           ] 113/929, 6.8 task/s, elapsed: 17s, ETA:   121s[>>>                           ] 114/929, 6.8 task/s, elapsed: 17s, ETA:   120s[>>>                           ] 115/929, 6.8 task/s, elapsed: 17s, ETA:   120s[>>>                           ] 116/929, 6.8 task/s, elapsed: 17s, ETA:   120s[>>>                           ] 117/929, 6.7 task/s, elapsed: 17s, ETA:   120s[>>>                           ] 118/929, 6.8 task/s, elapsed: 17s, ETA:   120s[>>>                           ] 119/929, 6.8 task/s, elapsed: 18s, ETA:   120s[>>>                           ] 120/929, 6.8 task/s, elapsed: 18s, ETA:   119s[>>>                           ] 121/929, 6.8 task/s, elapsed: 18s, ETA:   119s[>>>                           ] 122/929, 6.8 task/s, elapsed: 18s, ETA:   119s[>>>                           ] 123/929, 6.8 task/s, elapsed: 18s, ETA:   119s[>>>>                          ] 124/929, 6.8 task/s, elapsed: 18s, ETA:   118s[>>>>                          ] 125/929, 6.8 task/s, elapsed: 18s, ETA:   118s[>>>>                          ] 126/929, 6.8 task/s, elapsed: 18s, ETA:   118s[>>>>                          ] 127/929, 6.8 task/s, elapsed: 19s, ETA:   117s[>>>>                          ] 128/929, 6.8 task/s, elapsed: 19s, ETA:   117s[>>>>                          ] 129/929, 6.8 task/s, elapsed: 19s, ETA:   117s[>>>>                          ] 130/929, 6.9 task/s, elapsed: 19s, ETA:   117s[>>>>                          ] 131/929, 6.9 task/s, elapsed: 19s, ETA:   116s[>>>>                          ] 132/929, 6.9 task/s, elapsed: 19s, ETA:   116s[>>>>                          ] 133/929, 6.9 task/s, elapsed: 19s, ETA:   116s[>>>>                          ] 134/929, 6.9 task/s, elapsed: 19s, ETA:   116s[>>>>                          ] 135/929, 6.9 task/s, elapsed: 20s, ETA:   116s[>>>>                          ] 136/929, 6.9 task/s, elapsed: 20s, ETA:   115s[>>>>                          ] 137/929, 6.9 task/s, elapsed: 20s, ETA:   115s[>>>>                          ] 138/929, 6.9 task/s, elapsed: 20s, ETA:   115s[>>>>                          ] 139/929, 6.9 task/s, elapsed: 20s, ETA:   115s[>>>>                          ] 140/929, 6.9 task/s, elapsed: 20s, ETA:   115s[>>>>                          ] 141/929, 6.9 task/s, elapsed: 21s, ETA:   115s[>>>>                          ] 142/929, 6.9 task/s, elapsed: 21s, ETA:   114s[>>>>                          ] 143/929, 6.9 task/s, elapsed: 21s, ETA:   114s[>>>>                          ] 144/929, 6.9 task/s, elapsed: 21s, ETA:   114s[>>>>                          ] 145/929, 6.9 task/s, elapsed: 21s, ETA:   114s[>>>>                          ] 146/929, 6.9 task/s, elapsed: 21s, ETA:   114s[>>>>                          ] 147/929, 6.9 task/s, elapsed: 21s, ETA:   113s[>>>>                          ] 148/929, 6.9 task/s, elapsed: 21s, ETA:   113s[>>>>                          ] 149/929, 6.9 task/s, elapsed: 22s, ETA:   113s[>>>>                          ] 150/929, 6.9 task/s, elapsed: 22s, ETA:   113s[>>>>                          ] 151/929, 6.9 task/s, elapsed: 22s, ETA:   113s[>>>>                          ] 152/929, 6.9 task/s, elapsed: 22s, ETA:   113s[>>>>                          ] 153/929, 6.9 task/s, elapsed: 22s, ETA:   112s[>>>>                          ] 154/929, 6.9 task/s, elapsed: 22s, ETA:   112s[>>>>>                         ] 155/929, 6.9 task/s, elapsed: 22s, ETA:   112s[>>>>>                         ] 156/929, 6.9 task/s, elapsed: 23s, ETA:   112s[>>>>>                         ] 157/929, 6.9 task/s, elapsed: 23s, ETA:   112s[>>>>>                         ] 158/929, 6.9 task/s, elapsed: 23s, ETA:   111s[>>>>>                         ] 159/929, 6.9 task/s, elapsed: 23s, ETA:   111s[>>>>>                         ] 160/929, 6.9 task/s, elapsed: 23s, ETA:   111s[>>>>>                         ] 161/929, 6.9 task/s, elapsed: 23s, ETA:   111s[>>>>>                         ] 162/929, 6.9 task/s, elapsed: 23s, ETA:   111s[>>>>>                         ] 163/929, 6.9 task/s, elapsed: 24s, ETA:   111s[>>>>>                         ] 164/929, 6.9 task/s, elapsed: 24s, ETA:   111s[>>>>>                         ] 165/929, 6.9 task/s, elapsed: 24s, ETA:   110s[>>>>>                         ] 166/929, 6.9 task/s, elapsed: 24s, ETA:   110s[>>>>>                         ] 167/929, 6.9 task/s, elapsed: 24s, ETA:   110s[>>>>>                         ] 168/929, 6.9 task/s, elapsed: 24s, ETA:   110s[>>>>>                         ] 169/929, 6.9 task/s, elapsed: 24s, ETA:   109s[>>>>>                         ] 170/929, 6.9 task/s, elapsed: 24s, ETA:   109s[>>>>>                         ] 171/929, 7.0 task/s, elapsed: 25s, ETA:   109s[>>>>>                         ] 172/929, 7.0 task/s, elapsed: 25s, ETA:   109s[>>>>>                         ] 173/929, 7.0 task/s, elapsed: 25s, ETA:   109s[>>>>>                         ] 174/929, 7.0 task/s, elapsed: 25s, ETA:   109s[>>>>>                         ] 175/929, 7.0 task/s, elapsed: 25s, ETA:   108s[>>>>>                         ] 176/929, 7.0 task/s, elapsed: 25s, ETA:   108s[>>>>>                         ] 177/929, 7.0 task/s, elapsed: 25s, ETA:   108s[>>>>>                         ] 178/929, 7.0 task/s, elapsed: 26s, ETA:   108s[>>>>>                         ] 179/929, 7.0 task/s, elapsed: 26s, ETA:   108s[>>>>>                         ] 180/929, 7.0 task/s, elapsed: 26s, ETA:   108s[>>>>>                         ] 181/929, 7.0 task/s, elapsed: 26s, ETA:   107s[>>>>>                         ] 182/929, 7.0 task/s, elapsed: 26s, ETA:   107s[>>>>>                         ] 183/929, 7.0 task/s, elapsed: 26s, ETA:   107s[>>>>>                         ] 184/929, 7.0 task/s, elapsed: 26s, ETA:   107s[>>>>>                         ] 185/929, 7.0 task/s, elapsed: 27s, ETA:   107s[>>>>>>                        ] 186/929, 7.0 task/s, elapsed: 27s, ETA:   107s[>>>>>>                        ] 187/929, 7.0 task/s, elapsed: 27s, ETA:   107s[>>>>>>                        ] 188/929, 7.0 task/s, elapsed: 27s, ETA:   106s[>>>>>>                        ] 189/929, 7.0 task/s, elapsed: 27s, ETA:   106s[>>>>>>                        ] 190/929, 7.0 task/s, elapsed: 27s, ETA:   106s[>>>>>>                        ] 191/929, 7.0 task/s, elapsed: 27s, ETA:   106s[>>>>>>                        ] 192/929, 7.0 task/s, elapsed: 28s, ETA:   106s[>>>>>>                        ] 193/929, 7.0 task/s, elapsed: 28s, ETA:   105s[>>>>>>                        ] 194/929, 7.0 task/s, elapsed: 28s, ETA:   105s[>>>>>>                        ] 195/929, 7.0 task/s, elapsed: 28s, ETA:   105s[>>>>>>                        ] 196/929, 7.0 task/s, elapsed: 28s, ETA:   105s[>>>>>>                        ] 197/929, 7.0 task/s, elapsed: 28s, ETA:   105s[>>>>>>                        ] 198/929, 7.0 task/s, elapsed: 28s, ETA:   104s[>>>>>>                        ] 199/929, 7.0 task/s, elapsed: 28s, ETA:   104s[>>>>>>                        ] 200/929, 7.0 task/s, elapsed: 29s, ETA:   104s[>>>>>>                        ] 201/929, 7.0 task/s, elapsed: 29s, ETA:   104s[>>>>>>                        ] 202/929, 7.0 task/s, elapsed: 29s, ETA:   104s[>>>>>>                        ] 203/929, 7.0 task/s, elapsed: 29s, ETA:   104s[>>>>>>                        ] 204/929, 7.0 task/s, elapsed: 29s, ETA:   103s[>>>>>>                        ] 205/929, 7.0 task/s, elapsed: 29s, ETA:   103s[>>>>>>                        ] 206/929, 7.0 task/s, elapsed: 29s, ETA:   103s[>>>>>>                        ] 207/929, 7.0 task/s, elapsed: 30s, ETA:   103s[>>>>>>                        ] 208/929, 7.0 task/s, elapsed: 30s, ETA:   103s[>>>>>>                        ] 209/929, 7.0 task/s, elapsed: 30s, ETA:   103s[>>>>>>                        ] 210/929, 7.0 task/s, elapsed: 30s, ETA:   102s[>>>>>>                        ] 211/929, 7.0 task/s, elapsed: 30s, ETA:   102s[>>>>>>                        ] 212/929, 7.0 task/s, elapsed: 30s, ETA:   102s[>>>>>>                        ] 213/929, 7.0 task/s, elapsed: 30s, ETA:   102s[>>>>>>                        ] 214/929, 7.0 task/s, elapsed: 30s, ETA:   102s[>>>>>>                        ] 215/929, 7.0 task/s, elapsed: 31s, ETA:   102s[>>>>>>                        ] 216/929, 7.0 task/s, elapsed: 31s, ETA:   101s[>>>>>>>                       ] 217/929, 7.0 task/s, elapsed: 31s, ETA:   101s[>>>>>>>                       ] 218/929, 7.0 task/s, elapsed: 31s, ETA:   101s[>>>>>>>                       ] 219/929, 7.0 task/s, elapsed: 31s, ETA:   101s[>>>>>>>                       ] 220/929, 7.0 task/s, elapsed: 31s, ETA:   101s[>>>>>>>                       ] 221/929, 7.0 task/s, elapsed: 31s, ETA:   101s[>>>>>>>                       ] 222/929, 7.0 task/s, elapsed: 32s, ETA:   100s[>>>>>>>                       ] 223/929, 7.0 task/s, elapsed: 32s, ETA:   100s[>>>>>>>                       ] 224/929, 7.0 task/s, elapsed: 32s, ETA:   100s[>>>>>>>                       ] 225/929, 7.0 task/s, elapsed: 32s, ETA:   100s[>>>>>>>                       ] 226/929, 7.0 task/s, elapsed: 32s, ETA:   100s[>>>>>>>                       ] 227/929, 7.0 task/s, elapsed: 32s, ETA:   100s[>>>>>>>                       ] 228/929, 7.0 task/s, elapsed: 32s, ETA:   100s[>>>>>>>                       ] 229/929, 7.0 task/s, elapsed: 33s, ETA:   100s[>>>>>>>                       ] 230/929, 7.0 task/s, elapsed: 33s, ETA:    99s[>>>>>>>                       ] 231/929, 7.0 task/s, elapsed: 33s, ETA:    99s[>>>>>>>                       ] 232/929, 7.0 task/s, elapsed: 33s, ETA:    99s[>>>>>>>                       ] 233/929, 7.0 task/s, elapsed: 33s, ETA:    99s[>>>>>>>                       ] 234/929, 7.0 task/s, elapsed: 33s, ETA:    99s[>>>>>>>                       ] 235/929, 7.0 task/s, elapsed: 33s, ETA:    99s[>>>>>>>                       ] 236/929, 7.0 task/s, elapsed: 34s, ETA:    98s[>>>>>>>                       ] 237/929, 7.0 task/s, elapsed: 34s, ETA:    98s[>>>>>>>                       ] 238/929, 7.0 task/s, elapsed: 34s, ETA:    98s[>>>>>>>                       ] 239/929, 7.0 task/s, elapsed: 34s, ETA:    98s[>>>>>>>                       ] 240/929, 7.0 task/s, elapsed: 34s, ETA:    98s[>>>>>>>                       ] 241/929, 7.0 task/s, elapsed: 34s, ETA:    98s[>>>>>>>                       ] 242/929, 7.0 task/s, elapsed: 34s, ETA:    98s[>>>>>>>                       ] 243/929, 7.0 task/s, elapsed: 35s, ETA:    97s[>>>>>>>                       ] 244/929, 7.0 task/s, elapsed: 35s, ETA:    97s[>>>>>>>                       ] 245/929, 7.0 task/s, elapsed: 35s, ETA:    97s[>>>>>>>                       ] 246/929, 7.0 task/s, elapsed: 35s, ETA:    97s[>>>>>>>                       ] 247/929, 7.1 task/s, elapsed: 35s, ETA:    97s[>>>>>>>>                      ] 248/929, 7.0 task/s, elapsed: 35s, ETA:    97s[>>>>>>>>                      ] 249/929, 7.1 task/s, elapsed: 35s, ETA:    96s[>>>>>>>>                      ] 250/929, 7.1 task/s, elapsed: 35s, ETA:    96s[>>>>>>>>                      ] 251/929, 7.1 task/s, elapsed: 36s, ETA:    96s[>>>>>>>>                      ] 252/929, 7.1 task/s, elapsed: 36s, ETA:    96s[>>>>>>>>                      ] 253/929, 7.1 task/s, elapsed: 36s, ETA:    96s[>>>>>>>>                      ] 254/929, 7.1 task/s, elapsed: 36s, ETA:    96s[>>>>>>>>                      ] 255/929, 7.1 task/s, elapsed: 36s, ETA:    95s[>>>>>>>>                      ] 256/929, 7.1 task/s, elapsed: 36s, ETA:    95s[>>>>>>>>                      ] 257/929, 7.1 task/s, elapsed: 36s, ETA:    95s[>>>>>>>>                      ] 258/929, 7.1 task/s, elapsed: 37s, ETA:    95s[>>>>>>>>                      ] 259/929, 7.1 task/s, elapsed: 37s, ETA:    95s[>>>>>>>>                      ] 260/929, 7.1 task/s, elapsed: 37s, ETA:    95s[>>>>>>>>                      ] 261/929, 7.1 task/s, elapsed: 37s, ETA:    95s[>>>>>>>>                      ] 262/929, 7.1 task/s, elapsed: 37s, ETA:    94s[>>>>>>>>                      ] 263/929, 7.1 task/s, elapsed: 37s, ETA:    94s[>>>>>>>>                      ] 264/929, 7.1 task/s, elapsed: 37s, ETA:    94s[>>>>>>>>                      ] 265/929, 7.1 task/s, elapsed: 38s, ETA:    94s[>>>>>>>>                      ] 266/929, 7.1 task/s, elapsed: 38s, ETA:    94s[>>>>>>>>                      ] 267/929, 7.1 task/s, elapsed: 38s, ETA:    94s[>>>>>>>>                      ] 268/929, 7.1 task/s, elapsed: 38s, ETA:    94s[>>>>>>>>                      ] 269/929, 7.1 task/s, elapsed: 38s, ETA:    94s[>>>>>>>>                      ] 270/929, 7.1 task/s, elapsed: 38s, ETA:    93s[>>>>>>>>                      ] 271/929, 7.1 task/s, elapsed: 38s, ETA:    93s[>>>>>>>>                      ] 272/929, 7.1 task/s, elapsed: 39s, ETA:    93s[>>>>>>>>                      ] 273/929, 7.1 task/s, elapsed: 39s, ETA:    93s[>>>>>>>>                      ] 274/929, 7.1 task/s, elapsed: 39s, ETA:    93s[>>>>>>>>                      ] 275/929, 7.1 task/s, elapsed: 39s, ETA:    93s[>>>>>>>>                      ] 276/929, 7.1 task/s, elapsed: 39s, ETA:    93s[>>>>>>>>                      ] 277/929, 7.1 task/s, elapsed: 39s, ETA:    92s[>>>>>>>>                      ] 278/929, 7.1 task/s, elapsed: 39s, ETA:    92s[>>>>>>>>>                     ] 279/929, 7.1 task/s, elapsed: 39s, ETA:    92s[>>>>>>>>>                     ] 280/929, 7.1 task/s, elapsed: 40s, ETA:    92s[>>>>>>>>>                     ] 281/929, 7.1 task/s, elapsed: 40s, ETA:    92s[>>>>>>>>>                     ] 282/929, 7.1 task/s, elapsed: 40s, ETA:    91s[>>>>>>>>>                     ] 283/929, 7.1 task/s, elapsed: 40s, ETA:    91s[>>>>>>>>>                     ] 284/929, 7.1 task/s, elapsed: 40s, ETA:    91s[>>>>>>>>>                     ] 285/929, 7.1 task/s, elapsed: 40s, ETA:    91s[>>>>>>>>>                     ] 286/929, 7.1 task/s, elapsed: 40s, ETA:    91s[>>>>>>>>>                     ] 287/929, 7.1 task/s, elapsed: 41s, ETA:    91s[>>>>>>>>>                     ] 288/929, 7.1 task/s, elapsed: 41s, ETA:    91s[>>>>>>>>>                     ] 289/929, 7.1 task/s, elapsed: 41s, ETA:    90s[>>>>>>>>>                     ] 290/929, 7.1 task/s, elapsed: 41s, ETA:    90s[>>>>>>>>>                     ] 291/929, 7.1 task/s, elapsed: 41s, ETA:    90s[>>>>>>>>>                     ] 292/929, 7.1 task/s, elapsed: 41s, ETA:    90s[>>>>>>>>>                     ] 293/929, 7.1 task/s, elapsed: 41s, ETA:    90s[>>>>>>>>>                     ] 294/929, 7.1 task/s, elapsed: 41s, ETA:    90s[>>>>>>>>>                     ] 295/929, 7.1 task/s, elapsed: 42s, ETA:    89s[>>>>>>>>>                     ] 296/929, 7.1 task/s, elapsed: 42s, ETA:    89s[>>>>>>>>>                     ] 297/929, 7.1 task/s, elapsed: 42s, ETA:    89s[>>>>>>>>>                     ] 298/929, 7.1 task/s, elapsed: 42s, ETA:    89s[>>>>>>>>>                     ] 299/929, 7.1 task/s, elapsed: 42s, ETA:    89s[>>>>>>>>>                     ] 300/929, 7.1 task/s, elapsed: 42s, ETA:    89s[>>>>>>>>>                     ] 301/929, 7.1 task/s, elapsed: 42s, ETA:    89s[>>>>>>>>>                     ] 302/929, 7.1 task/s, elapsed: 43s, ETA:    88s[>>>>>>>>>                     ] 303/929, 7.1 task/s, elapsed: 43s, ETA:    88s[>>>>>>>>>                     ] 304/929, 7.1 task/s, elapsed: 43s, ETA:    88s[>>>>>>>>>                     ] 305/929, 7.1 task/s, elapsed: 43s, ETA:    88s[>>>>>>>>>                     ] 306/929, 7.1 task/s, elapsed: 43s, ETA:    88s[>>>>>>>>>                     ] 307/929, 7.1 task/s, elapsed: 43s, ETA:    88s[>>>>>>>>>                     ] 308/929, 7.1 task/s, elapsed: 43s, ETA:    88s[>>>>>>>>>                     ] 309/929, 7.1 task/s, elapsed: 44s, ETA:    88s[>>>>>>>>>>                    ] 310/929, 7.1 task/s, elapsed: 44s, ETA:    87s[>>>>>>>>>>                    ] 311/929, 7.1 task/s, elapsed: 44s, ETA:    87s[>>>>>>>>>>                    ] 312/929, 7.1 task/s, elapsed: 44s, ETA:    87s[>>>>>>>>>>                    ] 313/929, 7.1 task/s, elapsed: 44s, ETA:    87s[>>>>>>>>>>                    ] 314/929, 7.1 task/s, elapsed: 44s, ETA:    87s[>>>>>>>>>>                    ] 315/929, 7.1 task/s, elapsed: 44s, ETA:    87s[>>>>>>>>>>                    ] 316/929, 7.1 task/s, elapsed: 45s, ETA:    86s[>>>>>>>>>>                    ] 317/929, 7.1 task/s, elapsed: 45s, ETA:    86s[>>>>>>>>>>                    ] 318/929, 7.1 task/s, elapsed: 45s, ETA:    86s[>>>>>>>>>>                    ] 319/929, 7.1 task/s, elapsed: 45s, ETA:    86s[>>>>>>>>>>                    ] 320/929, 7.1 task/s, elapsed: 45s, ETA:    86s[>>>>>>>>>>                    ] 321/929, 7.1 task/s, elapsed: 45s, ETA:    86s[>>>>>>>>>>                    ] 322/929, 7.1 task/s, elapsed: 45s, ETA:    86s[>>>>>>>>>>                    ] 323/929, 7.1 task/s, elapsed: 46s, ETA:    85s[>>>>>>>>>>                    ] 324/929, 7.1 task/s, elapsed: 46s, ETA:    85s[>>>>>>>>>>                    ] 325/929, 7.1 task/s, elapsed: 46s, ETA:    85s[>>>>>>>>>>                    ] 326/929, 7.1 task/s, elapsed: 46s, ETA:    85s[>>>>>>>>>>                    ] 327/929, 7.1 task/s, elapsed: 46s, ETA:    85s[>>>>>>>>>>                    ] 328/929, 7.1 task/s, elapsed: 46s, ETA:    85s[>>>>>>>>>>                    ] 329/929, 7.1 task/s, elapsed: 46s, ETA:    85s[>>>>>>>>>>                    ] 330/929, 7.1 task/s, elapsed: 47s, ETA:    84s[>>>>>>>>>>                    ] 331/929, 7.1 task/s, elapsed: 47s, ETA:    84s[>>>>>>>>>>                    ] 332/929, 7.1 task/s, elapsed: 47s, ETA:    84s[>>>>>>>>>>                    ] 333/929, 7.1 task/s, elapsed: 47s, ETA:    84s[>>>>>>>>>>                    ] 334/929, 7.1 task/s, elapsed: 47s, ETA:    84s[>>>>>>>>>>                    ] 335/929, 7.1 task/s, elapsed: 47s, ETA:    84s[>>>>>>>>>>                    ] 336/929, 7.1 task/s, elapsed: 47s, ETA:    84s[>>>>>>>>>>                    ] 337/929, 7.1 task/s, elapsed: 48s, ETA:    83s[>>>>>>>>>>                    ] 338/929, 7.1 task/s, elapsed: 48s, ETA:    83s[>>>>>>>>>>                    ] 339/929, 7.1 task/s, elapsed: 48s, ETA:    83s[>>>>>>>>>>                    ] 340/929, 7.1 task/s, elapsed: 48s, ETA:    83s[>>>>>>>>>>>                   ] 341/929, 7.1 task/s, elapsed: 48s, ETA:    83s[>>>>>>>>>>>                   ] 342/929, 7.1 task/s, elapsed: 48s, ETA:    83s[>>>>>>>>>>>                   ] 343/929, 7.1 task/s, elapsed: 48s, ETA:    83s[>>>>>>>>>>>                   ] 344/929, 7.1 task/s, elapsed: 48s, ETA:    82s[>>>>>>>>>>>                   ] 345/929, 7.1 task/s, elapsed: 49s, ETA:    82s[>>>>>>>>>>>                   ] 346/929, 7.1 task/s, elapsed: 49s, ETA:    82s[>>>>>>>>>>>                   ] 347/929, 7.1 task/s, elapsed: 49s, ETA:    82s[>>>>>>>>>>>                   ] 348/929, 7.1 task/s, elapsed: 49s, ETA:    82s[>>>>>>>>>>>                   ] 349/929, 7.1 task/s, elapsed: 49s, ETA:    82s[>>>>>>>>>>>                   ] 350/929, 7.1 task/s, elapsed: 49s, ETA:    81s[>>>>>>>>>>>                   ] 351/929, 7.1 task/s, elapsed: 49s, ETA:    81s[>>>>>>>>>>>                   ] 352/929, 7.1 task/s, elapsed: 50s, ETA:    81s[>>>>>>>>>>>                   ] 353/929, 7.1 task/s, elapsed: 50s, ETA:    81s[>>>>>>>>>>>                   ] 354/929, 7.1 task/s, elapsed: 50s, ETA:    81s[>>>>>>>>>>>                   ] 355/929, 7.1 task/s, elapsed: 50s, ETA:    81s[>>>>>>>>>>>                   ] 356/929, 7.1 task/s, elapsed: 50s, ETA:    80s[>>>>>>>>>>>                   ] 357/929, 7.1 task/s, elapsed: 50s, ETA:    80s[>>>>>>>>>>>                   ] 358/929, 7.1 task/s, elapsed: 50s, ETA:    80s[>>>>>>>>>>>                   ] 359/929, 7.1 task/s, elapsed: 50s, ETA:    80s[>>>>>>>>>>>                   ] 360/929, 7.1 task/s, elapsed: 51s, ETA:    80s[>>>>>>>>>>>                   ] 361/929, 7.1 task/s, elapsed: 51s, ETA:    80s[>>>>>>>>>>>                   ] 362/929, 7.1 task/s, elapsed: 51s, ETA:    80s[>>>>>>>>>>>                   ] 363/929, 7.1 task/s, elapsed: 51s, ETA:    79s[>>>>>>>>>>>                   ] 364/929, 7.1 task/s, elapsed: 51s, ETA:    79s[>>>>>>>>>>>                   ] 365/929, 7.1 task/s, elapsed: 51s, ETA:    79s[>>>>>>>>>>>                   ] 366/929, 7.1 task/s, elapsed: 51s, ETA:    79s[>>>>>>>>>>>                   ] 367/929, 7.1 task/s, elapsed: 51s, ETA:    79s[>>>>>>>>>>>                   ] 368/929, 7.1 task/s, elapsed: 52s, ETA:    79s[>>>>>>>>>>>                   ] 369/929, 7.1 task/s, elapsed: 52s, ETA:    79s[>>>>>>>>>>>                   ] 370/929, 7.1 task/s, elapsed: 52s, ETA:    78s[>>>>>>>>>>>                   ] 371/929, 7.1 task/s, elapsed: 52s, ETA:    78s[>>>>>>>>>>>>                  ] 372/929, 7.1 task/s, elapsed: 52s, ETA:    78s[>>>>>>>>>>>>                  ] 373/929, 7.1 task/s, elapsed: 52s, ETA:    78s[>>>>>>>>>>>>                  ] 374/929, 7.1 task/s, elapsed: 52s, ETA:    78s[>>>>>>>>>>>>                  ] 375/929, 7.1 task/s, elapsed: 53s, ETA:    78s[>>>>>>>>>>>>                  ] 376/929, 7.1 task/s, elapsed: 53s, ETA:    77s[>>>>>>>>>>>>                  ] 377/929, 7.1 task/s, elapsed: 53s, ETA:    77s[>>>>>>>>>>>>                  ] 378/929, 7.1 task/s, elapsed: 53s, ETA:    77s[>>>>>>>>>>>>                  ] 379/929, 7.1 task/s, elapsed: 53s, ETA:    77s[>>>>>>>>>>>>                  ] 380/929, 7.1 task/s, elapsed: 53s, ETA:    77s[>>>>>>>>>>>>                  ] 381/929, 7.1 task/s, elapsed: 53s, ETA:    77s[>>>>>>>>>>>>                  ] 382/929, 7.1 task/s, elapsed: 54s, ETA:    77s[>>>>>>>>>>>>                  ] 383/929, 7.1 task/s, elapsed: 54s, ETA:    76s[>>>>>>>>>>>>                  ] 384/929, 7.1 task/s, elapsed: 54s, ETA:    76s[>>>>>>>>>>>>                  ] 385/929, 7.1 task/s, elapsed: 54s, ETA:    76s[>>>>>>>>>>>>                  ] 386/929, 7.1 task/s, elapsed: 54s, ETA:    76s[>>>>>>>>>>>>                  ] 387/929, 7.1 task/s, elapsed: 54s, ETA:    76s[>>>>>>>>>>>>                  ] 388/929, 7.1 task/s, elapsed: 54s, ETA:    76s[>>>>>>>>>>>>                  ] 389/929, 7.1 task/s, elapsed: 54s, ETA:    76s[>>>>>>>>>>>>                  ] 390/929, 7.2 task/s, elapsed: 55s, ETA:    75s[>>>>>>>>>>>>                  ] 391/929, 7.2 task/s, elapsed: 55s, ETA:    75s[>>>>>>>>>>>>                  ] 392/929, 7.2 task/s, elapsed: 55s, ETA:    75s[>>>>>>>>>>>>                  ] 393/929, 7.2 task/s, elapsed: 55s, ETA:    75s[>>>>>>>>>>>>                  ] 394/929, 7.2 task/s, elapsed: 55s, ETA:    75s[>>>>>>>>>>>>                  ] 395/929, 7.1 task/s, elapsed: 55s, ETA:    75s[>>>>>>>>>>>>                  ] 396/929, 7.1 task/s, elapsed: 55s, ETA:    75s[>>>>>>>>>>>>                  ] 397/929, 7.2 task/s, elapsed: 56s, ETA:    74s[>>>>>>>>>>>>                  ] 398/929, 7.1 task/s, elapsed: 56s, ETA:    74s[>>>>>>>>>>>>                  ] 399/929, 7.1 task/s, elapsed: 56s, ETA:    74s[>>>>>>>>>>>>                  ] 400/929, 7.1 task/s, elapsed: 56s, ETA:    74s[>>>>>>>>>>>>                  ] 401/929, 7.1 task/s, elapsed: 56s, ETA:    74s[>>>>>>>>>>>>                  ] 402/929, 7.1 task/s, elapsed: 56s, ETA:    74s[>>>>>>>>>>>>>                 ] 403/929, 7.1 task/s, elapsed: 56s, ETA:    74s[>>>>>>>>>>>>>                 ] 404/929, 7.1 task/s, elapsed: 57s, ETA:    73s[>>>>>>>>>>>>>                 ] 405/929, 7.1 task/s, elapsed: 57s, ETA:    73s[>>>>>>>>>>>>>                 ] 406/929, 7.1 task/s, elapsed: 57s, ETA:    73s[>>>>>>>>>>>>>                 ] 407/929, 7.1 task/s, elapsed: 57s, ETA:    73s[>>>>>>>>>>>>>                 ] 408/929, 7.1 task/s, elapsed: 57s, ETA:    73s[>>>>>>>>>>>>>                 ] 409/929, 7.1 task/s, elapsed: 57s, ETA:    73s[>>>>>>>>>>>>>                 ] 410/929, 7.1 task/s, elapsed: 57s, ETA:    73s[>>>>>>>>>>>>>                 ] 411/929, 7.1 task/s, elapsed: 58s, ETA:    73s[>>>>>>>>>>>>>                 ] 412/929, 7.1 task/s, elapsed: 58s, ETA:    72s[>>>>>>>>>>>>>                 ] 413/929, 7.1 task/s, elapsed: 58s, ETA:    72s[>>>>>>>>>>>>>                 ] 414/929, 7.1 task/s, elapsed: 58s, ETA:    72s[>>>>>>>>>>>>>                 ] 415/929, 7.1 task/s, elapsed: 58s, ETA:    72s[>>>>>>>>>>>>>                 ] 416/929, 7.1 task/s, elapsed: 58s, ETA:    72s[>>>>>>>>>>>>>                 ] 417/929, 7.1 task/s, elapsed: 58s, ETA:    72s[>>>>>>>>>>>>>                 ] 418/929, 7.1 task/s, elapsed: 59s, ETA:    72s[>>>>>>>>>>>>>                 ] 419/929, 7.1 task/s, elapsed: 59s, ETA:    71s[>>>>>>>>>>>>>                 ] 420/929, 7.1 task/s, elapsed: 59s, ETA:    71s[>>>>>>>>>>>>>                 ] 421/929, 7.1 task/s, elapsed: 59s, ETA:    71s[>>>>>>>>>>>>>                 ] 422/929, 7.1 task/s, elapsed: 59s, ETA:    71s[>>>>>>>>>>>>>                 ] 423/929, 7.1 task/s, elapsed: 59s, ETA:    71s[>>>>>>>>>>>>>                 ] 424/929, 7.1 task/s, elapsed: 59s, ETA:    71s[>>>>>>>>>>>>>                 ] 425/929, 7.1 task/s, elapsed: 59s, ETA:    71s[>>>>>>>>>>>>>                 ] 426/929, 7.1 task/s, elapsed: 60s, ETA:    70s[>>>>>>>>>>>>>                 ] 427/929, 7.1 task/s, elapsed: 60s, ETA:    70s[>>>>>>>>>>>>>                 ] 428/929, 7.1 task/s, elapsed: 60s, ETA:    70s[>>>>>>>>>>>>>                 ] 429/929, 7.2 task/s, elapsed: 60s, ETA:    70s[>>>>>>>>>>>>>                 ] 430/929, 7.2 task/s, elapsed: 60s, ETA:    70s[>>>>>>>>>>>>>                 ] 431/929, 7.2 task/s, elapsed: 60s, ETA:    70s[>>>>>>>>>>>>>                 ] 432/929, 7.2 task/s, elapsed: 60s, ETA:    69s[>>>>>>>>>>>>>                 ] 433/929, 7.1 task/s, elapsed: 61s, ETA:    69s[>>>>>>>>>>>>>>                ] 434/929, 7.1 task/s, elapsed: 61s, ETA:    69s[>>>>>>>>>>>>>>                ] 435/929, 7.1 task/s, elapsed: 61s, ETA:    69s[>>>>>>>>>>>>>>                ] 436/929, 7.1 task/s, elapsed: 61s, ETA:    69s[>>>>>>>>>>>>>>                ] 437/929, 7.1 task/s, elapsed: 61s, ETA:    69s[>>>>>>>>>>>>>>                ] 438/929, 7.1 task/s, elapsed: 61s, ETA:    69s[>>>>>>>>>>>>>>                ] 439/929, 7.2 task/s, elapsed: 61s, ETA:    69s[>>>>>>>>>>>>>>                ] 440/929, 7.1 task/s, elapsed: 62s, ETA:    68s[>>>>>>>>>>>>>>                ] 441/929, 7.1 task/s, elapsed: 62s, ETA:    68s[>>>>>>>>>>>>>>                ] 442/929, 7.1 task/s, elapsed: 62s, ETA:    68s[>>>>>>>>>>>>>>                ] 443/929, 7.1 task/s, elapsed: 62s, ETA:    68s[>>>>>>>>>>>>>>                ] 444/929, 7.1 task/s, elapsed: 62s, ETA:    68s[>>>>>>>>>>>>>>                ] 445/929, 7.1 task/s, elapsed: 62s, ETA:    68s[>>>>>>>>>>>>>>                ] 446/929, 7.2 task/s, elapsed: 62s, ETA:    68s[>>>>>>>>>>>>>>                ] 447/929, 7.2 task/s, elapsed: 63s, ETA:    67s[>>>>>>>>>>>>>>                ] 448/929, 7.2 task/s, elapsed: 63s, ETA:    67s[>>>>>>>>>>>>>>                ] 449/929, 7.2 task/s, elapsed: 63s, ETA:    67s[>>>>>>>>>>>>>>                ] 450/929, 7.2 task/s, elapsed: 63s, ETA:    67s[>>>>>>>>>>>>>>                ] 451/929, 7.2 task/s, elapsed: 63s, ETA:    67s[>>>>>>>>>>>>>>                ] 452/929, 7.1 task/s, elapsed: 63s, ETA:    67s[>>>>>>>>>>>>>>                ] 453/929, 7.1 task/s, elapsed: 63s, ETA:    67s[>>>>>>>>>>>>>>                ] 454/929, 7.2 task/s, elapsed: 63s, ETA:    66s[>>>>>>>>>>>>>>                ] 455/929, 7.2 task/s, elapsed: 64s, ETA:    66s[>>>>>>>>>>>>>>                ] 456/929, 7.2 task/s, elapsed: 64s, ETA:    66s[>>>>>>>>>>>>>>                ] 457/929, 7.2 task/s, elapsed: 64s, ETA:    66s[>>>>>>>>>>>>>>                ] 458/929, 7.2 task/s, elapsed: 64s, ETA:    66s[>>>>>>>>>>>>>>                ] 459/929, 7.2 task/s, elapsed: 64s, ETA:    66s[>>>>>>>>>>>>>>                ] 460/929, 7.2 task/s, elapsed: 64s, ETA:    66s[>>>>>>>>>>>>>>                ] 461/929, 7.2 task/s, elapsed: 64s, ETA:    65s[>>>>>>>>>>>>>>                ] 462/929, 7.2 task/s, elapsed: 65s, ETA:    65s[>>>>>>>>>>>>>>                ] 463/929, 7.2 task/s, elapsed: 65s, ETA:    65s[>>>>>>>>>>>>>>                ] 464/929, 7.2 task/s, elapsed: 65s, ETA:    65s[>>>>>>>>>>>>>>>               ] 465/929, 7.2 task/s, elapsed: 65s, ETA:    65s[>>>>>>>>>>>>>>>               ] 466/929, 7.2 task/s, elapsed: 65s, ETA:    65s[>>>>>>>>>>>>>>>               ] 467/929, 7.2 task/s, elapsed: 65s, ETA:    65s[>>>>>>>>>>>>>>>               ] 468/929, 7.2 task/s, elapsed: 65s, ETA:    64s[>>>>>>>>>>>>>>>               ] 469/929, 7.2 task/s, elapsed: 66s, ETA:    64s[>>>>>>>>>>>>>>>               ] 470/929, 7.2 task/s, elapsed: 66s, ETA:    64s[>>>>>>>>>>>>>>>               ] 471/929, 7.2 task/s, elapsed: 66s, ETA:    64s[>>>>>>>>>>>>>>>               ] 472/929, 7.2 task/s, elapsed: 66s, ETA:    64s[>>>>>>>>>>>>>>>               ] 473/929, 7.2 task/s, elapsed: 66s, ETA:    64s[>>>>>>>>>>>>>>>               ] 474/929, 7.2 task/s, elapsed: 66s, ETA:    64s[>>>>>>>>>>>>>>>               ] 475/929, 7.2 task/s, elapsed: 66s, ETA:    63s[>>>>>>>>>>>>>>>               ] 476/929, 7.2 task/s, elapsed: 67s, ETA:    63s[>>>>>>>>>>>>>>>               ] 477/929, 7.2 task/s, elapsed: 67s, ETA:    63s[>>>>>>>>>>>>>>>               ] 478/929, 7.2 task/s, elapsed: 67s, ETA:    63s[>>>>>>>>>>>>>>>               ] 479/929, 7.2 task/s, elapsed: 67s, ETA:    63s[>>>>>>>>>>>>>>>               ] 480/929, 7.2 task/s, elapsed: 67s, ETA:    63s[>>>>>>>>>>>>>>>               ] 481/929, 7.2 task/s, elapsed: 67s, ETA:    63s[>>>>>>>>>>>>>>>               ] 482/929, 7.2 task/s, elapsed: 67s, ETA:    62s[>>>>>>>>>>>>>>>               ] 483/929, 7.2 task/s, elapsed: 67s, ETA:    62s[>>>>>>>>>>>>>>>               ] 484/929, 7.2 task/s, elapsed: 68s, ETA:    62s[>>>>>>>>>>>>>>>               ] 485/929, 7.2 task/s, elapsed: 68s, ETA:    62s[>>>>>>>>>>>>>>>               ] 486/929, 7.2 task/s, elapsed: 68s, ETA:    62s[>>>>>>>>>>>>>>>               ] 487/929, 7.2 task/s, elapsed: 68s, ETA:    62s[>>>>>>>>>>>>>>>               ] 488/929, 7.2 task/s, elapsed: 68s, ETA:    62s[>>>>>>>>>>>>>>>               ] 489/929, 7.2 task/s, elapsed: 68s, ETA:    61s[>>>>>>>>>>>>>>>               ] 490/929, 7.2 task/s, elapsed: 69s, ETA:    61s[>>>>>>>>>>>>>>>               ] 491/929, 7.2 task/s, elapsed: 69s, ETA:    61s[>>>>>>>>>>>>>>>               ] 492/929, 7.2 task/s, elapsed: 69s, ETA:    61s[>>>>>>>>>>>>>>>               ] 493/929, 7.2 task/s, elapsed: 69s, ETA:    61s[>>>>>>>>>>>>>>>               ] 494/929, 7.2 task/s, elapsed: 69s, ETA:    61s[>>>>>>>>>>>>>>>               ] 495/929, 7.2 task/s, elapsed: 69s, ETA:    61s[>>>>>>>>>>>>>>>>              ] 496/929, 7.2 task/s, elapsed: 69s, ETA:    61s[>>>>>>>>>>>>>>>>              ] 497/929, 7.2 task/s, elapsed: 69s, ETA:    60s[>>>>>>>>>>>>>>>>              ] 498/929, 7.2 task/s, elapsed: 70s, ETA:    60s[>>>>>>>>>>>>>>>>              ] 499/929, 7.2 task/s, elapsed: 70s, ETA:    60s[>>>>>>>>>>>>>>>>              ] 500/929, 7.2 task/s, elapsed: 70s, ETA:    60s[>>>>>>>>>>>>>>>>              ] 501/929, 7.2 task/s, elapsed: 70s, ETA:    60s[>>>>>>>>>>>>>>>>              ] 502/929, 7.2 task/s, elapsed: 70s, ETA:    60s[>>>>>>>>>>>>>>>>              ] 503/929, 7.2 task/s, elapsed: 70s, ETA:    60s[>>>>>>>>>>>>>>>>              ] 504/929, 7.1 task/s, elapsed: 70s, ETA:    59s[>>>>>>>>>>>>>>>>              ] 505/929, 7.2 task/s, elapsed: 71s, ETA:    59s[>>>>>>>>>>>>>>>>              ] 506/929, 7.2 task/s, elapsed: 71s, ETA:    59s[>>>>>>>>>>>>>>>>              ] 507/929, 7.2 task/s, elapsed: 71s, ETA:    59s[>>>>>>>>>>>>>>>>              ] 508/929, 7.2 task/s, elapsed: 71s, ETA:    59s[>>>>>>>>>>>>>>>>              ] 509/929, 7.2 task/s, elapsed: 71s, ETA:    59s[>>>>>>>>>>>>>>>>              ] 510/929, 7.2 task/s, elapsed: 71s, ETA:    59s[>>>>>>>>>>>>>>>>              ] 511/929, 7.2 task/s, elapsed: 71s, ETA:    58s[>>>>>>>>>>>>>>>>              ] 512/929, 7.2 task/s, elapsed: 72s, ETA:    58s[>>>>>>>>>>>>>>>>              ] 513/929, 7.2 task/s, elapsed: 72s, ETA:    58s[>>>>>>>>>>>>>>>>              ] 514/929, 7.2 task/s, elapsed: 72s, ETA:    58s[>>>>>>>>>>>>>>>>              ] 515/929, 7.2 task/s, elapsed: 72s, ETA:    58s[>>>>>>>>>>>>>>>>              ] 516/929, 7.2 task/s, elapsed: 72s, ETA:    58s[>>>>>>>>>>>>>>>>              ] 517/929, 7.2 task/s, elapsed: 72s, ETA:    58s[>>>>>>>>>>>>>>>>              ] 518/929, 7.2 task/s, elapsed: 72s, ETA:    57s[>>>>>>>>>>>>>>>>              ] 519/929, 7.2 task/s, elapsed: 72s, ETA:    57s[>>>>>>>>>>>>>>>>              ] 520/929, 7.2 task/s, elapsed: 73s, ETA:    57s[>>>>>>>>>>>>>>>>              ] 521/929, 7.2 task/s, elapsed: 73s, ETA:    57s[>>>>>>>>>>>>>>>>              ] 522/929, 7.2 task/s, elapsed: 73s, ETA:    57s[>>>>>>>>>>>>>>>>              ] 523/929, 7.2 task/s, elapsed: 73s, ETA:    57s[>>>>>>>>>>>>>>>>              ] 524/929, 7.2 task/s, elapsed: 73s, ETA:    57s[>>>>>>>>>>>>>>>>              ] 525/929, 7.2 task/s, elapsed: 73s, ETA:    56s[>>>>>>>>>>>>>>>>              ] 526/929, 7.2 task/s, elapsed: 73s, ETA:    56s[>>>>>>>>>>>>>>>>>             ] 527/929, 7.2 task/s, elapsed: 74s, ETA:    56s[>>>>>>>>>>>>>>>>>             ] 528/929, 7.2 task/s, elapsed: 74s, ETA:    56s[>>>>>>>>>>>>>>>>>             ] 529/929, 7.2 task/s, elapsed: 74s, ETA:    56s[>>>>>>>>>>>>>>>>>             ] 530/929, 7.2 task/s, elapsed: 74s, ETA:    56s[>>>>>>>>>>>>>>>>>             ] 531/929, 7.2 task/s, elapsed: 74s, ETA:    56s[>>>>>>>>>>>>>>>>>             ] 532/929, 7.2 task/s, elapsed: 74s, ETA:    55s[>>>>>>>>>>>>>>>>>             ] 533/929, 7.2 task/s, elapsed: 74s, ETA:    55s[>>>>>>>>>>>>>>>>>             ] 534/929, 7.2 task/s, elapsed: 75s, ETA:    55s[>>>>>>>>>>>>>>>>>             ] 535/929, 7.2 task/s, elapsed: 75s, ETA:    55s[>>>>>>>>>>>>>>>>>             ] 536/929, 7.2 task/s, elapsed: 75s, ETA:    55s[>>>>>>>>>>>>>>>>>             ] 537/929, 7.2 task/s, elapsed: 75s, ETA:    55s[>>>>>>>>>>>>>>>>>             ] 538/929, 7.2 task/s, elapsed: 75s, ETA:    55s[>>>>>>>>>>>>>>>>>             ] 539/929, 7.2 task/s, elapsed: 75s, ETA:    54s[>>>>>>>>>>>>>>>>>             ] 540/929, 7.2 task/s, elapsed: 75s, ETA:    54s[>>>>>>>>>>>>>>>>>             ] 541/929, 7.2 task/s, elapsed: 76s, ETA:    54s[>>>>>>>>>>>>>>>>>             ] 542/929, 7.2 task/s, elapsed: 76s, ETA:    54s[>>>>>>>>>>>>>>>>>             ] 543/929, 7.2 task/s, elapsed: 76s, ETA:    54s[>>>>>>>>>>>>>>>>>             ] 544/929, 7.2 task/s, elapsed: 76s, ETA:    54s[>>>>>>>>>>>>>>>>>             ] 545/929, 7.2 task/s, elapsed: 76s, ETA:    54s[>>>>>>>>>>>>>>>>>             ] 546/929, 7.2 task/s, elapsed: 76s, ETA:    53s[>>>>>>>>>>>>>>>>>             ] 547/929, 7.2 task/s, elapsed: 76s, ETA:    53s[>>>>>>>>>>>>>>>>>             ] 548/929, 7.2 task/s, elapsed: 77s, ETA:    53s[>>>>>>>>>>>>>>>>>             ] 549/929, 7.2 task/s, elapsed: 77s, ETA:    53s[>>>>>>>>>>>>>>>>>             ] 550/929, 7.2 task/s, elapsed: 77s, ETA:    53s[>>>>>>>>>>>>>>>>>             ] 551/929, 7.2 task/s, elapsed: 77s, ETA:    53s[>>>>>>>>>>>>>>>>>             ] 552/929, 7.2 task/s, elapsed: 77s, ETA:    53s[>>>>>>>>>>>>>>>>>             ] 553/929, 7.2 task/s, elapsed: 77s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 554/929, 7.2 task/s, elapsed: 77s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 555/929, 7.2 task/s, elapsed: 77s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 556/929, 7.2 task/s, elapsed: 78s, ETA:    52s[>>>>>>>>>>>>>>>>>             ] 557/929, 7.2 task/s, elapsed: 78s, ETA:    52s[>>>>>>>>>>>>>>>>>>            ] 558/929, 7.2 task/s, elapsed: 78s, ETA:    52s[>>>>>>>>>>>>>>>>>>            ] 559/929, 7.2 task/s, elapsed: 78s, ETA:    52s[>>>>>>>>>>>>>>>>>>            ] 560/929, 7.2 task/s, elapsed: 78s, ETA:    52s[>>>>>>>>>>>>>>>>>>            ] 561/929, 7.2 task/s, elapsed: 78s, ETA:    51s[>>>>>>>>>>>>>>>>>>            ] 562/929, 7.2 task/s, elapsed: 78s, ETA:    51s[>>>>>>>>>>>>>>>>>>            ] 563/929, 7.2 task/s, elapsed: 79s, ETA:    51s[>>>>>>>>>>>>>>>>>>            ] 564/929, 7.2 task/s, elapsed: 79s, ETA:    51s[>>>>>>>>>>>>>>>>>>            ] 565/929, 7.2 task/s, elapsed: 79s, ETA:    51s[>>>>>>>>>>>>>>>>>>            ] 566/929, 7.2 task/s, elapsed: 79s, ETA:    51s[>>>>>>>>>>>>>>>>>>            ] 567/929, 7.1 task/s, elapsed: 79s, ETA:    51s[>>>>>>>>>>>>>>>>>>            ] 568/929, 7.1 task/s, elapsed: 79s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 569/929, 7.1 task/s, elapsed: 80s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 570/929, 7.2 task/s, elapsed: 80s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 571/929, 7.2 task/s, elapsed: 80s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 572/929, 7.2 task/s, elapsed: 80s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 573/929, 7.2 task/s, elapsed: 80s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 574/929, 7.1 task/s, elapsed: 80s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 575/929, 7.2 task/s, elapsed: 80s, ETA:    50s[>>>>>>>>>>>>>>>>>>            ] 576/929, 7.1 task/s, elapsed: 81s, ETA:    49s[>>>>>>>>>>>>>>>>>>            ] 577/929, 7.1 task/s, elapsed: 81s, ETA:    49s[>>>>>>>>>>>>>>>>>>            ] 578/929, 7.1 task/s, elapsed: 81s, ETA:    49s[>>>>>>>>>>>>>>>>>>            ] 579/929, 7.1 task/s, elapsed: 81s, ETA:    49s[>>>>>>>>>>>>>>>>>>            ] 580/929, 7.1 task/s, elapsed: 81s, ETA:    49s[>>>>>>>>>>>>>>>>>>            ] 581/929, 7.1 task/s, elapsed: 81s, ETA:    49s[>>>>>>>>>>>>>>>>>>            ] 582/929, 7.1 task/s, elapsed: 81s, ETA:    49s[>>>>>>>>>>>>>>>>>>            ] 583/929, 7.1 task/s, elapsed: 82s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 584/929, 7.1 task/s, elapsed: 82s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 585/929, 7.1 task/s, elapsed: 82s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 586/929, 7.1 task/s, elapsed: 82s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 587/929, 7.1 task/s, elapsed: 82s, ETA:    48s[>>>>>>>>>>>>>>>>>>            ] 588/929, 7.1 task/s, elapsed: 82s, ETA:    48s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 7.2 task/s, elapsed: 82s, ETA:    48s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 7.1 task/s, elapsed: 83s, ETA:    47s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 7.1 task/s, elapsed: 83s, ETA:    47s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 7.1 task/s, elapsed: 83s, ETA:    47s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 7.1 task/s, elapsed: 83s, ETA:    47s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 7.1 task/s, elapsed: 83s, ETA:    47s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 7.1 task/s, elapsed: 83s, ETA:    47s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 7.2 task/s, elapsed: 83s, ETA:    47s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 7.2 task/s, elapsed: 83s, ETA:    46s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 7.1 task/s, elapsed: 84s, ETA:    46s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 7.2 task/s, elapsed: 84s, ETA:    46s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 7.2 task/s, elapsed: 84s, ETA:    46s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 7.2 task/s, elapsed: 84s, ETA:    46s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 7.2 task/s, elapsed: 84s, ETA:    46s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 7.2 task/s, elapsed: 84s, ETA:    46s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 7.2 task/s, elapsed: 84s, ETA:    45s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 7.1 task/s, elapsed: 85s, ETA:    45s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 7.1 task/s, elapsed: 85s, ETA:    45s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 7.1 task/s, elapsed: 85s, ETA:    45s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 7.2 task/s, elapsed: 85s, ETA:    45s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 7.2 task/s, elapsed: 85s, ETA:    45s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 7.2 task/s, elapsed: 85s, ETA:    45s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 7.2 task/s, elapsed: 85s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 7.2 task/s, elapsed: 86s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 7.2 task/s, elapsed: 86s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 7.2 task/s, elapsed: 86s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 7.2 task/s, elapsed: 86s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 7.2 task/s, elapsed: 86s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 7.2 task/s, elapsed: 86s, ETA:    44s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 7.2 task/s, elapsed: 86s, ETA:    43s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 7.2 task/s, elapsed: 87s, ETA:    43s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 7.2 task/s, elapsed: 87s, ETA:    43s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 7.2 task/s, elapsed: 87s, ETA:    43s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 7.2 task/s, elapsed: 87s, ETA:    43s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 7.2 task/s, elapsed: 87s, ETA:    43s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 7.2 task/s, elapsed: 87s, ETA:    43s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 7.2 task/s, elapsed: 87s, ETA:    42s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 7.2 task/s, elapsed: 87s, ETA:    42s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 7.2 task/s, elapsed: 88s, ETA:    42s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 7.2 task/s, elapsed: 88s, ETA:    42s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 7.2 task/s, elapsed: 88s, ETA:    42s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 7.2 task/s, elapsed: 88s, ETA:    42s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 7.2 task/s, elapsed: 88s, ETA:    42s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 7.2 task/s, elapsed: 88s, ETA:    41s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 7.2 task/s, elapsed: 88s, ETA:    41s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 7.2 task/s, elapsed: 88s, ETA:    41s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 7.2 task/s, elapsed: 89s, ETA:    41s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 7.2 task/s, elapsed: 89s, ETA:    41s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 7.2 task/s, elapsed: 89s, ETA:    41s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 7.2 task/s, elapsed: 89s, ETA:    41s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 7.2 task/s, elapsed: 89s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 7.2 task/s, elapsed: 89s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 7.2 task/s, elapsed: 89s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 7.2 task/s, elapsed: 90s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 7.2 task/s, elapsed: 90s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 7.2 task/s, elapsed: 90s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 7.2 task/s, elapsed: 90s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 7.2 task/s, elapsed: 90s, ETA:    40s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 7.2 task/s, elapsed: 90s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 7.2 task/s, elapsed: 90s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 7.2 task/s, elapsed: 91s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 7.2 task/s, elapsed: 91s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 7.2 task/s, elapsed: 91s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 7.2 task/s, elapsed: 91s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 7.2 task/s, elapsed: 91s, ETA:    39s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 7.2 task/s, elapsed: 91s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 7.2 task/s, elapsed: 92s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 7.2 task/s, elapsed: 92s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 7.2 task/s, elapsed: 92s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 7.2 task/s, elapsed: 92s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 7.2 task/s, elapsed: 92s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 7.2 task/s, elapsed: 92s, ETA:    38s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 7.2 task/s, elapsed: 92s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 7.2 task/s, elapsed: 92s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 7.2 task/s, elapsed: 93s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 7.2 task/s, elapsed: 93s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 7.2 task/s, elapsed: 93s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 7.2 task/s, elapsed: 93s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 7.2 task/s, elapsed: 93s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 7.2 task/s, elapsed: 93s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 7.2 task/s, elapsed: 93s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 7.2 task/s, elapsed: 93s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 7.2 task/s, elapsed: 94s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 7.2 task/s, elapsed: 94s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 7.2 task/s, elapsed: 94s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 7.2 task/s, elapsed: 94s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 7.2 task/s, elapsed: 94s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 7.2 task/s, elapsed: 94s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 7.2 task/s, elapsed: 94s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 7.2 task/s, elapsed: 94s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 7.2 task/s, elapsed: 95s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 7.2 task/s, elapsed: 95s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 7.2 task/s, elapsed: 95s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 7.2 task/s, elapsed: 95s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 7.2 task/s, elapsed: 95s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 7.2 task/s, elapsed: 95s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 7.2 task/s, elapsed: 95s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 7.2 task/s, elapsed: 95s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 7.2 task/s, elapsed: 96s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 7.2 task/s, elapsed: 96s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 7.2 task/s, elapsed: 96s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 7.2 task/s, elapsed: 96s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 7.2 task/s, elapsed: 96s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 7.2 task/s, elapsed: 96s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 7.2 task/s, elapsed: 96s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 7.2 task/s, elapsed: 96s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 7.2 task/s, elapsed: 97s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 7.2 task/s, elapsed: 97s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 7.2 task/s, elapsed: 97s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 7.2 task/s, elapsed: 97s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 7.2 task/s, elapsed: 97s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 7.2 task/s, elapsed: 97s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 7.2 task/s, elapsed: 97s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 7.2 task/s, elapsed: 97s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 7.2 task/s, elapsed: 98s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 7.2 task/s, elapsed: 98s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 7.2 task/s, elapsed: 98s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 7.2 task/s, elapsed: 98s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 7.2 task/s, elapsed: 98s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 7.2 task/s, elapsed: 98s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 7.2 task/s, elapsed: 98s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 7.2 task/s, elapsed: 98s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 7.2 task/s, elapsed: 99s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 7.2 task/s, elapsed: 99s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 7.2 task/s, elapsed: 99s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 7.2 task/s, elapsed: 99s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 7.2 task/s, elapsed: 99s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 7.2 task/s, elapsed: 99s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 7.2 task/s, elapsed: 99s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 7.2 task/s, elapsed: 99s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 7.2 task/s, elapsed: 100s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 7.2 task/s, elapsed: 100s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 7.2 task/s, elapsed: 100s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 7.2 task/s, elapsed: 100s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 7.2 task/s, elapsed: 100s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 7.2 task/s, elapsed: 100s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 7.2 task/s, elapsed: 100s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 7.2 task/s, elapsed: 100s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 7.2 task/s, elapsed: 101s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 7.2 task/s, elapsed: 101s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 7.2 task/s, elapsed: 101s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 7.2 task/s, elapsed: 101s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 7.2 task/s, elapsed: 101s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 7.2 task/s, elapsed: 101s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 7.2 task/s, elapsed: 101s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 7.2 task/s, elapsed: 101s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 7.2 task/s, elapsed: 102s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 7.2 task/s, elapsed: 102s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>      ] 737/929, 7.2 task/s, elapsed: 102s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>>      ] 738/929, 7.2 task/s, elapsed: 102s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>      ] 739/929, 7.2 task/s, elapsed: 102s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>      ] 740/929, 7.2 task/s, elapsed: 102s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>      ] 741/929, 7.2 task/s, elapsed: 102s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>      ] 742/929, 7.2 task/s, elapsed: 102s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>      ] 743/929, 7.2 task/s, elapsed: 102s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 7.3 task/s, elapsed: 103s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 7.3 task/s, elapsed: 103s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 7.3 task/s, elapsed: 103s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 7.3 task/s, elapsed: 103s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 7.3 task/s, elapsed: 103s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 7.3 task/s, elapsed: 103s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 7.3 task/s, elapsed: 103s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 7.3 task/s, elapsed: 103s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 7.3 task/s, elapsed: 104s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 7.3 task/s, elapsed: 104s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 7.3 task/s, elapsed: 104s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 7.3 task/s, elapsed: 104s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 7.3 task/s, elapsed: 104s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 7.3 task/s, elapsed: 104s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 7.3 task/s, elapsed: 104s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 7.3 task/s, elapsed: 104s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 7.3 task/s, elapsed: 105s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 7.3 task/s, elapsed: 105s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 7.3 task/s, elapsed: 105s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 7.3 task/s, elapsed: 105s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 7.3 task/s, elapsed: 105s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 7.3 task/s, elapsed: 105s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 7.3 task/s, elapsed: 105s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 7.3 task/s, elapsed: 105s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 7.3 task/s, elapsed: 105s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 769/929, 7.3 task/s, elapsed: 106s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 770/929, 7.3 task/s, elapsed: 106s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 771/929, 7.3 task/s, elapsed: 106s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 772/929, 7.3 task/s, elapsed: 106s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 773/929, 7.3 task/s, elapsed: 106s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 774/929, 7.3 task/s, elapsed: 106s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 7.3 task/s, elapsed: 106s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 7.3 task/s, elapsed: 106s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 7.3 task/s, elapsed: 107s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 7.3 task/s, elapsed: 107s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 7.3 task/s, elapsed: 107s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 7.3 task/s, elapsed: 107s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 7.3 task/s, elapsed: 107s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 7.3 task/s, elapsed: 107s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 7.3 task/s, elapsed: 107s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 7.3 task/s, elapsed: 107s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 7.3 task/s, elapsed: 108s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 7.3 task/s, elapsed: 108s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 7.3 task/s, elapsed: 108s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 7.3 task/s, elapsed: 108s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 7.3 task/s, elapsed: 108s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 7.3 task/s, elapsed: 108s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 7.3 task/s, elapsed: 108s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 7.3 task/s, elapsed: 108s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 7.3 task/s, elapsed: 109s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 7.3 task/s, elapsed: 109s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 7.3 task/s, elapsed: 109s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 7.3 task/s, elapsed: 109s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 7.3 task/s, elapsed: 109s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 7.3 task/s, elapsed: 109s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 7.3 task/s, elapsed: 109s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 7.3 task/s, elapsed: 109s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 801/929, 7.3 task/s, elapsed: 109s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 802/929, 7.3 task/s, elapsed: 110s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 803/929, 7.3 task/s, elapsed: 110s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 804/929, 7.3 task/s, elapsed: 110s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 805/929, 7.3 task/s, elapsed: 110s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 7.3 task/s, elapsed: 110s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 7.3 task/s, elapsed: 110s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 7.3 task/s, elapsed: 110s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 7.3 task/s, elapsed: 110s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 7.3 task/s, elapsed: 111s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 7.3 task/s, elapsed: 111s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 7.3 task/s, elapsed: 111s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 7.3 task/s, elapsed: 111s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 7.3 task/s, elapsed: 111s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 7.3 task/s, elapsed: 111s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 7.3 task/s, elapsed: 111s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 7.3 task/s, elapsed: 111s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 7.3 task/s, elapsed: 112s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 7.3 task/s, elapsed: 112s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 7.3 task/s, elapsed: 112s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 7.3 task/s, elapsed: 112s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 7.3 task/s, elapsed: 112s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 7.3 task/s, elapsed: 112s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 7.3 task/s, elapsed: 112s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 7.3 task/s, elapsed: 112s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 7.3 task/s, elapsed: 113s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 7.3 task/s, elapsed: 113s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 7.3 task/s, elapsed: 113s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 7.3 task/s, elapsed: 113s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 7.3 task/s, elapsed: 113s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 7.3 task/s, elapsed: 113s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 7.3 task/s, elapsed: 113s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 833/929, 7.3 task/s, elapsed: 113s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 834/929, 7.4 task/s, elapsed: 113s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 835/929, 7.4 task/s, elapsed: 114s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 836/929, 7.4 task/s, elapsed: 114s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 7.4 task/s, elapsed: 114s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 7.4 task/s, elapsed: 114s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 7.4 task/s, elapsed: 114s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 7.4 task/s, elapsed: 114s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 7.4 task/s, elapsed: 114s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 7.4 task/s, elapsed: 114s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 7.4 task/s, elapsed: 115s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 7.4 task/s, elapsed: 115s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 7.4 task/s, elapsed: 115s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 7.4 task/s, elapsed: 115s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 7.4 task/s, elapsed: 115s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 7.4 task/s, elapsed: 115s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 7.4 task/s, elapsed: 115s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 7.4 task/s, elapsed: 115s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 7.4 task/s, elapsed: 116s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 7.4 task/s, elapsed: 116s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 7.4 task/s, elapsed: 116s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 7.4 task/s, elapsed: 116s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 7.4 task/s, elapsed: 116s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 7.4 task/s, elapsed: 116s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 7.4 task/s, elapsed: 116s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 7.4 task/s, elapsed: 116s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 7.4 task/s, elapsed: 116s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 7.4 task/s, elapsed: 117s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 7.4 task/s, elapsed: 117s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 7.4 task/s, elapsed: 117s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 7.4 task/s, elapsed: 117s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 7.4 task/s, elapsed: 117s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 865/929, 7.4 task/s, elapsed: 117s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 7.4 task/s, elapsed: 117s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 7.4 task/s, elapsed: 117s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 7.4 task/s, elapsed: 117s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 7.4 task/s, elapsed: 118s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 7.4 task/s, elapsed: 118s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 7.4 task/s, elapsed: 118s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 7.4 task/s, elapsed: 118s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 7.4 task/s, elapsed: 118s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 7.4 task/s, elapsed: 118s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 7.4 task/s, elapsed: 118s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 7.4 task/s, elapsed: 118s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 7.4 task/s, elapsed: 118s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 7.4 task/s, elapsed: 118s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 7.4 task/s, elapsed: 119s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 7.4 task/s, elapsed: 119s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 7.4 task/s, elapsed: 119s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 7.4 task/s, elapsed: 120s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 7.4 task/s, elapsed: 120s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 7.4 task/s, elapsed: 120s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 7.4 task/s, elapsed: 120s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 7.4 task/s, elapsed: 120s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 7.4 task/s, elapsed: 120s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 7.4 task/s, elapsed: 120s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 7.4 task/s, elapsed: 120s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 7.5 task/s, elapsed: 120s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 7.5 task/s, elapsed: 120s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 7.5 task/s, elapsed: 121s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 7.5 task/s, elapsed: 121s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 7.5 task/s, elapsed: 121s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 7.5 task/s, elapsed: 121s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 7.5 task/s, elapsed: 121s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 7.5 task/s, elapsed: 121s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 7.5 task/s, elapsed: 121s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 7.5 task/s, elapsed: 121s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 7.5 task/s, elapsed: 121s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 7.5 task/s, elapsed: 122s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 7.5 task/s, elapsed: 122s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 7.5 task/s, elapsed: 122s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 7.5 task/s, elapsed: 122s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 7.5 task/s, elapsed: 122s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 7.5 task/s, elapsed: 122s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 7.5 task/s, elapsed: 122s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 7.5 task/s, elapsed: 122s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 7.5 task/s, elapsed: 122s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 7.5 task/s, elapsed: 122s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 7.5 task/s, elapsed: 123s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 7.5 task/s, elapsed: 123s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 7.5 task/s, elapsed: 123s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 7.5 task/s, elapsed: 124s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 7.5 task/s, elapsed: 124s, ETA:     0s2022-10-10 11:33:44,300 - mmseg - INFO - per class results:2022-10-10 11:33:44,300 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 89.76 | 98.26 || rigid_plastic | 16.59 | 22.42 ||   cardboard   | 44.45 | 49.83 ||     metal     | 12.65 | 28.19 ||  soft_plastic |  56.2 | 61.29 |+---------------+-------+-------+2022-10-10 11:33:44,300 - mmseg - INFO - Summary:2022-10-10 11:33:44,300 - mmseg - INFO - +-------+-------+------+|  aAcc |  mIoU | mAcc |+-------+-------+------+| 89.98 | 43.93 | 52.0 |+-------+-------+------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:33:44,305 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 11:33:44,305 - mmseg - INFO - Iter [929/40000]	lr: 4.800e-05, eta: 10:37:15, time: 1.382, data_time: 0.017, memory: 67494, aAcc: 0.8998, mIoU: 0.4393, mAcc: 0.5200, IoU.background: 0.8976, IoU.rigid_plastic: 0.1659, IoU.cardboard: 0.4445, IoU.metal: 0.1265, IoU.soft_plastic: 0.5620, Acc.background: 0.9826, Acc.rigid_plastic: 0.2242, Acc.cardboard: 0.4983, Acc.metal: 0.2819, Acc.soft_plastic: 0.6129, src.decode.loss_seg: 0.1459, src.decode.acc_seg: 94.6251, src.loss: 0.1620, mix.decode.loss_seg: 0.0984, mix.decode.acc_seg: 96.1433, mix.loss: 0.0984, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:34:47,630 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 10:48:11, time: 4.805, data_time: 3.552, memory: 67494, src.decode.loss_seg: 0.1471, src.decode.acc_seg: 94.9775, src.loss: 0.1631, mix.decode.loss_seg: 0.1114, mix.decode.acc_seg: 95.6850, mix.loss: 0.1114, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:35:50,560 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 10:47:19, time: 1.259, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1550, src.decode.acc_seg: 94.2869, src.loss: 0.1711, mix.decode.loss_seg: 0.0954, mix.decode.acc_seg: 95.8729, mix.loss: 0.0954, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:36:53,878 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 10:46:27, time: 1.266, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1565, src.decode.acc_seg: 94.4643, src.loss: 0.1725, mix.decode.loss_seg: 0.1060, mix.decode.acc_seg: 95.7197, mix.loss: 0.1060, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:37:57,058 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 10:45:35, time: 1.264, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1804, src.decode.acc_seg: 93.3601, src.loss: 0.1964, mix.decode.loss_seg: 0.0930, mix.decode.acc_seg: 96.1889, mix.loss: 0.0930, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:38:59,767 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 10:44:41, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1562, src.decode.acc_seg: 94.5464, src.loss: 0.1722, mix.decode.loss_seg: 0.0973, mix.decode.acc_seg: 96.1000, mix.loss: 0.0973, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:40:03,019 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 10:43:49, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1449, src.decode.acc_seg: 94.7946, src.loss: 0.1610, mix.decode.loss_seg: 0.0890, mix.decode.acc_seg: 96.4641, mix.loss: 0.0890, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:41:06,451 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 10:42:58, time: 1.269, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1342, src.decode.acc_seg: 95.2949, src.loss: 0.1503, mix.decode.loss_seg: 0.0858, mix.decode.acc_seg: 96.6249, mix.loss: 0.0858, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:42:09,165 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 10:42:04, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1178, src.decode.acc_seg: 95.9246, src.loss: 0.1338, mix.decode.loss_seg: 0.0674, mix.decode.acc_seg: 97.4713, mix.loss: 0.0674, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:43:12,329 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 10:41:11, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1394, src.decode.acc_seg: 95.3066, src.loss: 0.1554, mix.decode.loss_seg: 0.0806, mix.decode.acc_seg: 96.8609, mix.loss: 0.0806, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:44:15,710 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 10:40:19, time: 1.268, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1518, src.decode.acc_seg: 94.3624, src.loss: 0.1678, mix.decode.loss_seg: 0.0862, mix.decode.acc_seg: 96.5789, mix.loss: 0.0862, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:45:18,813 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 10:39:26, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1202, src.decode.acc_seg: 95.5334, src.loss: 0.1363, mix.decode.loss_seg: 0.0888, mix.decode.acc_seg: 96.3286, mix.loss: 0.0888, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:46:22,292 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 10:38:34, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1507, src.decode.acc_seg: 94.4690, src.loss: 0.1667, mix.decode.loss_seg: 0.1100, mix.decode.acc_seg: 96.1409, mix.loss: 0.1100, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:47:25,491 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 10:37:41, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1648, src.decode.acc_seg: 94.0333, src.loss: 0.1808, mix.decode.loss_seg: 0.1039, mix.decode.acc_seg: 96.0387, mix.loss: 0.1039, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:48:29,023 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 10:36:49, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1504, src.decode.acc_seg: 94.8265, src.loss: 0.1664, mix.decode.loss_seg: 0.0744, mix.decode.acc_seg: 96.7911, mix.loss: 0.0744, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:49:32,573 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 10:35:57, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1419, src.decode.acc_seg: 94.9785, src.loss: 0.1579, mix.decode.loss_seg: 0.0839, mix.decode.acc_seg: 96.5906, mix.loss: 0.0839, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:50:36,126 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 10:35:04, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1426, src.decode.acc_seg: 94.6405, src.loss: 0.1586, mix.decode.loss_seg: 0.0807, mix.decode.acc_seg: 96.9122, mix.loss: 0.0807, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:51:39,059 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 10:34:10, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1433, src.decode.acc_seg: 95.1420, src.loss: 0.1593, mix.decode.loss_seg: 0.0926, mix.decode.acc_seg: 96.4166, mix.loss: 0.0926, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:52:42,367 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 10:33:17, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1184, src.decode.acc_seg: 95.8079, src.loss: 0.1344, mix.decode.loss_seg: 0.0705, mix.decode.acc_seg: 97.0645, mix.loss: 0.0705, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:53:45,811 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 10:32:24, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1272, src.decode.acc_seg: 95.3717, src.loss: 0.1432, mix.decode.loss_seg: 0.0649, mix.decode.acc_seg: 97.4086, mix.loss: 0.0649, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:54:48,774 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 11:54:48,775 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 10:31:29, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1134, src.decode.acc_seg: 95.8586, src.loss: 0.1294, mix.decode.loss_seg: 0.0794, mix.decode.acc_seg: 96.7448, mix.loss: 0.0794, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:55:52,097 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 10:30:35, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1352, src.decode.acc_seg: 94.9745, src.loss: 0.1512, mix.decode.loss_seg: 0.0983, mix.decode.acc_seg: 96.0789, mix.loss: 0.0983, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:56:55,180 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 10:29:41, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1305, src.decode.acc_seg: 95.1054, src.loss: 0.1466, mix.decode.loss_seg: 0.0772, mix.decode.acc_seg: 97.0618, mix.loss: 0.0772, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:57:58,780 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 10:28:48, time: 1.272, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1466, src.decode.acc_seg: 94.5479, src.loss: 0.1626, mix.decode.loss_seg: 0.0930, mix.decode.acc_seg: 96.0109, mix.loss: 0.0930, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 11:59:01,765 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 10:27:53, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1183, src.decode.acc_seg: 95.8124, src.loss: 0.1343, mix.decode.loss_seg: 0.0707, mix.decode.acc_seg: 96.9249, mix.loss: 0.0707, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:00:04,679 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 10:26:58, time: 1.258, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1326, src.decode.acc_seg: 95.7501, src.loss: 0.1487, mix.decode.loss_seg: 0.0773, mix.decode.acc_seg: 96.9826, mix.loss: 0.0773, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:01:08,085 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 10:26:04, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1252, src.decode.acc_seg: 95.4930, src.loss: 0.1412, mix.decode.loss_seg: 0.0679, mix.decode.acc_seg: 97.2763, mix.loss: 0.0679, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:02:11,136 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 10:25:09, time: 1.261, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1230, src.decode.acc_seg: 95.4581, src.loss: 0.1391, mix.decode.loss_seg: 0.0750, mix.decode.acc_seg: 97.0560, mix.loss: 0.0750, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:03:14,301 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 10:24:14, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1334, src.decode.acc_seg: 95.3663, src.loss: 0.1494, mix.decode.loss_seg: 0.0850, mix.decode.acc_seg: 96.4099, mix.loss: 0.0850, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:04:17,463 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 10:23:19, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1451, src.decode.acc_seg: 94.8532, src.loss: 0.1612, mix.decode.loss_seg: 0.0881, mix.decode.acc_seg: 96.5208, mix.loss: 0.0881, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:05:20,668 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 10:22:25, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1269, src.decode.acc_seg: 95.5148, src.loss: 0.1429, mix.decode.loss_seg: 0.0789, mix.decode.acc_seg: 96.7051, mix.loss: 0.0789, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:06:24,142 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 10:21:31, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1260, src.decode.acc_seg: 95.6508, src.loss: 0.1421, mix.decode.loss_seg: 0.0739, mix.decode.acc_seg: 97.1917, mix.loss: 0.0739, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:07:26,871 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 10:20:34, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1340, src.decode.acc_seg: 95.1571, src.loss: 0.1500, mix.decode.loss_seg: 0.0823, mix.decode.acc_seg: 96.6715, mix.loss: 0.0823, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:08:30,496 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 10:19:40, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1150, src.decode.acc_seg: 95.9184, src.loss: 0.1310, mix.decode.loss_seg: 0.0815, mix.decode.acc_seg: 96.8202, mix.loss: 0.0815, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:09:33,300 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 10:18:44, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1285, src.decode.acc_seg: 95.5065, src.loss: 0.1445, mix.decode.loss_seg: 0.0715, mix.decode.acc_seg: 97.2178, mix.loss: 0.0715, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:10:36,466 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 10:17:49, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1301, src.decode.acc_seg: 94.9966, src.loss: 0.1462, mix.decode.loss_seg: 0.0824, mix.decode.acc_seg: 96.5637, mix.loss: 0.0824, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:11:39,283 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 10:16:52, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1245, src.decode.acc_seg: 95.4146, src.loss: 0.1405, mix.decode.loss_seg: 0.0866, mix.decode.acc_seg: 96.7580, mix.loss: 0.0866, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:12:42,173 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 10:15:56, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1389, src.decode.acc_seg: 95.1407, src.loss: 0.1549, mix.decode.loss_seg: 0.0775, mix.decode.acc_seg: 96.6997, mix.loss: 0.0775, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:13:45,225 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 10:15:00, time: 1.261, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1190, src.decode.acc_seg: 95.7225, src.loss: 0.1350, mix.decode.loss_seg: 0.0853, mix.decode.acc_seg: 96.3951, mix.loss: 0.0853, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:14:48,977 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 10:14:06, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1467, src.decode.acc_seg: 94.7059, src.loss: 0.1627, mix.decode.loss_seg: 0.0875, mix.decode.acc_seg: 96.6850, mix.loss: 0.0875, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:15:52,140 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 12:15:52,140 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 10:13:10, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1352, src.decode.acc_seg: 95.3426, src.loss: 0.1513, mix.decode.loss_seg: 0.0726, mix.decode.acc_seg: 97.0839, mix.loss: 0.0726, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:16:56,144 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 10:12:17, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1204, src.decode.acc_seg: 95.7046, src.loss: 0.1364, mix.decode.loss_seg: 0.0713, mix.decode.acc_seg: 97.0468, mix.loss: 0.0713, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:17:59,303 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 10:11:21, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1321, src.decode.acc_seg: 95.2457, src.loss: 0.1482, mix.decode.loss_seg: 0.0703, mix.decode.acc_seg: 97.1719, mix.loss: 0.0703, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:19:02,398 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 10:10:25, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1073, src.decode.acc_seg: 96.2077, src.loss: 0.1233, mix.decode.loss_seg: 0.0710, mix.decode.acc_seg: 97.1507, mix.loss: 0.0710, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:20:05,546 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 10:09:29, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1438, src.decode.acc_seg: 94.8944, src.loss: 0.1599, mix.decode.loss_seg: 0.0809, mix.decode.acc_seg: 96.7828, mix.loss: 0.0809, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:21:07,899 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 10:08:30, time: 1.247, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1245, src.decode.acc_seg: 95.6458, src.loss: 0.1405, mix.decode.loss_seg: 0.0769, mix.decode.acc_seg: 96.9074, mix.loss: 0.0769, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:22:10,644 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 10:07:33, time: 1.255, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1208, src.decode.acc_seg: 95.8680, src.loss: 0.1369, mix.decode.loss_seg: 0.0804, mix.decode.acc_seg: 96.8063, mix.loss: 0.0804, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:23:14,284 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 10:06:38, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1047, src.decode.acc_seg: 96.2056, src.loss: 0.1208, mix.decode.loss_seg: 0.0651, mix.decode.acc_seg: 97.5005, mix.loss: 0.0651, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:24:17,077 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 10:05:41, time: 1.256, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1090, src.decode.acc_seg: 96.0067, src.loss: 0.1250, mix.decode.loss_seg: 0.0689, mix.decode.acc_seg: 97.1821, mix.loss: 0.0689, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:25:20,301 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 10:04:44, time: 1.264, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0988, src.decode.acc_seg: 96.5022, src.loss: 0.1149, mix.decode.loss_seg: 0.0652, mix.decode.acc_seg: 97.2965, mix.loss: 0.0652, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:26:23,384 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 10:03:48, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1200, src.decode.acc_seg: 95.4706, src.loss: 0.1361, mix.decode.loss_seg: 0.0775, mix.decode.acc_seg: 97.0062, mix.loss: 0.0775, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:27:26,517 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 10:02:51, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1262, src.decode.acc_seg: 95.4977, src.loss: 0.1422, mix.decode.loss_seg: 0.0852, mix.decode.acc_seg: 96.6873, mix.loss: 0.0852, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:28:29,690 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 10:01:55, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1187, src.decode.acc_seg: 95.8458, src.loss: 0.1348, mix.decode.loss_seg: 0.0780, mix.decode.acc_seg: 96.9423, mix.loss: 0.0780, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:29:32,835 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 10:00:58, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1208, src.decode.acc_seg: 95.4772, src.loss: 0.1369, mix.decode.loss_seg: 0.1028, mix.decode.acc_seg: 95.8289, mix.loss: 0.1028, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:30:35,898 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 10:00:01, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1159, src.decode.acc_seg: 95.8728, src.loss: 0.1320, mix.decode.loss_seg: 0.0794, mix.decode.acc_seg: 96.8467, mix.loss: 0.0794, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:31:38,780 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 9:59:04, time: 1.258, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0962, src.decode.acc_seg: 96.3822, src.loss: 0.1122, mix.decode.loss_seg: 0.0626, mix.decode.acc_seg: 97.5642, mix.loss: 0.0626, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:32:42,000 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 9:58:07, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1100, src.decode.acc_seg: 95.8617, src.loss: 0.1260, mix.decode.loss_seg: 0.0703, mix.decode.acc_seg: 97.1545, mix.loss: 0.0703, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:33:44,616 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 9:57:09, time: 1.252, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1332, src.decode.acc_seg: 95.3017, src.loss: 0.1492, mix.decode.loss_seg: 0.0809, mix.decode.acc_seg: 96.4597, mix.loss: 0.0809, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:34:47,729 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 9:56:12, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1095, src.decode.acc_seg: 95.9534, src.loss: 0.1256, mix.decode.loss_seg: 0.0713, mix.decode.acc_seg: 96.8778, mix.loss: 0.0713, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:35:50,938 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 9:55:15, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1162, src.decode.acc_seg: 95.7824, src.loss: 0.1322, mix.decode.loss_seg: 0.0550, mix.decode.acc_seg: 97.5983, mix.loss: 0.0550, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:36:53,988 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 12:36:53,988 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 9:54:17, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1009, src.decode.acc_seg: 96.3045, src.loss: 0.1169, mix.decode.loss_seg: 0.0661, mix.decode.acc_seg: 97.3303, mix.loss: 0.0661, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:37:57,233 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 9:53:21, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0867, src.decode.acc_seg: 96.8097, src.loss: 0.1028, mix.decode.loss_seg: 0.0561, mix.decode.acc_seg: 97.6879, mix.loss: 0.0561, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:39:00,310 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 9:52:23, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1170, src.decode.acc_seg: 95.7958, src.loss: 0.1331, mix.decode.loss_seg: 0.0656, mix.decode.acc_seg: 97.3470, mix.loss: 0.0656, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:40:03,422 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 9:51:26, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1152, src.decode.acc_seg: 96.0417, src.loss: 0.1313, mix.decode.loss_seg: 0.0721, mix.decode.acc_seg: 97.3799, mix.loss: 0.0721, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:41:06,388 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 9:50:28, time: 1.259, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.1021, src.decode.acc_seg: 96.1513, src.loss: 0.1182, mix.decode.loss_seg: 0.0770, mix.decode.acc_seg: 96.6966, mix.loss: 0.0770, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:42:09,502 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 9:49:31, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1150, src.decode.acc_seg: 95.8114, src.loss: 0.1310, mix.decode.loss_seg: 0.0684, mix.decode.acc_seg: 97.3064, mix.loss: 0.0684, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:43:12,330 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 9:48:33, time: 1.257, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0999, src.decode.acc_seg: 96.3411, src.loss: 0.1160, mix.decode.loss_seg: 0.0632, mix.decode.acc_seg: 97.5248, mix.loss: 0.0632, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:44:15,663 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 9:47:36, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1428, src.decode.acc_seg: 95.0904, src.loss: 0.1588, mix.decode.loss_seg: 0.0836, mix.decode.acc_seg: 96.7708, mix.loss: 0.0836, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:45:19,317 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 9:46:39, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1066, src.decode.acc_seg: 96.2572, src.loss: 0.1226, mix.decode.loss_seg: 0.0562, mix.decode.acc_seg: 97.8175, mix.loss: 0.0562, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:46:22,861 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 9:45:43, time: 1.271, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0915, src.decode.acc_seg: 96.6904, src.loss: 0.1075, mix.decode.loss_seg: 0.0641, mix.decode.acc_seg: 97.3681, mix.loss: 0.0641, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:47:25,607 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 9:44:44, time: 1.255, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1196, src.decode.acc_seg: 95.7113, src.loss: 0.1356, mix.decode.loss_seg: 0.0764, mix.decode.acc_seg: 97.1498, mix.loss: 0.0764, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:48:28,616 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 9:43:46, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0989, src.decode.acc_seg: 96.3327, src.loss: 0.1149, mix.decode.loss_seg: 0.0571, mix.decode.acc_seg: 97.5505, mix.loss: 0.0571, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:49:32,010 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 9:42:49, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0904, src.decode.acc_seg: 96.6618, src.loss: 0.1064, mix.decode.loss_seg: 0.0617, mix.decode.acc_seg: 97.4051, mix.loss: 0.0617, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:50:35,291 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 9:41:52, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0955, src.decode.acc_seg: 96.6131, src.loss: 0.1116, mix.decode.loss_seg: 0.0657, mix.decode.acc_seg: 97.2445, mix.loss: 0.0657, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:51:38,856 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 9:40:55, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1172, src.decode.acc_seg: 95.8503, src.loss: 0.1333, mix.decode.loss_seg: 0.0687, mix.decode.acc_seg: 97.3312, mix.loss: 0.0687, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:52:42,752 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 9:39:59, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1174, src.decode.acc_seg: 95.6365, src.loss: 0.1334, mix.decode.loss_seg: 0.0643, mix.decode.acc_seg: 97.2357, mix.loss: 0.0643, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:53:45,688 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 9:39:01, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1090, src.decode.acc_seg: 96.3604, src.loss: 0.1251, mix.decode.loss_seg: 0.0677, mix.decode.acc_seg: 97.2683, mix.loss: 0.0677, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:54:48,384 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 9:38:02, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1067, src.decode.acc_seg: 96.2807, src.loss: 0.1228, mix.decode.loss_seg: 0.0735, mix.decode.acc_seg: 97.2054, mix.loss: 0.0735, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:55:51,553 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 9:37:04, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0989, src.decode.acc_seg: 96.5970, src.loss: 0.1149, mix.decode.loss_seg: 0.0601, mix.decode.acc_seg: 97.4882, mix.loss: 0.0601, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 12:56:57,015 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 9:36:11, time: 1.309, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0944, src.decode.acc_seg: 96.6940, src.loss: 0.1104, mix.decode.loss_seg: 0.0464, mix.decode.acc_seg: 98.1350, mix.loss: 0.0464, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.6 task/s, elapsed: 2s, ETA:  1630s[                                 ] 2/929, 1.0 task/s, elapsed: 2s, ETA:   887s[                                 ] 3/929, 1.5 task/s, elapsed: 2s, ETA:   629s[                                 ] 4/929, 1.9 task/s, elapsed: 2s, ETA:   499s[                                 ] 5/929, 2.2 task/s, elapsed: 2s, ETA:   426s[                                 ] 6/929, 2.5 task/s, elapsed: 2s, ETA:   373s[                                 ] 7/929, 2.7 task/s, elapsed: 3s, ETA:   337s[                                 ] 8/929, 3.0 task/s, elapsed: 3s, ETA:   309s[                                 ] 9/929, 3.2 task/s, elapsed: 3s, ETA:   288s[                                ] 10/929, 3.4 task/s, elapsed: 3s, ETA:   270s[                                ] 11/929, 3.6 task/s, elapsed: 3s, ETA:   256s[                                ] 12/929, 3.8 task/s, elapsed: 3s, ETA:   243s[                                ] 13/929, 3.9 task/s, elapsed: 3s, ETA:   233s[                                ] 14/929, 4.1 task/s, elapsed: 3s, ETA:   224s[                                ] 15/929, 4.2 task/s, elapsed: 4s, ETA:   217s[                                ] 16/929, 4.3 task/s, elapsed: 4s, ETA:   211s[                                ] 17/929, 4.4 task/s, elapsed: 4s, ETA:   206s[                                ] 18/929, 4.5 task/s, elapsed: 4s, ETA:   201s[                                ] 19/929, 4.6 task/s, elapsed: 4s, ETA:   196s[                                ] 20/929, 4.7 task/s, elapsed: 4s, ETA:   192s[                                ] 21/929, 4.8 task/s, elapsed: 4s, ETA:   188s[                                ] 22/929, 4.9 task/s, elapsed: 4s, ETA:   184s[                                ] 23/929, 5.0 task/s, elapsed: 5s, ETA:   182s[                                ] 24/929, 5.0 task/s, elapsed: 5s, ETA:   180s[                                ] 25/929, 5.1 task/s, elapsed: 5s, ETA:   177s[                                ] 26/929, 5.2 task/s, elapsed: 5s, ETA:   174s[                                ] 27/929, 5.2 task/s, elapsed: 5s, ETA:   172s[                                ] 28/929, 5.3 task/s, elapsed: 5s, ETA:   170s[                                ] 29/929, 5.4 task/s, elapsed: 5s, ETA:   168s[>                               ] 30/929, 5.4 task/s, elapsed: 6s, ETA:   166s[>                               ] 31/929, 5.5 task/s, elapsed: 6s, ETA:   165s[>                               ] 32/929, 5.5 task/s, elapsed: 6s, ETA:   163s[>                               ] 33/929, 5.6 task/s, elapsed: 6s, ETA:   161s[>                               ] 34/929, 5.6 task/s, elapsed: 6s, ETA:   159s[>                               ] 35/929, 5.7 task/s, elapsed: 6s, ETA:   157s[>                               ] 36/929, 5.7 task/s, elapsed: 6s, ETA:   156s[>                               ] 37/929, 5.8 task/s, elapsed: 6s, ETA:   155s[>                               ] 38/929, 5.8 task/s, elapsed: 7s, ETA:   153s[>                               ] 39/929, 5.8 task/s, elapsed: 7s, ETA:   152s[>                               ] 40/929, 5.9 task/s, elapsed: 7s, ETA:   151s[>                               ] 41/929, 5.9 task/s, elapsed: 7s, ETA:   150s[>                               ] 42/929, 5.9 task/s, elapsed: 7s, ETA:   149s[>                               ] 43/929, 6.0 task/s, elapsed: 7s, ETA:   148s[>                               ] 44/929, 6.0 task/s, elapsed: 7s, ETA:   147s[>                               ] 45/929, 6.0 task/s, elapsed: 7s, ETA:   146s[>                               ] 46/929, 6.1 task/s, elapsed: 8s, ETA:   145s[>                               ] 47/929, 6.1 task/s, elapsed: 8s, ETA:   144s[>                               ] 48/929, 6.1 task/s, elapsed: 8s, ETA:   143s[>                               ] 49/929, 6.2 task/s, elapsed: 8s, ETA:   143s[>                               ] 50/929, 6.2 task/s, elapsed: 8s, ETA:   142s[>                               ] 51/929, 6.2 task/s, elapsed: 8s, ETA:   141s[>                               ] 52/929, 6.2 task/s, elapsed: 8s, ETA:   140s[>                               ] 53/929, 6.3 task/s, elapsed: 8s, ETA:   140s[>                               ] 54/929, 6.3 task/s, elapsed: 9s, ETA:   139s[>                               ] 55/929, 6.3 task/s, elapsed: 9s, ETA:   138s[>                               ] 56/929, 6.3 task/s, elapsed: 9s, ETA:   138s[>                               ] 57/929, 6.4 task/s, elapsed: 9s, ETA:   137s[>                               ] 58/929, 6.4 task/s, elapsed: 9s, ETA:   136s[>>                              ] 59/929, 6.4 task/s, elapsed: 9s, ETA:   136s[>>                              ] 60/929, 6.4 task/s, elapsed: 9s, ETA:   135s[>>                              ] 61/929, 6.4 task/s, elapsed: 9s, ETA:   135s[>>                             ] 62/929, 6.5 task/s, elapsed: 10s, ETA:   134s[>>                             ] 63/929, 6.5 task/s, elapsed: 10s, ETA:   134s[>>                             ] 64/929, 6.5 task/s, elapsed: 10s, ETA:   133s[>>                             ] 65/929, 6.5 task/s, elapsed: 10s, ETA:   133s[>>                             ] 66/929, 6.5 task/s, elapsed: 10s, ETA:   133s[>>                             ] 67/929, 6.5 task/s, elapsed: 10s, ETA:   132s[>>                             ] 68/929, 6.6 task/s, elapsed: 10s, ETA:   131s[>>                             ] 69/929, 6.6 task/s, elapsed: 11s, ETA:   131s[>>                             ] 70/929, 6.6 task/s, elapsed: 11s, ETA:   130s[>>                             ] 71/929, 6.6 task/s, elapsed: 11s, ETA:   130s[>>                             ] 72/929, 6.6 task/s, elapsed: 11s, ETA:   130s[>>                             ] 73/929, 6.6 task/s, elapsed: 11s, ETA:   129s[>>                             ] 74/929, 6.6 task/s, elapsed: 11s, ETA:   129s[>>                             ] 75/929, 6.7 task/s, elapsed: 11s, ETA:   128s[>>                             ] 76/929, 6.7 task/s, elapsed: 11s, ETA:   128s[>>                             ] 77/929, 6.7 task/s, elapsed: 12s, ETA:   128s[>>                             ] 78/929, 6.7 task/s, elapsed: 12s, ETA:   127s[>>                             ] 79/929, 6.7 task/s, elapsed: 12s, ETA:   127s[>>                             ] 80/929, 6.7 task/s, elapsed: 12s, ETA:   126s[>>                             ] 81/929, 6.7 task/s, elapsed: 12s, ETA:   126s[>>                             ] 82/929, 6.8 task/s, elapsed: 12s, ETA:   125s[>>                             ] 83/929, 6.8 task/s, elapsed: 12s, ETA:   125s[>>                             ] 84/929, 6.8 task/s, elapsed: 12s, ETA:   125s[>>                             ] 85/929, 6.8 task/s, elapsed: 13s, ETA:   124s[>>                             ] 86/929, 6.8 task/s, elapsed: 13s, ETA:   124s[>>                             ] 87/929, 6.8 task/s, elapsed: 13s, ETA:   124s[>>                             ] 88/929, 6.8 task/s, elapsed: 13s, ETA:   123s[>>                             ] 89/929, 6.8 task/s, elapsed: 13s, ETA:   123s[>>>                            ] 90/929, 6.8 task/s, elapsed: 13s, ETA:   123s[>>>                            ] 91/929, 6.8 task/s, elapsed: 13s, ETA:   123s[>>>                            ] 92/929, 6.8 task/s, elapsed: 13s, ETA:   122s[>>>                            ] 93/929, 6.8 task/s, elapsed: 14s, ETA:   122s[>>>                            ] 94/929, 6.9 task/s, elapsed: 14s, ETA:   122s[>>>                            ] 95/929, 6.9 task/s, elapsed: 14s, ETA:   121s[>>>                            ] 96/929, 6.9 task/s, elapsed: 14s, ETA:   121s[>>>                            ] 97/929, 6.9 task/s, elapsed: 14s, ETA:   121s[>>>                            ] 98/929, 6.9 task/s, elapsed: 14s, ETA:   121s[>>>                            ] 99/929, 6.9 task/s, elapsed: 14s, ETA:   120s[>>>                           ] 100/929, 6.9 task/s, elapsed: 14s, ETA:   120s[>>>                           ] 101/929, 6.9 task/s, elapsed: 15s, ETA:   120s[>>>                           ] 102/929, 6.9 task/s, elapsed: 15s, ETA:   119s[>>>                           ] 103/929, 6.9 task/s, elapsed: 15s, ETA:   119s[>>>                           ] 104/929, 7.0 task/s, elapsed: 15s, ETA:   119s[>>>                           ] 105/929, 7.0 task/s, elapsed: 15s, ETA:   118s[>>>                           ] 106/929, 7.0 task/s, elapsed: 15s, ETA:   118s[>>>                           ] 107/929, 7.0 task/s, elapsed: 15s, ETA:   118s[>>>                           ] 108/929, 7.0 task/s, elapsed: 15s, ETA:   118s[>>>                           ] 109/929, 7.0 task/s, elapsed: 16s, ETA:   117s[>>>                           ] 110/929, 7.0 task/s, elapsed: 16s, ETA:   117s[>>>                           ] 111/929, 7.0 task/s, elapsed: 16s, ETA:   117s[>>>                           ] 112/929, 7.0 task/s, elapsed: 16s, ETA:   117s[>>>                           ] 113/929, 7.0 task/s, elapsed: 16s, ETA:   116s[>>>                           ] 114/929, 7.0 task/s, elapsed: 16s, ETA:   116s[>>>                           ] 115/929, 7.0 task/s, elapsed: 16s, ETA:   116s[>>>                           ] 116/929, 7.0 task/s, elapsed: 16s, ETA:   116s[>>>                           ] 117/929, 7.0 task/s, elapsed: 17s, ETA:   115s[>>>                           ] 118/929, 7.0 task/s, elapsed: 17s, ETA:   115s[>>>                           ] 119/929, 7.0 task/s, elapsed: 17s, ETA:   115s[>>>                           ] 120/929, 7.1 task/s, elapsed: 17s, ETA:   115s[>>>                           ] 121/929, 7.1 task/s, elapsed: 17s, ETA:   114s[>>>                           ] 122/929, 7.1 task/s, elapsed: 17s, ETA:   114s[>>>                           ] 123/929, 7.1 task/s, elapsed: 17s, ETA:   114s[>>>>                          ] 124/929, 7.1 task/s, elapsed: 18s, ETA:   114s[>>>>                          ] 125/929, 7.1 task/s, elapsed: 18s, ETA:   113s[>>>>                          ] 126/929, 7.1 task/s, elapsed: 18s, ETA:   113s[>>>>                          ] 127/929, 7.1 task/s, elapsed: 18s, ETA:   113s[>>>>                          ] 128/929, 7.1 task/s, elapsed: 18s, ETA:   113s[>>>>                          ] 129/929, 7.1 task/s, elapsed: 18s, ETA:   113s[>>>>                          ] 130/929, 7.1 task/s, elapsed: 18s, ETA:   112s[>>>>                          ] 131/929, 7.1 task/s, elapsed: 18s, ETA:   112s[>>>>                          ] 132/929, 7.1 task/s, elapsed: 19s, ETA:   112s[>>>>                          ] 133/929, 7.1 task/s, elapsed: 19s, ETA:   112s[>>>>                          ] 134/929, 7.1 task/s, elapsed: 19s, ETA:   111s[>>>>                          ] 135/929, 7.1 task/s, elapsed: 19s, ETA:   111s[>>>>                          ] 136/929, 7.1 task/s, elapsed: 19s, ETA:   111s[>>>>                          ] 137/929, 7.1 task/s, elapsed: 19s, ETA:   111s[>>>>                          ] 138/929, 7.2 task/s, elapsed: 19s, ETA:   111s[>>>>                          ] 139/929, 7.2 task/s, elapsed: 19s, ETA:   110s[>>>>                          ] 140/929, 7.1 task/s, elapsed: 20s, ETA:   110s[>>>>                          ] 141/929, 7.1 task/s, elapsed: 20s, ETA:   110s[>>>>                          ] 142/929, 7.1 task/s, elapsed: 20s, ETA:   110s[>>>>                          ] 143/929, 7.2 task/s, elapsed: 20s, ETA:   110s[>>>>                          ] 144/929, 7.2 task/s, elapsed: 20s, ETA:   110s[>>>>                          ] 145/929, 7.2 task/s, elapsed: 20s, ETA:   110s[>>>>                          ] 146/929, 7.2 task/s, elapsed: 20s, ETA:   109s[>>>>                          ] 147/929, 7.2 task/s, elapsed: 20s, ETA:   109s[>>>>                          ] 148/929, 7.2 task/s, elapsed: 21s, ETA:   109s[>>>>                          ] 149/929, 7.2 task/s, elapsed: 21s, ETA:   109s[>>>>                          ] 150/929, 7.2 task/s, elapsed: 21s, ETA:   108s[>>>>                          ] 151/929, 7.2 task/s, elapsed: 21s, ETA:   108s[>>>>                          ] 152/929, 7.2 task/s, elapsed: 21s, ETA:   108s[>>>>                          ] 153/929, 7.2 task/s, elapsed: 21s, ETA:   108s[>>>>                          ] 154/929, 7.2 task/s, elapsed: 21s, ETA:   108s[>>>>>                         ] 155/929, 7.2 task/s, elapsed: 22s, ETA:   107s[>>>>>                         ] 156/929, 7.2 task/s, elapsed: 22s, ETA:   107s[>>>>>                         ] 157/929, 7.2 task/s, elapsed: 22s, ETA:   107s[>>>>>                         ] 158/929, 7.2 task/s, elapsed: 22s, ETA:   107s[>>>>>                         ] 159/929, 7.2 task/s, elapsed: 22s, ETA:   107s[>>>>>                         ] 160/929, 7.2 task/s, elapsed: 22s, ETA:   106s[>>>>>                         ] 161/929, 7.2 task/s, elapsed: 22s, ETA:   106s[>>>>>                         ] 162/929, 7.2 task/s, elapsed: 22s, ETA:   106s[>>>>>                         ] 163/929, 7.2 task/s, elapsed: 23s, ETA:   106s[>>>>>                         ] 164/929, 7.2 task/s, elapsed: 23s, ETA:   106s[>>>>>                         ] 165/929, 7.2 task/s, elapsed: 23s, ETA:   105s[>>>>>                         ] 166/929, 7.2 task/s, elapsed: 23s, ETA:   105s[>>>>>                         ] 167/929, 7.2 task/s, elapsed: 23s, ETA:   105s[>>>>>                         ] 168/929, 7.2 task/s, elapsed: 23s, ETA:   105s[>>>>>                         ] 169/929, 7.2 task/s, elapsed: 23s, ETA:   105s[>>>>>                         ] 170/929, 7.2 task/s, elapsed: 24s, ETA:   105s[>>>>>                         ] 171/929, 7.2 task/s, elapsed: 24s, ETA:   105s[>>>>>                         ] 172/929, 7.2 task/s, elapsed: 24s, ETA:   105s[>>>>>                         ] 173/929, 7.2 task/s, elapsed: 24s, ETA:   104s[>>>>>                         ] 174/929, 7.2 task/s, elapsed: 24s, ETA:   104s[>>>>>                         ] 175/929, 7.2 task/s, elapsed: 24s, ETA:   104s[>>>>>                         ] 176/929, 7.2 task/s, elapsed: 24s, ETA:   104s[>>>>>                         ] 177/929, 7.2 task/s, elapsed: 24s, ETA:   104s[>>>>>                         ] 178/929, 7.3 task/s, elapsed: 25s, ETA:   104s[>>>>>                         ] 179/929, 7.3 task/s, elapsed: 25s, ETA:   103s[>>>>>                         ] 180/929, 7.3 task/s, elapsed: 25s, ETA:   103s[>>>>>                         ] 181/929, 7.3 task/s, elapsed: 25s, ETA:   103s[>>>>>                         ] 182/929, 7.3 task/s, elapsed: 25s, ETA:   103s[>>>>>                         ] 183/929, 7.3 task/s, elapsed: 25s, ETA:   103s[>>>>>                         ] 184/929, 7.3 task/s, elapsed: 25s, ETA:   102s[>>>>>                         ] 185/929, 7.3 task/s, elapsed: 25s, ETA:   102s[>>>>>>                        ] 186/929, 7.3 task/s, elapsed: 26s, ETA:   102s[>>>>>>                        ] 187/929, 7.3 task/s, elapsed: 26s, ETA:   102s[>>>>>>                        ] 188/929, 7.3 task/s, elapsed: 26s, ETA:   102s[>>>>>>                        ] 189/929, 7.3 task/s, elapsed: 26s, ETA:   102s[>>>>>>                        ] 190/929, 7.3 task/s, elapsed: 26s, ETA:   101s[>>>>>>                        ] 191/929, 7.3 task/s, elapsed: 26s, ETA:   101s[>>>>>>                        ] 192/929, 7.3 task/s, elapsed: 26s, ETA:   101s[>>>>>>                        ] 193/929, 7.3 task/s, elapsed: 26s, ETA:   101s[>>>>>>                        ] 194/929, 7.3 task/s, elapsed: 27s, ETA:   101s[>>>>>>                        ] 195/929, 7.3 task/s, elapsed: 27s, ETA:   101s[>>>>>>                        ] 196/929, 7.3 task/s, elapsed: 27s, ETA:   100s[>>>>>>                        ] 197/929, 7.3 task/s, elapsed: 27s, ETA:   100s[>>>>>>                        ] 198/929, 7.3 task/s, elapsed: 27s, ETA:   100s[>>>>>>                        ] 199/929, 7.3 task/s, elapsed: 27s, ETA:   100s[>>>>>>                        ] 200/929, 7.3 task/s, elapsed: 27s, ETA:   100s[>>>>>>                        ] 201/929, 7.3 task/s, elapsed: 27s, ETA:    99s[>>>>>>                        ] 202/929, 7.3 task/s, elapsed: 28s, ETA:    99s[>>>>>>                        ] 203/929, 7.3 task/s, elapsed: 28s, ETA:    99s[>>>>>>                        ] 204/929, 7.3 task/s, elapsed: 28s, ETA:    99s[>>>>>>                        ] 205/929, 7.3 task/s, elapsed: 28s, ETA:    99s[>>>>>>                        ] 206/929, 7.3 task/s, elapsed: 28s, ETA:    99s[>>>>>>                        ] 207/929, 7.3 task/s, elapsed: 28s, ETA:    98s[>>>>>>                        ] 208/929, 7.3 task/s, elapsed: 28s, ETA:    98s[>>>>>>                        ] 209/929, 7.3 task/s, elapsed: 29s, ETA:    98s[>>>>>>                        ] 210/929, 7.3 task/s, elapsed: 29s, ETA:    98s[>>>>>>                        ] 211/929, 7.3 task/s, elapsed: 29s, ETA:    98s[>>>>>>                        ] 212/929, 7.3 task/s, elapsed: 29s, ETA:    98s[>>>>>>                        ] 213/929, 7.3 task/s, elapsed: 29s, ETA:    98s[>>>>>>                        ] 214/929, 7.3 task/s, elapsed: 29s, ETA:    97s[>>>>>>                        ] 215/929, 7.3 task/s, elapsed: 29s, ETA:    97s[>>>>>>                        ] 216/929, 7.3 task/s, elapsed: 29s, ETA:    97s[>>>>>>>                       ] 217/929, 7.3 task/s, elapsed: 30s, ETA:    97s[>>>>>>>                       ] 218/929, 7.3 task/s, elapsed: 30s, ETA:    97s[>>>>>>>                       ] 219/929, 7.3 task/s, elapsed: 30s, ETA:    97s[>>>>>>>                       ] 220/929, 7.3 task/s, elapsed: 30s, ETA:    96s[>>>>>>>                       ] 221/929, 7.3 task/s, elapsed: 30s, ETA:    96s[>>>>>>>                       ] 222/929, 7.4 task/s, elapsed: 30s, ETA:    96s[>>>>>>>                       ] 223/929, 7.3 task/s, elapsed: 30s, ETA:    96s[>>>>>>>                       ] 224/929, 7.4 task/s, elapsed: 30s, ETA:    96s[>>>>>>>                       ] 225/929, 7.4 task/s, elapsed: 31s, ETA:    96s[>>>>>>>                       ] 226/929, 7.4 task/s, elapsed: 31s, ETA:    96s[>>>>>>>                       ] 227/929, 7.4 task/s, elapsed: 31s, ETA:    95s[>>>>>>>                       ] 228/929, 7.4 task/s, elapsed: 31s, ETA:    95s[>>>>>>>                       ] 229/929, 7.4 task/s, elapsed: 31s, ETA:    95s[>>>>>>>                       ] 230/929, 7.4 task/s, elapsed: 31s, ETA:    95s[>>>>>>>                       ] 231/929, 7.4 task/s, elapsed: 31s, ETA:    95s[>>>>>>>                       ] 232/929, 7.4 task/s, elapsed: 31s, ETA:    95s[>>>>>>>                       ] 233/929, 7.4 task/s, elapsed: 32s, ETA:    95s[>>>>>>>                       ] 234/929, 7.4 task/s, elapsed: 32s, ETA:    94s[>>>>>>>                       ] 235/929, 7.4 task/s, elapsed: 32s, ETA:    94s[>>>>>>>                       ] 236/929, 7.4 task/s, elapsed: 32s, ETA:    94s[>>>>>>>                       ] 237/929, 7.4 task/s, elapsed: 32s, ETA:    94s[>>>>>>>                       ] 238/929, 7.4 task/s, elapsed: 32s, ETA:    94s[>>>>>>>                       ] 239/929, 7.4 task/s, elapsed: 32s, ETA:    93s[>>>>>>>                       ] 240/929, 7.4 task/s, elapsed: 33s, ETA:    93s[>>>>>>>                       ] 241/929, 7.4 task/s, elapsed: 33s, ETA:    93s[>>>>>>>                       ] 242/929, 7.4 task/s, elapsed: 33s, ETA:    93s[>>>>>>>                       ] 243/929, 7.4 task/s, elapsed: 33s, ETA:    93s[>>>>>>>                       ] 244/929, 7.4 task/s, elapsed: 33s, ETA:    93s[>>>>>>>                       ] 245/929, 7.4 task/s, elapsed: 33s, ETA:    93s[>>>>>>>                       ] 246/929, 7.4 task/s, elapsed: 33s, ETA:    92s[>>>>>>>                       ] 247/929, 7.4 task/s, elapsed: 33s, ETA:    92s[>>>>>>>>                      ] 248/929, 7.4 task/s, elapsed: 34s, ETA:    92s[>>>>>>>>                      ] 249/929, 7.4 task/s, elapsed: 34s, ETA:    92s[>>>>>>>>                      ] 250/929, 7.4 task/s, elapsed: 34s, ETA:    92s[>>>>>>>>                      ] 251/929, 7.4 task/s, elapsed: 34s, ETA:    92s[>>>>>>>>                      ] 252/929, 7.4 task/s, elapsed: 34s, ETA:    91s[>>>>>>>>                      ] 253/929, 7.4 task/s, elapsed: 34s, ETA:    91s[>>>>>>>>                      ] 254/929, 7.4 task/s, elapsed: 34s, ETA:    91s[>>>>>>>>                      ] 255/929, 7.4 task/s, elapsed: 34s, ETA:    91s[>>>>>>>>                      ] 256/929, 7.4 task/s, elapsed: 34s, ETA:    91s[>>>>>>>>                      ] 257/929, 7.4 task/s, elapsed: 35s, ETA:    90s[>>>>>>>>                      ] 258/929, 7.4 task/s, elapsed: 35s, ETA:    90s[>>>>>>>>                      ] 259/929, 7.4 task/s, elapsed: 35s, ETA:    90s[>>>>>>>>                      ] 260/929, 7.4 task/s, elapsed: 35s, ETA:    90s[>>>>>>>>                      ] 261/929, 7.4 task/s, elapsed: 35s, ETA:    90s[>>>>>>>>                      ] 262/929, 7.4 task/s, elapsed: 35s, ETA:    90s[>>>>>>>>                      ] 263/929, 7.4 task/s, elapsed: 35s, ETA:    89s[>>>>>>>>                      ] 264/929, 7.4 task/s, elapsed: 35s, ETA:    89s[>>>>>>>>                      ] 265/929, 7.4 task/s, elapsed: 36s, ETA:    89s[>>>>>>>>                      ] 266/929, 7.5 task/s, elapsed: 36s, ETA:    89s[>>>>>>>>                      ] 267/929, 7.5 task/s, elapsed: 36s, ETA:    89s[>>>>>>>>                      ] 268/929, 7.5 task/s, elapsed: 36s, ETA:    89s[>>>>>>>>                      ] 269/929, 7.5 task/s, elapsed: 36s, ETA:    88s[>>>>>>>>                      ] 270/929, 7.5 task/s, elapsed: 36s, ETA:    88s[>>>>>>>>                      ] 271/929, 7.5 task/s, elapsed: 36s, ETA:    88s[>>>>>>>>                      ] 272/929, 7.5 task/s, elapsed: 36s, ETA:    88s[>>>>>>>>                      ] 273/929, 7.5 task/s, elapsed: 37s, ETA:    88s[>>>>>>>>                      ] 274/929, 7.5 task/s, elapsed: 37s, ETA:    88s[>>>>>>>>                      ] 275/929, 7.5 task/s, elapsed: 37s, ETA:    88s[>>>>>>>>                      ] 276/929, 7.5 task/s, elapsed: 37s, ETA:    87s[>>>>>>>>                      ] 277/929, 7.5 task/s, elapsed: 37s, ETA:    87s[>>>>>>>>                      ] 278/929, 7.5 task/s, elapsed: 37s, ETA:    87s[>>>>>>>>>                     ] 279/929, 7.5 task/s, elapsed: 37s, ETA:    87s[>>>>>>>>>                     ] 280/929, 7.5 task/s, elapsed: 37s, ETA:    87s[>>>>>>>>>                     ] 281/929, 7.5 task/s, elapsed: 38s, ETA:    86s[>>>>>>>>>                     ] 282/929, 7.5 task/s, elapsed: 38s, ETA:    86s[>>>>>>>>>                     ] 283/929, 7.5 task/s, elapsed: 38s, ETA:    86s[>>>>>>>>>                     ] 284/929, 7.5 task/s, elapsed: 38s, ETA:    86s[>>>>>>>>>                     ] 285/929, 7.5 task/s, elapsed: 38s, ETA:    86s[>>>>>>>>>                     ] 286/929, 7.5 task/s, elapsed: 38s, ETA:    86s[>>>>>>>>>                     ] 287/929, 7.5 task/s, elapsed: 38s, ETA:    86s[>>>>>>>>>                     ] 288/929, 7.5 task/s, elapsed: 38s, ETA:    85s[>>>>>>>>>                     ] 289/929, 7.5 task/s, elapsed: 38s, ETA:    85s[>>>>>>>>>                     ] 290/929, 7.5 task/s, elapsed: 39s, ETA:    85s[>>>>>>>>>                     ] 291/929, 7.5 task/s, elapsed: 39s, ETA:    85s[>>>>>>>>>                     ] 292/929, 7.5 task/s, elapsed: 39s, ETA:    85s[>>>>>>>>>                     ] 293/929, 7.5 task/s, elapsed: 39s, ETA:    85s[>>>>>>>>>                     ] 294/929, 7.5 task/s, elapsed: 39s, ETA:    84s[>>>>>>>>>                     ] 295/929, 7.5 task/s, elapsed: 39s, ETA:    84s[>>>>>>>>>                     ] 296/929, 7.5 task/s, elapsed: 39s, ETA:    84s[>>>>>>>>>                     ] 297/929, 7.5 task/s, elapsed: 39s, ETA:    84s[>>>>>>>>>                     ] 298/929, 7.5 task/s, elapsed: 40s, ETA:    84s[>>>>>>>>>                     ] 299/929, 7.5 task/s, elapsed: 40s, ETA:    84s[>>>>>>>>>                     ] 300/929, 7.5 task/s, elapsed: 40s, ETA:    84s[>>>>>>>>>                     ] 301/929, 7.5 task/s, elapsed: 40s, ETA:    83s[>>>>>>>>>                     ] 302/929, 7.5 task/s, elapsed: 40s, ETA:    83s[>>>>>>>>>                     ] 303/929, 7.5 task/s, elapsed: 40s, ETA:    83s[>>>>>>>>>                     ] 304/929, 7.5 task/s, elapsed: 40s, ETA:    83s[>>>>>>>>>                     ] 305/929, 7.5 task/s, elapsed: 40s, ETA:    83s[>>>>>>>>>                     ] 306/929, 7.5 task/s, elapsed: 41s, ETA:    83s[>>>>>>>>>                     ] 307/929, 7.6 task/s, elapsed: 41s, ETA:    82s[>>>>>>>>>                     ] 308/929, 7.6 task/s, elapsed: 41s, ETA:    82s[>>>>>>>>>                     ] 309/929, 7.6 task/s, elapsed: 41s, ETA:    82s[>>>>>>>>>>                    ] 310/929, 7.6 task/s, elapsed: 41s, ETA:    82s[>>>>>>>>>>                    ] 311/929, 7.6 task/s, elapsed: 41s, ETA:    82s[>>>>>>>>>>                    ] 312/929, 7.6 task/s, elapsed: 41s, ETA:    82s[>>>>>>>>>>                    ] 313/929, 7.6 task/s, elapsed: 41s, ETA:    81s[>>>>>>>>>>                    ] 314/929, 7.6 task/s, elapsed: 41s, ETA:    81s[>>>>>>>>>>                    ] 315/929, 7.6 task/s, elapsed: 42s, ETA:    81s[>>>>>>>>>>                    ] 316/929, 7.6 task/s, elapsed: 42s, ETA:    81s[>>>>>>>>>>                    ] 317/929, 7.6 task/s, elapsed: 42s, ETA:    81s[>>>>>>>>>>                    ] 318/929, 7.6 task/s, elapsed: 42s, ETA:    81s[>>>>>>>>>>                    ] 319/929, 7.6 task/s, elapsed: 42s, ETA:    80s[>>>>>>>>>>                    ] 320/929, 7.6 task/s, elapsed: 42s, ETA:    80s[>>>>>>>>>>                    ] 321/929, 7.6 task/s, elapsed: 42s, ETA:    80s[>>>>>>>>>>                    ] 322/929, 7.6 task/s, elapsed: 42s, ETA:    80s[>>>>>>>>>>                    ] 323/929, 7.6 task/s, elapsed: 43s, ETA:    80s[>>>>>>>>>>                    ] 324/929, 7.6 task/s, elapsed: 43s, ETA:    80s[>>>>>>>>>>                    ] 325/929, 7.6 task/s, elapsed: 43s, ETA:    80s[>>>>>>>>>>                    ] 326/929, 7.6 task/s, elapsed: 43s, ETA:    79s[>>>>>>>>>>                    ] 327/929, 7.6 task/s, elapsed: 43s, ETA:    79s[>>>>>>>>>>                    ] 328/929, 7.6 task/s, elapsed: 43s, ETA:    79s[>>>>>>>>>>                    ] 329/929, 7.6 task/s, elapsed: 43s, ETA:    79s[>>>>>>>>>>                    ] 330/929, 7.6 task/s, elapsed: 43s, ETA:    79s[>>>>>>>>>>                    ] 331/929, 7.6 task/s, elapsed: 44s, ETA:    79s[>>>>>>>>>>                    ] 332/929, 7.6 task/s, elapsed: 44s, ETA:    78s[>>>>>>>>>>                    ] 333/929, 7.6 task/s, elapsed: 44s, ETA:    78s[>>>>>>>>>>                    ] 334/929, 7.6 task/s, elapsed: 44s, ETA:    78s[>>>>>>>>>>                    ] 335/929, 7.6 task/s, elapsed: 44s, ETA:    78s[>>>>>>>>>>                    ] 336/929, 7.6 task/s, elapsed: 44s, ETA:    78s[>>>>>>>>>>                    ] 337/929, 7.6 task/s, elapsed: 44s, ETA:    78s[>>>>>>>>>>                    ] 338/929, 7.6 task/s, elapsed: 44s, ETA:    78s[>>>>>>>>>>                    ] 339/929, 7.6 task/s, elapsed: 45s, ETA:    77s[>>>>>>>>>>                    ] 340/929, 7.6 task/s, elapsed: 45s, ETA:    77s[>>>>>>>>>>>                   ] 341/929, 7.6 task/s, elapsed: 45s, ETA:    77s[>>>>>>>>>>>                   ] 342/929, 7.6 task/s, elapsed: 45s, ETA:    77s[>>>>>>>>>>>                   ] 343/929, 7.6 task/s, elapsed: 45s, ETA:    77s[>>>>>>>>>>>                   ] 344/929, 7.6 task/s, elapsed: 45s, ETA:    77s[>>>>>>>>>>>                   ] 345/929, 7.6 task/s, elapsed: 45s, ETA:    77s[>>>>>>>>>>>                   ] 346/929, 7.6 task/s, elapsed: 45s, ETA:    76s[>>>>>>>>>>>                   ] 347/929, 7.6 task/s, elapsed: 45s, ETA:    76s[>>>>>>>>>>>                   ] 348/929, 7.6 task/s, elapsed: 46s, ETA:    76s[>>>>>>>>>>>                   ] 349/929, 7.6 task/s, elapsed: 46s, ETA:    76s[>>>>>>>>>>>                   ] 350/929, 7.6 task/s, elapsed: 46s, ETA:    76s[>>>>>>>>>>>                   ] 351/929, 7.6 task/s, elapsed: 46s, ETA:    76s[>>>>>>>>>>>                   ] 352/929, 7.6 task/s, elapsed: 46s, ETA:    75s[>>>>>>>>>>>                   ] 353/929, 7.6 task/s, elapsed: 46s, ETA:    75s[>>>>>>>>>>>                   ] 354/929, 7.6 task/s, elapsed: 46s, ETA:    75s[>>>>>>>>>>>                   ] 355/929, 7.7 task/s, elapsed: 46s, ETA:    75s[>>>>>>>>>>>                   ] 356/929, 7.7 task/s, elapsed: 47s, ETA:    75s[>>>>>>>>>>>                   ] 357/929, 7.7 task/s, elapsed: 47s, ETA:    75s[>>>>>>>>>>>                   ] 358/929, 7.7 task/s, elapsed: 47s, ETA:    75s[>>>>>>>>>>>                   ] 359/929, 7.7 task/s, elapsed: 47s, ETA:    74s[>>>>>>>>>>>                   ] 360/929, 7.7 task/s, elapsed: 47s, ETA:    74s[>>>>>>>>>>>                   ] 361/929, 7.7 task/s, elapsed: 47s, ETA:    74s[>>>>>>>>>>>                   ] 362/929, 7.7 task/s, elapsed: 47s, ETA:    74s[>>>>>>>>>>>                   ] 363/929, 7.7 task/s, elapsed: 47s, ETA:    74s[>>>>>>>>>>>                   ] 364/929, 7.7 task/s, elapsed: 47s, ETA:    74s[>>>>>>>>>>>                   ] 365/929, 7.7 task/s, elapsed: 48s, ETA:    74s[>>>>>>>>>>>                   ] 366/929, 7.7 task/s, elapsed: 48s, ETA:    73s[>>>>>>>>>>>                   ] 367/929, 7.7 task/s, elapsed: 48s, ETA:    73s[>>>>>>>>>>>                   ] 368/929, 7.7 task/s, elapsed: 48s, ETA:    73s[>>>>>>>>>>>                   ] 369/929, 7.7 task/s, elapsed: 48s, ETA:    73s[>>>>>>>>>>>                   ] 370/929, 7.7 task/s, elapsed: 48s, ETA:    73s[>>>>>>>>>>>                   ] 371/929, 7.7 task/s, elapsed: 48s, ETA:    73s[>>>>>>>>>>>>                  ] 372/929, 7.7 task/s, elapsed: 48s, ETA:    73s[>>>>>>>>>>>>                  ] 373/929, 7.7 task/s, elapsed: 49s, ETA:    72s[>>>>>>>>>>>>                  ] 374/929, 7.7 task/s, elapsed: 49s, ETA:    72s[>>>>>>>>>>>>                  ] 375/929, 7.7 task/s, elapsed: 49s, ETA:    72s[>>>>>>>>>>>>                  ] 376/929, 7.7 task/s, elapsed: 49s, ETA:    72s[>>>>>>>>>>>>                  ] 377/929, 7.7 task/s, elapsed: 49s, ETA:    72s[>>>>>>>>>>>>                  ] 378/929, 7.7 task/s, elapsed: 49s, ETA:    72s[>>>>>>>>>>>>                  ] 379/929, 7.7 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 380/929, 7.7 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 381/929, 7.7 task/s, elapsed: 49s, ETA:    71s[>>>>>>>>>>>>                  ] 382/929, 7.7 task/s, elapsed: 50s, ETA:    71s[>>>>>>>>>>>>                  ] 383/929, 7.7 task/s, elapsed: 50s, ETA:    71s[>>>>>>>>>>>>                  ] 384/929, 7.7 task/s, elapsed: 50s, ETA:    71s[>>>>>>>>>>>>                  ] 385/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 386/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 387/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 388/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 389/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 390/929, 7.7 task/s, elapsed: 50s, ETA:    70s[>>>>>>>>>>>>                  ] 391/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 392/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 393/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 394/929, 7.7 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 395/929, 7.8 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 396/929, 7.8 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 397/929, 7.8 task/s, elapsed: 51s, ETA:    69s[>>>>>>>>>>>>                  ] 398/929, 7.8 task/s, elapsed: 51s, ETA:    68s[>>>>>>>>>>>>                  ] 399/929, 7.8 task/s, elapsed: 51s, ETA:    68s[>>>>>>>>>>>>                  ] 400/929, 7.8 task/s, elapsed: 51s, ETA:    68s[>>>>>>>>>>>>                  ] 401/929, 7.8 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>                  ] 402/929, 7.8 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>>                 ] 403/929, 7.8 task/s, elapsed: 52s, ETA:    68s[>>>>>>>>>>>>>                 ] 404/929, 7.8 task/s, elapsed: 52s, ETA:    67s[>>>>>>>>>>>>>                 ] 405/929, 7.8 task/s, elapsed: 52s, ETA:    67s[>>>>>>>>>>>>>                 ] 406/929, 7.8 task/s, elapsed: 52s, ETA:    67s[>>>>>>>>>>>>>                 ] 407/929, 7.8 task/s, elapsed: 52s, ETA:    67s[>>>>>>>>>>>>>                 ] 408/929, 7.8 task/s, elapsed: 52s, ETA:    67s[>>>>>>>>>>>>>                 ] 409/929, 7.8 task/s, elapsed: 52s, ETA:    67s[>>>>>>>>>>>>>                 ] 410/929, 7.8 task/s, elapsed: 52s, ETA:    66s[>>>>>>>>>>>>>                 ] 411/929, 7.8 task/s, elapsed: 53s, ETA:    66s[>>>>>>>>>>>>>                 ] 412/929, 7.8 task/s, elapsed: 53s, ETA:    66s[>>>>>>>>>>>>>                 ] 413/929, 7.8 task/s, elapsed: 53s, ETA:    66s[>>>>>>>>>>>>>                 ] 414/929, 7.8 task/s, elapsed: 53s, ETA:    66s[>>>>>>>>>>>>>                 ] 415/929, 7.8 task/s, elapsed: 53s, ETA:    66s[>>>>>>>>>>>>>                 ] 416/929, 7.8 task/s, elapsed: 53s, ETA:    66s[>>>>>>>>>>>>>                 ] 417/929, 7.8 task/s, elapsed: 53s, ETA:    65s[>>>>>>>>>>>>>                 ] 418/929, 7.8 task/s, elapsed: 53s, ETA:    65s[>>>>>>>>>>>>>                 ] 419/929, 7.8 task/s, elapsed: 53s, ETA:    65s[>>>>>>>>>>>>>                 ] 420/929, 7.8 task/s, elapsed: 54s, ETA:    65s[>>>>>>>>>>>>>                 ] 421/929, 7.8 task/s, elapsed: 54s, ETA:    65s[>>>>>>>>>>>>>                 ] 422/929, 7.9 task/s, elapsed: 54s, ETA:    65s[>>>>>>>>>>>>>                 ] 423/929, 7.9 task/s, elapsed: 54s, ETA:    64s[>>>>>>>>>>>>>                 ] 424/929, 7.9 task/s, elapsed: 54s, ETA:    64s[>>>>>>>>>>>>>                 ] 425/929, 7.9 task/s, elapsed: 54s, ETA:    64s[>>>>>>>>>>>>>                 ] 426/929, 7.9 task/s, elapsed: 54s, ETA:    64s[>>>>>>>>>>>>>                 ] 427/929, 7.9 task/s, elapsed: 54s, ETA:    64s[>>>>>>>>>>>>>                 ] 428/929, 7.9 task/s, elapsed: 54s, ETA:    64s[>>>>>>>>>>>>>                 ] 429/929, 7.9 task/s, elapsed: 54s, ETA:    63s[>>>>>>>>>>>>>                 ] 430/929, 7.9 task/s, elapsed: 55s, ETA:    63s[>>>>>>>>>>>>>                 ] 431/929, 7.9 task/s, elapsed: 55s, ETA:    63s[>>>>>>>>>>>>>                 ] 432/929, 7.9 task/s, elapsed: 55s, ETA:    63s[>>>>>>>>>>>>>                 ] 433/929, 7.9 task/s, elapsed: 55s, ETA:    63s[>>>>>>>>>>>>>>                ] 434/929, 7.9 task/s, elapsed: 55s, ETA:    63s[>>>>>>>>>>>>>>                ] 435/929, 7.9 task/s, elapsed: 55s, ETA:    63s[>>>>>>>>>>>>>>                ] 436/929, 7.9 task/s, elapsed: 55s, ETA:    62s[>>>>>>>>>>>>>>                ] 437/929, 7.9 task/s, elapsed: 55s, ETA:    62s[>>>>>>>>>>>>>>                ] 438/929, 7.9 task/s, elapsed: 55s, ETA:    62s[>>>>>>>>>>>>>>                ] 439/929, 7.9 task/s, elapsed: 56s, ETA:    62s[>>>>>>>>>>>>>>                ] 440/929, 7.9 task/s, elapsed: 56s, ETA:    62s[>>>>>>>>>>>>>>                ] 441/929, 7.9 task/s, elapsed: 56s, ETA:    62s[>>>>>>>>>>>>>>                ] 442/929, 7.9 task/s, elapsed: 56s, ETA:    62s[>>>>>>>>>>>>>>                ] 443/929, 7.9 task/s, elapsed: 56s, ETA:    61s[>>>>>>>>>>>>>>                ] 444/929, 7.9 task/s, elapsed: 56s, ETA:    61s[>>>>>>>>>>>>>>                ] 445/929, 7.9 task/s, elapsed: 56s, ETA:    61s[>>>>>>>>>>>>>>                ] 446/929, 7.9 task/s, elapsed: 56s, ETA:    61s[>>>>>>>>>>>>>>                ] 447/929, 7.9 task/s, elapsed: 56s, ETA:    61s[>>>>>>>>>>>>>>                ] 448/929, 7.9 task/s, elapsed: 57s, ETA:    61s[>>>>>>>>>>>>>>                ] 449/929, 7.9 task/s, elapsed: 57s, ETA:    61s[>>>>>>>>>>>>>>                ] 450/929, 7.9 task/s, elapsed: 57s, ETA:    60s[>>>>>>>>>>>>>>                ] 451/929, 7.9 task/s, elapsed: 57s, ETA:    60s[>>>>>>>>>>>>>>                ] 452/929, 7.9 task/s, elapsed: 57s, ETA:    60s[>>>>>>>>>>>>>>                ] 453/929, 7.9 task/s, elapsed: 57s, ETA:    60s[>>>>>>>>>>>>>>                ] 454/929, 7.9 task/s, elapsed: 57s, ETA:    60s[>>>>>>>>>>>>>>                ] 455/929, 7.9 task/s, elapsed: 57s, ETA:    60s[>>>>>>>>>>>>>>                ] 456/929, 7.9 task/s, elapsed: 57s, ETA:    60s[>>>>>>>>>>>>>>                ] 457/929, 7.9 task/s, elapsed: 58s, ETA:    59s[>>>>>>>>>>>>>>                ] 458/929, 7.9 task/s, elapsed: 58s, ETA:    59s[>>>>>>>>>>>>>>                ] 459/929, 7.9 task/s, elapsed: 58s, ETA:    59s[>>>>>>>>>>>>>>                ] 460/929, 8.0 task/s, elapsed: 58s, ETA:    59s[>>>>>>>>>>>>>>                ] 461/929, 8.0 task/s, elapsed: 58s, ETA:    59s[>>>>>>>>>>>>>>                ] 462/929, 8.0 task/s, elapsed: 58s, ETA:    59s[>>>>>>>>>>>>>>                ] 463/929, 8.0 task/s, elapsed: 58s, ETA:    59s[>>>>>>>>>>>>>>                ] 464/929, 8.0 task/s, elapsed: 58s, ETA:    58s[>>>>>>>>>>>>>>>               ] 465/929, 8.0 task/s, elapsed: 58s, ETA:    58s[>>>>>>>>>>>>>>>               ] 466/929, 8.0 task/s, elapsed: 58s, ETA:    58s[>>>>>>>>>>>>>>>               ] 467/929, 8.0 task/s, elapsed: 59s, ETA:    58s[>>>>>>>>>>>>>>>               ] 468/929, 8.0 task/s, elapsed: 59s, ETA:    58s[>>>>>>>>>>>>>>>               ] 469/929, 8.0 task/s, elapsed: 59s, ETA:    58s[>>>>>>>>>>>>>>>               ] 470/929, 8.0 task/s, elapsed: 59s, ETA:    57s[>>>>>>>>>>>>>>>               ] 471/929, 8.0 task/s, elapsed: 59s, ETA:    57s[>>>>>>>>>>>>>>>               ] 472/929, 8.0 task/s, elapsed: 59s, ETA:    57s[>>>>>>>>>>>>>>>               ] 473/929, 8.0 task/s, elapsed: 59s, ETA:    57s[>>>>>>>>>>>>>>>               ] 474/929, 8.0 task/s, elapsed: 59s, ETA:    57s[>>>>>>>>>>>>>>>               ] 475/929, 8.0 task/s, elapsed: 59s, ETA:    57s[>>>>>>>>>>>>>>>               ] 476/929, 8.0 task/s, elapsed: 59s, ETA:    57s[>>>>>>>>>>>>>>>               ] 477/929, 8.0 task/s, elapsed: 60s, ETA:    56s[>>>>>>>>>>>>>>>               ] 478/929, 8.0 task/s, elapsed: 60s, ETA:    56s[>>>>>>>>>>>>>>>               ] 479/929, 8.0 task/s, elapsed: 60s, ETA:    56s[>>>>>>>>>>>>>>>               ] 480/929, 8.0 task/s, elapsed: 60s, ETA:    56s[>>>>>>>>>>>>>>>               ] 481/929, 8.0 task/s, elapsed: 60s, ETA:    56s[>>>>>>>>>>>>>>>               ] 482/929, 8.0 task/s, elapsed: 60s, ETA:    56s[>>>>>>>>>>>>>>>               ] 483/929, 8.0 task/s, elapsed: 60s, ETA:    56s[>>>>>>>>>>>>>>>               ] 484/929, 8.0 task/s, elapsed: 60s, ETA:    55s[>>>>>>>>>>>>>>>               ] 485/929, 8.0 task/s, elapsed: 60s, ETA:    55s[>>>>>>>>>>>>>>>               ] 486/929, 8.0 task/s, elapsed: 60s, ETA:    55s[>>>>>>>>>>>>>>>               ] 487/929, 8.0 task/s, elapsed: 61s, ETA:    55s[>>>>>>>>>>>>>>>               ] 488/929, 8.0 task/s, elapsed: 61s, ETA:    55s[>>>>>>>>>>>>>>>               ] 489/929, 8.0 task/s, elapsed: 61s, ETA:    55s[>>>>>>>>>>>>>>>               ] 490/929, 8.0 task/s, elapsed: 61s, ETA:    55s[>>>>>>>>>>>>>>>               ] 491/929, 8.0 task/s, elapsed: 61s, ETA:    54s[>>>>>>>>>>>>>>>               ] 492/929, 8.1 task/s, elapsed: 61s, ETA:    54s[>>>>>>>>>>>>>>>               ] 493/929, 8.1 task/s, elapsed: 61s, ETA:    54s[>>>>>>>>>>>>>>>               ] 494/929, 8.1 task/s, elapsed: 61s, ETA:    54s[>>>>>>>>>>>>>>>               ] 495/929, 8.1 task/s, elapsed: 61s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 496/929, 8.1 task/s, elapsed: 62s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 497/929, 8.1 task/s, elapsed: 62s, ETA:    54s[>>>>>>>>>>>>>>>>              ] 498/929, 8.1 task/s, elapsed: 62s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 499/929, 8.1 task/s, elapsed: 62s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 500/929, 8.1 task/s, elapsed: 62s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 501/929, 8.1 task/s, elapsed: 62s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 502/929, 8.1 task/s, elapsed: 62s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 503/929, 8.1 task/s, elapsed: 62s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 504/929, 8.1 task/s, elapsed: 62s, ETA:    53s[>>>>>>>>>>>>>>>>              ] 505/929, 8.1 task/s, elapsed: 62s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 506/929, 8.1 task/s, elapsed: 63s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 507/929, 8.1 task/s, elapsed: 63s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 508/929, 8.1 task/s, elapsed: 63s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 509/929, 8.1 task/s, elapsed: 63s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 510/929, 8.1 task/s, elapsed: 63s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 511/929, 8.1 task/s, elapsed: 63s, ETA:    52s[>>>>>>>>>>>>>>>>              ] 512/929, 8.1 task/s, elapsed: 63s, ETA:    51s[>>>>>>>>>>>>>>>>              ] 513/929, 8.1 task/s, elapsed: 63s, ETA:    51s[>>>>>>>>>>>>>>>>              ] 514/929, 8.1 task/s, elapsed: 63s, ETA:    51s[>>>>>>>>>>>>>>>>              ] 515/929, 8.1 task/s, elapsed: 63s, ETA:    51s[>>>>>>>>>>>>>>>>              ] 516/929, 8.1 task/s, elapsed: 64s, ETA:    51s[>>>>>>>>>>>>>>>>              ] 517/929, 8.1 task/s, elapsed: 64s, ETA:    51s[>>>>>>>>>>>>>>>>              ] 518/929, 8.1 task/s, elapsed: 64s, ETA:    51s[>>>>>>>>>>>>>>>>              ] 519/929, 8.1 task/s, elapsed: 64s, ETA:    50s[>>>>>>>>>>>>>>>>              ] 520/929, 8.1 task/s, elapsed: 64s, ETA:    50s[>>>>>>>>>>>>>>>>              ] 521/929, 8.1 task/s, elapsed: 64s, ETA:    50s[>>>>>>>>>>>>>>>>              ] 522/929, 8.1 task/s, elapsed: 64s, ETA:    50s[>>>>>>>>>>>>>>>>              ] 523/929, 8.1 task/s, elapsed: 64s, ETA:    50s[>>>>>>>>>>>>>>>>              ] 524/929, 8.1 task/s, elapsed: 64s, ETA:    50s[>>>>>>>>>>>>>>>>              ] 525/929, 8.1 task/s, elapsed: 64s, ETA:    50s[>>>>>>>>>>>>>>>>              ] 526/929, 8.1 task/s, elapsed: 65s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 527/929, 8.1 task/s, elapsed: 65s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 528/929, 8.2 task/s, elapsed: 65s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 529/929, 8.2 task/s, elapsed: 65s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 530/929, 8.2 task/s, elapsed: 65s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 531/929, 8.2 task/s, elapsed: 65s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 532/929, 8.2 task/s, elapsed: 65s, ETA:    49s[>>>>>>>>>>>>>>>>>             ] 533/929, 8.2 task/s, elapsed: 65s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 534/929, 8.2 task/s, elapsed: 65s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 535/929, 8.2 task/s, elapsed: 65s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 536/929, 8.2 task/s, elapsed: 66s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 537/929, 8.2 task/s, elapsed: 66s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 538/929, 8.2 task/s, elapsed: 66s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 539/929, 8.2 task/s, elapsed: 66s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 540/929, 8.2 task/s, elapsed: 66s, ETA:    48s[>>>>>>>>>>>>>>>>>             ] 541/929, 8.2 task/s, elapsed: 66s, ETA:    47s[>>>>>>>>>>>>>>>>>             ] 542/929, 8.2 task/s, elapsed: 66s, ETA:    47s[>>>>>>>>>>>>>>>>>             ] 543/929, 8.2 task/s, elapsed: 66s, ETA:    47s[>>>>>>>>>>>>>>>>>             ] 544/929, 8.2 task/s, elapsed: 66s, ETA:    47s[>>>>>>>>>>>>>>>>>             ] 545/929, 8.2 task/s, elapsed: 66s, ETA:    47s[>>>>>>>>>>>>>>>>>             ] 546/929, 8.2 task/s, elapsed: 67s, ETA:    47s[>>>>>>>>>>>>>>>>>             ] 547/929, 8.2 task/s, elapsed: 67s, ETA:    47s[>>>>>>>>>>>>>>>>>             ] 548/929, 8.2 task/s, elapsed: 67s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 549/929, 8.2 task/s, elapsed: 67s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 550/929, 8.2 task/s, elapsed: 67s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 551/929, 8.2 task/s, elapsed: 67s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 552/929, 8.2 task/s, elapsed: 67s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 553/929, 8.2 task/s, elapsed: 67s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 554/929, 8.2 task/s, elapsed: 67s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 555/929, 8.2 task/s, elapsed: 68s, ETA:    46s[>>>>>>>>>>>>>>>>>             ] 556/929, 8.2 task/s, elapsed: 68s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 557/929, 8.2 task/s, elapsed: 68s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 558/929, 8.2 task/s, elapsed: 68s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 559/929, 8.2 task/s, elapsed: 68s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 560/929, 8.2 task/s, elapsed: 68s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 561/929, 8.2 task/s, elapsed: 68s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 562/929, 8.2 task/s, elapsed: 68s, ETA:    45s[>>>>>>>>>>>>>>>>>>            ] 563/929, 8.2 task/s, elapsed: 68s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 564/929, 8.2 task/s, elapsed: 68s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 565/929, 8.2 task/s, elapsed: 69s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 566/929, 8.2 task/s, elapsed: 69s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 567/929, 8.2 task/s, elapsed: 69s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 568/929, 8.2 task/s, elapsed: 69s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 569/929, 8.2 task/s, elapsed: 69s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 570/929, 8.3 task/s, elapsed: 69s, ETA:    44s[>>>>>>>>>>>>>>>>>>            ] 571/929, 8.3 task/s, elapsed: 69s, ETA:    43s[>>>>>>>>>>>>>>>>>>            ] 572/929, 8.3 task/s, elapsed: 69s, ETA:    43s[>>>>>>>>>>>>>>>>>>            ] 573/929, 8.3 task/s, elapsed: 69s, ETA:    43s[>>>>>>>>>>>>>>>>>>            ] 574/929, 8.3 task/s, elapsed: 70s, ETA:    43s[>>>>>>>>>>>>>>>>>>            ] 575/929, 8.3 task/s, elapsed: 70s, ETA:    43s[>>>>>>>>>>>>>>>>>>            ] 576/929, 8.3 task/s, elapsed: 70s, ETA:    43s[>>>>>>>>>>>>>>>>>>            ] 577/929, 8.3 task/s, elapsed: 70s, ETA:    43s[>>>>>>>>>>>>>>>>>>            ] 578/929, 8.3 task/s, elapsed: 70s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 579/929, 8.3 task/s, elapsed: 70s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 580/929, 8.3 task/s, elapsed: 70s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 581/929, 8.3 task/s, elapsed: 70s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 582/929, 8.3 task/s, elapsed: 70s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 583/929, 8.3 task/s, elapsed: 71s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 584/929, 8.3 task/s, elapsed: 71s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 585/929, 8.3 task/s, elapsed: 71s, ETA:    42s[>>>>>>>>>>>>>>>>>>            ] 586/929, 8.3 task/s, elapsed: 71s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 587/929, 8.3 task/s, elapsed: 71s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 588/929, 8.3 task/s, elapsed: 71s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 8.3 task/s, elapsed: 71s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 8.3 task/s, elapsed: 71s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 8.3 task/s, elapsed: 71s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 8.3 task/s, elapsed: 71s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 8.3 task/s, elapsed: 72s, ETA:    41s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 8.3 task/s, elapsed: 72s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 8.3 task/s, elapsed: 72s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 8.3 task/s, elapsed: 72s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 8.3 task/s, elapsed: 72s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 8.3 task/s, elapsed: 72s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 8.3 task/s, elapsed: 72s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 8.3 task/s, elapsed: 72s, ETA:    40s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 8.3 task/s, elapsed: 72s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 8.3 task/s, elapsed: 72s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 8.3 task/s, elapsed: 73s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 8.3 task/s, elapsed: 73s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 8.3 task/s, elapsed: 73s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 8.3 task/s, elapsed: 73s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 8.3 task/s, elapsed: 73s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 8.3 task/s, elapsed: 73s, ETA:    39s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 8.3 task/s, elapsed: 73s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 8.3 task/s, elapsed: 73s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 8.3 task/s, elapsed: 73s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 8.3 task/s, elapsed: 73s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 8.3 task/s, elapsed: 74s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 8.3 task/s, elapsed: 74s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 8.3 task/s, elapsed: 74s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 8.3 task/s, elapsed: 74s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 8.3 task/s, elapsed: 74s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 8.3 task/s, elapsed: 74s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 8.3 task/s, elapsed: 74s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 8.4 task/s, elapsed: 74s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 8.4 task/s, elapsed: 74s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 8.4 task/s, elapsed: 74s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 8.4 task/s, elapsed: 75s, ETA:    37s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 8.4 task/s, elapsed: 75s, ETA:    36s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 8.4 task/s, elapsed: 75s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 8.4 task/s, elapsed: 76s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 8.4 task/s, elapsed: 76s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 8.4 task/s, elapsed: 76s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 8.4 task/s, elapsed: 76s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 8.4 task/s, elapsed: 76s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 8.4 task/s, elapsed: 76s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 8.4 task/s, elapsed: 76s, ETA:    35s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 8.4 task/s, elapsed: 76s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 8.4 task/s, elapsed: 76s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 8.4 task/s, elapsed: 76s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 8.4 task/s, elapsed: 77s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 8.4 task/s, elapsed: 77s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 8.4 task/s, elapsed: 77s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 8.4 task/s, elapsed: 77s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 8.4 task/s, elapsed: 77s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 8.4 task/s, elapsed: 77s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 8.4 task/s, elapsed: 77s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 8.4 task/s, elapsed: 77s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 8.4 task/s, elapsed: 77s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 8.4 task/s, elapsed: 77s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 8.4 task/s, elapsed: 78s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 8.4 task/s, elapsed: 78s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 8.4 task/s, elapsed: 78s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 8.4 task/s, elapsed: 78s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 8.4 task/s, elapsed: 78s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 8.4 task/s, elapsed: 78s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 8.4 task/s, elapsed: 78s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 8.4 task/s, elapsed: 78s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 8.4 task/s, elapsed: 78s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 8.4 task/s, elapsed: 79s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 8.4 task/s, elapsed: 79s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 8.4 task/s, elapsed: 79s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 8.4 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 8.4 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 8.5 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 8.5 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 8.5 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 8.5 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 8.5 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 8.5 task/s, elapsed: 80s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 8.5 task/s, elapsed: 80s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 8.5 task/s, elapsed: 81s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 8.5 task/s, elapsed: 81s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 8.5 task/s, elapsed: 81s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 8.5 task/s, elapsed: 81s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 8.5 task/s, elapsed: 81s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 8.5 task/s, elapsed: 81s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 8.5 task/s, elapsed: 81s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 8.5 task/s, elapsed: 81s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 8.5 task/s, elapsed: 81s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 8.5 task/s, elapsed: 81s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 8.5 task/s, elapsed: 81s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 8.5 task/s, elapsed: 82s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 8.5 task/s, elapsed: 82s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 8.5 task/s, elapsed: 82s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 8.5 task/s, elapsed: 82s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 8.5 task/s, elapsed: 82s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 8.5 task/s, elapsed: 82s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 8.5 task/s, elapsed: 82s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 8.5 task/s, elapsed: 82s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 8.5 task/s, elapsed: 82s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 8.5 task/s, elapsed: 83s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 8.5 task/s, elapsed: 83s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 8.5 task/s, elapsed: 83s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 8.5 task/s, elapsed: 83s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 8.5 task/s, elapsed: 83s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 8.5 task/s, elapsed: 83s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 8.5 task/s, elapsed: 83s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 8.5 task/s, elapsed: 83s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 8.5 task/s, elapsed: 83s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 8.5 task/s, elapsed: 84s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 8.5 task/s, elapsed: 84s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 8.5 task/s, elapsed: 84s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 8.5 task/s, elapsed: 84s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 8.5 task/s, elapsed: 84s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 8.5 task/s, elapsed: 84s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 8.5 task/s, elapsed: 84s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 8.5 task/s, elapsed: 84s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 8.5 task/s, elapsed: 84s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 8.5 task/s, elapsed: 84s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 8.5 task/s, elapsed: 85s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 8.5 task/s, elapsed: 85s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 8.5 task/s, elapsed: 85s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 8.5 task/s, elapsed: 86s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 8.5 task/s, elapsed: 86s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 8.5 task/s, elapsed: 86s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 8.5 task/s, elapsed: 86s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 8.5 task/s, elapsed: 86s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 8.5 task/s, elapsed: 86s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 8.5 task/s, elapsed: 86s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 8.5 task/s, elapsed: 86s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 8.5 task/s, elapsed: 86s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 8.5 task/s, elapsed: 86s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 8.5 task/s, elapsed: 87s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 8.5 task/s, elapsed: 87s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 8.6 task/s, elapsed: 87s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 8.6 task/s, elapsed: 87s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 8.6 task/s, elapsed: 87s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 8.6 task/s, elapsed: 87s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 8.6 task/s, elapsed: 87s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 8.6 task/s, elapsed: 87s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 8.6 task/s, elapsed: 87s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 8.6 task/s, elapsed: 87s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 8.6 task/s, elapsed: 88s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 8.6 task/s, elapsed: 88s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 8.6 task/s, elapsed: 88s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 8.6 task/s, elapsed: 88s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 8.6 task/s, elapsed: 88s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 8.6 task/s, elapsed: 88s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 8.6 task/s, elapsed: 88s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 8.6 task/s, elapsed: 88s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 8.6 task/s, elapsed: 88s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 8.6 task/s, elapsed: 89s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 8.6 task/s, elapsed: 89s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 8.6 task/s, elapsed: 89s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 8.6 task/s, elapsed: 89s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 8.6 task/s, elapsed: 89s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 8.6 task/s, elapsed: 89s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 8.6 task/s, elapsed: 89s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 8.6 task/s, elapsed: 89s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 8.6 task/s, elapsed: 89s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 8.6 task/s, elapsed: 89s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 8.6 task/s, elapsed: 90s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 8.6 task/s, elapsed: 90s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 8.6 task/s, elapsed: 90s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 8.6 task/s, elapsed: 90s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 8.6 task/s, elapsed: 90s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 8.6 task/s, elapsed: 90s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 8.6 task/s, elapsed: 90s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 8.6 task/s, elapsed: 90s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 8.6 task/s, elapsed: 90s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 8.6 task/s, elapsed: 91s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 8.6 task/s, elapsed: 91s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 8.6 task/s, elapsed: 92s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 8.6 task/s, elapsed: 92s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 8.6 task/s, elapsed: 92s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 8.6 task/s, elapsed: 93s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 8.6 task/s, elapsed: 93s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 8.6 task/s, elapsed: 93s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 8.6 task/s, elapsed: 93s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 8.6 task/s, elapsed: 93s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 8.6 task/s, elapsed: 93s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 8.6 task/s, elapsed: 93s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 8.6 task/s, elapsed: 93s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 8.6 task/s, elapsed: 93s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 8.6 task/s, elapsed: 93s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 8.6 task/s, elapsed: 94s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 8.6 task/s, elapsed: 94s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 8.6 task/s, elapsed: 94s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 8.6 task/s, elapsed: 94s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 8.6 task/s, elapsed: 94s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 8.6 task/s, elapsed: 94s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 8.6 task/s, elapsed: 94s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 8.6 task/s, elapsed: 94s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 8.6 task/s, elapsed: 94s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 8.6 task/s, elapsed: 95s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 8.6 task/s, elapsed: 95s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 8.6 task/s, elapsed: 95s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 8.6 task/s, elapsed: 95s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 8.7 task/s, elapsed: 95s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 8.7 task/s, elapsed: 95s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 8.7 task/s, elapsed: 95s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 8.7 task/s, elapsed: 95s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 8.7 task/s, elapsed: 95s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 8.7 task/s, elapsed: 95s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 8.7 task/s, elapsed: 96s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 8.7 task/s, elapsed: 96s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 8.7 task/s, elapsed: 96s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 8.7 task/s, elapsed: 96s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 8.7 task/s, elapsed: 96s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 8.7 task/s, elapsed: 96s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 8.7 task/s, elapsed: 96s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 8.7 task/s, elapsed: 96s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 8.7 task/s, elapsed: 96s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 8.7 task/s, elapsed: 96s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 8.7 task/s, elapsed: 97s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 8.7 task/s, elapsed: 97s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 8.7 task/s, elapsed: 98s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 8.7 task/s, elapsed: 98s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 8.7 task/s, elapsed: 99s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 8.7 task/s, elapsed: 99s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 8.7 task/s, elapsed: 99s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 8.7 task/s, elapsed: 99s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 8.7 task/s, elapsed: 99s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 8.7 task/s, elapsed: 99s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 8.7 task/s, elapsed: 99s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 8.7 task/s, elapsed: 99s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 8.7 task/s, elapsed: 99s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 866/929, 8.7 task/s, elapsed: 100s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 867/929, 8.7 task/s, elapsed: 100s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 8.7 task/s, elapsed: 100s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 8.7 task/s, elapsed: 100s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 8.7 task/s, elapsed: 100s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 8.7 task/s, elapsed: 100s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 8.7 task/s, elapsed: 100s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 8.7 task/s, elapsed: 100s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 8.7 task/s, elapsed: 100s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 8.7 task/s, elapsed: 101s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 8.7 task/s, elapsed: 101s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 8.7 task/s, elapsed: 101s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 8.7 task/s, elapsed: 101s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 8.7 task/s, elapsed: 101s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 8.7 task/s, elapsed: 101s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 8.7 task/s, elapsed: 101s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 8.7 task/s, elapsed: 101s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 8.7 task/s, elapsed: 101s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 8.7 task/s, elapsed: 101s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 8.7 task/s, elapsed: 102s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 8.7 task/s, elapsed: 102s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 8.7 task/s, elapsed: 102s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 8.7 task/s, elapsed: 102s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 8.7 task/s, elapsed: 102s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 8.7 task/s, elapsed: 102s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 8.7 task/s, elapsed: 102s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 8.7 task/s, elapsed: 102s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 8.7 task/s, elapsed: 102s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 8.7 task/s, elapsed: 103s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 8.7 task/s, elapsed: 103s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 8.7 task/s, elapsed: 103s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 897/929, 8.7 task/s, elapsed: 103s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 898/929, 8.7 task/s, elapsed: 103s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 8.7 task/s, elapsed: 103s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 8.7 task/s, elapsed: 103s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 8.7 task/s, elapsed: 103s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 8.7 task/s, elapsed: 103s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 8.7 task/s, elapsed: 104s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 8.7 task/s, elapsed: 104s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 8.7 task/s, elapsed: 104s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 8.7 task/s, elapsed: 104s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 8.7 task/s, elapsed: 104s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 8.7 task/s, elapsed: 104s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 8.7 task/s, elapsed: 104s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 8.7 task/s, elapsed: 104s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 8.7 task/s, elapsed: 104s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 8.7 task/s, elapsed: 104s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 8.7 task/s, elapsed: 105s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 8.7 task/s, elapsed: 105s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 8.7 task/s, elapsed: 105s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 8.7 task/s, elapsed: 105s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 8.7 task/s, elapsed: 105s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 8.7 task/s, elapsed: 105s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 8.7 task/s, elapsed: 105s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 8.7 task/s, elapsed: 105s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 8.7 task/s, elapsed: 105s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 8.7 task/s, elapsed: 105s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 8.7 task/s, elapsed: 106s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 8.7 task/s, elapsed: 106s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 8.7 task/s, elapsed: 106s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 8.7 task/s, elapsed: 106s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 8.7 task/s, elapsed: 106s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 8.7 task/s, elapsed: 106s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 8.8 task/s, elapsed: 106s, ETA:     0s2022-10-10 13:00:49,956 - mmseg - INFO - per class results:2022-10-10 13:00:49,957 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.83 | 96.21 || rigid_plastic | 21.75 | 24.38 ||   cardboard   | 56.46 |  71.5 ||     metal     | 27.67 | 35.06 ||  soft_plastic | 62.43 | 70.11 |+---------------+-------+-------+2022-10-10 13:00:49,957 - mmseg - INFO - Summary:2022-10-10 13:00:49,957 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.29 | 51.83 | 59.45 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:00:49,960 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 13:00:49,960 - mmseg - INFO - Iter [929/40000]	lr: 4.200e-05, eta: 9:35:36, time: 1.456, data_time: 0.019, memory: 67494, aAcc: 0.9129, mIoU: 0.5183, mAcc: 0.5945, IoU.background: 0.9083, IoU.rigid_plastic: 0.2175, IoU.cardboard: 0.5646, IoU.metal: 0.2767, IoU.soft_plastic: 0.6243, Acc.background: 0.9621, Acc.rigid_plastic: 0.2438, Acc.cardboard: 0.7150, Acc.metal: 0.3506, Acc.soft_plastic: 0.7011, src.decode.loss_seg: 0.0834, src.decode.acc_seg: 97.1617, src.loss: 0.0995, mix.decode.loss_seg: 0.0515, mix.decode.acc_seg: 97.8213, mix.loss: 0.0515, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:01:53,364 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 9:40:49, time: 4.471, data_time: 3.216, memory: 67494, src.decode.loss_seg: 0.0794, src.decode.acc_seg: 97.0985, src.loss: 0.0954, mix.decode.loss_seg: 0.0483, mix.decode.acc_seg: 98.2045, mix.loss: 0.0483, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:02:56,373 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 9:39:49, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1055, src.decode.acc_seg: 96.3072, src.loss: 0.1215, mix.decode.loss_seg: 0.0729, mix.decode.acc_seg: 97.2959, mix.loss: 0.0729, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:03:59,977 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 9:38:49, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1107, src.decode.acc_seg: 96.0029, src.loss: 0.1267, mix.decode.loss_seg: 0.0662, mix.decode.acc_seg: 97.2085, mix.loss: 0.0662, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:05:03,377 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 9:37:49, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0931, src.decode.acc_seg: 96.7986, src.loss: 0.1091, mix.decode.loss_seg: 0.0636, mix.decode.acc_seg: 97.3505, mix.loss: 0.0636, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:06:06,254 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 9:36:48, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1138, src.decode.acc_seg: 96.1474, src.loss: 0.1298, mix.decode.loss_seg: 0.0642, mix.decode.acc_seg: 97.1870, mix.loss: 0.0642, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:07:09,132 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 9:35:47, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1006, src.decode.acc_seg: 96.2709, src.loss: 0.1167, mix.decode.loss_seg: 0.0778, mix.decode.acc_seg: 96.9564, mix.loss: 0.0778, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:08:11,936 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 9:34:46, time: 1.256, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1189, src.decode.acc_seg: 95.6184, src.loss: 0.1349, mix.decode.loss_seg: 0.0771, mix.decode.acc_seg: 96.9921, mix.loss: 0.0771, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:09:15,398 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 9:33:46, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0964, src.decode.acc_seg: 96.5886, src.loss: 0.1124, mix.decode.loss_seg: 0.0571, mix.decode.acc_seg: 97.6908, mix.loss: 0.0571, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:10:18,560 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 9:32:45, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0952, src.decode.acc_seg: 96.5880, src.loss: 0.1112, mix.decode.loss_seg: 0.0688, mix.decode.acc_seg: 97.3567, mix.loss: 0.0688, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:11:21,375 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 9:31:44, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1205, src.decode.acc_seg: 95.8632, src.loss: 0.1365, mix.decode.loss_seg: 0.0676, mix.decode.acc_seg: 97.3972, mix.loss: 0.0676, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:12:25,137 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 9:30:44, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0875, src.decode.acc_seg: 96.8741, src.loss: 0.1036, mix.decode.loss_seg: 0.0702, mix.decode.acc_seg: 97.1909, mix.loss: 0.0702, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:13:27,611 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 9:29:42, time: 1.250, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1133, src.decode.acc_seg: 96.1490, src.loss: 0.1293, mix.decode.loss_seg: 0.0726, mix.decode.acc_seg: 97.4064, mix.loss: 0.0726, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:14:30,366 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 9:28:41, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1050, src.decode.acc_seg: 96.3052, src.loss: 0.1210, mix.decode.loss_seg: 0.0576, mix.decode.acc_seg: 97.6049, mix.loss: 0.0576, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:15:34,047 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 9:27:41, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0990, src.decode.acc_seg: 96.6298, src.loss: 0.1150, mix.decode.loss_seg: 0.0571, mix.decode.acc_seg: 97.7096, mix.loss: 0.0571, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:16:36,927 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 9:26:40, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0837, src.decode.acc_seg: 97.0898, src.loss: 0.0997, mix.decode.loss_seg: 0.0558, mix.decode.acc_seg: 97.6687, mix.loss: 0.0558, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:17:40,094 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 9:25:39, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0906, src.decode.acc_seg: 96.8663, src.loss: 0.1067, mix.decode.loss_seg: 0.0628, mix.decode.acc_seg: 97.3823, mix.loss: 0.0628, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:18:43,287 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 9:24:38, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1396, src.decode.acc_seg: 95.2666, src.loss: 0.1557, mix.decode.loss_seg: 0.0924, mix.decode.acc_seg: 96.4276, mix.loss: 0.0924, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:19:47,126 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 9:23:39, time: 1.277, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.1392, src.decode.acc_seg: 94.9926, src.loss: 0.1552, mix.decode.loss_seg: 0.0841, mix.decode.acc_seg: 96.6658, mix.loss: 0.0841, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:20:50,495 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 9:22:39, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1282, src.decode.acc_seg: 95.4564, src.loss: 0.1442, mix.decode.loss_seg: 0.0745, mix.decode.acc_seg: 97.0391, mix.loss: 0.0745, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:21:53,174 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 13:21:53,174 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 9:21:37, time: 1.254, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0913, src.decode.acc_seg: 96.7277, src.loss: 0.1074, mix.decode.loss_seg: 0.0588, mix.decode.acc_seg: 97.5680, mix.loss: 0.0588, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:22:57,085 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 9:20:37, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0912, src.decode.acc_seg: 96.7740, src.loss: 0.1073, mix.decode.loss_seg: 0.0619, mix.decode.acc_seg: 97.4266, mix.loss: 0.0619, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:24:00,155 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 9:19:36, time: 1.261, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0879, src.decode.acc_seg: 96.9658, src.loss: 0.1040, mix.decode.loss_seg: 0.0616, mix.decode.acc_seg: 97.8050, mix.loss: 0.0616, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:25:03,204 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 9:18:35, time: 1.261, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1097, src.decode.acc_seg: 96.1269, src.loss: 0.1258, mix.decode.loss_seg: 0.0829, mix.decode.acc_seg: 96.3962, mix.loss: 0.0829, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:26:05,814 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 9:17:33, time: 1.252, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1238, src.decode.acc_seg: 95.3790, src.loss: 0.1398, mix.decode.loss_seg: 0.0744, mix.decode.acc_seg: 96.8755, mix.loss: 0.0744, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:27:09,185 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 9:16:33, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0914, src.decode.acc_seg: 96.7626, src.loss: 0.1074, mix.decode.loss_seg: 0.0740, mix.decode.acc_seg: 96.8892, mix.loss: 0.0740, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:28:12,078 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 9:15:31, time: 1.258, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0835, src.decode.acc_seg: 97.0193, src.loss: 0.0995, mix.decode.loss_seg: 0.0593, mix.decode.acc_seg: 97.4232, mix.loss: 0.0593, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:29:14,895 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 9:14:30, time: 1.256, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.1010, src.decode.acc_seg: 96.2545, src.loss: 0.1171, mix.decode.loss_seg: 0.0603, mix.decode.acc_seg: 97.4439, mix.loss: 0.0603, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:30:18,957 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 9:13:31, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1069, src.decode.acc_seg: 96.1515, src.loss: 0.1229, mix.decode.loss_seg: 0.0667, mix.decode.acc_seg: 97.3242, mix.loss: 0.0667, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:31:21,823 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 9:12:29, time: 1.257, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1458, src.decode.acc_seg: 94.7580, src.loss: 0.1618, mix.decode.loss_seg: 0.0835, mix.decode.acc_seg: 96.4713, mix.loss: 0.0835, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:32:24,852 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 9:11:28, time: 1.261, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.1059, src.decode.acc_seg: 95.8236, src.loss: 0.1220, mix.decode.loss_seg: 0.0679, mix.decode.acc_seg: 97.1724, mix.loss: 0.0679, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:33:28,257 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 9:10:27, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0954, src.decode.acc_seg: 96.6724, src.loss: 0.1114, mix.decode.loss_seg: 0.0577, mix.decode.acc_seg: 97.6880, mix.loss: 0.0577, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:34:31,320 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 9:09:26, time: 1.261, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1051, src.decode.acc_seg: 95.9507, src.loss: 0.1212, mix.decode.loss_seg: 0.0590, mix.decode.acc_seg: 97.7365, mix.loss: 0.0590, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:35:34,765 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 9:08:25, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1001, src.decode.acc_seg: 96.2564, src.loss: 0.1162, mix.decode.loss_seg: 0.0615, mix.decode.acc_seg: 97.4190, mix.loss: 0.0615, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:36:38,221 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 9:07:25, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0908, src.decode.acc_seg: 96.6085, src.loss: 0.1069, mix.decode.loss_seg: 0.0552, mix.decode.acc_seg: 97.7337, mix.loss: 0.0552, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:37:41,787 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 9:06:25, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1079, src.decode.acc_seg: 96.4763, src.loss: 0.1239, mix.decode.loss_seg: 0.0809, mix.decode.acc_seg: 97.1296, mix.loss: 0.0809, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:38:44,526 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 9:05:23, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0768, src.decode.acc_seg: 97.2189, src.loss: 0.0928, mix.decode.loss_seg: 0.0531, mix.decode.acc_seg: 97.7467, mix.loss: 0.0531, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:39:47,250 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 9:04:21, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0856, src.decode.acc_seg: 96.8400, src.loss: 0.1017, mix.decode.loss_seg: 0.0624, mix.decode.acc_seg: 97.5678, mix.loss: 0.0624, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:40:51,002 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 9:03:21, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0714, src.decode.acc_seg: 97.5063, src.loss: 0.0874, mix.decode.loss_seg: 0.0469, mix.decode.acc_seg: 98.0824, mix.loss: 0.0469, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:41:54,275 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 9:02:20, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0818, src.decode.acc_seg: 97.1189, src.loss: 0.0979, mix.decode.loss_seg: 0.0566, mix.decode.acc_seg: 97.5690, mix.loss: 0.0566, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:42:57,188 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 13:42:57,189 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 9:01:18, time: 1.258, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0726, src.decode.acc_seg: 97.4629, src.loss: 0.0886, mix.decode.loss_seg: 0.0515, mix.decode.acc_seg: 97.8290, mix.loss: 0.0515, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:43:59,917 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 9:00:16, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0931, src.decode.acc_seg: 96.7271, src.loss: 0.1092, mix.decode.loss_seg: 0.0700, mix.decode.acc_seg: 97.2487, mix.loss: 0.0700, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:45:03,245 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 8:59:15, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1087, src.decode.acc_seg: 96.0094, src.loss: 0.1247, mix.decode.loss_seg: 0.0654, mix.decode.acc_seg: 97.1425, mix.loss: 0.0654, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:46:06,239 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 8:58:14, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0910, src.decode.acc_seg: 96.6607, src.loss: 0.1070, mix.decode.loss_seg: 0.0621, mix.decode.acc_seg: 97.5142, mix.loss: 0.0621, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:47:09,926 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 8:57:14, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0890, src.decode.acc_seg: 96.8561, src.loss: 0.1051, mix.decode.loss_seg: 0.0575, mix.decode.acc_seg: 97.6862, mix.loss: 0.0575, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:48:12,790 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 8:56:12, time: 1.257, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0863, src.decode.acc_seg: 96.8884, src.loss: 0.1024, mix.decode.loss_seg: 0.0604, mix.decode.acc_seg: 97.5656, mix.loss: 0.0604, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:49:15,417 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 8:55:10, time: 1.253, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0941, src.decode.acc_seg: 96.5843, src.loss: 0.1101, mix.decode.loss_seg: 0.0666, mix.decode.acc_seg: 97.3009, mix.loss: 0.0666, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:50:17,647 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 8:54:07, time: 1.245, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1111, src.decode.acc_seg: 95.8419, src.loss: 0.1272, mix.decode.loss_seg: 0.0737, mix.decode.acc_seg: 97.1092, mix.loss: 0.0737, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:51:20,370 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 8:53:05, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0939, src.decode.acc_seg: 96.4445, src.loss: 0.1099, mix.decode.loss_seg: 0.0625, mix.decode.acc_seg: 97.5765, mix.loss: 0.0625, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:52:23,248 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 8:52:03, time: 1.258, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0835, src.decode.acc_seg: 96.7127, src.loss: 0.0995, mix.decode.loss_seg: 0.0543, mix.decode.acc_seg: 97.6430, mix.loss: 0.0543, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:53:26,664 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 8:51:02, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0863, src.decode.acc_seg: 96.7236, src.loss: 0.1024, mix.decode.loss_seg: 0.0576, mix.decode.acc_seg: 97.4428, mix.loss: 0.0576, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:54:29,621 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 8:50:01, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1072, src.decode.acc_seg: 96.1421, src.loss: 0.1232, mix.decode.loss_seg: 0.0519, mix.decode.acc_seg: 97.9846, mix.loss: 0.0519, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:55:32,106 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 8:48:58, time: 1.250, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0914, src.decode.acc_seg: 96.3333, src.loss: 0.1075, mix.decode.loss_seg: 0.0732, mix.decode.acc_seg: 97.0492, mix.loss: 0.0732, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:56:34,947 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 8:47:56, time: 1.257, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0862, src.decode.acc_seg: 97.0778, src.loss: 0.1022, mix.decode.loss_seg: 0.0616, mix.decode.acc_seg: 97.5324, mix.loss: 0.0616, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:57:36,981 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 8:46:53, time: 1.241, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0938, src.decode.acc_seg: 96.7880, src.loss: 0.1099, mix.decode.loss_seg: 0.0632, mix.decode.acc_seg: 97.7223, mix.loss: 0.0632, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:58:39,275 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 8:45:50, time: 1.246, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0784, src.decode.acc_seg: 97.2824, src.loss: 0.0945, mix.decode.loss_seg: 0.0517, mix.decode.acc_seg: 97.7914, mix.loss: 0.0517, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 13:59:42,032 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 8:44:48, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1051, src.decode.acc_seg: 96.3640, src.loss: 0.1211, mix.decode.loss_seg: 0.0606, mix.decode.acc_seg: 97.5664, mix.loss: 0.0606, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:00:44,848 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 8:43:46, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1098, src.decode.acc_seg: 96.3143, src.loss: 0.1258, mix.decode.loss_seg: 0.0689, mix.decode.acc_seg: 97.3840, mix.loss: 0.0689, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:01:48,375 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 8:42:46, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0857, src.decode.acc_seg: 96.8027, src.loss: 0.1018, mix.decode.loss_seg: 0.0585, mix.decode.acc_seg: 97.4644, mix.loss: 0.0585, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:02:51,396 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 8:41:44, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0831, src.decode.acc_seg: 97.1492, src.loss: 0.0991, mix.decode.loss_seg: 0.0555, mix.decode.acc_seg: 97.7728, mix.loss: 0.0555, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:03:53,536 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 14:03:53,537 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 8:40:41, time: 1.243, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0818, src.decode.acc_seg: 97.0819, src.loss: 0.0978, mix.decode.loss_seg: 0.0644, mix.decode.acc_seg: 97.3572, mix.loss: 0.0644, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:04:56,783 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 8:39:40, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0857, src.decode.acc_seg: 96.7903, src.loss: 0.1017, mix.decode.loss_seg: 0.0599, mix.decode.acc_seg: 97.4763, mix.loss: 0.0599, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:05:59,379 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 8:38:38, time: 1.252, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0844, src.decode.acc_seg: 97.0328, src.loss: 0.1004, mix.decode.loss_seg: 0.0605, mix.decode.acc_seg: 97.5736, mix.loss: 0.0605, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:07:02,603 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 8:37:36, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0820, src.decode.acc_seg: 97.0272, src.loss: 0.0980, mix.decode.loss_seg: 0.0621, mix.decode.acc_seg: 97.4964, mix.loss: 0.0621, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:08:05,405 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 8:36:34, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0952, src.decode.acc_seg: 96.6088, src.loss: 0.1112, mix.decode.loss_seg: 0.0560, mix.decode.acc_seg: 97.8334, mix.loss: 0.0560, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:09:09,507 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 8:35:34, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0818, src.decode.acc_seg: 97.0597, src.loss: 0.0978, mix.decode.loss_seg: 0.0567, mix.decode.acc_seg: 97.6476, mix.loss: 0.0567, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:10:12,155 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 8:34:32, time: 1.253, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0867, src.decode.acc_seg: 96.9039, src.loss: 0.1027, mix.decode.loss_seg: 0.0515, mix.decode.acc_seg: 97.9297, mix.loss: 0.0515, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:11:14,930 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 8:33:30, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0862, src.decode.acc_seg: 96.9866, src.loss: 0.1022, mix.decode.loss_seg: 0.0500, mix.decode.acc_seg: 97.9870, mix.loss: 0.0500, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:12:18,407 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 8:32:29, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0743, src.decode.acc_seg: 97.3454, src.loss: 0.0903, mix.decode.loss_seg: 0.0580, mix.decode.acc_seg: 97.6743, mix.loss: 0.0580, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:13:21,510 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 8:31:28, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0757, src.decode.acc_seg: 97.2054, src.loss: 0.0917, mix.decode.loss_seg: 0.0623, mix.decode.acc_seg: 97.3336, mix.loss: 0.0623, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:14:23,823 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 8:30:25, time: 1.246, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1162, src.decode.acc_seg: 96.1021, src.loss: 0.1323, mix.decode.loss_seg: 0.0658, mix.decode.acc_seg: 97.4979, mix.loss: 0.0658, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:15:26,554 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 8:29:23, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0912, src.decode.acc_seg: 97.0464, src.loss: 0.1072, mix.decode.loss_seg: 0.0586, mix.decode.acc_seg: 97.6787, mix.loss: 0.0586, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:16:29,268 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 8:28:21, time: 1.254, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0951, src.decode.acc_seg: 96.7568, src.loss: 0.1111, mix.decode.loss_seg: 0.0581, mix.decode.acc_seg: 97.4581, mix.loss: 0.0581, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:17:32,130 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 8:27:19, time: 1.257, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0858, src.decode.acc_seg: 96.8664, src.loss: 0.1018, mix.decode.loss_seg: 0.0640, mix.decode.acc_seg: 97.4998, mix.loss: 0.0640, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:18:34,410 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 8:26:16, time: 1.246, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0870, src.decode.acc_seg: 96.8454, src.loss: 0.1030, mix.decode.loss_seg: 0.0531, mix.decode.acc_seg: 97.7600, mix.loss: 0.0531, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:19:37,641 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 8:25:14, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.1042, src.decode.acc_seg: 96.2181, src.loss: 0.1202, mix.decode.loss_seg: 0.0605, mix.decode.acc_seg: 97.3826, mix.loss: 0.0605, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:20:40,819 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 8:24:13, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0886, src.decode.acc_seg: 96.7822, src.loss: 0.1046, mix.decode.loss_seg: 0.0574, mix.decode.acc_seg: 97.7073, mix.loss: 0.0574, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:21:42,910 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 8:23:10, time: 1.242, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0738, src.decode.acc_seg: 97.2865, src.loss: 0.0898, mix.decode.loss_seg: 0.0567, mix.decode.acc_seg: 98.0108, mix.loss: 0.0567, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:22:48,296 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 8:22:12, time: 1.308, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0959, src.decode.acc_seg: 96.5264, src.loss: 0.1120, mix.decode.loss_seg: 0.0505, mix.decode.acc_seg: 97.7607, mix.loss: 0.0505, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:23:56,783 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 8:21:18, time: 1.370, data_time: 0.017, memory: 67494, src.decode.loss_seg: 0.0825, src.decode.acc_seg: 96.8967, src.loss: 0.0985, mix.decode.loss_seg: 0.0502, mix.decode.acc_seg: 97.8626, mix.loss: 0.0502, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1145s[                                 ] 2/929, 1.5 task/s, elapsed: 1s, ETA:   619s[                                 ] 3/929, 2.1 task/s, elapsed: 1s, ETA:   443s[                                 ] 4/929, 2.6 task/s, elapsed: 2s, ETA:   355s[                                 ] 5/929, 3.0 task/s, elapsed: 2s, ETA:   303s[                                 ] 6/929, 3.4 task/s, elapsed: 2s, ETA:   269s[                                 ] 7/929, 3.8 task/s, elapsed: 2s, ETA:   245s[                                 ] 8/929, 4.1 task/s, elapsed: 2s, ETA:   226s[                                 ] 9/929, 4.4 task/s, elapsed: 2s, ETA:   211s[                                ] 10/929, 4.6 task/s, elapsed: 2s, ETA:   199s[                                ] 11/929, 4.8 task/s, elapsed: 2s, ETA:   190s[                                ] 12/929, 5.0 task/s, elapsed: 2s, ETA:   182s[                                ] 13/929, 5.2 task/s, elapsed: 2s, ETA:   175s[                                ] 14/929, 5.4 task/s, elapsed: 3s, ETA:   170s[                                ] 15/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 16/929, 5.7 task/s, elapsed: 3s, ETA:   160s[                                ] 17/929, 5.8 task/s, elapsed: 3s, ETA:   156s[                                ] 18/929, 6.0 task/s, elapsed: 3s, ETA:   153s[                                ] 19/929, 6.1 task/s, elapsed: 3s, ETA:   150s[                                ] 20/929, 6.2 task/s, elapsed: 3s, ETA:   147s[                                ] 21/929, 6.3 task/s, elapsed: 3s, ETA:   144s[                                ] 22/929, 6.4 task/s, elapsed: 3s, ETA:   141s[                                ] 23/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 24/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 25/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 26/929, 6.8 task/s, elapsed: 4s, ETA:   134s[                                ] 27/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 28/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 29/929, 7.0 task/s, elapsed: 4s, ETA:   129s[>                               ] 30/929, 7.0 task/s, elapsed: 4s, ETA:   128s[>                               ] 31/929, 7.1 task/s, elapsed: 4s, ETA:   127s[>                               ] 32/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 33/929, 7.2 task/s, elapsed: 5s, ETA:   125s[>                               ] 34/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 35/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 36/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 37/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 38/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 39/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 40/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 41/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 42/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 43/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 44/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 45/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 46/929, 7.8 task/s, elapsed: 6s, ETA:   114s[>                               ] 47/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 48/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 49/929, 7.9 task/s, elapsed: 6s, ETA:   112s[>                               ] 50/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 51/929, 7.9 task/s, elapsed: 6s, ETA:   111s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 53/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 54/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 55/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 56/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 57/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>                               ] 58/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 59/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 61/929, 8.1 task/s, elapsed: 7s, ETA:   107s[>>                              ] 62/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 63/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 64/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 65/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 66/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   104s[>>                              ] 68/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 69/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 70/929, 8.3 task/s, elapsed: 8s, ETA:   103s[>>                              ] 71/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 72/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 73/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 74/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 75/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 76/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 78/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 79/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                              ] 80/929, 8.5 task/s, elapsed: 9s, ETA:   100s[>>                             ] 81/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 82/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 83/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 85/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 86/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 87/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 88/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>                             ] 89/929, 8.6 task/s, elapsed: 10s, ETA:    98s[>>>                            ] 90/929, 8.6 task/s, elapsed: 10s, ETA:    97s[>>>                            ] 91/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 92/929, 8.7 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 93/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 94/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 95/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 96/929, 8.7 task/s, elapsed: 11s, ETA:    96s[>>>                            ] 97/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 98/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                            ] 99/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                           ] 100/929, 8.7 task/s, elapsed: 11s, ETA:    95s[>>>                           ] 101/929, 8.8 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 102/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 103/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 104/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 105/929, 8.8 task/s, elapsed: 12s, ETA:    94s[>>>                           ] 106/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 107/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 108/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 109/929, 8.8 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 110/929, 8.9 task/s, elapsed: 12s, ETA:    93s[>>>                           ] 111/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 112/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 113/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 114/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 115/929, 8.9 task/s, elapsed: 13s, ETA:    92s[>>>                           ] 116/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 117/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 118/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 119/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 120/929, 8.9 task/s, elapsed: 13s, ETA:    91s[>>>                           ] 121/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>                           ] 122/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>                           ] 123/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 124/929, 8.9 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 125/929, 9.0 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 126/929, 9.0 task/s, elapsed: 14s, ETA:    90s[>>>>                          ] 127/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 128/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 129/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 130/929, 9.0 task/s, elapsed: 14s, ETA:    89s[>>>>                          ] 131/929, 9.0 task/s, elapsed: 15s, ETA:    89s[>>>>                          ] 132/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 133/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 134/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 135/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 136/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 137/929, 9.0 task/s, elapsed: 15s, ETA:    88s[>>>>                          ] 138/929, 9.0 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 139/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 140/929, 9.1 task/s, elapsed: 15s, ETA:    87s[>>>>                          ] 141/929, 9.1 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 142/929, 9.1 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 143/929, 9.1 task/s, elapsed: 16s, ETA:    87s[>>>>                          ] 144/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 145/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 146/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 147/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 148/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 149/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 150/929, 9.1 task/s, elapsed: 16s, ETA:    86s[>>>>                          ] 151/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 152/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 153/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>                          ] 154/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 155/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 156/929, 9.1 task/s, elapsed: 17s, ETA:    85s[>>>>>                         ] 157/929, 9.1 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 158/929, 9.1 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 159/929, 9.1 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 160/929, 9.1 task/s, elapsed: 17s, ETA:    84s[>>>>>                         ] 161/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 162/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 163/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 164/929, 9.1 task/s, elapsed: 18s, ETA:    84s[>>>>>                         ] 165/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 166/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 167/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 168/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 169/929, 9.2 task/s, elapsed: 18s, ETA:    83s[>>>>>                         ] 170/929, 9.2 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 171/929, 9.2 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 172/929, 9.2 task/s, elapsed: 19s, ETA:    83s[>>>>>                         ] 173/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 174/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 175/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 176/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 177/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 178/929, 9.2 task/s, elapsed: 19s, ETA:    82s[>>>>>                         ] 179/929, 9.2 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 180/929, 9.2 task/s, elapsed: 20s, ETA:    82s[>>>>>                         ] 181/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 182/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 183/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 184/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>                         ] 185/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>>                        ] 186/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>>                        ] 187/929, 9.2 task/s, elapsed: 20s, ETA:    81s[>>>>>>                        ] 188/929, 9.2 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 189/929, 9.2 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 190/929, 9.2 task/s, elapsed: 21s, ETA:    81s[>>>>>>                        ] 191/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 192/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 193/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 194/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 195/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 196/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 197/929, 9.2 task/s, elapsed: 21s, ETA:    80s[>>>>>>                        ] 198/929, 9.2 task/s, elapsed: 22s, ETA:    80s[>>>>>>                        ] 199/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 200/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 201/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 202/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 203/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 204/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 205/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 206/929, 9.2 task/s, elapsed: 22s, ETA:    79s[>>>>>>                        ] 207/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 208/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 209/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 210/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 211/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 212/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 213/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 214/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 215/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>                        ] 216/929, 9.2 task/s, elapsed: 23s, ETA:    78s[>>>>>>>                       ] 217/929, 9.2 task/s, elapsed: 24s, ETA:    78s[>>>>>>>                       ] 218/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 219/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 220/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 221/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 222/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 223/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 224/929, 9.2 task/s, elapsed: 24s, ETA:    77s[>>>>>>>                       ] 225/929, 9.2 task/s, elapsed: 24s, ETA:    76s[>>>>>>>                       ] 226/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 227/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 228/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 229/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 230/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 231/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 232/929, 9.2 task/s, elapsed: 25s, ETA:    76s[>>>>>>>                       ] 233/929, 9.2 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 234/929, 9.2 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 235/929, 9.2 task/s, elapsed: 25s, ETA:    75s[>>>>>>>                       ] 236/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 237/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 238/929, 9.2 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 239/929, 9.3 task/s, elapsed: 26s, ETA:    75s[>>>>>>>                       ] 240/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 241/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 242/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 243/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 244/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 245/929, 9.3 task/s, elapsed: 26s, ETA:    74s[>>>>>>>                       ] 246/929, 9.3 task/s, elapsed: 27s, ETA:    74s[>>>>>>>                       ] 247/929, 9.3 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 248/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 249/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 250/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 251/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 252/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 253/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 254/929, 9.3 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 255/929, 9.3 task/s, elapsed: 27s, ETA:    72s[>>>>>>>>                      ] 256/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 257/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 258/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 259/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 260/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 261/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 262/929, 9.3 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 263/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 264/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 265/929, 9.3 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 266/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 267/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 268/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 269/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 270/929, 9.3 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 271/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 272/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 273/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 274/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 275/929, 9.3 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 276/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>                      ] 277/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>                      ] 278/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 279/929, 9.3 task/s, elapsed: 30s, ETA:    70s[>>>>>>>>>                     ] 280/929, 9.3 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 281/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 282/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 283/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 284/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 285/929, 9.4 task/s, elapsed: 30s, ETA:    69s[>>>>>>>>>                     ] 286/929, 9.4 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 287/929, 9.4 task/s, elapsed: 31s, ETA:    69s[>>>>>>>>>                     ] 288/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 289/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 290/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 291/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 292/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 293/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 294/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 295/929, 9.4 task/s, elapsed: 31s, ETA:    68s[>>>>>>>>>                     ] 296/929, 9.4 task/s, elapsed: 32s, ETA:    68s[>>>>>>>>>                     ] 297/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 298/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 299/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 300/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 301/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 302/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 303/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 304/929, 9.4 task/s, elapsed: 32s, ETA:    67s[>>>>>>>>>                     ] 305/929, 9.4 task/s, elapsed: 32s, ETA:    66s[>>>>>>>>>                     ] 306/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 307/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 308/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>                     ] 309/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 310/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 311/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 312/929, 9.4 task/s, elapsed: 33s, ETA:    66s[>>>>>>>>>>                    ] 313/929, 9.4 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 314/929, 9.4 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 315/929, 9.4 task/s, elapsed: 33s, ETA:    65s[>>>>>>>>>>                    ] 316/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 317/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 318/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 319/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 320/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 321/929, 9.4 task/s, elapsed: 34s, ETA:    65s[>>>>>>>>>>                    ] 322/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 323/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 324/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 325/929, 9.4 task/s, elapsed: 34s, ETA:    64s[>>>>>>>>>>                    ] 326/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 327/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 328/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 329/929, 9.4 task/s, elapsed: 35s, ETA:    64s[>>>>>>>>>>                    ] 330/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 331/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 332/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 333/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 334/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 335/929, 9.4 task/s, elapsed: 35s, ETA:    63s[>>>>>>>>>>                    ] 336/929, 9.4 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 337/929, 9.5 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 338/929, 9.5 task/s, elapsed: 36s, ETA:    63s[>>>>>>>>>>                    ] 339/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>                    ] 340/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 341/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 342/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 343/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 344/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 345/929, 9.5 task/s, elapsed: 36s, ETA:    62s[>>>>>>>>>>>                   ] 346/929, 9.5 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 347/929, 9.5 task/s, elapsed: 37s, ETA:    62s[>>>>>>>>>>>                   ] 348/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 349/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 350/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 351/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 352/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 353/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 354/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 355/929, 9.5 task/s, elapsed: 37s, ETA:    61s[>>>>>>>>>>>                   ] 356/929, 9.5 task/s, elapsed: 38s, ETA:    61s[>>>>>>>>>>>                   ] 357/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 358/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 359/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 360/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 361/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 362/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 363/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 364/929, 9.5 task/s, elapsed: 38s, ETA:    60s[>>>>>>>>>>>                   ] 365/929, 9.5 task/s, elapsed: 39s, ETA:    60s[>>>>>>>>>>>                   ] 366/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 367/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 368/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 369/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 370/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>                   ] 371/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>>                  ] 372/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>>                  ] 373/929, 9.5 task/s, elapsed: 39s, ETA:    59s[>>>>>>>>>>>>                  ] 374/929, 9.5 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 375/929, 9.5 task/s, elapsed: 40s, ETA:    59s[>>>>>>>>>>>>                  ] 376/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 377/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 378/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 379/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 380/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 381/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 382/929, 9.5 task/s, elapsed: 40s, ETA:    58s[>>>>>>>>>>>>                  ] 383/929, 9.5 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 384/929, 9.5 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 385/929, 9.5 task/s, elapsed: 41s, ETA:    58s[>>>>>>>>>>>>                  ] 386/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 387/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 388/929, 9.4 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 389/929, 9.4 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 390/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 391/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 392/929, 9.5 task/s, elapsed: 41s, ETA:    57s[>>>>>>>>>>>>                  ] 393/929, 9.5 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 394/929, 9.5 task/s, elapsed: 42s, ETA:    57s[>>>>>>>>>>>>                  ] 395/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 396/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 397/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 398/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 399/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 400/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 401/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>                  ] 402/929, 9.5 task/s, elapsed: 42s, ETA:    56s[>>>>>>>>>>>>>                 ] 403/929, 9.5 task/s, elapsed: 43s, ETA:    56s[>>>>>>>>>>>>>                 ] 404/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 405/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 406/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 407/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 408/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 409/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 410/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 411/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 412/929, 9.5 task/s, elapsed: 43s, ETA:    55s[>>>>>>>>>>>>>                 ] 413/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 414/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 415/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 416/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 417/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 418/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 419/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 420/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 421/929, 9.5 task/s, elapsed: 44s, ETA:    54s[>>>>>>>>>>>>>                 ] 422/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 423/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 424/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 425/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 426/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 427/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 428/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 429/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 430/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 431/929, 9.5 task/s, elapsed: 45s, ETA:    53s[>>>>>>>>>>>>>                 ] 432/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>                 ] 433/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 434/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 435/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 436/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 437/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 438/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 439/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 440/929, 9.5 task/s, elapsed: 46s, ETA:    52s[>>>>>>>>>>>>>>                ] 441/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 442/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 443/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 444/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 445/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 446/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 447/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 448/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 449/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 450/929, 9.5 task/s, elapsed: 47s, ETA:    51s[>>>>>>>>>>>>>>                ] 451/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 452/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 453/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 454/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 455/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 456/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 457/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 458/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 459/929, 9.5 task/s, elapsed: 48s, ETA:    50s[>>>>>>>>>>>>>>                ] 460/929, 9.5 task/s, elapsed: 48s, ETA:    49s[>>>>>>>>>>>>>>                ] 461/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 462/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 463/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>                ] 464/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 465/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 466/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 467/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 468/929, 9.5 task/s, elapsed: 49s, ETA:    49s[>>>>>>>>>>>>>>>               ] 469/929, 9.5 task/s, elapsed: 49s, ETA:    48s[>>>>>>>>>>>>>>>               ] 470/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 471/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 472/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 473/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 474/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 475/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 476/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 477/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 478/929, 9.5 task/s, elapsed: 50s, ETA:    48s[>>>>>>>>>>>>>>>               ] 479/929, 9.5 task/s, elapsed: 50s, ETA:    47s[>>>>>>>>>>>>>>>               ] 480/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 481/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 482/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 483/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 484/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 485/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 486/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 487/929, 9.5 task/s, elapsed: 51s, ETA:    47s[>>>>>>>>>>>>>>>               ] 488/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 489/929, 9.5 task/s, elapsed: 51s, ETA:    46s[>>>>>>>>>>>>>>>               ] 490/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 491/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 492/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 493/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 494/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>               ] 495/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 496/929, 9.5 task/s, elapsed: 52s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 497/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 498/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 499/929, 9.5 task/s, elapsed: 52s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 500/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 501/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 502/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 503/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 504/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 505/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 506/929, 9.5 task/s, elapsed: 53s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 507/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 508/929, 9.5 task/s, elapsed: 53s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 509/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 510/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 511/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 512/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 513/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 514/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 515/929, 9.5 task/s, elapsed: 54s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 516/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 517/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 518/929, 9.5 task/s, elapsed: 54s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 519/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 520/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 521/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 522/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 523/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 524/929, 9.5 task/s, elapsed: 55s, ETA:    43s[>>>>>>>>>>>>>>>>              ] 525/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>              ] 526/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.5 task/s, elapsed: 55s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.5 task/s, elapsed: 56s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.5 task/s, elapsed: 56s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.5 task/s, elapsed: 57s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.5 task/s, elapsed: 57s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.5 task/s, elapsed: 58s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.5 task/s, elapsed: 58s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.5 task/s, elapsed: 59s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.5 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.6 task/s, elapsed: 59s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.6 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.6 task/s, elapsed: 60s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.6 task/s, elapsed: 60s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.6 task/s, elapsed: 61s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.6 task/s, elapsed: 61s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.6 task/s, elapsed: 62s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.6 task/s, elapsed: 62s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.6 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.6 task/s, elapsed: 63s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.6 task/s, elapsed: 63s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.6 task/s, elapsed: 64s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.6 task/s, elapsed: 64s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.6 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.6 task/s, elapsed: 65s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.6 task/s, elapsed: 65s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.6 task/s, elapsed: 66s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.6 task/s, elapsed: 66s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.6 task/s, elapsed: 67s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.6 task/s, elapsed: 67s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.6 task/s, elapsed: 68s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.6 task/s, elapsed: 68s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.6 task/s, elapsed: 69s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.6 task/s, elapsed: 69s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.6 task/s, elapsed: 70s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.6 task/s, elapsed: 70s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.6 task/s, elapsed: 71s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.6 task/s, elapsed: 71s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.6 task/s, elapsed: 72s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.6 task/s, elapsed: 72s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.6 task/s, elapsed: 73s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.6 task/s, elapsed: 73s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.6 task/s, elapsed: 74s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.6 task/s, elapsed: 74s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.6 task/s, elapsed: 75s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.6 task/s, elapsed: 75s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.6 task/s, elapsed: 76s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.6 task/s, elapsed: 76s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.6 task/s, elapsed: 77s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.6 task/s, elapsed: 77s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.6 task/s, elapsed: 78s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.6 task/s, elapsed: 78s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.6 task/s, elapsed: 79s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.6 task/s, elapsed: 79s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.6 task/s, elapsed: 80s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.6 task/s, elapsed: 80s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.6 task/s, elapsed: 81s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.6 task/s, elapsed: 82s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.6 task/s, elapsed: 83s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.6 task/s, elapsed: 83s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.6 task/s, elapsed: 84s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.6 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.6 task/s, elapsed: 85s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.6 task/s, elapsed: 86s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.6 task/s, elapsed: 87s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.6 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.6 task/s, elapsed: 88s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.6 task/s, elapsed: 89s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.6 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.6 task/s, elapsed: 90s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.6 task/s, elapsed: 91s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.6 task/s, elapsed: 92s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.6 task/s, elapsed: 92s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.6 task/s, elapsed: 93s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.6 task/s, elapsed: 94s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.6 task/s, elapsed: 95s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.6 task/s, elapsed: 95s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.6 task/s, elapsed: 96s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.6 task/s, elapsed: 96s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.6 task/s, elapsed: 97s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.6 task/s, elapsed: 97s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.6 task/s, elapsed: 97s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.6 task/s, elapsed: 97s, ETA:     0s2022-10-10 14:27:32,354 - mmseg - INFO - per class results:2022-10-10 14:27:32,355 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.75 | 96.56 || rigid_plastic | 25.25 | 30.12 ||   cardboard   | 56.76 | 70.59 ||     metal     | 27.97 | 35.08 ||  soft_plastic | 59.25 | 65.17 |+---------------+-------+-------+2022-10-10 14:27:32,355 - mmseg - INFO - Summary:2022-10-10 14:27:32,355 - mmseg - INFO - +-------+------+------+|  aAcc | mIoU | mAcc |+-------+------+------+| 91.24 | 52.0 | 59.5 |+-------+------+------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:27:32,359 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 14:27:32,360 - mmseg - INFO - Iter [929/40000]	lr: 3.600e-05, eta: 8:20:21, time: 1.328, data_time: 0.017, memory: 67494, aAcc: 0.9124, mIoU: 0.5200, mAcc: 0.5950, IoU.background: 0.9075, IoU.rigid_plastic: 0.2525, IoU.cardboard: 0.5676, IoU.metal: 0.2797, IoU.soft_plastic: 0.5925, Acc.background: 0.9656, Acc.rigid_plastic: 0.3012, Acc.cardboard: 0.7059, Acc.metal: 0.3508, Acc.soft_plastic: 0.6517, src.decode.loss_seg: 0.0691, src.decode.acc_seg: 97.6913, src.loss: 0.0852, mix.decode.loss_seg: 0.0477, mix.decode.acc_seg: 98.0419, mix.loss: 0.0477, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:28:34,617 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 8:23:01, time: 4.229, data_time: 2.998, memory: 67494, src.decode.loss_seg: 0.0883, src.decode.acc_seg: 96.8460, src.loss: 0.1044, mix.decode.loss_seg: 0.0473, mix.decode.acc_seg: 98.0755, mix.loss: 0.0473, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:29:37,346 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 8:21:58, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0794, src.decode.acc_seg: 97.1987, src.loss: 0.0954, mix.decode.loss_seg: 0.0526, mix.decode.acc_seg: 97.8873, mix.loss: 0.0526, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:30:40,280 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 8:20:54, time: 1.259, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0734, src.decode.acc_seg: 97.3469, src.loss: 0.0894, mix.decode.loss_seg: 0.0533, mix.decode.acc_seg: 97.8441, mix.loss: 0.0533, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:31:43,091 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 8:19:51, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0733, src.decode.acc_seg: 97.2067, src.loss: 0.0894, mix.decode.loss_seg: 0.0509, mix.decode.acc_seg: 97.8406, mix.loss: 0.0509, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:32:45,899 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 8:18:48, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0752, src.decode.acc_seg: 97.2252, src.loss: 0.0913, mix.decode.loss_seg: 0.0496, mix.decode.acc_seg: 97.9904, mix.loss: 0.0496, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:33:48,669 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 8:17:44, time: 1.255, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0806, src.decode.acc_seg: 97.2116, src.loss: 0.0967, mix.decode.loss_seg: 0.0488, mix.decode.acc_seg: 97.9564, mix.loss: 0.0488, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:34:50,960 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 8:16:40, time: 1.246, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0799, src.decode.acc_seg: 96.9977, src.loss: 0.0959, mix.decode.loss_seg: 0.0499, mix.decode.acc_seg: 97.9252, mix.loss: 0.0499, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:35:53,672 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 8:15:37, time: 1.254, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0806, src.decode.acc_seg: 97.1566, src.loss: 0.0967, mix.decode.loss_seg: 0.0455, mix.decode.acc_seg: 98.0800, mix.loss: 0.0455, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:36:56,829 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 8:14:34, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0758, src.decode.acc_seg: 97.3121, src.loss: 0.0918, mix.decode.loss_seg: 0.0508, mix.decode.acc_seg: 98.0092, mix.loss: 0.0508, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:37:59,552 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 8:13:31, time: 1.254, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0860, src.decode.acc_seg: 96.9071, src.loss: 0.1021, mix.decode.loss_seg: 0.0653, mix.decode.acc_seg: 97.4010, mix.loss: 0.0653, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:39:02,627 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 8:12:28, time: 1.262, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0982, src.decode.acc_seg: 96.3244, src.loss: 0.1142, mix.decode.loss_seg: 0.0557, mix.decode.acc_seg: 97.6181, mix.loss: 0.0557, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:40:05,809 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 8:11:25, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0952, src.decode.acc_seg: 96.3291, src.loss: 0.1112, mix.decode.loss_seg: 0.0489, mix.decode.acc_seg: 97.9548, mix.loss: 0.0489, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:41:08,428 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 8:10:22, time: 1.252, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0805, src.decode.acc_seg: 97.0471, src.loss: 0.0966, mix.decode.loss_seg: 0.0583, mix.decode.acc_seg: 97.5273, mix.loss: 0.0583, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:42:11,228 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 8:09:18, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0674, src.decode.acc_seg: 97.5613, src.loss: 0.0834, mix.decode.loss_seg: 0.0417, mix.decode.acc_seg: 98.2503, mix.loss: 0.0417, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:43:13,474 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 8:08:14, time: 1.245, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0719, src.decode.acc_seg: 97.3307, src.loss: 0.0880, mix.decode.loss_seg: 0.0491, mix.decode.acc_seg: 98.0124, mix.loss: 0.0491, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:44:16,108 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 8:07:11, time: 1.253, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0755, src.decode.acc_seg: 97.4086, src.loss: 0.0916, mix.decode.loss_seg: 0.0518, mix.decode.acc_seg: 98.0137, mix.loss: 0.0518, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:45:18,332 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 8:06:07, time: 1.244, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0685, src.decode.acc_seg: 97.5816, src.loss: 0.0846, mix.decode.loss_seg: 0.0456, mix.decode.acc_seg: 98.0783, mix.loss: 0.0456, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:46:20,073 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 8:05:02, time: 1.235, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0858, src.decode.acc_seg: 97.0364, src.loss: 0.1018, mix.decode.loss_seg: 0.0533, mix.decode.acc_seg: 97.7075, mix.loss: 0.0533, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:47:21,903 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 8:03:57, time: 1.237, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0785, src.decode.acc_seg: 97.2105, src.loss: 0.0945, mix.decode.loss_seg: 0.0510, mix.decode.acc_seg: 97.9480, mix.loss: 0.0510, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:48:23,909 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 14:48:23,909 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 8:02:53, time: 1.240, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0741, src.decode.acc_seg: 97.2669, src.loss: 0.0901, mix.decode.loss_seg: 0.0602, mix.decode.acc_seg: 97.5314, mix.loss: 0.0602, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:49:26,224 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 8:01:49, time: 1.246, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0630, src.decode.acc_seg: 97.7867, src.loss: 0.0790, mix.decode.loss_seg: 0.0495, mix.decode.acc_seg: 97.8335, mix.loss: 0.0495, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:50:29,270 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 8:00:46, time: 1.261, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0919, src.decode.acc_seg: 96.5358, src.loss: 0.1079, mix.decode.loss_seg: 0.0569, mix.decode.acc_seg: 97.6732, mix.loss: 0.0569, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:51:30,508 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 7:59:41, time: 1.225, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0747, src.decode.acc_seg: 97.1410, src.loss: 0.0907, mix.decode.loss_seg: 0.0474, mix.decode.acc_seg: 97.9382, mix.loss: 0.0474, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:52:32,637 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 7:58:37, time: 1.243, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0920, src.decode.acc_seg: 96.7074, src.loss: 0.1080, mix.decode.loss_seg: 0.0618, mix.decode.acc_seg: 97.4314, mix.loss: 0.0618, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:53:34,584 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 7:57:33, time: 1.239, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0894, src.decode.acc_seg: 96.7764, src.loss: 0.1055, mix.decode.loss_seg: 0.0545, mix.decode.acc_seg: 97.8594, mix.loss: 0.0545, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:54:35,787 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 7:56:27, time: 1.224, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0761, src.decode.acc_seg: 97.2035, src.loss: 0.0921, mix.decode.loss_seg: 0.0520, mix.decode.acc_seg: 97.8615, mix.loss: 0.0520, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:55:37,676 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 7:55:23, time: 1.238, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0765, src.decode.acc_seg: 97.1853, src.loss: 0.0925, mix.decode.loss_seg: 0.0538, mix.decode.acc_seg: 97.8293, mix.loss: 0.0538, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:56:39,813 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 7:54:19, time: 1.243, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0742, src.decode.acc_seg: 97.3240, src.loss: 0.0902, mix.decode.loss_seg: 0.0422, mix.decode.acc_seg: 98.1314, mix.loss: 0.0422, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:57:41,909 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 7:53:15, time: 1.242, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0787, src.decode.acc_seg: 97.1771, src.loss: 0.0948, mix.decode.loss_seg: 0.0580, mix.decode.acc_seg: 97.7712, mix.loss: 0.0580, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:58:44,214 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 7:52:11, time: 1.246, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0870, src.decode.acc_seg: 96.8966, src.loss: 0.1030, mix.decode.loss_seg: 0.0524, mix.decode.acc_seg: 97.9822, mix.loss: 0.0524, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 14:59:46,601 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 7:51:07, time: 1.248, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0829, src.decode.acc_seg: 97.1455, src.loss: 0.0989, mix.decode.loss_seg: 0.0572, mix.decode.acc_seg: 97.6354, mix.loss: 0.0572, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:00:48,889 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 7:50:03, time: 1.246, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0776, src.decode.acc_seg: 97.1968, src.loss: 0.0936, mix.decode.loss_seg: 0.0491, mix.decode.acc_seg: 97.9091, mix.loss: 0.0491, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:01:51,645 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 7:49:00, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0859, src.decode.acc_seg: 96.9606, src.loss: 0.1019, mix.decode.loss_seg: 0.0548, mix.decode.acc_seg: 97.9173, mix.loss: 0.0548, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:02:54,236 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 7:47:57, time: 1.252, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0661, src.decode.acc_seg: 97.6332, src.loss: 0.0821, mix.decode.loss_seg: 0.0513, mix.decode.acc_seg: 97.7721, mix.loss: 0.0513, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:03:56,427 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 7:46:53, time: 1.244, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0836, src.decode.acc_seg: 96.9699, src.loss: 0.0996, mix.decode.loss_seg: 0.0609, mix.decode.acc_seg: 97.5802, mix.loss: 0.0609, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:04:58,359 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 7:45:49, time: 1.239, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0753, src.decode.acc_seg: 97.1261, src.loss: 0.0913, mix.decode.loss_seg: 0.0558, mix.decode.acc_seg: 97.6087, mix.loss: 0.0558, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:06:00,610 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 7:44:45, time: 1.245, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0659, src.decode.acc_seg: 97.6086, src.loss: 0.0819, mix.decode.loss_seg: 0.0429, mix.decode.acc_seg: 98.1693, mix.loss: 0.0429, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:07:03,478 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 7:43:42, time: 1.257, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0731, src.decode.acc_seg: 97.2155, src.loss: 0.0891, mix.decode.loss_seg: 0.0528, mix.decode.acc_seg: 97.6972, mix.loss: 0.0528, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:08:04,677 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 7:42:37, time: 1.224, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0642, src.decode.acc_seg: 97.5406, src.loss: 0.0802, mix.decode.loss_seg: 0.0411, mix.decode.acc_seg: 98.1975, mix.loss: 0.0411, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:09:06,542 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 15:09:06,543 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 7:41:33, time: 1.237, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0783, src.decode.acc_seg: 97.2728, src.loss: 0.0943, mix.decode.loss_seg: 0.0642, mix.decode.acc_seg: 97.4259, mix.loss: 0.0642, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:10:08,487 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 7:40:28, time: 1.239, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0717, src.decode.acc_seg: 97.4166, src.loss: 0.0877, mix.decode.loss_seg: 0.0479, mix.decode.acc_seg: 98.0176, mix.loss: 0.0479, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:11:10,126 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 7:39:24, time: 1.233, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0851, src.decode.acc_seg: 97.0358, src.loss: 0.1011, mix.decode.loss_seg: 0.0558, mix.decode.acc_seg: 97.7589, mix.loss: 0.0558, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:12:13,141 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 7:38:21, time: 1.260, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0857, src.decode.acc_seg: 96.8359, src.loss: 0.1018, mix.decode.loss_seg: 0.0533, mix.decode.acc_seg: 97.9249, mix.loss: 0.0533, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:13:15,548 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 7:37:17, time: 1.248, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0750, src.decode.acc_seg: 97.2552, src.loss: 0.0910, mix.decode.loss_seg: 0.0557, mix.decode.acc_seg: 97.7043, mix.loss: 0.0557, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:14:18,367 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 7:36:14, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0859, src.decode.acc_seg: 96.7735, src.loss: 0.1019, mix.decode.loss_seg: 0.0544, mix.decode.acc_seg: 97.7494, mix.loss: 0.0544, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:15:20,506 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 7:35:11, time: 1.243, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0725, src.decode.acc_seg: 97.6046, src.loss: 0.0885, mix.decode.loss_seg: 0.0517, mix.decode.acc_seg: 97.9808, mix.loss: 0.0517, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:16:22,726 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 7:34:07, time: 1.244, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0666, src.decode.acc_seg: 97.5274, src.loss: 0.0827, mix.decode.loss_seg: 0.0522, mix.decode.acc_seg: 97.9437, mix.loss: 0.0522, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:17:24,838 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 7:33:03, time: 1.242, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0636, src.decode.acc_seg: 97.6351, src.loss: 0.0796, mix.decode.loss_seg: 0.0518, mix.decode.acc_seg: 97.9475, mix.loss: 0.0518, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:18:26,326 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 7:31:58, time: 1.230, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0888, src.decode.acc_seg: 96.7954, src.loss: 0.1048, mix.decode.loss_seg: 0.0507, mix.decode.acc_seg: 97.9037, mix.loss: 0.0507, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:19:28,683 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 7:30:55, time: 1.247, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0749, src.decode.acc_seg: 97.1604, src.loss: 0.0909, mix.decode.loss_seg: 0.0451, mix.decode.acc_seg: 98.0506, mix.loss: 0.0451, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:20:30,658 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 7:29:51, time: 1.239, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0577, src.decode.acc_seg: 97.9106, src.loss: 0.0737, mix.decode.loss_seg: 0.0415, mix.decode.acc_seg: 98.4214, mix.loss: 0.0415, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:21:33,021 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 7:28:47, time: 1.247, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0684, src.decode.acc_seg: 97.4903, src.loss: 0.0845, mix.decode.loss_seg: 0.0460, mix.decode.acc_seg: 98.0684, mix.loss: 0.0460, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:22:36,111 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 7:27:44, time: 1.262, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0647, src.decode.acc_seg: 97.6567, src.loss: 0.0808, mix.decode.loss_seg: 0.0623, mix.decode.acc_seg: 97.6150, mix.loss: 0.0623, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:23:38,395 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 7:26:41, time: 1.246, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0805, src.decode.acc_seg: 97.0866, src.loss: 0.0965, mix.decode.loss_seg: 0.0530, mix.decode.acc_seg: 97.5655, mix.loss: 0.0530, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:24:40,661 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 7:25:37, time: 1.245, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0780, src.decode.acc_seg: 97.2635, src.loss: 0.0941, mix.decode.loss_seg: 0.0550, mix.decode.acc_seg: 97.7679, mix.loss: 0.0550, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:25:42,958 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 7:24:34, time: 1.246, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0696, src.decode.acc_seg: 97.4672, src.loss: 0.0857, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 97.9917, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:26:45,298 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 7:23:30, time: 1.247, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0723, src.decode.acc_seg: 97.4049, src.loss: 0.0883, mix.decode.loss_seg: 0.0454, mix.decode.acc_seg: 98.0305, mix.loss: 0.0454, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:27:48,704 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 7:22:28, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0724, src.decode.acc_seg: 97.2018, src.loss: 0.0885, mix.decode.loss_seg: 0.0493, mix.decode.acc_seg: 97.9534, mix.loss: 0.0493, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:28:52,077 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 7:21:25, time: 1.267, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0713, src.decode.acc_seg: 97.3929, src.loss: 0.0873, mix.decode.loss_seg: 0.0474, mix.decode.acc_seg: 98.1234, mix.loss: 0.0474, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:29:55,966 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 15:29:55,966 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 7:20:23, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0853, src.decode.acc_seg: 96.9377, src.loss: 0.1013, mix.decode.loss_seg: 0.0543, mix.decode.acc_seg: 97.6244, mix.loss: 0.0543, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:30:59,499 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 7:19:21, time: 1.271, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0744, src.decode.acc_seg: 97.2844, src.loss: 0.0904, mix.decode.loss_seg: 0.0484, mix.decode.acc_seg: 98.0726, mix.loss: 0.0484, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:32:03,111 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 7:18:19, time: 1.272, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0741, src.decode.acc_seg: 97.2949, src.loss: 0.0901, mix.decode.loss_seg: 0.0534, mix.decode.acc_seg: 97.8201, mix.loss: 0.0534, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:33:06,921 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 7:17:17, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0774, src.decode.acc_seg: 97.1273, src.loss: 0.0934, mix.decode.loss_seg: 0.0481, mix.decode.acc_seg: 97.9058, mix.loss: 0.0481, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:34:10,204 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 7:16:15, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0700, src.decode.acc_seg: 97.3344, src.loss: 0.0860, mix.decode.loss_seg: 0.0611, mix.decode.acc_seg: 97.6178, mix.loss: 0.0611, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:35:13,644 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 7:15:12, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0659, src.decode.acc_seg: 97.5205, src.loss: 0.0819, mix.decode.loss_seg: 0.0484, mix.decode.acc_seg: 98.0919, mix.loss: 0.0484, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:36:16,409 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 7:14:09, time: 1.255, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0675, src.decode.acc_seg: 97.5677, src.loss: 0.0836, mix.decode.loss_seg: 0.0426, mix.decode.acc_seg: 98.2106, mix.loss: 0.0426, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:37:20,005 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 7:13:07, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0654, src.decode.acc_seg: 97.6492, src.loss: 0.0814, mix.decode.loss_seg: 0.0496, mix.decode.acc_seg: 98.0009, mix.loss: 0.0496, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:38:24,062 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 7:12:05, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0788, src.decode.acc_seg: 97.1620, src.loss: 0.0949, mix.decode.loss_seg: 0.0526, mix.decode.acc_seg: 97.8883, mix.loss: 0.0526, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:39:27,826 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 7:11:03, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0851, src.decode.acc_seg: 96.8249, src.loss: 0.1011, mix.decode.loss_seg: 0.0517, mix.decode.acc_seg: 97.8456, mix.loss: 0.0517, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:40:31,202 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 7:10:01, time: 1.268, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0748, src.decode.acc_seg: 97.3298, src.loss: 0.0908, mix.decode.loss_seg: 0.0449, mix.decode.acc_seg: 98.1670, mix.loss: 0.0449, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:41:34,401 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 7:08:58, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0730, src.decode.acc_seg: 97.3098, src.loss: 0.0890, mix.decode.loss_seg: 0.0482, mix.decode.acc_seg: 97.9995, mix.loss: 0.0482, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:42:37,874 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 7:07:56, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0747, src.decode.acc_seg: 97.2306, src.loss: 0.0907, mix.decode.loss_seg: 0.0510, mix.decode.acc_seg: 97.7709, mix.loss: 0.0510, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:43:42,222 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 7:06:54, time: 1.287, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0730, src.decode.acc_seg: 97.3031, src.loss: 0.0890, mix.decode.loss_seg: 0.0478, mix.decode.acc_seg: 98.2111, mix.loss: 0.0478, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:44:45,903 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 7:05:52, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0722, src.decode.acc_seg: 97.3978, src.loss: 0.0882, mix.decode.loss_seg: 0.0546, mix.decode.acc_seg: 97.6958, mix.loss: 0.0546, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:45:49,661 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 7:04:50, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0709, src.decode.acc_seg: 97.3918, src.loss: 0.0869, mix.decode.loss_seg: 0.0456, mix.decode.acc_seg: 98.1745, mix.loss: 0.0456, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:46:54,661 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 7:03:49, time: 1.300, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0816, src.decode.acc_seg: 97.0366, src.loss: 0.0976, mix.decode.loss_seg: 0.0553, mix.decode.acc_seg: 97.8636, mix.loss: 0.0553, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:47:58,222 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 7:02:47, time: 1.271, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0652, src.decode.acc_seg: 97.5601, src.loss: 0.0813, mix.decode.loss_seg: 0.0528, mix.decode.acc_seg: 97.8947, mix.loss: 0.0528, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:49:07,974 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 7:01:51, time: 1.395, data_time: 0.018, memory: 67494, src.decode.loss_seg: 0.0589, src.decode.acc_seg: 97.8116, src.loss: 0.0749, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 98.1291, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:50:15,871 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 7:00:53, time: 1.358, data_time: 0.018, memory: 67494, src.decode.loss_seg: 0.0685, src.decode.acc_seg: 97.3686, src.loss: 0.0846, mix.decode.loss_seg: 0.0457, mix.decode.acc_seg: 97.9534, mix.loss: 0.0457, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.7 task/s, elapsed: 2s, ETA:  1424s[                                 ] 2/929, 1.2 task/s, elapsed: 2s, ETA:   766s[                                 ] 3/929, 1.7 task/s, elapsed: 2s, ETA:   543s[                                 ] 4/929, 2.1 task/s, elapsed: 2s, ETA:   431s[                                 ] 5/929, 2.5 task/s, elapsed: 2s, ETA:   363s[                                 ] 6/929, 2.9 task/s, elapsed: 2s, ETA:   319s[                                 ] 7/929, 3.2 task/s, elapsed: 2s, ETA:   287s[                                 ] 8/929, 3.5 task/s, elapsed: 2s, ETA:   263s[                                 ] 9/929, 3.8 task/s, elapsed: 2s, ETA:   245s[                                ] 10/929, 4.0 task/s, elapsed: 3s, ETA:   230s[                                ] 11/929, 4.2 task/s, elapsed: 3s, ETA:   218s[                                ] 12/929, 4.4 task/s, elapsed: 3s, ETA:   207s[                                ] 13/929, 4.6 task/s, elapsed: 3s, ETA:   198s[                                ] 14/929, 4.8 task/s, elapsed: 3s, ETA:   191s[                                ] 15/929, 5.0 task/s, elapsed: 3s, ETA:   184s[                                ] 16/929, 5.1 task/s, elapsed: 3s, ETA:   178s[                                ] 17/929, 5.3 task/s, elapsed: 3s, ETA:   172s[                                ] 18/929, 5.4 task/s, elapsed: 3s, ETA:   168s[                                ] 19/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 20/929, 5.7 task/s, elapsed: 4s, ETA:   160s[                                ] 21/929, 5.8 task/s, elapsed: 4s, ETA:   156s[                                ] 22/929, 5.9 task/s, elapsed: 4s, ETA:   154s[                                ] 23/929, 6.0 task/s, elapsed: 4s, ETA:   151s[                                ] 24/929, 6.1 task/s, elapsed: 4s, ETA:   148s[                                ] 25/929, 6.2 task/s, elapsed: 4s, ETA:   146s[                                ] 26/929, 6.3 task/s, elapsed: 4s, ETA:   143s[                                ] 27/929, 6.4 task/s, elapsed: 4s, ETA:   141s[                                ] 28/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 29/929, 6.5 task/s, elapsed: 4s, ETA:   138s[>                               ] 30/929, 6.6 task/s, elapsed: 5s, ETA:   136s[>                               ] 31/929, 6.7 task/s, elapsed: 5s, ETA:   134s[>                               ] 32/929, 6.7 task/s, elapsed: 5s, ETA:   133s[>                               ] 33/929, 6.8 task/s, elapsed: 5s, ETA:   132s[>                               ] 34/929, 6.9 task/s, elapsed: 5s, ETA:   130s[>                               ] 35/929, 6.9 task/s, elapsed: 5s, ETA:   129s[>                               ] 36/929, 7.0 task/s, elapsed: 5s, ETA:   128s[>                               ] 37/929, 7.0 task/s, elapsed: 5s, ETA:   127s[>                               ] 38/929, 7.1 task/s, elapsed: 5s, ETA:   126s[>                               ] 39/929, 7.1 task/s, elapsed: 5s, ETA:   125s[>                               ] 40/929, 7.2 task/s, elapsed: 6s, ETA:   124s[>                               ] 41/929, 7.2 task/s, elapsed: 6s, ETA:   123s[>                               ] 42/929, 7.3 task/s, elapsed: 6s, ETA:   122s[>                               ] 43/929, 7.3 task/s, elapsed: 6s, ETA:   121s[>                               ] 44/929, 7.3 task/s, elapsed: 6s, ETA:   121s[>                               ] 45/929, 7.4 task/s, elapsed: 6s, ETA:   120s[>                               ] 46/929, 7.4 task/s, elapsed: 6s, ETA:   119s[>                               ] 47/929, 7.4 task/s, elapsed: 6s, ETA:   119s[>                               ] 48/929, 7.5 task/s, elapsed: 6s, ETA:   118s[>                               ] 49/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 50/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 51/929, 7.6 task/s, elapsed: 7s, ETA:   116s[>                               ] 52/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 53/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 54/929, 7.6 task/s, elapsed: 7s, ETA:   114s[>                               ] 55/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 56/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 57/929, 7.7 task/s, elapsed: 7s, ETA:   113s[>                               ] 58/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 59/929, 7.8 task/s, elapsed: 8s, ETA:   112s[>>                              ] 60/929, 7.8 task/s, elapsed: 8s, ETA:   112s[>>                              ] 61/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 62/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 63/929, 7.8 task/s, elapsed: 8s, ETA:   110s[>>                              ] 64/929, 7.9 task/s, elapsed: 8s, ETA:   110s[>>                              ] 65/929, 7.9 task/s, elapsed: 8s, ETA:   110s[>>                              ] 66/929, 7.9 task/s, elapsed: 8s, ETA:   109s[>>                              ] 67/929, 7.9 task/s, elapsed: 8s, ETA:   109s[>>                              ] 68/929, 8.0 task/s, elapsed: 9s, ETA:   108s[>>                              ] 69/929, 8.0 task/s, elapsed: 9s, ETA:   108s[>>                              ] 70/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 71/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 72/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 73/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 74/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 75/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 76/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 77/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                             ] 78/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 79/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 80/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 81/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 82/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 83/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 84/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 85/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 86/929, 8.2 task/s, elapsed: 10s, ETA:   102s[>>                             ] 87/929, 8.3 task/s, elapsed: 11s, ETA:   102s[>>                             ] 88/929, 8.3 task/s, elapsed: 11s, ETA:   102s[>>                             ] 89/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 90/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 91/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 92/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 93/929, 8.3 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 94/929, 8.3 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 95/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 96/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 97/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                            ] 98/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                            ] 99/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 100/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 101/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 102/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 103/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 104/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 105/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 106/929, 8.4 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 107/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 108/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 109/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 110/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 111/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 112/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 113/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 114/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 115/929, 8.5 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 116/929, 8.5 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 117/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 118/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 119/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 120/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 121/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 122/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 123/929, 8.5 task/s, elapsed: 14s, ETA:    94s[>>>>                          ] 124/929, 8.5 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 125/929, 8.6 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 126/929, 8.6 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 127/929, 8.6 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 128/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 129/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 130/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 131/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 132/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 133/929, 8.6 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 134/929, 8.6 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 135/929, 8.6 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 136/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 137/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 138/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 139/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 140/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 141/929, 8.6 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 142/929, 8.6 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 143/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 144/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 145/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 146/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 147/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 148/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 149/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 150/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 151/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 152/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>                          ] 153/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>                          ] 154/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 155/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 156/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 157/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 158/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 159/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 160/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 161/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 162/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 163/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 164/929, 8.7 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 165/929, 8.7 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 166/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 167/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 168/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 169/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 170/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 171/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 172/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 173/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 174/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 175/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 176/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 177/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 178/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 179/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 180/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 181/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 182/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 183/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 184/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 185/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 186/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 187/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 188/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 189/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 190/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 191/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 192/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 193/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 194/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 195/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 196/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 197/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 198/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 199/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 200/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 201/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 202/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 203/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 204/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 205/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 206/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 207/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 208/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 209/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 210/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 211/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 212/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 213/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 214/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 215/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 216/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 217/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 218/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 219/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 220/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 221/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 222/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 223/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 224/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 225/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 226/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 227/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 228/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 229/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 230/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 231/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 232/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 233/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 234/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 235/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 236/929, 8.9 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 237/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 239/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 240/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 241/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 242/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 243/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 244/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 245/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 246/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>                       ] 247/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 248/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 249/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 250/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 251/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 252/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 254/929, 8.9 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 255/929, 8.9 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 256/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 257/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 258/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 259/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 260/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 261/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 262/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 263/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 264/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 265/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 266/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 267/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 268/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 269/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 270/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 271/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 272/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 273/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 274/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 275/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 276/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 277/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 278/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 279/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 280/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 281/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 282/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 283/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 284/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 285/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 286/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 287/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 288/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 289/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 290/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 292/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 293/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 294/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 295/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 296/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 297/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 298/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 299/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 300/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 301/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 302/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 303/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 304/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 305/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 306/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 307/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 308/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 309/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 310/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 311/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 312/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 313/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 314/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 315/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 316/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 317/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 318/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 319/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 320/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 321/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 322/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 323/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 324/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 325/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 326/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 327/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 328/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 329/929, 9.0 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 330/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 331/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 332/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 333/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 334/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 335/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 336/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 337/929, 9.0 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 338/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 339/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 340/929, 9.1 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 341/929, 9.1 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 342/929, 9.1 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 343/929, 9.1 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 344/929, 9.1 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 345/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 346/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 347/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 348/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 349/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 350/929, 9.1 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 351/929, 9.1 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 352/929, 9.1 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 353/929, 9.1 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 354/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 355/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 356/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 357/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 358/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 359/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 360/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 361/929, 9.1 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 362/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 366/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 367/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 368/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 369/929, 9.1 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 370/929, 9.1 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 371/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 376/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 377/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 378/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 379/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 380/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 384/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 385/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 386/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 387/929, 9.1 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 388/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 394/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 395/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 396/929, 9.1 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 397/929, 9.1 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 398/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 403/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 404/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 405/929, 9.1 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 406/929, 9.1 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 407/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 412/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 413/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 414/929, 9.1 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 415/929, 9.1 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 416/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 422/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 423/929, 9.1 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 424/929, 9.1 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 425/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 430/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 431/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 432/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 433/929, 9.1 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 434/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 441/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 442/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 450/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 451/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 460/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 468/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 469/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 477/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.2 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.2 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.2 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.2 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.2 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.2 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.2 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.2 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.2 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.2 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.2 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.2 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.2 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.2 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.2 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.2 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.2 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.2 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.2 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.2 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.2 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.2 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.2 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.2 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.2 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.2 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.2 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.2 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.2 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.2 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.2 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.3 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.3 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.3 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.3 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.3 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.3 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.3 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.3 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.3 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.3 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.3 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.3 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.3 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.3 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.3 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.3 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.3 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.3 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.3 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.3 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.3 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.3 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.3 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.3 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.3 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.3 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.3 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.3 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.3 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.3 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.3 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.3 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.3 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.3 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.3 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.3 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.3 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.3 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.3 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.3 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.3 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.3 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.3 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.3 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.3 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.3 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.3 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.3 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.3 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.3 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.3 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.3 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.3 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.3 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.3 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.3 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.3 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.3 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.3 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.3 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.3 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.3 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.3 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.3 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.3 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.3 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.3 task/s, elapsed: 99s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.3 task/s, elapsed: 100s, ETA:     0s2022-10-10 15:53:55,194 - mmseg - INFO - per class results:2022-10-10 15:53:55,195 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  |  91.0 | 96.11 || rigid_plastic | 26.71 | 31.63 ||   cardboard   | 56.48 | 71.42 ||     metal     | 34.92 | 42.13 ||  soft_plastic |  63.5 | 72.51 |+---------------+-------+-------+2022-10-10 15:53:55,195 - mmseg - INFO - Summary:2022-10-10 15:53:55,196 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.41 | 54.52 | 62.76 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:53:55,202 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 15:53:55,202 - mmseg - INFO - Iter [929/40000]	lr: 3.000e-05, eta: 6:59:51, time: 1.277, data_time: 0.014, memory: 67494, aAcc: 0.9141, mIoU: 0.5452, mAcc: 0.6276, IoU.background: 0.9100, IoU.rigid_plastic: 0.2671, IoU.cardboard: 0.5648, IoU.metal: 0.3492, IoU.soft_plastic: 0.6350, Acc.background: 0.9611, Acc.rigid_plastic: 0.3163, Acc.cardboard: 0.7142, Acc.metal: 0.4213, Acc.soft_plastic: 0.7251, src.decode.loss_seg: 0.0761, src.decode.acc_seg: 97.2598, src.loss: 0.0921, mix.decode.loss_seg: 0.0477, mix.decode.acc_seg: 98.1119, mix.loss: 0.0477, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:54:59,468 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 7:01:24, time: 4.395, data_time: 3.124, memory: 67494, src.decode.loss_seg: 0.0624, src.decode.acc_seg: 97.6703, src.loss: 0.0784, mix.decode.loss_seg: 0.0389, mix.decode.acc_seg: 98.2987, mix.loss: 0.0389, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:56:03,335 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 7:00:21, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0812, src.decode.acc_seg: 97.1601, src.loss: 0.0972, mix.decode.loss_seg: 0.0590, mix.decode.acc_seg: 97.6812, mix.loss: 0.0590, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:57:07,188 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 6:59:18, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0581, src.decode.acc_seg: 97.9235, src.loss: 0.0741, mix.decode.loss_seg: 0.0412, mix.decode.acc_seg: 98.3745, mix.loss: 0.0412, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:58:11,526 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 6:58:15, time: 1.287, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0573, src.decode.acc_seg: 97.8481, src.loss: 0.0733, mix.decode.loss_seg: 0.0452, mix.decode.acc_seg: 98.3259, mix.loss: 0.0452, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 15:59:15,906 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 6:57:13, time: 1.288, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0704, src.decode.acc_seg: 97.5079, src.loss: 0.0864, mix.decode.loss_seg: 0.0490, mix.decode.acc_seg: 97.9364, mix.loss: 0.0490, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:00:20,079 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 6:56:10, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0810, src.decode.acc_seg: 97.2503, src.loss: 0.0970, mix.decode.loss_seg: 0.0512, mix.decode.acc_seg: 97.9111, mix.loss: 0.0512, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:01:23,882 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 6:55:07, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0682, src.decode.acc_seg: 97.5363, src.loss: 0.0842, mix.decode.loss_seg: 0.0545, mix.decode.acc_seg: 97.7765, mix.loss: 0.0545, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:02:28,136 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 6:54:05, time: 1.285, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0724, src.decode.acc_seg: 97.4852, src.loss: 0.0884, mix.decode.loss_seg: 0.0511, mix.decode.acc_seg: 97.9881, mix.loss: 0.0511, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:03:32,127 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 6:53:02, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0721, src.decode.acc_seg: 97.3358, src.loss: 0.0881, mix.decode.loss_seg: 0.0418, mix.decode.acc_seg: 98.2919, mix.loss: 0.0418, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:04:36,224 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 6:51:59, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0699, src.decode.acc_seg: 97.4236, src.loss: 0.0860, mix.decode.loss_seg: 0.0466, mix.decode.acc_seg: 98.0999, mix.loss: 0.0466, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:05:39,765 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 6:50:56, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0785, src.decode.acc_seg: 97.2087, src.loss: 0.0945, mix.decode.loss_seg: 0.0481, mix.decode.acc_seg: 97.9364, mix.loss: 0.0481, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:06:44,123 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 6:49:54, time: 1.287, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0590, src.decode.acc_seg: 97.9154, src.loss: 0.0750, mix.decode.loss_seg: 0.0430, mix.decode.acc_seg: 98.1797, mix.loss: 0.0430, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:07:47,524 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 6:48:50, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0713, src.decode.acc_seg: 97.5077, src.loss: 0.0874, mix.decode.loss_seg: 0.0444, mix.decode.acc_seg: 97.9948, mix.loss: 0.0444, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:08:50,917 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 6:47:47, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0731, src.decode.acc_seg: 97.4095, src.loss: 0.0892, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 98.0266, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:09:55,272 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 6:46:44, time: 1.287, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0672, src.decode.acc_seg: 97.6625, src.loss: 0.0832, mix.decode.loss_seg: 0.0449, mix.decode.acc_seg: 98.1950, mix.loss: 0.0449, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:10:59,087 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 6:45:41, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0588, src.decode.acc_seg: 97.7980, src.loss: 0.0748, mix.decode.loss_seg: 0.0447, mix.decode.acc_seg: 97.9847, mix.loss: 0.0447, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:12:02,772 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 6:44:38, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0694, src.decode.acc_seg: 97.5031, src.loss: 0.0854, mix.decode.loss_seg: 0.0502, mix.decode.acc_seg: 97.9970, mix.loss: 0.0502, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:13:06,420 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 6:43:35, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0693, src.decode.acc_seg: 97.4651, src.loss: 0.0853, mix.decode.loss_seg: 0.0465, mix.decode.acc_seg: 98.0338, mix.loss: 0.0465, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:14:10,381 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 6:42:32, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0717, src.decode.acc_seg: 97.4509, src.loss: 0.0877, mix.decode.loss_seg: 0.0439, mix.decode.acc_seg: 98.1173, mix.loss: 0.0439, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:15:14,368 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 16:15:14,368 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 6:41:29, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0713, src.decode.acc_seg: 97.3540, src.loss: 0.0874, mix.decode.loss_seg: 0.0440, mix.decode.acc_seg: 98.2514, mix.loss: 0.0440, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:16:18,294 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 6:40:27, time: 1.278, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0667, src.decode.acc_seg: 97.5139, src.loss: 0.0827, mix.decode.loss_seg: 0.0415, mix.decode.acc_seg: 98.2396, mix.loss: 0.0415, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:17:21,479 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 6:39:23, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0732, src.decode.acc_seg: 97.3913, src.loss: 0.0893, mix.decode.loss_seg: 0.0458, mix.decode.acc_seg: 98.0886, mix.loss: 0.0458, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:18:25,124 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 6:38:20, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0654, src.decode.acc_seg: 97.6043, src.loss: 0.0814, mix.decode.loss_seg: 0.0476, mix.decode.acc_seg: 98.0974, mix.loss: 0.0476, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:19:28,705 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 6:37:17, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0616, src.decode.acc_seg: 97.7464, src.loss: 0.0777, mix.decode.loss_seg: 0.0459, mix.decode.acc_seg: 97.9665, mix.loss: 0.0459, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:20:32,360 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 6:36:13, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0544, src.decode.acc_seg: 98.0129, src.loss: 0.0705, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.2292, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:21:36,563 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 6:35:11, time: 1.284, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0667, src.decode.acc_seg: 97.5632, src.loss: 0.0827, mix.decode.loss_seg: 0.0481, mix.decode.acc_seg: 98.0285, mix.loss: 0.0481, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:22:40,257 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 6:34:08, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0700, src.decode.acc_seg: 97.4064, src.loss: 0.0861, mix.decode.loss_seg: 0.0486, mix.decode.acc_seg: 98.0604, mix.loss: 0.0486, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:23:43,717 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 6:33:04, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0635, src.decode.acc_seg: 97.7456, src.loss: 0.0795, mix.decode.loss_seg: 0.0393, mix.decode.acc_seg: 98.2730, mix.loss: 0.0393, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:24:48,060 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 6:32:02, time: 1.287, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0594, src.decode.acc_seg: 97.7245, src.loss: 0.0754, mix.decode.loss_seg: 0.0449, mix.decode.acc_seg: 98.0946, mix.loss: 0.0449, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:25:51,535 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 6:30:58, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0592, src.decode.acc_seg: 97.7146, src.loss: 0.0752, mix.decode.loss_seg: 0.0415, mix.decode.acc_seg: 98.3766, mix.loss: 0.0415, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:26:55,534 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 6:29:55, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0675, src.decode.acc_seg: 97.5343, src.loss: 0.0835, mix.decode.loss_seg: 0.0409, mix.decode.acc_seg: 98.2158, mix.loss: 0.0409, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:27:59,307 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 6:28:52, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0736, src.decode.acc_seg: 97.3682, src.loss: 0.0896, mix.decode.loss_seg: 0.0542, mix.decode.acc_seg: 97.7847, mix.loss: 0.0542, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:29:02,949 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 6:27:49, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0686, src.decode.acc_seg: 97.4089, src.loss: 0.0846, mix.decode.loss_seg: 0.0521, mix.decode.acc_seg: 97.8826, mix.loss: 0.0521, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:30:06,832 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 6:26:46, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0586, src.decode.acc_seg: 97.9233, src.loss: 0.0747, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.2801, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:31:10,298 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 6:25:43, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0526, src.decode.acc_seg: 98.1444, src.loss: 0.0686, mix.decode.loss_seg: 0.0437, mix.decode.acc_seg: 98.3567, mix.loss: 0.0437, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:32:13,484 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 6:24:39, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0578, src.decode.acc_seg: 97.9472, src.loss: 0.0739, mix.decode.loss_seg: 0.0466, mix.decode.acc_seg: 98.1259, mix.loss: 0.0466, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:33:17,095 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 6:23:36, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0510, src.decode.acc_seg: 98.1277, src.loss: 0.0671, mix.decode.loss_seg: 0.0434, mix.decode.acc_seg: 98.1484, mix.loss: 0.0434, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:34:20,614 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 6:22:33, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0598, src.decode.acc_seg: 97.7880, src.loss: 0.0758, mix.decode.loss_seg: 0.0359, mix.decode.acc_seg: 98.4777, mix.loss: 0.0359, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:35:24,508 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 6:21:30, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0592, src.decode.acc_seg: 97.8792, src.loss: 0.0752, mix.decode.loss_seg: 0.0433, mix.decode.acc_seg: 98.1266, mix.loss: 0.0433, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:36:28,501 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 16:36:28,501 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 6:20:27, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0638, src.decode.acc_seg: 97.7727, src.loss: 0.0799, mix.decode.loss_seg: 0.0542, mix.decode.acc_seg: 97.7859, mix.loss: 0.0542, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:37:32,066 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 6:19:23, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0604, src.decode.acc_seg: 97.7094, src.loss: 0.0764, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.1566, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:38:35,656 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 6:18:20, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0606, src.decode.acc_seg: 97.7196, src.loss: 0.0766, mix.decode.loss_seg: 0.0426, mix.decode.acc_seg: 98.2296, mix.loss: 0.0426, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:39:39,177 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 6:17:17, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0564, src.decode.acc_seg: 97.8581, src.loss: 0.0724, mix.decode.loss_seg: 0.0416, mix.decode.acc_seg: 98.2395, mix.loss: 0.0416, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:40:42,472 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 6:16:13, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0551, src.decode.acc_seg: 97.9734, src.loss: 0.0712, mix.decode.loss_seg: 0.0425, mix.decode.acc_seg: 98.3101, mix.loss: 0.0425, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:41:45,792 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 6:15:10, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0515, src.decode.acc_seg: 98.1171, src.loss: 0.0675, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.3022, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:42:49,335 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 6:14:07, time: 1.271, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0683, src.decode.acc_seg: 97.5751, src.loss: 0.0844, mix.decode.loss_seg: 0.0429, mix.decode.acc_seg: 98.2401, mix.loss: 0.0429, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:43:52,879 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 6:13:03, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0655, src.decode.acc_seg: 97.5381, src.loss: 0.0816, mix.decode.loss_seg: 0.0440, mix.decode.acc_seg: 98.0545, mix.loss: 0.0440, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:44:56,597 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 6:12:00, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0556, src.decode.acc_seg: 97.8653, src.loss: 0.0716, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.5037, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:46:00,261 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 6:10:57, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0645, src.decode.acc_seg: 97.6009, src.loss: 0.0805, mix.decode.loss_seg: 0.0435, mix.decode.acc_seg: 98.2448, mix.loss: 0.0435, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:47:04,007 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 6:09:54, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0602, src.decode.acc_seg: 97.7746, src.loss: 0.0762, mix.decode.loss_seg: 0.0445, mix.decode.acc_seg: 98.2427, mix.loss: 0.0445, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:48:07,507 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 6:08:50, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0621, src.decode.acc_seg: 97.8065, src.loss: 0.0781, mix.decode.loss_seg: 0.0411, mix.decode.acc_seg: 98.2724, mix.loss: 0.0411, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:49:10,850 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 6:07:47, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0614, src.decode.acc_seg: 97.7080, src.loss: 0.0774, mix.decode.loss_seg: 0.0473, mix.decode.acc_seg: 97.9341, mix.loss: 0.0473, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:50:14,166 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 6:06:43, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0908, src.decode.acc_seg: 97.1510, src.loss: 0.1068, mix.decode.loss_seg: 0.0653, mix.decode.acc_seg: 97.6186, mix.loss: 0.0653, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:51:17,919 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 6:05:40, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0840, src.decode.acc_seg: 97.0950, src.loss: 0.1000, mix.decode.loss_seg: 0.0561, mix.decode.acc_seg: 97.7156, mix.loss: 0.0561, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:52:21,119 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 6:04:37, time: 1.264, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0674, src.decode.acc_seg: 97.5649, src.loss: 0.0834, mix.decode.loss_seg: 0.0445, mix.decode.acc_seg: 98.0113, mix.loss: 0.0445, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:53:24,426 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 6:03:33, time: 1.266, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0724, src.decode.acc_seg: 97.5441, src.loss: 0.0884, mix.decode.loss_seg: 0.0421, mix.decode.acc_seg: 98.1772, mix.loss: 0.0421, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:54:28,637 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 6:02:30, time: 1.284, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0634, src.decode.acc_seg: 97.5860, src.loss: 0.0794, mix.decode.loss_seg: 0.0485, mix.decode.acc_seg: 98.0599, mix.loss: 0.0485, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:55:31,994 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 6:01:27, time: 1.267, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0654, src.decode.acc_seg: 97.5739, src.loss: 0.0814, mix.decode.loss_seg: 0.0461, mix.decode.acc_seg: 98.0422, mix.loss: 0.0461, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:56:35,257 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 6:00:23, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0588, src.decode.acc_seg: 97.8995, src.loss: 0.0749, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.3985, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:57:38,743 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 16:57:38,744 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 5:59:20, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0659, src.decode.acc_seg: 97.7280, src.loss: 0.0819, mix.decode.loss_seg: 0.0457, mix.decode.acc_seg: 97.9927, mix.loss: 0.0457, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:58:42,098 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 5:58:17, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0537, src.decode.acc_seg: 97.9469, src.loss: 0.0697, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.5358, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 16:59:45,397 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 5:57:13, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0598, src.decode.acc_seg: 97.8148, src.loss: 0.0758, mix.decode.loss_seg: 0.0523, mix.decode.acc_seg: 97.8539, mix.loss: 0.0523, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:00:49,707 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 5:56:10, time: 1.286, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0576, src.decode.acc_seg: 97.8353, src.loss: 0.0736, mix.decode.loss_seg: 0.0436, mix.decode.acc_seg: 98.1669, mix.loss: 0.0436, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:01:53,564 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 5:55:07, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0502, src.decode.acc_seg: 98.1305, src.loss: 0.0662, mix.decode.loss_seg: 0.0368, mix.decode.acc_seg: 98.5157, mix.loss: 0.0368, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:02:56,905 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 5:54:04, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0378, src.decode.acc_seg: 98.5542, src.loss: 0.0538, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.5820, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:04:00,125 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 5:53:00, time: 1.264, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0630, src.decode.acc_seg: 97.7706, src.loss: 0.0790, mix.decode.loss_seg: 0.0473, mix.decode.acc_seg: 97.8830, mix.loss: 0.0473, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:05:03,665 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 5:51:57, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0672, src.decode.acc_seg: 97.7045, src.loss: 0.0833, mix.decode.loss_seg: 0.0451, mix.decode.acc_seg: 98.1891, mix.loss: 0.0451, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:06:06,800 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 5:50:53, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0529, src.decode.acc_seg: 98.0370, src.loss: 0.0690, mix.decode.loss_seg: 0.0417, mix.decode.acc_seg: 98.3338, mix.loss: 0.0417, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:07:10,113 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 5:49:50, time: 1.266, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0612, src.decode.acc_seg: 97.9256, src.loss: 0.0773, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.3804, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:08:13,883 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 5:48:47, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0716, src.decode.acc_seg: 97.4456, src.loss: 0.0876, mix.decode.loss_seg: 0.0530, mix.decode.acc_seg: 97.8430, mix.loss: 0.0530, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:09:18,295 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 5:47:44, time: 1.288, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0582, src.decode.acc_seg: 97.9665, src.loss: 0.0742, mix.decode.loss_seg: 0.0416, mix.decode.acc_seg: 98.2723, mix.loss: 0.0416, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:10:22,632 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 5:46:41, time: 1.287, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0590, src.decode.acc_seg: 97.7495, src.loss: 0.0750, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.3502, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:11:26,799 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 5:45:38, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0609, src.decode.acc_seg: 97.8269, src.loss: 0.0769, mix.decode.loss_seg: 0.0469, mix.decode.acc_seg: 98.0847, mix.loss: 0.0469, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:12:31,670 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 5:44:36, time: 1.297, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0672, src.decode.acc_seg: 97.5995, src.loss: 0.0832, mix.decode.loss_seg: 0.0446, mix.decode.acc_seg: 98.1369, mix.loss: 0.0446, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:13:37,315 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 5:43:34, time: 1.313, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0667, src.decode.acc_seg: 97.5474, src.loss: 0.0828, mix.decode.loss_seg: 0.0437, mix.decode.acc_seg: 98.0730, mix.loss: 0.0437, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:14:41,495 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 5:42:31, time: 1.284, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0596, src.decode.acc_seg: 97.8255, src.loss: 0.0757, mix.decode.loss_seg: 0.0464, mix.decode.acc_seg: 97.8664, mix.loss: 0.0464, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:15:51,965 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 5:41:32, time: 1.409, data_time: 0.018, memory: 67494, src.decode.loss_seg: 0.0554, src.decode.acc_seg: 97.8751, src.loss: 0.0714, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.4348, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:17:01,273 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 5:40:33, time: 1.386, data_time: 0.018, memory: 67494, src.decode.loss_seg: 0.0484, src.decode.acc_seg: 98.2167, src.loss: 0.0645, mix.decode.loss_seg: 0.0367, mix.decode.acc_seg: 98.4353, mix.loss: 0.0367, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:18:04,858 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 5:39:29, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0547, src.decode.acc_seg: 98.0419, src.loss: 0.0707, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.3783, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.9 task/s, elapsed: 1s, ETA:  1046s[                                 ] 2/929, 1.6 task/s, elapsed: 1s, ETA:   577s[                                 ] 3/929, 2.2 task/s, elapsed: 1s, ETA:   422s[                                 ] 4/929, 2.7 task/s, elapsed: 1s, ETA:   342s[                                 ] 5/929, 3.1 task/s, elapsed: 2s, ETA:   293s[                                 ] 6/929, 3.5 task/s, elapsed: 2s, ETA:   261s[                                 ] 7/929, 3.9 task/s, elapsed: 2s, ETA:   237s[                                 ] 8/929, 4.2 task/s, elapsed: 2s, ETA:   219s[                                 ] 9/929, 4.5 task/s, elapsed: 2s, ETA:   206s[                                ] 10/929, 4.7 task/s, elapsed: 2s, ETA:   194s[                                ] 11/929, 5.0 task/s, elapsed: 2s, ETA:   185s[                                ] 12/929, 5.2 task/s, elapsed: 2s, ETA:   177s[                                ] 13/929, 5.4 task/s, elapsed: 2s, ETA:   170s[                                ] 14/929, 5.5 task/s, elapsed: 3s, ETA:   165s[                                ] 15/929, 5.7 task/s, elapsed: 3s, ETA:   160s[                                ] 16/929, 5.8 task/s, elapsed: 3s, ETA:   158s[                                ] 17/929, 5.9 task/s, elapsed: 3s, ETA:   154s[                                ] 18/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 19/929, 6.1 task/s, elapsed: 3s, ETA:   148s[                                ] 20/929, 6.2 task/s, elapsed: 3s, ETA:   146s[                                ] 21/929, 6.3 task/s, elapsed: 3s, ETA:   143s[                                ] 22/929, 6.4 task/s, elapsed: 3s, ETA:   141s[                                ] 23/929, 6.5 task/s, elapsed: 4s, ETA:   139s[                                ] 24/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 25/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 26/929, 6.7 task/s, elapsed: 4s, ETA:   134s[                                ] 27/929, 6.8 task/s, elapsed: 4s, ETA:   132s[                                ] 28/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 29/929, 6.9 task/s, elapsed: 4s, ETA:   130s[>                               ] 30/929, 7.0 task/s, elapsed: 4s, ETA:   129s[>                               ] 31/929, 7.1 task/s, elapsed: 4s, ETA:   127s[>                               ] 32/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 33/929, 7.2 task/s, elapsed: 5s, ETA:   125s[>                               ] 34/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 35/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 36/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 37/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 38/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 39/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 40/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 41/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 42/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 43/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 44/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 45/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 46/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 47/929, 7.7 task/s, elapsed: 6s, ETA:   114s[>                               ] 48/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 49/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 50/929, 7.8 task/s, elapsed: 6s, ETA:   113s[>                               ] 51/929, 7.8 task/s, elapsed: 7s, ETA:   112s[>                               ] 52/929, 7.9 task/s, elapsed: 7s, ETA:   112s[>                               ] 53/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 54/929, 7.9 task/s, elapsed: 7s, ETA:   111s[>                               ] 55/929, 7.9 task/s, elapsed: 7s, ETA:   110s[>                               ] 56/929, 8.0 task/s, elapsed: 7s, ETA:   110s[>                               ] 57/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>                               ] 58/929, 8.0 task/s, elapsed: 7s, ETA:   109s[>>                              ] 59/929, 8.0 task/s, elapsed: 7s, ETA:   108s[>>                              ] 60/929, 8.1 task/s, elapsed: 7s, ETA:   108s[>>                              ] 61/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 62/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 63/929, 8.1 task/s, elapsed: 8s, ETA:   107s[>>                              ] 64/929, 8.1 task/s, elapsed: 8s, ETA:   106s[>>                              ] 65/929, 8.2 task/s, elapsed: 8s, ETA:   106s[>>                              ] 66/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 67/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 68/929, 8.2 task/s, elapsed: 8s, ETA:   105s[>>                              ] 69/929, 8.2 task/s, elapsed: 8s, ETA:   104s[>>                              ] 70/929, 8.3 task/s, elapsed: 8s, ETA:   104s[>>                              ] 71/929, 8.3 task/s, elapsed: 9s, ETA:   104s[>>                              ] 72/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 73/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 74/929, 8.3 task/s, elapsed: 9s, ETA:   103s[>>                              ] 75/929, 8.3 task/s, elapsed: 9s, ETA:   102s[>>                              ] 76/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 77/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 78/929, 8.4 task/s, elapsed: 9s, ETA:   102s[>>                              ] 79/929, 8.4 task/s, elapsed: 9s, ETA:   101s[>>                             ] 80/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 81/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 82/929, 8.4 task/s, elapsed: 10s, ETA:   101s[>>                             ] 83/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 84/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 85/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 86/929, 8.5 task/s, elapsed: 10s, ETA:   100s[>>                             ] 87/929, 8.4 task/s, elapsed: 10s, ETA:   100s[>>                             ] 88/929, 8.5 task/s, elapsed: 10s, ETA:    99s[>>                             ] 89/929, 8.5 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 90/929, 8.5 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 91/929, 8.5 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 92/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 93/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 94/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 95/929, 8.5 task/s, elapsed: 11s, ETA:    98s[>>>                            ] 96/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 97/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 98/929, 8.6 task/s, elapsed: 11s, ETA:    97s[>>>                            ] 99/929, 8.6 task/s, elapsed: 12s, ETA:    97s[>>>                           ] 100/929, 8.6 task/s, elapsed: 12s, ETA:    97s[>>>                           ] 101/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 102/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 103/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 104/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 105/929, 8.6 task/s, elapsed: 12s, ETA:    96s[>>>                           ] 106/929, 8.6 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 107/929, 8.6 task/s, elapsed: 12s, ETA:    95s[>>>                           ] 108/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 109/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 110/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 111/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 112/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 113/929, 8.6 task/s, elapsed: 13s, ETA:    95s[>>>                           ] 114/929, 8.6 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 115/929, 8.6 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 116/929, 8.7 task/s, elapsed: 13s, ETA:    94s[>>>                           ] 117/929, 8.7 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 118/929, 8.7 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 119/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 120/929, 8.7 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 121/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 122/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>                           ] 123/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>>                          ] 124/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>>                          ] 125/929, 8.7 task/s, elapsed: 14s, ETA:    93s[>>>>                          ] 126/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 127/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 128/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 129/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 130/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 131/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 132/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 133/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 134/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 135/929, 8.7 task/s, elapsed: 15s, ETA:    91s[>>>>                          ] 136/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 137/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 138/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 139/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 140/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 141/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 142/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 143/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 144/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 145/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 146/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 147/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 148/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 149/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 150/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 151/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 152/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 153/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 154/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 155/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 156/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 157/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 158/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 159/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 160/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 161/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 162/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 163/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 164/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 165/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 166/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 167/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 168/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 169/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 170/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 171/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 172/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 173/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 174/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 175/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 176/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 177/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 178/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 179/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 180/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 181/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 182/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 183/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 184/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 185/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 186/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 187/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 188/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 189/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 190/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 191/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 192/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 193/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 194/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 195/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 196/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 197/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 198/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 199/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 200/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 201/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 202/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 203/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 204/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 205/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 206/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 207/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 208/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 209/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 210/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 211/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 212/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 213/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 214/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 215/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 216/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 217/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 218/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 219/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 220/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 221/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 222/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 223/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 224/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 225/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 226/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 227/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 228/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 229/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 230/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 231/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 232/929, 9.0 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 233/929, 9.0 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 234/929, 9.0 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 235/929, 9.0 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 236/929, 9.0 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 237/929, 9.0 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 238/929, 9.0 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 239/929, 9.0 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 240/929, 9.0 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 241/929, 9.0 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 242/929, 9.0 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 243/929, 9.0 task/s, elapsed: 27s, ETA:    76s[>>>>>>>                       ] 244/929, 9.0 task/s, elapsed: 27s, ETA:    76s[>>>>>>>                       ] 245/929, 9.0 task/s, elapsed: 27s, ETA:    76s[>>>>>>>                       ] 246/929, 9.0 task/s, elapsed: 27s, ETA:    76s[>>>>>>>                       ] 247/929, 9.0 task/s, elapsed: 27s, ETA:    76s[>>>>>>>>                      ] 248/929, 9.0 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 249/929, 9.0 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 250/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 251/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 252/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 253/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 254/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 255/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 256/929, 9.0 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 257/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 258/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 259/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 260/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 261/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 262/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 263/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 264/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 265/929, 9.0 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 266/929, 9.0 task/s, elapsed: 29s, ETA:    73s[>>>>>>>>                      ] 267/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 268/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 269/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 270/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 271/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 272/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 273/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 274/929, 9.0 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 275/929, 9.0 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 276/929, 9.0 task/s, elapsed: 30s, ETA:    72s[>>>>>>>>                      ] 277/929, 9.1 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>                      ] 278/929, 9.1 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 279/929, 9.1 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 280/929, 9.1 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 281/929, 9.1 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 282/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 283/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 284/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 285/929, 9.1 task/s, elapsed: 31s, ETA:    71s[>>>>>>>>>                     ] 286/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 287/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 288/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 289/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 290/929, 9.1 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 292/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 293/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 294/929, 9.1 task/s, elapsed: 32s, ETA:    70s[>>>>>>>>>                     ] 295/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 296/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 297/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 298/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 299/929, 9.1 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 300/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 301/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 302/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 303/929, 9.1 task/s, elapsed: 33s, ETA:    69s[>>>>>>>>>                     ] 304/929, 9.1 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 305/929, 9.1 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 306/929, 9.1 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 307/929, 9.1 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 308/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>                     ] 309/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 310/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 311/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 312/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 313/929, 9.1 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 314/929, 9.1 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 315/929, 9.1 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 316/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 317/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 318/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 319/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 320/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 321/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 322/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 323/929, 9.1 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 324/929, 9.1 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 325/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 326/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 327/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 328/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 329/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 330/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 331/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 332/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 333/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 334/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 336/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 337/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 338/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 339/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 340/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>>                   ] 341/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>>                   ] 342/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 343/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 346/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 347/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 348/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 349/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 350/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 351/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 355/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 356/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 357/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 358/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 359/929, 9.1 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 360/929, 9.1 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 366/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 367/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 368/929, 9.1 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.1 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 376/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 377/929, 9.1 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.1 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 384/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 385/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 386/929, 9.1 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.1 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.1 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 394/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 395/929, 9.1 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.1 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.1 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 398/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 403/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 404/929, 9.1 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.1 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.1 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 412/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 413/929, 9.1 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.1 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.1 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.1 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 422/929, 9.1 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.2 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 430/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 431/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.2 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.2 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.2 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.2 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.2 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.2 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.2 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.2 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 458/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.2 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.2 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.2 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.2 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.2 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.2 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.2 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.2 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 513/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.2 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.2 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.2 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 522/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.2 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.2 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.2 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.2 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.2 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.2 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.2 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.2 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.2 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.2 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.2 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.2 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.2 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.2 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.2 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.2 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.2 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.2 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.2 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.2 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.2 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.2 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.2 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.2 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.2 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.2 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.2 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.2 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.2 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.2 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.2 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.2 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.2 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.2 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.2 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.2 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.2 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.2 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.2 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.2 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.2 task/s, elapsed: 82s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.2 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.2 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.2 task/s, elapsed: 83s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.2 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.2 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.2 task/s, elapsed: 84s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.2 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.2 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.2 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.2 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.2 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.2 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.2 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.2 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.2 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.2 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.2 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.2 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.2 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.2 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.2 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.2 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.2 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.2 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.2 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.2 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.2 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.2 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.2 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.2 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.2 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.3 task/s, elapsed: 100s, ETA:     0s2022-10-10 17:21:44,820 - mmseg - INFO - per class results:2022-10-10 17:21:44,821 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.84 | 95.94 || rigid_plastic | 35.28 | 43.34 ||   cardboard   | 55.88 | 71.51 ||     metal     |  34.8 | 39.31 ||  soft_plastic |  63.3 | 71.31 |+---------------+-------+-------+2022-10-10 17:21:44,821 - mmseg - INFO - Summary:2022-10-10 17:21:44,821 - mmseg - INFO - +------+-------+-------+| aAcc |  mIoU |  mAcc |+------+-------+-------+| 91.3 | 56.02 | 64.28 |+------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:21:44,825 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 17:21:44,825 - mmseg - INFO - Iter [929/40000]	lr: 2.400e-05, eta: 5:38:26, time: 1.271, data_time: 0.014, memory: 67494, aAcc: 0.9130, mIoU: 0.5602, mAcc: 0.6428, IoU.background: 0.9084, IoU.rigid_plastic: 0.3528, IoU.cardboard: 0.5588, IoU.metal: 0.3480, IoU.soft_plastic: 0.6330, Acc.background: 0.9594, Acc.rigid_plastic: 0.4334, Acc.cardboard: 0.7151, Acc.metal: 0.3931, Acc.soft_plastic: 0.7131, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 98.0981, src.loss: 0.0685, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.5212, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:22:48,937 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 5:39:07, time: 4.410, data_time: 3.143, memory: 67494, src.decode.loss_seg: 0.0484, src.decode.acc_seg: 98.2359, src.loss: 0.0645, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4794, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:23:52,382 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 5:38:03, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0490, src.decode.acc_seg: 98.2423, src.loss: 0.0650, mix.decode.loss_seg: 0.0382, mix.decode.acc_seg: 98.4483, mix.loss: 0.0382, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:24:56,443 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 5:36:59, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0496, src.decode.acc_seg: 98.1015, src.loss: 0.0656, mix.decode.loss_seg: 0.0425, mix.decode.acc_seg: 98.1993, mix.loss: 0.0425, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:26:00,106 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 5:35:55, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0494, src.decode.acc_seg: 98.0952, src.loss: 0.0654, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.3767, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:27:04,261 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 5:34:52, time: 1.283, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0807, src.decode.acc_seg: 97.5334, src.loss: 0.0967, mix.decode.loss_seg: 0.0436, mix.decode.acc_seg: 98.1744, mix.loss: 0.0436, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:28:08,089 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 5:33:48, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0527, src.decode.acc_seg: 97.9730, src.loss: 0.0687, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.1451, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:29:12,594 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 5:32:45, time: 1.290, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0588, src.decode.acc_seg: 97.8524, src.loss: 0.0748, mix.decode.loss_seg: 0.0430, mix.decode.acc_seg: 98.1865, mix.loss: 0.0430, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:30:16,798 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 5:31:41, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0543, src.decode.acc_seg: 98.0469, src.loss: 0.0703, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.3238, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:31:21,017 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 5:30:38, time: 1.284, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0463, src.decode.acc_seg: 98.3242, src.loss: 0.0623, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.4828, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:32:25,485 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 5:29:34, time: 1.289, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0494, src.decode.acc_seg: 98.1614, src.loss: 0.0655, mix.decode.loss_seg: 0.0418, mix.decode.acc_seg: 98.1210, mix.loss: 0.0418, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:33:29,339 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 5:28:30, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0651, src.decode.acc_seg: 97.7375, src.loss: 0.0811, mix.decode.loss_seg: 0.0418, mix.decode.acc_seg: 98.1546, mix.loss: 0.0418, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:34:33,455 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 5:27:27, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0633, src.decode.acc_seg: 97.7516, src.loss: 0.0793, mix.decode.loss_seg: 0.0456, mix.decode.acc_seg: 97.9873, mix.loss: 0.0456, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:35:37,343 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 5:26:23, time: 1.278, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0568, src.decode.acc_seg: 97.9079, src.loss: 0.0729, mix.decode.loss_seg: 0.0390, mix.decode.acc_seg: 98.3652, mix.loss: 0.0390, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:36:41,473 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 5:25:20, time: 1.283, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0667, src.decode.acc_seg: 97.6820, src.loss: 0.0827, mix.decode.loss_seg: 0.0445, mix.decode.acc_seg: 98.2715, mix.loss: 0.0445, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:37:45,048 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 5:24:16, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0538, src.decode.acc_seg: 98.0413, src.loss: 0.0698, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.5094, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:38:49,127 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 5:23:12, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0511, src.decode.acc_seg: 98.1505, src.loss: 0.0671, mix.decode.loss_seg: 0.0385, mix.decode.acc_seg: 98.4158, mix.loss: 0.0385, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:39:53,042 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 5:22:08, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0531, src.decode.acc_seg: 98.0352, src.loss: 0.0691, mix.decode.loss_seg: 0.0417, mix.decode.acc_seg: 98.2419, mix.loss: 0.0417, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:40:56,994 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 5:21:05, time: 1.279, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0554, src.decode.acc_seg: 97.9897, src.loss: 0.0714, mix.decode.loss_seg: 0.0408, mix.decode.acc_seg: 98.3426, mix.loss: 0.0408, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:42:00,664 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 5:20:01, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0545, src.decode.acc_seg: 98.0774, src.loss: 0.0706, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.2083, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:43:05,296 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 17:43:05,297 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 5:18:57, time: 1.293, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0619, src.decode.acc_seg: 97.9299, src.loss: 0.0779, mix.decode.loss_seg: 0.0439, mix.decode.acc_seg: 98.2139, mix.loss: 0.0439, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:44:11,283 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 5:17:55, time: 1.320, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0546, src.decode.acc_seg: 97.9717, src.loss: 0.0706, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.2051, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:45:15,169 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 5:16:51, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0532, src.decode.acc_seg: 98.1146, src.loss: 0.0693, mix.decode.loss_seg: 0.0384, mix.decode.acc_seg: 98.3869, mix.loss: 0.0384, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:46:19,152 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 5:15:48, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.1802, src.loss: 0.0648, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.4187, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:47:23,870 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 5:14:44, time: 1.294, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0556, src.decode.acc_seg: 97.9907, src.loss: 0.0716, mix.decode.loss_seg: 0.0420, mix.decode.acc_seg: 98.3057, mix.loss: 0.0420, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:48:28,296 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 5:13:41, time: 1.288, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0580, src.decode.acc_seg: 98.0226, src.loss: 0.0740, mix.decode.loss_seg: 0.0443, mix.decode.acc_seg: 98.2284, mix.loss: 0.0443, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:49:31,947 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 5:12:37, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0543, src.decode.acc_seg: 97.9334, src.loss: 0.0703, mix.decode.loss_seg: 0.0401, mix.decode.acc_seg: 98.2358, mix.loss: 0.0401, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:50:35,768 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 5:11:33, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0609, src.decode.acc_seg: 97.8389, src.loss: 0.0769, mix.decode.loss_seg: 0.0416, mix.decode.acc_seg: 98.2732, mix.loss: 0.0416, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:51:40,056 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 5:10:30, time: 1.286, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0574, src.decode.acc_seg: 97.8553, src.loss: 0.0734, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.0235, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:52:43,914 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 5:09:26, time: 1.277, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0518, src.decode.acc_seg: 98.0810, src.loss: 0.0678, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.5823, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:53:48,156 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 5:08:22, time: 1.285, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0525, src.decode.acc_seg: 98.0007, src.loss: 0.0686, mix.decode.loss_seg: 0.0424, mix.decode.acc_seg: 98.2400, mix.loss: 0.0424, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:54:52,013 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 5:07:19, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0598, src.decode.acc_seg: 97.8296, src.loss: 0.0758, mix.decode.loss_seg: 0.0415, mix.decode.acc_seg: 98.2426, mix.loss: 0.0415, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:55:56,689 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 5:06:15, time: 1.293, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0468, src.decode.acc_seg: 98.2165, src.loss: 0.0629, mix.decode.loss_seg: 0.0350, mix.decode.acc_seg: 98.4161, mix.loss: 0.0350, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:57:00,691 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 5:05:12, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0429, src.decode.acc_seg: 98.4275, src.loss: 0.0589, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6794, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:58:04,800 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 5:04:08, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0594, src.decode.acc_seg: 97.8756, src.loss: 0.0754, mix.decode.loss_seg: 0.0457, mix.decode.acc_seg: 98.2814, mix.loss: 0.0457, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 17:59:09,486 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 5:03:05, time: 1.294, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.3513, src.loss: 0.0594, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.6420, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:00:13,306 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 5:02:01, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.3653, src.loss: 0.0586, mix.decode.loss_seg: 0.0345, mix.decode.acc_seg: 98.4164, mix.loss: 0.0345, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:01:17,217 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 5:00:57, time: 1.278, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0584, src.decode.acc_seg: 97.8263, src.loss: 0.0744, mix.decode.loss_seg: 0.0441, mix.decode.acc_seg: 98.2691, mix.loss: 0.0441, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:02:20,910 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 4:59:53, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0573, src.decode.acc_seg: 97.7864, src.loss: 0.0734, mix.decode.loss_seg: 0.0405, mix.decode.acc_seg: 98.3340, mix.loss: 0.0405, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:03:24,757 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 4:58:49, time: 1.277, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0560, src.decode.acc_seg: 97.7842, src.loss: 0.0720, mix.decode.loss_seg: 0.0428, mix.decode.acc_seg: 98.0945, mix.loss: 0.0428, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:04:28,401 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 18:04:28,401 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 4:57:46, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0506, src.decode.acc_seg: 98.0596, src.loss: 0.0667, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.5206, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:05:32,471 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 4:56:42, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0575, src.decode.acc_seg: 97.8705, src.loss: 0.0735, mix.decode.loss_seg: 0.0432, mix.decode.acc_seg: 98.2106, mix.loss: 0.0432, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:06:35,976 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 4:55:38, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0633, src.decode.acc_seg: 97.8042, src.loss: 0.0793, mix.decode.loss_seg: 0.0458, mix.decode.acc_seg: 98.2095, mix.loss: 0.0458, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:07:39,728 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 4:54:34, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0543, src.decode.acc_seg: 97.9452, src.loss: 0.0703, mix.decode.loss_seg: 0.0406, mix.decode.acc_seg: 98.3073, mix.loss: 0.0406, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:08:44,010 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 4:53:30, time: 1.286, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0585, src.decode.acc_seg: 97.7210, src.loss: 0.0745, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.4700, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:09:47,511 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 4:52:27, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0472, src.decode.acc_seg: 98.2261, src.loss: 0.0633, mix.decode.loss_seg: 0.0395, mix.decode.acc_seg: 98.3471, mix.loss: 0.0395, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:10:51,674 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 4:51:23, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0633, src.decode.acc_seg: 97.7744, src.loss: 0.0793, mix.decode.loss_seg: 0.0384, mix.decode.acc_seg: 98.3502, mix.loss: 0.0384, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:11:55,369 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 4:50:19, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0475, src.decode.acc_seg: 98.2613, src.loss: 0.0636, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5580, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:12:59,599 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 4:49:15, time: 1.285, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0478, src.decode.acc_seg: 98.2497, src.loss: 0.0638, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.6016, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:14:03,386 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 4:48:12, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0504, src.decode.acc_seg: 98.0925, src.loss: 0.0664, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.3834, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:15:07,257 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 4:47:08, time: 1.277, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0595, src.decode.acc_seg: 97.8411, src.loss: 0.0755, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.2296, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:16:11,100 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 4:46:04, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0423, src.decode.acc_seg: 98.3869, src.loss: 0.0583, mix.decode.loss_seg: 0.0354, mix.decode.acc_seg: 98.4705, mix.loss: 0.0354, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:17:15,005 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 4:45:00, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0576, src.decode.acc_seg: 97.9076, src.loss: 0.0736, mix.decode.loss_seg: 0.0399, mix.decode.acc_seg: 98.3141, mix.loss: 0.0399, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:18:19,242 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 4:43:57, time: 1.285, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0588, src.decode.acc_seg: 97.8296, src.loss: 0.0748, mix.decode.loss_seg: 0.0491, mix.decode.acc_seg: 97.9681, mix.loss: 0.0491, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:19:23,383 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 4:42:53, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0437, src.decode.acc_seg: 98.3744, src.loss: 0.0598, mix.decode.loss_seg: 0.0321, mix.decode.acc_seg: 98.6015, mix.loss: 0.0321, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:20:27,364 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 4:41:49, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0527, src.decode.acc_seg: 98.0230, src.loss: 0.0688, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4361, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:21:31,425 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 4:40:46, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0548, src.decode.acc_seg: 97.9531, src.loss: 0.0708, mix.decode.loss_seg: 0.0511, mix.decode.acc_seg: 97.9221, mix.loss: 0.0511, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:22:35,358 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 4:39:42, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0590, src.decode.acc_seg: 97.7741, src.loss: 0.0750, mix.decode.loss_seg: 0.0392, mix.decode.acc_seg: 98.2041, mix.loss: 0.0392, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:23:39,404 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 4:38:38, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0487, src.decode.acc_seg: 98.0843, src.loss: 0.0648, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.3873, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:24:43,704 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 4:37:35, time: 1.286, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0523, src.decode.acc_seg: 98.0877, src.loss: 0.0683, mix.decode.loss_seg: 0.0375, mix.decode.acc_seg: 98.4984, mix.loss: 0.0375, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:25:47,601 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 18:25:47,601 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 4:36:31, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.3969, src.loss: 0.0602, mix.decode.loss_seg: 0.0454, mix.decode.acc_seg: 98.0249, mix.loss: 0.0454, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:26:51,624 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 4:35:27, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0496, src.decode.acc_seg: 98.2242, src.loss: 0.0657, mix.decode.loss_seg: 0.0375, mix.decode.acc_seg: 98.5428, mix.loss: 0.0375, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:27:55,866 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 4:34:24, time: 1.285, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0501, src.decode.acc_seg: 98.2424, src.loss: 0.0661, mix.decode.loss_seg: 0.0365, mix.decode.acc_seg: 98.3988, mix.loss: 0.0365, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:28:59,178 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 4:33:19, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.1847, src.loss: 0.0648, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.3810, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:30:02,584 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 4:32:15, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.3369, src.loss: 0.0608, mix.decode.loss_seg: 0.0317, mix.decode.acc_seg: 98.6077, mix.loss: 0.0317, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:31:06,864 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 4:31:12, time: 1.286, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0520, src.decode.acc_seg: 98.0820, src.loss: 0.0681, mix.decode.loss_seg: 0.0364, mix.decode.acc_seg: 98.4927, mix.loss: 0.0364, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:32:10,436 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 4:30:08, time: 1.271, data_time: 0.013, memory: 67494, src.decode.loss_seg: 0.0526, src.decode.acc_seg: 98.0311, src.loss: 0.0687, mix.decode.loss_seg: 0.0400, mix.decode.acc_seg: 98.1924, mix.loss: 0.0400, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:33:14,374 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 4:29:04, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0591, src.decode.acc_seg: 97.7789, src.loss: 0.0751, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.4281, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:34:18,307 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 4:28:00, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0394, src.decode.acc_seg: 98.5634, src.loss: 0.0554, mix.decode.loss_seg: 0.0340, mix.decode.acc_seg: 98.5548, mix.loss: 0.0340, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:35:22,397 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 4:26:57, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0546, src.decode.acc_seg: 97.9361, src.loss: 0.0706, mix.decode.loss_seg: 0.0406, mix.decode.acc_seg: 98.2470, mix.loss: 0.0406, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:36:26,126 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 4:25:53, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0493, src.decode.acc_seg: 98.1569, src.loss: 0.0654, mix.decode.loss_seg: 0.0361, mix.decode.acc_seg: 98.3817, mix.loss: 0.0361, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:37:30,270 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 4:24:49, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.2011, src.loss: 0.0648, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6385, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:38:35,251 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 4:23:46, time: 1.300, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0509, src.decode.acc_seg: 98.1339, src.loss: 0.0669, mix.decode.loss_seg: 0.0420, mix.decode.acc_seg: 98.2591, mix.loss: 0.0420, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:39:39,708 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 4:22:42, time: 1.289, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0477, src.decode.acc_seg: 98.1895, src.loss: 0.0637, mix.decode.loss_seg: 0.0317, mix.decode.acc_seg: 98.6569, mix.loss: 0.0317, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:40:45,363 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 4:21:39, time: 1.313, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0460, src.decode.acc_seg: 98.3295, src.loss: 0.0621, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.5275, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:41:51,162 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 4:20:36, time: 1.316, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0491, src.decode.acc_seg: 98.1850, src.loss: 0.0651, mix.decode.loss_seg: 0.0405, mix.decode.acc_seg: 98.2063, mix.loss: 0.0405, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:43:01,205 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 4:19:35, time: 1.401, data_time: 0.018, memory: 67494, src.decode.loss_seg: 0.0537, src.decode.acc_seg: 98.0487, src.loss: 0.0698, mix.decode.loss_seg: 0.0393, mix.decode.acc_seg: 98.3176, mix.loss: 0.0393, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:44:07,107 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 4:18:32, time: 1.318, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0673, src.decode.acc_seg: 97.6897, src.loss: 0.0833, mix.decode.loss_seg: 0.0496, mix.decode.acc_seg: 98.1735, mix.loss: 0.0496, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:45:11,281 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 4:17:29, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0530, src.decode.acc_seg: 98.0935, src.loss: 0.0690, mix.decode.loss_seg: 0.0380, mix.decode.acc_seg: 98.4588, mix.loss: 0.0380, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:46:14,932 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 4:16:25, time: 1.273, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0513, src.decode.acc_seg: 98.0819, src.loss: 0.0673, mix.decode.loss_seg: 0.0413, mix.decode.acc_seg: 98.2529, mix.loss: 0.0413, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.6 task/s, elapsed: 2s, ETA:  1451s[                                 ] 2/929, 1.2 task/s, elapsed: 2s, ETA:   773s[                                 ] 3/929, 1.7 task/s, elapsed: 2s, ETA:   546s[                                 ] 4/929, 2.1 task/s, elapsed: 2s, ETA:   433s[                                 ] 5/929, 2.5 task/s, elapsed: 2s, ETA:   365s[                                 ] 6/929, 2.9 task/s, elapsed: 2s, ETA:   320s[                                 ] 7/929, 3.2 task/s, elapsed: 2s, ETA:   287s[                                 ] 8/929, 3.5 task/s, elapsed: 2s, ETA:   262s[                                 ] 9/929, 3.8 task/s, elapsed: 2s, ETA:   243s[                                ] 10/929, 4.0 task/s, elapsed: 2s, ETA:   228s[                                ] 11/929, 4.3 task/s, elapsed: 3s, ETA:   216s[                                ] 12/929, 4.5 task/s, elapsed: 3s, ETA:   206s[                                ] 13/929, 4.7 task/s, elapsed: 3s, ETA:   197s[                                ] 14/929, 4.8 task/s, elapsed: 3s, ETA:   189s[                                ] 15/929, 5.0 task/s, elapsed: 3s, ETA:   183s[                                ] 16/929, 5.2 task/s, elapsed: 3s, ETA:   177s[                                ] 17/929, 5.3 task/s, elapsed: 3s, ETA:   172s[                                ] 18/929, 5.4 task/s, elapsed: 3s, ETA:   168s[                                ] 19/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 20/929, 5.7 task/s, elapsed: 4s, ETA:   160s[                                ] 21/929, 5.8 task/s, elapsed: 4s, ETA:   157s[                                ] 22/929, 5.9 task/s, elapsed: 4s, ETA:   154s[                                ] 23/929, 6.0 task/s, elapsed: 4s, ETA:   151s[                                ] 24/929, 6.1 task/s, elapsed: 4s, ETA:   148s[                                ] 25/929, 6.2 task/s, elapsed: 4s, ETA:   146s[                                ] 26/929, 6.3 task/s, elapsed: 4s, ETA:   144s[                                ] 27/929, 6.4 task/s, elapsed: 4s, ETA:   142s[                                ] 28/929, 6.4 task/s, elapsed: 4s, ETA:   140s[                                ] 29/929, 6.5 task/s, elapsed: 4s, ETA:   139s[>                               ] 30/929, 6.6 task/s, elapsed: 5s, ETA:   137s[>                               ] 31/929, 6.6 task/s, elapsed: 5s, ETA:   135s[>                               ] 32/929, 6.7 task/s, elapsed: 5s, ETA:   134s[>                               ] 33/929, 6.8 task/s, elapsed: 5s, ETA:   133s[>                               ] 34/929, 6.8 task/s, elapsed: 5s, ETA:   131s[>                               ] 35/929, 6.9 task/s, elapsed: 5s, ETA:   130s[>                               ] 36/929, 6.9 task/s, elapsed: 5s, ETA:   129s[>                               ] 37/929, 7.0 task/s, elapsed: 5s, ETA:   128s[>                               ] 38/929, 7.0 task/s, elapsed: 5s, ETA:   127s[>                               ] 39/929, 7.1 task/s, elapsed: 6s, ETA:   126s[>                               ] 40/929, 7.1 task/s, elapsed: 6s, ETA:   125s[>                               ] 41/929, 7.2 task/s, elapsed: 6s, ETA:   124s[>                               ] 42/929, 7.2 task/s, elapsed: 6s, ETA:   123s[>                               ] 43/929, 7.2 task/s, elapsed: 6s, ETA:   122s[>                               ] 44/929, 7.3 task/s, elapsed: 6s, ETA:   122s[>                               ] 45/929, 7.3 task/s, elapsed: 6s, ETA:   121s[>                               ] 46/929, 7.4 task/s, elapsed: 6s, ETA:   120s[>                               ] 47/929, 7.4 task/s, elapsed: 6s, ETA:   119s[>                               ] 48/929, 7.4 task/s, elapsed: 6s, ETA:   118s[>                               ] 49/929, 7.5 task/s, elapsed: 7s, ETA:   118s[>                               ] 50/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 51/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 52/929, 7.5 task/s, elapsed: 7s, ETA:   116s[>                               ] 53/929, 7.6 task/s, elapsed: 7s, ETA:   116s[>                               ] 54/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 55/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 56/929, 7.6 task/s, elapsed: 7s, ETA:   114s[>                               ] 57/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 58/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 59/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 60/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 61/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 62/929, 7.8 task/s, elapsed: 8s, ETA:   112s[>>                              ] 63/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 64/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 65/929, 7.8 task/s, elapsed: 8s, ETA:   110s[>>                              ] 66/929, 7.8 task/s, elapsed: 8s, ETA:   110s[>>                              ] 67/929, 7.9 task/s, elapsed: 9s, ETA:   110s[>>                              ] 68/929, 7.9 task/s, elapsed: 9s, ETA:   110s[>>                              ] 69/929, 7.9 task/s, elapsed: 9s, ETA:   109s[>>                              ] 70/929, 7.9 task/s, elapsed: 9s, ETA:   109s[>>                              ] 71/929, 7.9 task/s, elapsed: 9s, ETA:   109s[>>                              ] 72/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 73/929, 7.9 task/s, elapsed: 9s, ETA:   108s[>>                              ] 74/929, 8.0 task/s, elapsed: 9s, ETA:   108s[>>                              ] 75/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                             ] 76/929, 8.0 task/s, elapsed: 10s, ETA:   107s[>>                             ] 77/929, 8.0 task/s, elapsed: 10s, ETA:   107s[>>                             ] 78/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 79/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 80/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 81/929, 8.0 task/s, elapsed: 10s, ETA:   105s[>>                             ] 82/929, 8.1 task/s, elapsed: 10s, ETA:   105s[>>                             ] 83/929, 8.1 task/s, elapsed: 10s, ETA:   105s[>>                             ] 84/929, 8.1 task/s, elapsed: 10s, ETA:   104s[>>                             ] 85/929, 8.1 task/s, elapsed: 10s, ETA:   104s[>>                             ] 86/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>                             ] 87/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>                             ] 88/929, 8.1 task/s, elapsed: 11s, ETA:   103s[>>                             ] 89/929, 8.1 task/s, elapsed: 11s, ETA:   103s[>>>                            ] 90/929, 8.2 task/s, elapsed: 11s, ETA:   103s[>>>                            ] 91/929, 8.2 task/s, elapsed: 11s, ETA:   103s[>>>                            ] 92/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 93/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 94/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 95/929, 8.2 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 96/929, 8.2 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 97/929, 8.2 task/s, elapsed: 12s, ETA:   101s[>>>                            ] 98/929, 8.2 task/s, elapsed: 12s, ETA:   101s[>>>                            ] 99/929, 8.2 task/s, elapsed: 12s, ETA:   101s[>>>                           ] 100/929, 8.2 task/s, elapsed: 12s, ETA:   101s[>>>                           ] 101/929, 8.2 task/s, elapsed: 12s, ETA:   100s[>>>                           ] 102/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                           ] 103/929, 8.3 task/s, elapsed: 12s, ETA:   100s[>>>                           ] 104/929, 8.3 task/s, elapsed: 13s, ETA:   100s[>>>                           ] 105/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 106/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 107/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 108/929, 8.3 task/s, elapsed: 13s, ETA:    99s[>>>                           ] 109/929, 8.3 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 110/929, 8.3 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 111/929, 8.3 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 112/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 113/929, 8.4 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 114/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 115/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 116/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 117/929, 8.4 task/s, elapsed: 14s, ETA:    97s[>>>                           ] 118/929, 8.4 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 119/929, 8.4 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 120/929, 8.4 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 121/929, 8.4 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 122/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 123/929, 8.5 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 124/929, 8.5 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 125/929, 8.5 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 126/929, 8.5 task/s, elapsed: 15s, ETA:    95s[>>>>                          ] 127/929, 8.5 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 128/929, 8.5 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 129/929, 8.5 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 130/929, 8.5 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 131/929, 8.5 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 132/929, 8.5 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 133/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 134/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 135/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 136/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 137/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 138/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 139/929, 8.5 task/s, elapsed: 16s, ETA:    93s[>>>>                          ] 140/929, 8.5 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 141/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 142/929, 8.6 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 143/929, 8.6 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 144/929, 8.6 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 145/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 146/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 147/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 148/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 149/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 150/929, 8.6 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 151/929, 8.6 task/s, elapsed: 18s, ETA:    91s[>>>>                          ] 152/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>                          ] 153/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>                          ] 154/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>>                         ] 155/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>>                         ] 156/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>>                         ] 157/929, 8.6 task/s, elapsed: 18s, ETA:    90s[>>>>>                         ] 158/929, 8.6 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 159/929, 8.6 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 160/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 161/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 162/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 163/929, 8.6 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 164/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 165/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 166/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 167/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 168/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 169/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 170/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 171/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 172/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 173/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 174/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 175/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 176/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 177/929, 8.7 task/s, elapsed: 20s, ETA:    87s[>>>>>                         ] 178/929, 8.7 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 179/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 180/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 181/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 182/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 183/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 184/929, 8.7 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 185/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>>                        ] 186/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>>                        ] 187/929, 8.7 task/s, elapsed: 21s, ETA:    85s[>>>>>>                        ] 188/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 189/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 190/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 191/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 192/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 193/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 194/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 195/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 196/929, 8.7 task/s, elapsed: 22s, ETA:    84s[>>>>>>                        ] 197/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 198/929, 8.8 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 199/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 200/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 201/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 202/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 203/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 204/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 205/929, 8.8 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 206/929, 8.8 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 207/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 208/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 209/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 210/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 211/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 212/929, 8.8 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 213/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 214/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 215/929, 8.8 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 216/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 217/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 218/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 219/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 220/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 221/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 222/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 223/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 224/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 225/929, 8.8 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 226/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 227/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 228/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 229/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 230/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 231/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 232/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 233/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 234/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 235/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 236/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 237/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 239/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 240/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 241/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 242/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 243/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 244/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 245/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 246/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 247/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 248/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 249/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 250/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 251/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 252/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 254/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 255/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 256/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 257/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 258/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 259/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 260/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 261/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 262/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 263/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 264/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 265/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 266/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 267/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 268/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 269/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 270/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 271/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 272/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 273/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 274/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 275/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 276/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 277/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 278/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 279/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 280/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 281/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 282/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 283/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 284/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 285/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 286/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 287/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 288/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 289/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 290/929, 8.9 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 292/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 293/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 294/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 295/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 296/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 297/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 298/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 299/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 300/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 301/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 302/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 303/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 304/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 305/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 306/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 307/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 308/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 309/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 310/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 311/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 312/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 313/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 314/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 315/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 316/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 317/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 318/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 319/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 320/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 321/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 322/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 323/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 324/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 325/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 326/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 327/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 328/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 329/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 330/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 331/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 332/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 333/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 334/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 335/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 336/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 337/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 338/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 339/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 340/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 341/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 342/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 343/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 344/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 345/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 346/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 347/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 348/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 349/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 350/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 351/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 352/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 353/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 354/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 355/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 356/929, 9.0 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 357/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 358/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 359/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 360/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 361/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 362/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 363/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 364/929, 9.0 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.0 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 366/929, 9.0 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 367/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 368/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 369/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 370/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 371/929, 9.1 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>>                  ] 372/929, 9.1 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>>                  ] 373/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 376/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 377/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 378/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 379/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 380/929, 9.1 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 381/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 384/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 385/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 386/929, 9.1 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 387/929, 9.1 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 388/929, 9.1 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 389/929, 9.1 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 390/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 394/929, 9.1 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 395/929, 9.1 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 396/929, 9.1 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 397/929, 9.1 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 398/929, 9.1 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 399/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 403/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 404/929, 9.1 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>>                 ] 405/929, 9.1 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 406/929, 9.1 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 407/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 412/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 413/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 414/929, 9.1 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 415/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 422/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 423/929, 9.1 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 424/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 430/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 431/929, 9.1 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 432/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.1 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.1 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 441/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.1 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.1 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 450/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.1 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.1 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 468/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.1 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 477/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.1 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.1 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.1 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.1 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.1 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 523/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.1 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.2 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.2 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.1 task/s, elapsed: 58s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.2 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.2 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.2 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.2 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.2 task/s, elapsed: 59s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.2 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.2 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.2 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.2 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.2 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.2 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.2 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.2 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.2 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.2 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.2 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.2 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.2 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.2 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.2 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.2 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.2 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.2 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.2 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.2 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.2 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.2 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.2 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.2 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.2 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.2 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.2 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.2 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.2 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.2 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.2 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.2 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.2 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.2 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.2 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.2 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.2 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.2 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.2 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.2 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.2 task/s, elapsed: 74s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.2 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.2 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.2 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.2 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.2 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.2 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.2 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.2 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.2 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.2 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.2 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.2 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.2 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.2 task/s, elapsed: 85s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.2 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.2 task/s, elapsed: 86s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.2 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.2 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.2 task/s, elapsed: 87s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.2 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.2 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.2 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.2 task/s, elapsed: 88s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.2 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.2 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.2 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.2 task/s, elapsed: 89s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.2 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.2 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.2 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.2 task/s, elapsed: 90s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.2 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.2 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.2 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.2 task/s, elapsed: 91s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.2 task/s, elapsed: 92s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.2 task/s, elapsed: 93s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.2 task/s, elapsed: 94s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.3 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.3 task/s, elapsed: 95s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.3 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.3 task/s, elapsed: 96s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.3 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.3 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.3 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.3 task/s, elapsed: 97s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.3 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.3 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.3 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.3 task/s, elapsed: 98s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.3 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.3 task/s, elapsed: 99s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.3 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.3 task/s, elapsed: 100s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.3 task/s, elapsed: 100s, ETA:     0s2022-10-10 18:49:55,139 - mmseg - INFO - per class results:2022-10-10 18:49:55,140 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 90.97 | 96.11 || rigid_plastic | 25.15 | 28.34 ||   cardboard   | 57.81 | 73.37 ||     metal     | 33.73 |  41.5 ||  soft_plastic | 63.24 | 70.86 |+---------------+-------+-------+2022-10-10 18:49:55,140 - mmseg - INFO - Summary:2022-10-10 18:49:55,141 - mmseg - INFO - +------+-------+-------+| aAcc |  mIoU |  mAcc |+------+-------+-------+| 91.5 | 54.18 | 62.04 |+------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:49:55,145 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 18:49:55,145 - mmseg - INFO - Iter [929/40000]	lr: 1.800e-05, eta: 4:15:21, time: 1.279, data_time: 0.014, memory: 67494, aAcc: 0.9150, mIoU: 0.5418, mAcc: 0.6204, IoU.background: 0.9097, IoU.rigid_plastic: 0.2515, IoU.cardboard: 0.5781, IoU.metal: 0.3373, IoU.soft_plastic: 0.6324, Acc.background: 0.9611, Acc.rigid_plastic: 0.2834, Acc.cardboard: 0.7337, Acc.metal: 0.4150, Acc.soft_plastic: 0.7086, src.decode.loss_seg: 0.0499, src.decode.acc_seg: 98.1644, src.loss: 0.0659, mix.decode.loss_seg: 0.0353, mix.decode.acc_seg: 98.5008, mix.loss: 0.0353, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:50:59,079 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 4:15:24, time: 4.404, data_time: 3.139, memory: 67494, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.1788, src.loss: 0.0648, mix.decode.loss_seg: 0.0401, mix.decode.acc_seg: 98.2043, mix.loss: 0.0401, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:52:03,111 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 4:14:20, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0465, src.decode.acc_seg: 98.2444, src.loss: 0.0625, mix.decode.loss_seg: 0.0437, mix.decode.acc_seg: 98.2854, mix.loss: 0.0437, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:53:07,037 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 4:13:15, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0514, src.decode.acc_seg: 98.1233, src.loss: 0.0674, mix.decode.loss_seg: 0.0399, mix.decode.acc_seg: 98.5259, mix.loss: 0.0399, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:54:11,032 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 4:12:11, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0516, src.decode.acc_seg: 98.0552, src.loss: 0.0676, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.2929, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:55:15,299 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 4:11:07, time: 1.285, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.3566, src.loss: 0.0577, mix.decode.loss_seg: 0.0364, mix.decode.acc_seg: 98.2316, mix.loss: 0.0364, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:56:19,870 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 4:10:03, time: 1.291, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0420, src.decode.acc_seg: 98.4602, src.loss: 0.0580, mix.decode.loss_seg: 0.0334, mix.decode.acc_seg: 98.4755, mix.loss: 0.0334, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:57:24,090 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 4:08:59, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0413, src.decode.acc_seg: 98.4003, src.loss: 0.0574, mix.decode.loss_seg: 0.0298, mix.decode.acc_seg: 98.7245, mix.loss: 0.0298, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:58:28,529 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 4:07:55, time: 1.289, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0561, src.decode.acc_seg: 97.8829, src.loss: 0.0721, mix.decode.loss_seg: 0.0352, mix.decode.acc_seg: 98.4958, mix.loss: 0.0352, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 18:59:31,784 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 4:06:51, time: 1.265, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0516, src.decode.acc_seg: 98.0295, src.loss: 0.0676, mix.decode.loss_seg: 0.0364, mix.decode.acc_seg: 98.4477, mix.loss: 0.0364, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:00:35,480 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 4:05:46, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0508, src.decode.acc_seg: 98.0457, src.loss: 0.0668, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.4797, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:01:39,076 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 4:04:42, time: 1.272, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.2037, src.loss: 0.0648, mix.decode.loss_seg: 0.0354, mix.decode.acc_seg: 98.5544, mix.loss: 0.0354, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:02:42,770 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 4:03:38, time: 1.274, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0473, src.decode.acc_seg: 98.2139, src.loss: 0.0634, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.3981, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:03:46,055 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 4:02:33, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0524, src.decode.acc_seg: 98.0798, src.loss: 0.0684, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.5650, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:04:49,927 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 4:01:29, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0389, src.decode.acc_seg: 98.6876, src.loss: 0.0549, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.8502, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:05:53,903 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 4:00:25, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0548, src.decode.acc_seg: 97.8952, src.loss: 0.0708, mix.decode.loss_seg: 0.0380, mix.decode.acc_seg: 98.3977, mix.loss: 0.0380, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:06:57,617 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 3:59:21, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0556, src.decode.acc_seg: 98.0622, src.loss: 0.0717, mix.decode.loss_seg: 0.0427, mix.decode.acc_seg: 98.1992, mix.loss: 0.0427, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:08:01,496 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 3:58:17, time: 1.278, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0522, src.decode.acc_seg: 98.0733, src.loss: 0.0682, mix.decode.loss_seg: 0.0369, mix.decode.acc_seg: 98.5291, mix.loss: 0.0369, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:09:05,273 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 3:57:12, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0568, src.decode.acc_seg: 97.8218, src.loss: 0.0728, mix.decode.loss_seg: 0.0434, mix.decode.acc_seg: 98.0230, mix.loss: 0.0434, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:10:08,688 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 3:56:08, time: 1.268, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0489, src.decode.acc_seg: 98.1521, src.loss: 0.0650, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.5416, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:11:12,290 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 19:11:12,291 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 3:55:04, time: 1.272, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0465, src.decode.acc_seg: 98.2315, src.loss: 0.0625, mix.decode.loss_seg: 0.0327, mix.decode.acc_seg: 98.6414, mix.loss: 0.0327, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:12:15,457 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 3:53:59, time: 1.263, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.3700, src.loss: 0.0586, mix.decode.loss_seg: 0.0352, mix.decode.acc_seg: 98.5114, mix.loss: 0.0352, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:13:19,456 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 3:52:55, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0489, src.decode.acc_seg: 98.2539, src.loss: 0.0649, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.4684, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:14:23,703 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 3:51:51, time: 1.285, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0568, src.decode.acc_seg: 97.9892, src.loss: 0.0729, mix.decode.loss_seg: 0.0375, mix.decode.acc_seg: 98.4731, mix.loss: 0.0375, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:15:27,556 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 3:50:47, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0485, src.decode.acc_seg: 98.2278, src.loss: 0.0645, mix.decode.loss_seg: 0.0465, mix.decode.acc_seg: 98.2785, mix.loss: 0.0465, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:16:31,474 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 3:49:43, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0496, src.decode.acc_seg: 98.1980, src.loss: 0.0656, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.6706, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:17:35,617 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 3:48:38, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0540, src.decode.acc_seg: 97.9198, src.loss: 0.0701, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.2744, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:18:39,797 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 3:47:34, time: 1.284, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.2975, src.loss: 0.0607, mix.decode.loss_seg: 0.0349, mix.decode.acc_seg: 98.4378, mix.loss: 0.0349, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:19:43,871 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 3:46:30, time: 1.281, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0509, src.decode.acc_seg: 98.1632, src.loss: 0.0669, mix.decode.loss_seg: 0.0369, mix.decode.acc_seg: 98.3375, mix.loss: 0.0369, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:20:47,785 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 3:45:26, time: 1.278, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0486, src.decode.acc_seg: 98.1433, src.loss: 0.0647, mix.decode.loss_seg: 0.0374, mix.decode.acc_seg: 98.5724, mix.loss: 0.0374, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:21:52,058 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 3:44:22, time: 1.285, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0486, src.decode.acc_seg: 98.2880, src.loss: 0.0647, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.6833, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:22:55,583 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 3:43:18, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4816, src.loss: 0.0568, mix.decode.loss_seg: 0.0396, mix.decode.acc_seg: 98.3429, mix.loss: 0.0396, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:23:59,286 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 3:42:14, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0508, src.decode.acc_seg: 98.1511, src.loss: 0.0668, mix.decode.loss_seg: 0.0352, mix.decode.acc_seg: 98.4758, mix.loss: 0.0352, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:25:03,067 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 3:41:09, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0457, src.decode.acc_seg: 98.4044, src.loss: 0.0617, mix.decode.loss_seg: 0.0327, mix.decode.acc_seg: 98.7238, mix.loss: 0.0327, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:26:07,082 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 3:40:05, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0495, src.decode.acc_seg: 98.1726, src.loss: 0.0655, mix.decode.loss_seg: 0.0386, mix.decode.acc_seg: 98.3856, mix.loss: 0.0386, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:27:10,875 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 3:39:01, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0551, src.decode.acc_seg: 97.9453, src.loss: 0.0711, mix.decode.loss_seg: 0.0404, mix.decode.acc_seg: 98.3953, mix.loss: 0.0404, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:28:14,980 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 3:37:57, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0539, src.decode.acc_seg: 97.9844, src.loss: 0.0699, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.3913, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:29:19,195 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 3:36:53, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0455, src.decode.acc_seg: 98.2302, src.loss: 0.0615, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.6017, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:30:23,107 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 3:35:49, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0440, src.decode.acc_seg: 98.3528, src.loss: 0.0601, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.6564, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:31:27,356 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 3:34:45, time: 1.285, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0513, src.decode.acc_seg: 98.2607, src.loss: 0.0674, mix.decode.loss_seg: 0.0403, mix.decode.acc_seg: 98.4864, mix.loss: 0.0403, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:32:31,058 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 19:32:31,058 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 3:33:40, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0519, src.decode.acc_seg: 98.0118, src.loss: 0.0679, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.2716, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:33:34,725 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 3:32:36, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0431, src.decode.acc_seg: 98.3759, src.loss: 0.0591, mix.decode.loss_seg: 0.0340, mix.decode.acc_seg: 98.5167, mix.loss: 0.0340, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:34:38,488 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 3:31:32, time: 1.275, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0475, src.decode.acc_seg: 98.1842, src.loss: 0.0635, mix.decode.loss_seg: 0.0437, mix.decode.acc_seg: 98.2076, mix.loss: 0.0437, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:35:42,920 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 3:30:28, time: 1.289, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0490, src.decode.acc_seg: 98.2287, src.loss: 0.0650, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.6165, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:36:46,360 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 3:29:24, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.2251, src.loss: 0.0607, mix.decode.loss_seg: 0.0347, mix.decode.acc_seg: 98.5570, mix.loss: 0.0347, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:37:50,088 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 3:28:19, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.3702, src.loss: 0.0570, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.4821, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:38:54,164 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 3:27:15, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0509, src.decode.acc_seg: 98.1628, src.loss: 0.0669, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.4246, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:39:57,849 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 3:26:11, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0443, src.decode.acc_seg: 98.3017, src.loss: 0.0603, mix.decode.loss_seg: 0.0294, mix.decode.acc_seg: 98.6853, mix.loss: 0.0294, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:41:01,945 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 3:25:07, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0519, src.decode.acc_seg: 98.1955, src.loss: 0.0679, mix.decode.loss_seg: 0.0283, mix.decode.acc_seg: 98.7557, mix.loss: 0.0283, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:42:05,740 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 3:24:03, time: 1.276, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0473, src.decode.acc_seg: 98.1823, src.loss: 0.0633, mix.decode.loss_seg: 0.0348, mix.decode.acc_seg: 98.5320, mix.loss: 0.0348, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:43:09,865 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 3:22:59, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0463, src.decode.acc_seg: 98.3401, src.loss: 0.0623, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.5560, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:44:13,185 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 3:21:54, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0410, src.decode.acc_seg: 98.4501, src.loss: 0.0571, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5399, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:45:16,980 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 3:20:50, time: 1.276, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0572, src.decode.acc_seg: 98.0213, src.loss: 0.0732, mix.decode.loss_seg: 0.0393, mix.decode.acc_seg: 98.4015, mix.loss: 0.0393, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:46:20,913 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 3:19:46, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0500, src.decode.acc_seg: 98.2432, src.loss: 0.0660, mix.decode.loss_seg: 0.0397, mix.decode.acc_seg: 98.3805, mix.loss: 0.0397, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:47:24,663 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 3:18:42, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0504, src.decode.acc_seg: 98.1754, src.loss: 0.0664, mix.decode.loss_seg: 0.0349, mix.decode.acc_seg: 98.3982, mix.loss: 0.0349, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:48:29,047 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 3:17:38, time: 1.288, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0461, src.decode.acc_seg: 98.2559, src.loss: 0.0621, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.4856, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:49:32,862 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 3:16:33, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0414, src.decode.acc_seg: 98.5161, src.loss: 0.0575, mix.decode.loss_seg: 0.0291, mix.decode.acc_seg: 98.8064, mix.loss: 0.0291, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:50:36,919 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 3:15:29, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0459, src.decode.acc_seg: 98.2818, src.loss: 0.0619, mix.decode.loss_seg: 0.0355, mix.decode.acc_seg: 98.4888, mix.loss: 0.0355, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:51:40,575 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 3:14:25, time: 1.273, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0544, src.decode.acc_seg: 98.0232, src.loss: 0.0705, mix.decode.loss_seg: 0.0345, mix.decode.acc_seg: 98.4938, mix.loss: 0.0345, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:52:44,540 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 3:13:21, time: 1.279, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0507, src.decode.acc_seg: 98.1336, src.loss: 0.0668, mix.decode.loss_seg: 0.0374, mix.decode.acc_seg: 98.3822, mix.loss: 0.0374, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:53:48,843 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 19:53:48,843 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 3:12:17, time: 1.286, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0471, src.decode.acc_seg: 98.2919, src.loss: 0.0631, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.5524, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:54:52,075 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 3:11:13, time: 1.265, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0421, src.decode.acc_seg: 98.4854, src.loss: 0.0581, mix.decode.loss_seg: 0.0360, mix.decode.acc_seg: 98.4368, mix.loss: 0.0360, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:55:56,017 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 3:10:08, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0526, src.decode.acc_seg: 98.0998, src.loss: 0.0686, mix.decode.loss_seg: 0.0331, mix.decode.acc_seg: 98.6665, mix.loss: 0.0331, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:56:59,930 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 3:09:04, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0365, src.decode.acc_seg: 98.6081, src.loss: 0.0525, mix.decode.loss_seg: 0.0335, mix.decode.acc_seg: 98.5846, mix.loss: 0.0335, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:58:03,714 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 3:08:00, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4442, src.loss: 0.0568, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.6160, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 19:59:07,840 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 3:06:56, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0402, src.decode.acc_seg: 98.4482, src.loss: 0.0563, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.4787, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:00:11,849 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 3:05:52, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.3324, src.loss: 0.0594, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.7112, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:01:15,670 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 3:04:48, time: 1.276, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0401, src.decode.acc_seg: 98.4988, src.loss: 0.0561, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.6206, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:02:19,115 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 3:03:44, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0476, src.decode.acc_seg: 98.1852, src.loss: 0.0637, mix.decode.loss_seg: 0.0376, mix.decode.acc_seg: 98.4520, mix.loss: 0.0376, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:03:23,201 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 3:02:39, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0405, src.decode.acc_seg: 98.4490, src.loss: 0.0565, mix.decode.loss_seg: 0.0313, mix.decode.acc_seg: 98.6744, mix.loss: 0.0313, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:04:27,493 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 3:01:35, time: 1.286, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0531, src.decode.acc_seg: 98.1343, src.loss: 0.0691, mix.decode.loss_seg: 0.0398, mix.decode.acc_seg: 98.3483, mix.loss: 0.0398, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:05:33,444 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 3:00:32, time: 1.319, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0390, src.decode.acc_seg: 98.5331, src.loss: 0.0550, mix.decode.loss_seg: 0.0335, mix.decode.acc_seg: 98.5684, mix.loss: 0.0335, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:06:37,083 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 2:59:28, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0488, src.decode.acc_seg: 98.1354, src.loss: 0.0648, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.5037, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:07:41,427 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 2:58:24, time: 1.287, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0437, src.decode.acc_seg: 98.3661, src.loss: 0.0598, mix.decode.loss_seg: 0.0355, mix.decode.acc_seg: 98.5539, mix.loss: 0.0355, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:08:48,545 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 2:57:20, time: 1.342, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0432, src.decode.acc_seg: 98.4314, src.loss: 0.0592, mix.decode.loss_seg: 0.0307, mix.decode.acc_seg: 98.7146, mix.loss: 0.0307, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:09:57,312 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 2:56:17, time: 1.375, data_time: 0.017, memory: 67494, src.decode.loss_seg: 0.0419, src.decode.acc_seg: 98.4162, src.loss: 0.0580, mix.decode.loss_seg: 0.0347, mix.decode.acc_seg: 98.4980, mix.loss: 0.0347, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:11:01,354 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 2:55:13, time: 1.281, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.3672, src.loss: 0.0601, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.5889, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:12:05,269 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 2:54:09, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0393, src.decode.acc_seg: 98.5791, src.loss: 0.0553, mix.decode.loss_seg: 0.0278, mix.decode.acc_seg: 98.7552, mix.loss: 0.0278, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:13:09,236 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 2:53:05, time: 1.279, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0414, src.decode.acc_seg: 98.4297, src.loss: 0.0575, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.6761, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:14:13,109 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 2:52:01, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0353, src.decode.acc_seg: 98.6959, src.loss: 0.0513, mix.decode.loss_seg: 0.0298, mix.decode.acc_seg: 98.6773, mix.loss: 0.0298, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.6 task/s, elapsed: 2s, ETA:  1431s[                                 ] 2/929, 1.2 task/s, elapsed: 2s, ETA:   771s[                                 ] 3/929, 1.7 task/s, elapsed: 2s, ETA:   549s[                                 ] 4/929, 2.1 task/s, elapsed: 2s, ETA:   438s[                                 ] 5/929, 2.5 task/s, elapsed: 2s, ETA:   371s[                                 ] 6/929, 2.8 task/s, elapsed: 2s, ETA:   325s[                                 ] 7/929, 3.1 task/s, elapsed: 2s, ETA:   293s[                                 ] 8/929, 3.4 task/s, elapsed: 2s, ETA:   269s[                                 ] 9/929, 3.7 task/s, elapsed: 2s, ETA:   249s[                                ] 10/929, 3.9 task/s, elapsed: 3s, ETA:   234s[                                ] 11/929, 4.2 task/s, elapsed: 3s, ETA:   221s[                                ] 12/929, 4.4 task/s, elapsed: 3s, ETA:   211s[                                ] 13/929, 4.5 task/s, elapsed: 3s, ETA:   202s[                                ] 14/929, 4.7 task/s, elapsed: 3s, ETA:   194s[                                ] 15/929, 4.9 task/s, elapsed: 3s, ETA:   187s[                                ] 16/929, 5.0 task/s, elapsed: 3s, ETA:   182s[                                ] 17/929, 5.2 task/s, elapsed: 3s, ETA:   176s[                                ] 18/929, 5.3 task/s, elapsed: 3s, ETA:   172s[                                ] 19/929, 5.4 task/s, elapsed: 4s, ETA:   168s[                                ] 20/929, 5.5 task/s, elapsed: 4s, ETA:   165s[                                ] 21/929, 5.6 task/s, elapsed: 4s, ETA:   161s[                                ] 22/929, 5.7 task/s, elapsed: 4s, ETA:   158s[                                ] 23/929, 5.8 task/s, elapsed: 4s, ETA:   155s[                                ] 24/929, 5.9 task/s, elapsed: 4s, ETA:   152s[                                ] 25/929, 6.0 task/s, elapsed: 4s, ETA:   150s[                                ] 26/929, 6.1 task/s, elapsed: 4s, ETA:   147s[                                ] 27/929, 6.2 task/s, elapsed: 4s, ETA:   145s[                                ] 28/929, 6.3 task/s, elapsed: 4s, ETA:   143s[                                ] 29/929, 6.4 task/s, elapsed: 5s, ETA:   141s[>                               ] 30/929, 6.5 task/s, elapsed: 5s, ETA:   139s[>                               ] 31/929, 6.5 task/s, elapsed: 5s, ETA:   138s[>                               ] 32/929, 6.6 task/s, elapsed: 5s, ETA:   136s[>                               ] 33/929, 6.6 task/s, elapsed: 5s, ETA:   135s[>                               ] 34/929, 6.7 task/s, elapsed: 5s, ETA:   133s[>                               ] 35/929, 6.8 task/s, elapsed: 5s, ETA:   132s[>                               ] 36/929, 6.8 task/s, elapsed: 5s, ETA:   131s[>                               ] 37/929, 6.9 task/s, elapsed: 5s, ETA:   130s[>                               ] 38/929, 6.9 task/s, elapsed: 5s, ETA:   129s[>                               ] 39/929, 7.0 task/s, elapsed: 6s, ETA:   128s[>                               ] 40/929, 7.0 task/s, elapsed: 6s, ETA:   127s[>                               ] 41/929, 7.0 task/s, elapsed: 6s, ETA:   126s[>                               ] 42/929, 7.1 task/s, elapsed: 6s, ETA:   125s[>                               ] 43/929, 7.1 task/s, elapsed: 6s, ETA:   124s[>                               ] 44/929, 7.2 task/s, elapsed: 6s, ETA:   124s[>                               ] 45/929, 7.2 task/s, elapsed: 6s, ETA:   123s[>                               ] 46/929, 7.2 task/s, elapsed: 6s, ETA:   122s[>                               ] 47/929, 7.3 task/s, elapsed: 6s, ETA:   122s[>                               ] 48/929, 7.3 task/s, elapsed: 7s, ETA:   121s[>                               ] 49/929, 7.3 task/s, elapsed: 7s, ETA:   120s[>                               ] 50/929, 7.3 task/s, elapsed: 7s, ETA:   120s[>                               ] 51/929, 7.4 task/s, elapsed: 7s, ETA:   119s[>                               ] 52/929, 7.4 task/s, elapsed: 7s, ETA:   118s[>                               ] 53/929, 7.4 task/s, elapsed: 7s, ETA:   118s[>                               ] 54/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 55/929, 7.5 task/s, elapsed: 7s, ETA:   117s[>                               ] 56/929, 7.5 task/s, elapsed: 7s, ETA:   116s[>                               ] 57/929, 7.5 task/s, elapsed: 8s, ETA:   116s[>                               ] 58/929, 7.5 task/s, elapsed: 8s, ETA:   115s[>>                              ] 59/929, 7.6 task/s, elapsed: 8s, ETA:   115s[>>                              ] 60/929, 7.6 task/s, elapsed: 8s, ETA:   114s[>>                              ] 61/929, 7.6 task/s, elapsed: 8s, ETA:   114s[>>                              ] 62/929, 7.6 task/s, elapsed: 8s, ETA:   113s[>>                              ] 63/929, 7.7 task/s, elapsed: 8s, ETA:   113s[>>                              ] 64/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 65/929, 7.7 task/s, elapsed: 8s, ETA:   112s[>>                              ] 66/929, 7.7 task/s, elapsed: 9s, ETA:   112s[>>                              ] 67/929, 7.7 task/s, elapsed: 9s, ETA:   112s[>>                              ] 68/929, 7.7 task/s, elapsed: 9s, ETA:   112s[>>                              ] 69/929, 7.7 task/s, elapsed: 9s, ETA:   111s[>>                              ] 70/929, 7.7 task/s, elapsed: 9s, ETA:   111s[>>                              ] 71/929, 7.8 task/s, elapsed: 9s, ETA:   111s[>>                              ] 72/929, 7.8 task/s, elapsed: 9s, ETA:   110s[>>                              ] 73/929, 7.8 task/s, elapsed: 9s, ETA:   110s[>>                              ] 74/929, 7.8 task/s, elapsed: 9s, ETA:   109s[>>                             ] 75/929, 7.8 task/s, elapsed: 10s, ETA:   109s[>>                             ] 76/929, 7.8 task/s, elapsed: 10s, ETA:   109s[>>                             ] 77/929, 7.9 task/s, elapsed: 10s, ETA:   108s[>>                             ] 78/929, 7.9 task/s, elapsed: 10s, ETA:   108s[>>                             ] 79/929, 7.9 task/s, elapsed: 10s, ETA:   108s[>>                             ] 80/929, 7.9 task/s, elapsed: 10s, ETA:   107s[>>                             ] 81/929, 7.9 task/s, elapsed: 10s, ETA:   107s[>>                             ] 82/929, 7.9 task/s, elapsed: 10s, ETA:   107s[>>                             ] 83/929, 8.0 task/s, elapsed: 10s, ETA:   106s[>>                             ] 84/929, 8.0 task/s, elapsed: 11s, ETA:   106s[>>                             ] 85/929, 8.0 task/s, elapsed: 11s, ETA:   106s[>>                             ] 86/929, 8.0 task/s, elapsed: 11s, ETA:   105s[>>                             ] 87/929, 8.0 task/s, elapsed: 11s, ETA:   105s[>>                             ] 88/929, 8.0 task/s, elapsed: 11s, ETA:   105s[>>                             ] 89/929, 8.0 task/s, elapsed: 11s, ETA:   104s[>>>                            ] 90/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>>                            ] 91/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>>                            ] 92/929, 8.1 task/s, elapsed: 11s, ETA:   104s[>>>                            ] 93/929, 8.1 task/s, elapsed: 12s, ETA:   103s[>>>                            ] 94/929, 8.1 task/s, elapsed: 12s, ETA:   103s[>>>                            ] 95/929, 8.1 task/s, elapsed: 12s, ETA:   103s[>>>                            ] 96/929, 8.1 task/s, elapsed: 12s, ETA:   103s[>>>                            ] 97/929, 8.1 task/s, elapsed: 12s, ETA:   103s[>>>                            ] 98/929, 8.1 task/s, elapsed: 12s, ETA:   102s[>>>                            ] 99/929, 8.1 task/s, elapsed: 12s, ETA:   102s[>>>                           ] 100/929, 8.1 task/s, elapsed: 12s, ETA:   102s[>>>                           ] 101/929, 8.1 task/s, elapsed: 12s, ETA:   102s[>>>                           ] 102/929, 8.1 task/s, elapsed: 13s, ETA:   102s[>>>                           ] 103/929, 8.1 task/s, elapsed: 13s, ETA:   102s[>>>                           ] 104/929, 8.1 task/s, elapsed: 13s, ETA:   101s[>>>                           ] 105/929, 8.2 task/s, elapsed: 13s, ETA:   101s[>>>                           ] 106/929, 8.2 task/s, elapsed: 13s, ETA:   101s[>>>                           ] 107/929, 8.2 task/s, elapsed: 13s, ETA:   101s[>>>                           ] 108/929, 8.2 task/s, elapsed: 13s, ETA:   100s[>>>                           ] 109/929, 8.2 task/s, elapsed: 13s, ETA:   100s[>>>                           ] 110/929, 8.2 task/s, elapsed: 13s, ETA:   100s[>>>                           ] 111/929, 8.2 task/s, elapsed: 14s, ETA:   100s[>>>                           ] 112/929, 8.2 task/s, elapsed: 14s, ETA:    99s[>>>                           ] 113/929, 8.2 task/s, elapsed: 14s, ETA:    99s[>>>                           ] 114/929, 8.2 task/s, elapsed: 14s, ETA:    99s[>>>                           ] 115/929, 8.3 task/s, elapsed: 14s, ETA:    99s[>>>                           ] 116/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 117/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 118/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 119/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 120/929, 8.3 task/s, elapsed: 14s, ETA:    98s[>>>                           ] 121/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>                           ] 122/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>                           ] 123/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>>                          ] 124/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>>                          ] 125/929, 8.3 task/s, elapsed: 15s, ETA:    97s[>>>>                          ] 126/929, 8.3 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 127/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 128/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 129/929, 8.4 task/s, elapsed: 15s, ETA:    96s[>>>>                          ] 130/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 131/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 132/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 133/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 134/929, 8.4 task/s, elapsed: 16s, ETA:    95s[>>>>                          ] 135/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 136/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 137/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 138/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 139/929, 8.4 task/s, elapsed: 16s, ETA:    94s[>>>>                          ] 140/929, 8.4 task/s, elapsed: 17s, ETA:    94s[>>>>                          ] 141/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 142/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 143/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 144/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 145/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 146/929, 8.4 task/s, elapsed: 17s, ETA:    93s[>>>>                          ] 147/929, 8.5 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 148/929, 8.5 task/s, elapsed: 17s, ETA:    92s[>>>>                          ] 149/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 150/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 151/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 152/929, 8.5 task/s, elapsed: 18s, ETA:    92s[>>>>                          ] 153/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>                          ] 154/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 155/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 156/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 157/929, 8.5 task/s, elapsed: 18s, ETA:    91s[>>>>>                         ] 158/929, 8.5 task/s, elapsed: 19s, ETA:    91s[>>>>>                         ] 159/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 160/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 161/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 162/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 163/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 164/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 165/929, 8.5 task/s, elapsed: 19s, ETA:    90s[>>>>>                         ] 166/929, 8.5 task/s, elapsed: 19s, ETA:    89s[>>>>>                         ] 167/929, 8.5 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 168/929, 8.5 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 169/929, 8.6 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 170/929, 8.6 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 171/929, 8.6 task/s, elapsed: 20s, ETA:    89s[>>>>>                         ] 172/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 173/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 174/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 175/929, 8.6 task/s, elapsed: 20s, ETA:    88s[>>>>>                         ] 176/929, 8.6 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 177/929, 8.6 task/s, elapsed: 21s, ETA:    88s[>>>>>                         ] 178/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 179/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 180/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 181/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 182/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 183/929, 8.6 task/s, elapsed: 21s, ETA:    87s[>>>>>                         ] 184/929, 8.6 task/s, elapsed: 21s, ETA:    86s[>>>>>                         ] 185/929, 8.6 task/s, elapsed: 21s, ETA:    86s[>>>>>>                        ] 186/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 187/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 188/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 189/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 190/929, 8.6 task/s, elapsed: 22s, ETA:    86s[>>>>>>                        ] 191/929, 8.6 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 192/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 193/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 194/929, 8.7 task/s, elapsed: 22s, ETA:    85s[>>>>>>                        ] 195/929, 8.7 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 196/929, 8.7 task/s, elapsed: 23s, ETA:    85s[>>>>>>                        ] 197/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 198/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 199/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 200/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 201/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 202/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 203/929, 8.7 task/s, elapsed: 23s, ETA:    84s[>>>>>>                        ] 204/929, 8.7 task/s, elapsed: 23s, ETA:    83s[>>>>>>                        ] 205/929, 8.7 task/s, elapsed: 24s, ETA:    83s[>>>>>>                        ] 206/929, 8.7 task/s, elapsed: 24s, ETA:    83s[>>>>>>                        ] 207/929, 8.7 task/s, elapsed: 24s, ETA:    83s[>>>>>>                        ] 208/929, 8.7 task/s, elapsed: 24s, ETA:    83s[>>>>>>                        ] 209/929, 8.7 task/s, elapsed: 24s, ETA:    83s[>>>>>>                        ] 210/929, 8.7 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 211/929, 8.7 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 212/929, 8.7 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 213/929, 8.7 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 214/929, 8.7 task/s, elapsed: 24s, ETA:    82s[>>>>>>                        ] 215/929, 8.7 task/s, elapsed: 25s, ETA:    82s[>>>>>>                        ] 216/929, 8.7 task/s, elapsed: 25s, ETA:    82s[>>>>>>>                       ] 217/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 218/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 219/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 220/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 221/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 222/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 223/929, 8.8 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 224/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 225/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 226/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 227/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 228/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 229/929, 8.8 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 230/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 231/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 232/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 233/929, 8.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 234/929, 8.8 task/s, elapsed: 27s, ETA:    79s[>>>>>>>                       ] 235/929, 8.8 task/s, elapsed: 27s, ETA:    79s[>>>>>>>                       ] 236/929, 8.8 task/s, elapsed: 27s, ETA:    79s[>>>>>>>                       ] 237/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 239/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 240/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 241/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 242/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 243/929, 8.8 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 244/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 245/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 246/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 247/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 248/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 249/929, 8.8 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 250/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 251/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>>                      ] 252/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 254/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 255/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 256/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 257/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 258/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 259/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 260/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 261/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 262/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 263/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 264/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 265/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 266/929, 8.9 task/s, elapsed: 30s, ETA:    75s[>>>>>>>>                      ] 267/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 268/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 269/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 270/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 271/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 272/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 273/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 274/929, 8.9 task/s, elapsed: 31s, ETA:    74s[>>>>>>>>                      ] 275/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 276/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 277/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 278/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 279/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 280/929, 8.9 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 281/929, 8.9 task/s, elapsed: 32s, ETA:    73s[>>>>>>>>>                     ] 282/929, 8.9 task/s, elapsed: 32s, ETA:    73s[>>>>>>>>>                     ] 283/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 284/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 285/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 286/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 287/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 288/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 289/929, 8.9 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 290/929, 8.9 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 292/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 293/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 294/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 295/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 296/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 297/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 298/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 299/929, 8.9 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 300/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 301/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 302/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 303/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 304/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 305/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 306/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 307/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 308/929, 8.9 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 309/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 310/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 311/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 312/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 313/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 314/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 315/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 316/929, 8.9 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 317/929, 8.9 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 318/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 319/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 320/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 321/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 322/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 323/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 324/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 325/929, 8.9 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 326/929, 8.9 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 327/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 328/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 329/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 330/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 331/929, 8.9 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 332/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 333/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 334/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 335/929, 8.9 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 336/929, 8.9 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 337/929, 8.9 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 338/929, 8.9 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 339/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 340/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 341/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 342/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 343/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 344/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 345/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 346/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 347/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 348/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 349/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 350/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 351/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 352/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 353/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 354/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 355/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 356/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 357/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 358/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 359/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 360/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 361/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 362/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 363/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 364/929, 9.0 task/s, elapsed: 40s, ETA:    63s[>>>>>>>>>>>                   ] 365/929, 9.0 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 366/929, 9.0 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 367/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 368/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 369/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 370/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>                   ] 371/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>>                  ] 372/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>>                  ] 373/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>>                  ] 374/929, 9.0 task/s, elapsed: 41s, ETA:    62s[>>>>>>>>>>>>                  ] 375/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 376/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 377/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 378/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 379/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 380/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 381/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 382/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 383/929, 9.0 task/s, elapsed: 42s, ETA:    61s[>>>>>>>>>>>>                  ] 384/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 385/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 386/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 387/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 388/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 389/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 390/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 391/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 392/929, 9.0 task/s, elapsed: 43s, ETA:    60s[>>>>>>>>>>>>                  ] 393/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 394/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 395/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 396/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 397/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 398/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 399/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 400/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 401/929, 9.0 task/s, elapsed: 44s, ETA:    59s[>>>>>>>>>>>>                  ] 402/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 403/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 404/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 405/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 406/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 407/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 408/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 409/929, 9.0 task/s, elapsed: 45s, ETA:    58s[>>>>>>>>>>>>>                 ] 410/929, 9.0 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 412/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 413/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 414/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 415/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 416/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 417/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 418/929, 9.0 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 419/929, 9.0 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 421/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 422/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 423/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 424/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 425/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 426/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 427/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 428/929, 9.0 task/s, elapsed: 47s, ETA:    55s[>>>>>>>>>>>>>                 ] 429/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 430/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 431/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 432/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 433/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 434/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 435/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 436/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 437/929, 9.0 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 438/929, 9.0 task/s, elapsed: 48s, ETA:    54s[>>>>>>>>>>>>>>                ] 439/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 440/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 441/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 442/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 443/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 444/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 445/929, 9.0 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.0 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 447/929, 9.0 task/s, elapsed: 49s, ETA:    53s[>>>>>>>>>>>>>>                ] 448/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 449/929, 9.1 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 450/929, 9.1 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 451/929, 9.1 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 452/929, 9.1 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 453/929, 9.1 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 454/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 455/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 456/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 457/929, 9.1 task/s, elapsed: 50s, ETA:    52s[>>>>>>>>>>>>>>                ] 458/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 460/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 461/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 462/929, 9.1 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 463/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>                ] 464/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 465/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 466/929, 9.1 task/s, elapsed: 51s, ETA:    51s[>>>>>>>>>>>>>>>               ] 467/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 468/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 469/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 470/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 471/929, 9.1 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 472/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 473/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 474/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 475/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 476/929, 9.1 task/s, elapsed: 52s, ETA:    50s[>>>>>>>>>>>>>>>               ] 477/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 478/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 479/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 480/929, 9.1 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 481/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 482/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 483/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 484/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.1 task/s, elapsed: 53s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.1 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 487/929, 9.1 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 488/929, 9.1 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 489/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 491/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 492/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 493/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.1 task/s, elapsed: 54s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.1 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 496/929, 9.1 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 497/929, 9.1 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 498/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 500/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 501/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 502/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.1 task/s, elapsed: 55s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 505/929, 9.1 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 506/929, 9.1 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 507/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 509/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 510/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 514/929, 9.1 task/s, elapsed: 56s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 515/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 518/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 519/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 523/929, 9.1 task/s, elapsed: 57s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 524/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.1 task/s, elapsed: 58s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.1 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.1 task/s, elapsed: 59s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.1 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.1 task/s, elapsed: 60s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.1 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.1 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.1 task/s, elapsed: 61s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.1 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.1 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.1 task/s, elapsed: 62s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.1 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.1 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.1 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.1 task/s, elapsed: 63s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.1 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.1 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.1 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.1 task/s, elapsed: 64s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.1 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.1 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.1 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.1 task/s, elapsed: 65s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.1 task/s, elapsed: 66s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.1 task/s, elapsed: 67s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.1 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.1 task/s, elapsed: 68s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.1 task/s, elapsed: 69s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.1 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.1 task/s, elapsed: 70s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.1 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.1 task/s, elapsed: 71s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.1 task/s, elapsed: 72s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.1 task/s, elapsed: 73s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.1 task/s, elapsed: 75s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.1 task/s, elapsed: 76s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.1 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.1 task/s, elapsed: 77s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.1 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.1 task/s, elapsed: 78s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.1 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.1 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.1 task/s, elapsed: 79s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.1 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.1 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.1 task/s, elapsed: 80s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.1 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.1 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.1 task/s, elapsed: 81s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.1 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.1 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.1 task/s, elapsed: 82s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.1 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.1 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.1 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.1 task/s, elapsed: 83s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.1 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.1 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.1 task/s, elapsed: 84s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.1 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.1 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.1 task/s, elapsed: 85s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.1 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.1 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.1 task/s, elapsed: 86s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.1 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.1 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.1 task/s, elapsed: 87s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.1 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.1 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.1 task/s, elapsed: 88s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.1 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.1 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.1 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.1 task/s, elapsed: 89s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.1 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.1 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.1 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.1 task/s, elapsed: 90s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.1 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.1 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.1 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.1 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.2 task/s, elapsed: 91s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.2 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.2 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.2 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.2 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.2 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.2 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.2 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.2 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.2 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.2 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.2 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.2 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.2 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.2 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.2 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.2 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.2 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.2 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.2 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.2 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.1 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.1 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.1 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.1 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.1 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.1 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.1 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.1 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.1 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.1 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.1 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.1 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.1 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.1 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.1 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.1 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.1 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.1 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.1 task/s, elapsed: 101s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.1 task/s, elapsed: 101s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.1 task/s, elapsed: 102s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.1 task/s, elapsed: 102s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.1 task/s, elapsed: 102s, ETA:     0s2022-10-10 20:17:55,190 - mmseg - INFO - per class results:2022-10-10 20:17:55,191 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.21 | 95.99 || rigid_plastic | 36.91 | 41.38 ||   cardboard   | 58.41 | 74.53 ||     metal     | 26.17 | 38.42 ||  soft_plastic | 64.41 | 72.39 |+---------------+-------+-------+2022-10-10 20:17:55,191 - mmseg - INFO - Summary:2022-10-10 20:17:55,191 - mmseg - INFO - +-------+-------+-------+|  aAcc |  mIoU |  mAcc |+-------+-------+-------+| 91.72 | 55.42 | 64.54 |+-------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:17:55,195 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 20:17:55,195 - mmseg - INFO - Iter [929/40000]	lr: 1.200e-05, eta: 2:50:57, time: 1.285, data_time: 0.014, memory: 67494, aAcc: 0.9172, mIoU: 0.5542, mAcc: 0.6454, IoU.background: 0.9121, IoU.rigid_plastic: 0.3691, IoU.cardboard: 0.5841, IoU.metal: 0.2617, IoU.soft_plastic: 0.6441, Acc.background: 0.9599, Acc.rigid_plastic: 0.4138, Acc.cardboard: 0.7453, Acc.metal: 0.3842, Acc.soft_plastic: 0.7239, src.decode.loss_seg: 0.0447, src.decode.acc_seg: 98.3185, src.loss: 0.0607, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4002, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:18:59,240 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 2:50:32, time: 4.437, data_time: 3.171, memory: 67494, src.decode.loss_seg: 0.0383, src.decode.acc_seg: 98.5076, src.loss: 0.0543, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.7395, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:20:03,061 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 2:49:27, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0445, src.decode.acc_seg: 98.3580, src.loss: 0.0606, mix.decode.loss_seg: 0.0332, mix.decode.acc_seg: 98.6329, mix.loss: 0.0332, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:21:07,357 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 2:48:23, time: 1.286, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0469, src.decode.acc_seg: 98.2677, src.loss: 0.0629, mix.decode.loss_seg: 0.0254, mix.decode.acc_seg: 98.9050, mix.loss: 0.0254, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:22:11,787 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 2:47:19, time: 1.289, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.4374, src.loss: 0.0593, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.3137, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:23:15,296 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 2:46:14, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0448, src.decode.acc_seg: 98.3549, src.loss: 0.0609, mix.decode.loss_seg: 0.0361, mix.decode.acc_seg: 98.4969, mix.loss: 0.0361, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:24:19,080 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 2:45:09, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0411, src.decode.acc_seg: 98.4221, src.loss: 0.0571, mix.decode.loss_seg: 0.0297, mix.decode.acc_seg: 98.6837, mix.loss: 0.0297, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:25:23,519 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 2:44:05, time: 1.289, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0388, src.decode.acc_seg: 98.5276, src.loss: 0.0548, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.6276, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:26:26,874 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 2:43:01, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0443, src.decode.acc_seg: 98.3442, src.loss: 0.0603, mix.decode.loss_seg: 0.0334, mix.decode.acc_seg: 98.6396, mix.loss: 0.0334, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:27:31,042 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 2:41:56, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0436, src.decode.acc_seg: 98.3149, src.loss: 0.0596, mix.decode.loss_seg: 0.0363, mix.decode.acc_seg: 98.3279, mix.loss: 0.0363, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:28:35,219 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 2:40:52, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0382, src.decode.acc_seg: 98.5449, src.loss: 0.0542, mix.decode.loss_seg: 0.0286, mix.decode.acc_seg: 98.8023, mix.loss: 0.0286, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:29:39,648 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 2:39:47, time: 1.289, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0454, src.decode.acc_seg: 98.3474, src.loss: 0.0614, mix.decode.loss_seg: 0.0410, mix.decode.acc_seg: 98.5280, mix.loss: 0.0410, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:30:43,161 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 2:38:43, time: 1.270, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0483, src.decode.acc_seg: 98.1715, src.loss: 0.0643, mix.decode.loss_seg: 0.0367, mix.decode.acc_seg: 98.4670, mix.loss: 0.0367, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:31:47,881 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 2:37:39, time: 1.294, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0436, src.decode.acc_seg: 98.4389, src.loss: 0.0596, mix.decode.loss_seg: 0.0287, mix.decode.acc_seg: 98.7860, mix.loss: 0.0287, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:32:51,823 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 2:36:34, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0486, src.decode.acc_seg: 98.2138, src.loss: 0.0647, mix.decode.loss_seg: 0.0336, mix.decode.acc_seg: 98.5547, mix.loss: 0.0336, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:33:55,665 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 2:35:30, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0365, src.decode.acc_seg: 98.6170, src.loss: 0.0525, mix.decode.loss_seg: 0.0306, mix.decode.acc_seg: 98.7805, mix.loss: 0.0306, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:35:00,020 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 2:34:25, time: 1.287, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0412, src.decode.acc_seg: 98.4297, src.loss: 0.0573, mix.decode.loss_seg: 0.0302, mix.decode.acc_seg: 98.6674, mix.loss: 0.0302, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:36:04,111 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 2:33:21, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0479, src.decode.acc_seg: 98.2065, src.loss: 0.0639, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.6063, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:37:07,993 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 2:32:17, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0445, src.decode.acc_seg: 98.2660, src.loss: 0.0605, mix.decode.loss_seg: 0.0393, mix.decode.acc_seg: 98.3399, mix.loss: 0.0393, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:38:12,017 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 2:31:12, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0441, src.decode.acc_seg: 98.2818, src.loss: 0.0601, mix.decode.loss_seg: 0.0398, mix.decode.acc_seg: 98.3506, mix.loss: 0.0398, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:39:16,153 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 20:39:16,153 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 2:30:08, time: 1.283, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0356, src.decode.acc_seg: 98.6537, src.loss: 0.0517, mix.decode.loss_seg: 0.0310, mix.decode.acc_seg: 98.6694, mix.loss: 0.0310, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:40:19,986 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 2:29:03, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0375, src.decode.acc_seg: 98.5919, src.loss: 0.0535, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.5386, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:41:24,014 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 2:27:59, time: 1.281, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0393, src.decode.acc_seg: 98.5351, src.loss: 0.0554, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.7099, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:42:27,837 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 2:26:54, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.4291, src.loss: 0.0565, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.5735, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:43:31,939 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 2:25:50, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0432, src.decode.acc_seg: 98.3643, src.loss: 0.0592, mix.decode.loss_seg: 0.0347, mix.decode.acc_seg: 98.5896, mix.loss: 0.0347, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:44:36,470 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 2:24:46, time: 1.291, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0445, src.decode.acc_seg: 98.3192, src.loss: 0.0605, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.7210, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:45:40,944 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 2:23:41, time: 1.289, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0450, src.decode.acc_seg: 98.3143, src.loss: 0.0610, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.5813, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:46:44,824 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 2:22:37, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0468, src.decode.acc_seg: 98.2144, src.loss: 0.0628, mix.decode.loss_seg: 0.0366, mix.decode.acc_seg: 98.3953, mix.loss: 0.0366, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:47:48,486 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 2:21:33, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0422, src.decode.acc_seg: 98.4080, src.loss: 0.0583, mix.decode.loss_seg: 0.0370, mix.decode.acc_seg: 98.4696, mix.loss: 0.0370, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:48:52,779 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 2:20:28, time: 1.286, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0376, src.decode.acc_seg: 98.5770, src.loss: 0.0536, mix.decode.loss_seg: 0.0262, mix.decode.acc_seg: 98.8747, mix.loss: 0.0262, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:49:56,884 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 2:19:24, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0452, src.decode.acc_seg: 98.3591, src.loss: 0.0612, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.4046, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:51:00,222 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 2:18:19, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0407, src.decode.acc_seg: 98.4968, src.loss: 0.0567, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.6237, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:52:05,140 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 2:17:15, time: 1.298, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0431, src.decode.acc_seg: 98.3415, src.loss: 0.0591, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.5420, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:53:08,874 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 2:16:11, time: 1.275, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0435, src.decode.acc_seg: 98.3236, src.loss: 0.0595, mix.decode.loss_seg: 0.0389, mix.decode.acc_seg: 98.4177, mix.loss: 0.0389, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:54:12,692 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 2:15:06, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0359, src.decode.acc_seg: 98.5861, src.loss: 0.0519, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.5755, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:55:17,151 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 2:14:02, time: 1.289, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0400, src.decode.acc_seg: 98.4867, src.loss: 0.0561, mix.decode.loss_seg: 0.0344, mix.decode.acc_seg: 98.6110, mix.loss: 0.0344, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:56:20,829 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 2:12:57, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.2993, src.loss: 0.0594, mix.decode.loss_seg: 0.0329, mix.decode.acc_seg: 98.5548, mix.loss: 0.0329, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:57:24,984 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 2:11:53, time: 1.283, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0365, src.decode.acc_seg: 98.6326, src.loss: 0.0525, mix.decode.loss_seg: 0.0289, mix.decode.acc_seg: 98.7678, mix.loss: 0.0289, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:58:29,909 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 2:10:49, time: 1.299, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0494, src.decode.acc_seg: 98.1831, src.loss: 0.0654, mix.decode.loss_seg: 0.0372, mix.decode.acc_seg: 98.4568, mix.loss: 0.0372, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 20:59:33,946 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 2:09:44, time: 1.281, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0470, src.decode.acc_seg: 98.4186, src.loss: 0.0630, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.5421, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:00:38,094 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 21:00:38,094 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 2:08:40, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0521, src.decode.acc_seg: 98.2105, src.loss: 0.0681, mix.decode.loss_seg: 0.0346, mix.decode.acc_seg: 98.4577, mix.loss: 0.0346, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:01:41,924 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 2:07:36, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0465, src.decode.acc_seg: 98.2402, src.loss: 0.0625, mix.decode.loss_seg: 0.0362, mix.decode.acc_seg: 98.4202, mix.loss: 0.0362, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:02:46,095 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 2:06:31, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0440, src.decode.acc_seg: 98.3843, src.loss: 0.0600, mix.decode.loss_seg: 0.0316, mix.decode.acc_seg: 98.5858, mix.loss: 0.0316, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:03:49,888 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 2:05:27, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0420, src.decode.acc_seg: 98.3693, src.loss: 0.0581, mix.decode.loss_seg: 0.0358, mix.decode.acc_seg: 98.4200, mix.loss: 0.0358, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:04:54,113 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 2:04:22, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0365, src.decode.acc_seg: 98.5889, src.loss: 0.0525, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.6834, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:05:58,273 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 2:03:18, time: 1.283, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0436, src.decode.acc_seg: 98.4844, src.loss: 0.0596, mix.decode.loss_seg: 0.0330, mix.decode.acc_seg: 98.5395, mix.loss: 0.0330, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:07:02,157 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 2:02:14, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0457, src.decode.acc_seg: 98.3021, src.loss: 0.0617, mix.decode.loss_seg: 0.0399, mix.decode.acc_seg: 98.3251, mix.loss: 0.0399, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:08:05,454 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 2:01:09, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0481, src.decode.acc_seg: 98.3006, src.loss: 0.0641, mix.decode.loss_seg: 0.0409, mix.decode.acc_seg: 98.5420, mix.loss: 0.0409, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:09:09,159 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 2:00:05, time: 1.274, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0388, src.decode.acc_seg: 98.5383, src.loss: 0.0548, mix.decode.loss_seg: 0.0305, mix.decode.acc_seg: 98.7529, mix.loss: 0.0305, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:10:13,115 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 1:59:00, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0448, src.decode.acc_seg: 98.3567, src.loss: 0.0608, mix.decode.loss_seg: 0.0334, mix.decode.acc_seg: 98.4770, mix.loss: 0.0334, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:11:16,836 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 1:57:56, time: 1.274, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0453, src.decode.acc_seg: 98.2483, src.loss: 0.0613, mix.decode.loss_seg: 0.0386, mix.decode.acc_seg: 98.3797, mix.loss: 0.0386, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:12:21,098 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 1:56:52, time: 1.285, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0410, src.decode.acc_seg: 98.4545, src.loss: 0.0570, mix.decode.loss_seg: 0.0321, mix.decode.acc_seg: 98.6327, mix.loss: 0.0321, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:13:24,986 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 1:55:47, time: 1.278, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0511, src.decode.acc_seg: 98.1185, src.loss: 0.0672, mix.decode.loss_seg: 0.0372, mix.decode.acc_seg: 98.4501, mix.loss: 0.0372, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:14:29,196 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 1:54:43, time: 1.284, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0435, src.decode.acc_seg: 98.3487, src.loss: 0.0596, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.5352, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:15:33,378 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 1:53:38, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0471, src.decode.acc_seg: 98.2949, src.loss: 0.0631, mix.decode.loss_seg: 0.0345, mix.decode.acc_seg: 98.5199, mix.loss: 0.0345, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:16:37,199 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 1:52:34, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0352, src.decode.acc_seg: 98.6901, src.loss: 0.0512, mix.decode.loss_seg: 0.0252, mix.decode.acc_seg: 98.9188, mix.loss: 0.0252, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:17:41,572 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 1:51:30, time: 1.287, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0409, src.decode.acc_seg: 98.4909, src.loss: 0.0569, mix.decode.loss_seg: 0.0378, mix.decode.acc_seg: 98.4675, mix.loss: 0.0378, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:18:45,662 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 1:50:25, time: 1.282, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0452, src.decode.acc_seg: 98.3087, src.loss: 0.0612, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.5062, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:19:49,381 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 1:49:21, time: 1.274, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0461, src.decode.acc_seg: 98.3926, src.loss: 0.0621, mix.decode.loss_seg: 0.0379, mix.decode.acc_seg: 98.5002, mix.loss: 0.0379, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:20:53,630 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 1:48:17, time: 1.285, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0431, src.decode.acc_seg: 98.3629, src.loss: 0.0591, mix.decode.loss_seg: 0.0372, mix.decode.acc_seg: 98.3805, mix.loss: 0.0372, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:21:57,602 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 21:21:57,602 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 1:47:12, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0425, src.decode.acc_seg: 98.3877, src.loss: 0.0586, mix.decode.loss_seg: 0.0328, mix.decode.acc_seg: 98.6077, mix.loss: 0.0328, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:23:01,757 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 1:46:08, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0394, src.decode.acc_seg: 98.4798, src.loss: 0.0555, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6246, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:24:05,561 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 1:45:03, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0429, src.decode.acc_seg: 98.4017, src.loss: 0.0589, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5911, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:25:09,546 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 1:43:59, time: 1.280, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0449, src.decode.acc_seg: 98.2437, src.loss: 0.0609, mix.decode.loss_seg: 0.0345, mix.decode.acc_seg: 98.5020, mix.loss: 0.0345, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:26:13,773 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 1:42:55, time: 1.285, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0376, src.decode.acc_seg: 98.6443, src.loss: 0.0537, mix.decode.loss_seg: 0.0270, mix.decode.acc_seg: 98.8774, mix.loss: 0.0270, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:27:17,835 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 1:41:50, time: 1.281, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0419, src.decode.acc_seg: 98.4471, src.loss: 0.0579, mix.decode.loss_seg: 0.0319, mix.decode.acc_seg: 98.5490, mix.loss: 0.0319, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:28:22,248 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 1:40:46, time: 1.288, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0373, src.decode.acc_seg: 98.6538, src.loss: 0.0533, mix.decode.loss_seg: 0.0309, mix.decode.acc_seg: 98.7131, mix.loss: 0.0309, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:29:25,701 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 1:39:42, time: 1.269, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0348, src.decode.acc_seg: 98.6768, src.loss: 0.0508, mix.decode.loss_seg: 0.0251, mix.decode.acc_seg: 98.8937, mix.loss: 0.0251, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:30:30,253 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 1:38:37, time: 1.291, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0438, src.decode.acc_seg: 98.3353, src.loss: 0.0599, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.7316, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:31:35,899 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 1:37:33, time: 1.313, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0473, src.decode.acc_seg: 98.2407, src.loss: 0.0633, mix.decode.loss_seg: 0.0312, mix.decode.acc_seg: 98.7071, mix.loss: 0.0312, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:32:40,224 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 1:36:29, time: 1.287, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0367, src.decode.acc_seg: 98.6199, src.loss: 0.0527, mix.decode.loss_seg: 0.0292, mix.decode.acc_seg: 98.8107, mix.loss: 0.0292, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:33:44,412 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 1:35:25, time: 1.284, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0426, src.decode.acc_seg: 98.3508, src.loss: 0.0586, mix.decode.loss_seg: 0.0321, mix.decode.acc_seg: 98.5097, mix.loss: 0.0321, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:34:49,872 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 1:34:20, time: 1.309, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0352, src.decode.acc_seg: 98.6174, src.loss: 0.0512, mix.decode.loss_seg: 0.0272, mix.decode.acc_seg: 98.6900, mix.loss: 0.0272, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:35:58,135 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 1:33:16, time: 1.365, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0371, src.decode.acc_seg: 98.5411, src.loss: 0.0531, mix.decode.loss_seg: 0.0339, mix.decode.acc_seg: 98.5853, mix.loss: 0.0339, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:37:04,080 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 1:32:12, time: 1.319, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0417, src.decode.acc_seg: 98.4094, src.loss: 0.0578, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.6783, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:38:09,096 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 1:31:08, time: 1.300, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0431, src.decode.acc_seg: 98.4403, src.loss: 0.0592, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.6096, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:39:13,249 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 1:30:04, time: 1.283, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0410, src.decode.acc_seg: 98.4547, src.loss: 0.0570, mix.decode.loss_seg: 0.0333, mix.decode.acc_seg: 98.4965, mix.loss: 0.0333, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:40:17,721 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 1:28:59, time: 1.289, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0397, src.decode.acc_seg: 98.4960, src.loss: 0.0558, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.7394, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:41:22,088 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 1:27:55, time: 1.287, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0518, src.decode.acc_seg: 98.0119, src.loss: 0.0678, mix.decode.loss_seg: 0.0384, mix.decode.acc_seg: 98.3027, mix.loss: 0.0384, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:42:26,232 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 1:26:51, time: 1.283, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0438, src.decode.acc_seg: 98.3512, src.loss: 0.0598, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.6568, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.8 task/s, elapsed: 1s, ETA:  1102s[                                 ] 2/929, 1.6 task/s, elapsed: 1s, ETA:   598s[                                 ] 3/929, 2.2 task/s, elapsed: 1s, ETA:   429s[                                 ] 4/929, 2.7 task/s, elapsed: 1s, ETA:   345s[                                 ] 5/929, 3.1 task/s, elapsed: 2s, ETA:   295s[                                 ] 6/929, 3.5 task/s, elapsed: 2s, ETA:   261s[                                 ] 7/929, 3.9 task/s, elapsed: 2s, ETA:   237s[                                 ] 8/929, 4.2 task/s, elapsed: 2s, ETA:   220s[                                 ] 9/929, 4.5 task/s, elapsed: 2s, ETA:   206s[                                ] 10/929, 4.7 task/s, elapsed: 2s, ETA:   195s[                                ] 11/929, 4.9 task/s, elapsed: 2s, ETA:   186s[                                ] 12/929, 5.1 task/s, elapsed: 2s, ETA:   178s[                                ] 13/929, 5.3 task/s, elapsed: 2s, ETA:   172s[                                ] 14/929, 5.5 task/s, elapsed: 3s, ETA:   167s[                                ] 15/929, 5.6 task/s, elapsed: 3s, ETA:   163s[                                ] 16/929, 5.7 task/s, elapsed: 3s, ETA:   159s[                                ] 17/929, 5.9 task/s, elapsed: 3s, ETA:   155s[                                ] 18/929, 6.0 task/s, elapsed: 3s, ETA:   151s[                                ] 19/929, 6.1 task/s, elapsed: 3s, ETA:   148s[                                ] 20/929, 6.2 task/s, elapsed: 3s, ETA:   145s[                                ] 21/929, 6.4 task/s, elapsed: 3s, ETA:   143s[                                ] 22/929, 6.5 task/s, elapsed: 3s, ETA:   140s[                                ] 23/929, 6.6 task/s, elapsed: 4s, ETA:   138s[                                ] 24/929, 6.6 task/s, elapsed: 4s, ETA:   137s[                                ] 25/929, 6.7 task/s, elapsed: 4s, ETA:   135s[                                ] 26/929, 6.8 task/s, elapsed: 4s, ETA:   133s[                                ] 27/929, 6.9 task/s, elapsed: 4s, ETA:   131s[                                ] 28/929, 6.9 task/s, elapsed: 4s, ETA:   130s[                                ] 29/929, 7.0 task/s, elapsed: 4s, ETA:   128s[>                               ] 30/929, 7.1 task/s, elapsed: 4s, ETA:   127s[>                               ] 31/929, 7.1 task/s, elapsed: 4s, ETA:   126s[>                               ] 32/929, 7.2 task/s, elapsed: 4s, ETA:   125s[>                               ] 33/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 34/929, 7.3 task/s, elapsed: 5s, ETA:   123s[>                               ] 35/929, 7.3 task/s, elapsed: 5s, ETA:   122s[>                               ] 36/929, 7.4 task/s, elapsed: 5s, ETA:   121s[>                               ] 37/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 38/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 39/929, 7.4 task/s, elapsed: 5s, ETA:   120s[>                               ] 40/929, 7.5 task/s, elapsed: 5s, ETA:   119s[>                               ] 41/929, 7.5 task/s, elapsed: 5s, ETA:   118s[>                               ] 42/929, 7.5 task/s, elapsed: 6s, ETA:   118s[>                               ] 43/929, 7.5 task/s, elapsed: 6s, ETA:   118s[>                               ] 44/929, 7.6 task/s, elapsed: 6s, ETA:   117s[>                               ] 45/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 46/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 47/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 48/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 49/929, 7.7 task/s, elapsed: 6s, ETA:   115s[>                               ] 50/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 51/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 52/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 53/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 54/929, 7.7 task/s, elapsed: 7s, ETA:   113s[>                               ] 55/929, 7.7 task/s, elapsed: 7s, ETA:   113s[>                               ] 56/929, 7.8 task/s, elapsed: 7s, ETA:   112s[>                               ] 57/929, 7.8 task/s, elapsed: 7s, ETA:   112s[>                               ] 58/929, 7.8 task/s, elapsed: 7s, ETA:   111s[>>                              ] 59/929, 7.8 task/s, elapsed: 8s, ETA:   111s[>>                              ] 60/929, 7.9 task/s, elapsed: 8s, ETA:   111s[>>                              ] 61/929, 7.9 task/s, elapsed: 8s, ETA:   110s[>>                              ] 62/929, 7.9 task/s, elapsed: 8s, ETA:   110s[>>                              ] 63/929, 7.9 task/s, elapsed: 8s, ETA:   109s[>>                              ] 64/929, 7.9 task/s, elapsed: 8s, ETA:   109s[>>                              ] 65/929, 7.9 task/s, elapsed: 8s, ETA:   109s[>>                              ] 66/929, 8.0 task/s, elapsed: 8s, ETA:   108s[>>                              ] 67/929, 8.0 task/s, elapsed: 8s, ETA:   108s[>>                              ] 68/929, 8.0 task/s, elapsed: 9s, ETA:   108s[>>                              ] 69/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 70/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 71/929, 8.0 task/s, elapsed: 9s, ETA:   107s[>>                              ] 72/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 73/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 74/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 75/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 76/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 77/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                             ] 78/929, 8.1 task/s, elapsed: 10s, ETA:   104s[>>                             ] 79/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 80/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 81/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 82/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 83/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 84/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 85/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 86/929, 8.2 task/s, elapsed: 10s, ETA:   102s[>>                             ] 87/929, 8.2 task/s, elapsed: 11s, ETA:   102s[>>                             ] 88/929, 8.3 task/s, elapsed: 11s, ETA:   102s[>>                             ] 89/929, 8.3 task/s, elapsed: 11s, ETA:   102s[>>>                            ] 90/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 91/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 92/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 93/929, 8.3 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 94/929, 8.3 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 95/929, 8.3 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 96/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 97/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                            ] 98/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                            ] 99/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 100/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 101/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 102/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 103/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 104/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 105/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 106/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 107/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 108/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 109/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 110/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 111/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 112/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 113/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 114/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 115/929, 8.5 task/s, elapsed: 14s, ETA:    96s[>>>                           ] 116/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 117/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 118/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 119/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 120/929, 8.6 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 121/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 122/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 123/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>>                          ] 124/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>>                          ] 125/929, 8.6 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 126/929, 8.6 task/s, elapsed: 15s, ETA:    94s[>>>>                          ] 127/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 128/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 129/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 130/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 131/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 132/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 133/929, 8.6 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 134/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 135/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 136/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 137/929, 8.6 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 138/929, 8.6 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 139/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 140/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 141/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 142/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 143/929, 8.7 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 144/929, 8.7 task/s, elapsed: 17s, ETA:    91s[>>>>                          ] 145/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 146/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 147/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 148/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 149/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 150/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 151/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 152/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 153/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>                          ] 154/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 155/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 156/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 157/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 158/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 159/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 160/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 161/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 162/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 163/929, 8.7 task/s, elapsed: 19s, ETA:    88s[>>>>>                         ] 164/929, 8.7 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 165/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 166/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 167/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 168/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 169/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 170/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 171/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 172/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 173/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 174/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 175/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 176/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 177/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 178/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 179/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 180/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 181/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 182/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 183/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 184/929, 8.8 task/s, elapsed: 21s, ETA:    85s[>>>>>                         ] 185/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 186/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 187/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 188/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 189/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 190/929, 8.8 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 191/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 192/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 193/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 194/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 195/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 196/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 197/929, 8.8 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 198/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 199/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 200/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 201/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 202/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 203/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 204/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 205/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 206/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 207/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 208/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 209/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 210/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 211/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 212/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 213/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 214/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 215/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 216/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 217/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 218/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 219/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 220/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 221/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 222/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 223/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 224/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 225/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 226/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 227/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 228/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 229/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 230/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 231/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 232/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 233/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 234/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 235/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 236/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 237/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 239/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 240/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 241/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 242/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 243/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 244/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 245/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 246/929, 8.9 task/s, elapsed: 28s, ETA:    77s[>>>>>>>                       ] 247/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 248/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 249/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 250/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 251/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 252/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 254/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 255/929, 8.9 task/s, elapsed: 29s, ETA:    76s[>>>>>>>>                      ] 256/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 257/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 258/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 259/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 260/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 261/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 262/929, 8.9 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 263/929, 8.9 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 264/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 265/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 266/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 267/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 268/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 269/929, 8.9 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 270/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 271/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 272/929, 8.9 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 273/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 274/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 275/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 276/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 277/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 278/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 279/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>>                     ] 280/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 281/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 282/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 283/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 284/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 285/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 286/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 287/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 288/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 289/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 290/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 292/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 293/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 294/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 295/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 296/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 297/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 298/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 299/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 300/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 301/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 302/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 303/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 304/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 305/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 306/929, 9.0 task/s, elapsed: 34s, ETA:    70s[>>>>>>>>>                     ] 307/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 308/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 309/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 310/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 311/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 312/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 313/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 314/929, 9.0 task/s, elapsed: 35s, ETA:    69s[>>>>>>>>>>                    ] 315/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 316/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 317/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 318/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 319/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 320/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 321/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 322/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 323/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 324/929, 9.0 task/s, elapsed: 36s, ETA:    68s[>>>>>>>>>>                    ] 325/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 326/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 327/929, 9.0 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 328/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 329/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 330/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 331/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 332/929, 9.0 task/s, elapsed: 37s, ETA:    67s[>>>>>>>>>>                    ] 333/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 334/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 335/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 336/929, 9.0 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 337/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 338/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 339/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>                    ] 340/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 341/929, 9.0 task/s, elapsed: 38s, ETA:    66s[>>>>>>>>>>>                   ] 342/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 343/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 344/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 345/929, 9.0 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 346/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 347/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 348/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 349/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 350/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 351/929, 9.0 task/s, elapsed: 39s, ETA:    65s[>>>>>>>>>>>                   ] 352/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 353/929, 9.0 task/s, elapsed: 39s, ETA:    64s[>>>>>>>>>>>                   ] 354/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 355/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 356/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 357/929, 9.0 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 358/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 359/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 360/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 361/929, 8.9 task/s, elapsed: 40s, ETA:    64s[>>>>>>>>>>>                   ] 362/929, 8.9 task/s, elapsed: 41s, ETA:    64s[>>>>>>>>>>>                   ] 363/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 364/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 365/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 366/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 367/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 368/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 369/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 370/929, 8.9 task/s, elapsed: 41s, ETA:    63s[>>>>>>>>>>>                   ] 371/929, 8.9 task/s, elapsed: 42s, ETA:    63s[>>>>>>>>>>>>                  ] 372/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 373/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 374/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 375/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 376/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 377/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 378/929, 8.9 task/s, elapsed: 42s, ETA:    62s[>>>>>>>>>>>>                  ] 379/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 380/929, 8.9 task/s, elapsed: 43s, ETA:    62s[>>>>>>>>>>>>                  ] 381/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 382/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 383/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 384/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 385/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 386/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 387/929, 8.9 task/s, elapsed: 43s, ETA:    61s[>>>>>>>>>>>>                  ] 388/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 389/929, 8.9 task/s, elapsed: 44s, ETA:    61s[>>>>>>>>>>>>                  ] 390/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 391/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 392/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 393/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 394/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 395/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 396/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 397/929, 8.9 task/s, elapsed: 44s, ETA:    60s[>>>>>>>>>>>>                  ] 398/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 399/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 400/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 401/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>                  ] 402/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 403/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 404/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 405/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 406/929, 8.9 task/s, elapsed: 45s, ETA:    59s[>>>>>>>>>>>>>                 ] 407/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 408/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 409/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 410/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 411/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 412/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 413/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 414/929, 8.9 task/s, elapsed: 46s, ETA:    58s[>>>>>>>>>>>>>                 ] 415/929, 8.9 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 416/929, 8.9 task/s, elapsed: 46s, ETA:    57s[>>>>>>>>>>>>>                 ] 417/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 418/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 419/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 420/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 421/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 422/929, 9.0 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 423/929, 8.9 task/s, elapsed: 47s, ETA:    57s[>>>>>>>>>>>>>                 ] 424/929, 8.9 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 425/929, 9.0 task/s, elapsed: 47s, ETA:    56s[>>>>>>>>>>>>>                 ] 426/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 427/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 428/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 429/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 430/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 431/929, 9.0 task/s, elapsed: 48s, ETA:    56s[>>>>>>>>>>>>>                 ] 432/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>                 ] 433/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 434/929, 9.0 task/s, elapsed: 48s, ETA:    55s[>>>>>>>>>>>>>>                ] 435/929, 9.0 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 436/929, 9.0 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 437/929, 9.0 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 438/929, 9.0 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 439/929, 9.0 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 440/929, 9.0 task/s, elapsed: 49s, ETA:    55s[>>>>>>>>>>>>>>                ] 441/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 442/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 443/929, 9.0 task/s, elapsed: 49s, ETA:    54s[>>>>>>>>>>>>>>                ] 444/929, 9.0 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 445/929, 9.0 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 446/929, 9.0 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 447/929, 9.0 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 448/929, 9.0 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 449/929, 9.0 task/s, elapsed: 50s, ETA:    54s[>>>>>>>>>>>>>>                ] 450/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 451/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 452/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 453/929, 9.0 task/s, elapsed: 50s, ETA:    53s[>>>>>>>>>>>>>>                ] 454/929, 9.0 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 455/929, 9.0 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 456/929, 9.0 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 457/929, 9.0 task/s, elapsed: 51s, ETA:    53s[>>>>>>>>>>>>>>                ] 458/929, 9.0 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 459/929, 9.0 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 460/929, 9.0 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 461/929, 9.0 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 462/929, 9.0 task/s, elapsed: 51s, ETA:    52s[>>>>>>>>>>>>>>                ] 463/929, 9.0 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>                ] 464/929, 9.0 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 465/929, 9.0 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 466/929, 9.0 task/s, elapsed: 52s, ETA:    52s[>>>>>>>>>>>>>>>               ] 467/929, 9.0 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 468/929, 9.0 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 469/929, 9.0 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 470/929, 9.0 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 471/929, 9.0 task/s, elapsed: 52s, ETA:    51s[>>>>>>>>>>>>>>>               ] 472/929, 9.0 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 473/929, 9.0 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 474/929, 9.0 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 475/929, 9.0 task/s, elapsed: 53s, ETA:    51s[>>>>>>>>>>>>>>>               ] 476/929, 9.0 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 477/929, 9.0 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 478/929, 9.0 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 479/929, 9.0 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 480/929, 9.0 task/s, elapsed: 53s, ETA:    50s[>>>>>>>>>>>>>>>               ] 481/929, 9.0 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 482/929, 9.0 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 483/929, 9.0 task/s, elapsed: 54s, ETA:    50s[>>>>>>>>>>>>>>>               ] 484/929, 9.0 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 485/929, 9.0 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 486/929, 9.0 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 487/929, 9.0 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 488/929, 9.0 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 489/929, 9.0 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 490/929, 9.0 task/s, elapsed: 54s, ETA:    49s[>>>>>>>>>>>>>>>               ] 491/929, 9.0 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 492/929, 9.0 task/s, elapsed: 55s, ETA:    49s[>>>>>>>>>>>>>>>               ] 493/929, 9.0 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>               ] 494/929, 9.0 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>               ] 495/929, 9.0 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 496/929, 9.0 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 497/929, 9.0 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 498/929, 9.0 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 499/929, 9.0 task/s, elapsed: 55s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 500/929, 9.0 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 501/929, 9.0 task/s, elapsed: 56s, ETA:    48s[>>>>>>>>>>>>>>>>              ] 502/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 503/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 504/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 505/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 506/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 507/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 508/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 509/929, 9.0 task/s, elapsed: 56s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 510/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 511/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 512/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 513/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 514/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 515/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 516/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 517/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 518/929, 9.0 task/s, elapsed: 57s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 519/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 520/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 521/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 522/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 523/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 524/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 525/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 526/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.0 task/s, elapsed: 58s, ETA:    45s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.0 task/s, elapsed: 59s, ETA:    44s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.0 task/s, elapsed: 60s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.0 task/s, elapsed: 60s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.0 task/s, elapsed: 61s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.0 task/s, elapsed: 61s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.0 task/s, elapsed: 62s, ETA:    41s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.0 task/s, elapsed: 62s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.0 task/s, elapsed: 63s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.0 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.0 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.0 task/s, elapsed: 63s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.0 task/s, elapsed: 64s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.0 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.0 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.0 task/s, elapsed: 64s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.0 task/s, elapsed: 65s, ETA:    38s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.0 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.0 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.0 task/s, elapsed: 65s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.0 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.1 task/s, elapsed: 66s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.1 task/s, elapsed: 66s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.1 task/s, elapsed: 67s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.1 task/s, elapsed: 67s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.1 task/s, elapsed: 68s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.1 task/s, elapsed: 68s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.1 task/s, elapsed: 69s, ETA:    34s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.1 task/s, elapsed: 69s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.1 task/s, elapsed: 70s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.1 task/s, elapsed: 70s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.1 task/s, elapsed: 71s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.1 task/s, elapsed: 71s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.1 task/s, elapsed: 72s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.1 task/s, elapsed: 72s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.1 task/s, elapsed: 73s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.1 task/s, elapsed: 73s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.1 task/s, elapsed: 74s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.1 task/s, elapsed: 74s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.1 task/s, elapsed: 75s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.1 task/s, elapsed: 75s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.1 task/s, elapsed: 76s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.1 task/s, elapsed: 76s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.1 task/s, elapsed: 77s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.1 task/s, elapsed: 77s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.1 task/s, elapsed: 78s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.1 task/s, elapsed: 78s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.1 task/s, elapsed: 79s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.1 task/s, elapsed: 79s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.1 task/s, elapsed: 80s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.1 task/s, elapsed: 80s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.1 task/s, elapsed: 81s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.1 task/s, elapsed: 81s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.1 task/s, elapsed: 82s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.1 task/s, elapsed: 82s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.1 task/s, elapsed: 83s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.1 task/s, elapsed: 83s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.1 task/s, elapsed: 84s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.1 task/s, elapsed: 84s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.1 task/s, elapsed: 85s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.1 task/s, elapsed: 85s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.1 task/s, elapsed: 86s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.1 task/s, elapsed: 87s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.1 task/s, elapsed: 88s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.1 task/s, elapsed: 89s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.1 task/s, elapsed: 89s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.1 task/s, elapsed: 90s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.1 task/s, elapsed: 90s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.1 task/s, elapsed: 91s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.1 task/s, elapsed: 92s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.1 task/s, elapsed: 92s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.1 task/s, elapsed: 93s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.1 task/s, elapsed: 93s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.1 task/s, elapsed: 94s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.1 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.1 task/s, elapsed: 94s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.1 task/s, elapsed: 95s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.1 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.1 task/s, elapsed: 95s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.1 task/s, elapsed: 96s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.1 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.1 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.1 task/s, elapsed: 96s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.1 task/s, elapsed: 97s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.1 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.1 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.1 task/s, elapsed: 97s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.1 task/s, elapsed: 98s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.1 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.1 task/s, elapsed: 98s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.1 task/s, elapsed: 99s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.1 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.1 task/s, elapsed: 99s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.1 task/s, elapsed: 100s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.1 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.1 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.1 task/s, elapsed: 100s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.1 task/s, elapsed: 101s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.1 task/s, elapsed: 101s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.1 task/s, elapsed: 101s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.1 task/s, elapsed: 101s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.1 task/s, elapsed: 102s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.1 task/s, elapsed: 102s, ETA:     0s2022-10-10 21:46:07,368 - mmseg - INFO - per class results:2022-10-10 21:46:07,369 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.15 | 95.83 || rigid_plastic | 34.42 | 38.96 ||   cardboard   | 58.53 | 74.98 ||     metal     | 32.17 | 39.74 ||  soft_plastic | 64.97 | 73.64 |+---------------+-------+-------+2022-10-10 21:46:07,369 - mmseg - INFO - Summary:2022-10-10 21:46:07,369 - mmseg - INFO - +------+-------+-------+| aAcc |  mIoU |  mAcc |+------+-------+-------+| 91.7 | 56.25 | 64.63 |+------+-------+-------+/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:46:07,380 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 21:46:07,380 - mmseg - INFO - Iter [929/40000]	lr: 6.002e-06, eta: 1:25:46, time: 1.278, data_time: 0.015, memory: 67494, aAcc: 0.9170, mIoU: 0.5625, mAcc: 0.6463, IoU.background: 0.9115, IoU.rigid_plastic: 0.3442, IoU.cardboard: 0.5853, IoU.metal: 0.3217, IoU.soft_plastic: 0.6497, Acc.background: 0.9583, Acc.rigid_plastic: 0.3896, Acc.cardboard: 0.7498, Acc.metal: 0.3974, Acc.soft_plastic: 0.7364, src.decode.loss_seg: 0.0422, src.decode.acc_seg: 98.3879, src.loss: 0.0582, mix.decode.loss_seg: 0.0357, mix.decode.acc_seg: 98.4517, mix.loss: 0.0357, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:47:10,687 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 1:24:59, time: 4.411, data_time: 3.159, memory: 67494, src.decode.loss_seg: 0.0428, src.decode.acc_seg: 98.3947, src.loss: 0.0589, mix.decode.loss_seg: 0.0349, mix.decode.acc_seg: 98.5273, mix.loss: 0.0349, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:48:15,412 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 1:23:55, time: 1.294, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0385, src.decode.acc_seg: 98.5384, src.loss: 0.0545, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.6832, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:49:19,495 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 1:22:50, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0383, src.decode.acc_seg: 98.5529, src.loss: 0.0543, mix.decode.loss_seg: 0.0338, mix.decode.acc_seg: 98.5362, mix.loss: 0.0338, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:50:23,371 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 1:21:45, time: 1.278, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0371, src.decode.acc_seg: 98.6166, src.loss: 0.0531, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.7985, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:51:26,931 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 1:20:41, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0376, src.decode.acc_seg: 98.6008, src.loss: 0.0536, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.6938, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:52:31,205 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 1:19:36, time: 1.286, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0359, src.decode.acc_seg: 98.6517, src.loss: 0.0520, mix.decode.loss_seg: 0.0298, mix.decode.acc_seg: 98.6491, mix.loss: 0.0298, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:53:36,343 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 1:18:32, time: 1.303, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0336, src.decode.acc_seg: 98.6756, src.loss: 0.0496, mix.decode.loss_seg: 0.0255, mix.decode.acc_seg: 98.8548, mix.loss: 0.0255, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:54:39,940 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 1:17:27, time: 1.272, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.5641, src.loss: 0.0564, mix.decode.loss_seg: 0.0366, mix.decode.acc_seg: 98.4387, mix.loss: 0.0366, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:55:43,777 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 1:16:22, time: 1.277, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.3907, src.loss: 0.0576, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.6603, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:56:48,102 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 1:15:18, time: 1.286, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0406, src.decode.acc_seg: 98.4662, src.loss: 0.0567, mix.decode.loss_seg: 0.0325, mix.decode.acc_seg: 98.6081, mix.loss: 0.0325, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:57:52,123 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 1:14:13, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0432, src.decode.acc_seg: 98.3485, src.loss: 0.0592, mix.decode.loss_seg: 0.0322, mix.decode.acc_seg: 98.6091, mix.loss: 0.0322, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 21:58:56,312 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 1:13:09, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0434, src.decode.acc_seg: 98.3446, src.loss: 0.0594, mix.decode.loss_seg: 0.0319, mix.decode.acc_seg: 98.6780, mix.loss: 0.0319, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:00:00,309 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 1:12:04, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0389, src.decode.acc_seg: 98.5257, src.loss: 0.0550, mix.decode.loss_seg: 0.0310, mix.decode.acc_seg: 98.6738, mix.loss: 0.0310, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:01:04,101 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 1:10:59, time: 1.276, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0353, src.decode.acc_seg: 98.6448, src.loss: 0.0513, mix.decode.loss_seg: 0.0311, mix.decode.acc_seg: 98.6965, mix.loss: 0.0311, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:02:07,763 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 1:09:55, time: 1.273, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0362, src.decode.acc_seg: 98.6021, src.loss: 0.0523, mix.decode.loss_seg: 0.0268, mix.decode.acc_seg: 98.8287, mix.loss: 0.0268, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:03:11,532 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 1:08:50, time: 1.275, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0406, src.decode.acc_seg: 98.4599, src.loss: 0.0566, mix.decode.loss_seg: 0.0371, mix.decode.acc_seg: 98.3712, mix.loss: 0.0371, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:04:15,517 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 1:07:46, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0368, src.decode.acc_seg: 98.5944, src.loss: 0.0528, mix.decode.loss_seg: 0.0301, mix.decode.acc_seg: 98.7719, mix.loss: 0.0301, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:05:19,717 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 1:06:41, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0384, src.decode.acc_seg: 98.5229, src.loss: 0.0544, mix.decode.loss_seg: 0.0274, mix.decode.acc_seg: 98.7890, mix.loss: 0.0274, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:06:23,527 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 1:05:36, time: 1.276, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0394, src.decode.acc_seg: 98.4597, src.loss: 0.0554, mix.decode.loss_seg: 0.0301, mix.decode.acc_seg: 98.6631, mix.loss: 0.0301, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:07:27,544 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 22:07:27,544 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 1:04:32, time: 1.280, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0399, src.decode.acc_seg: 98.4328, src.loss: 0.0560, mix.decode.loss_seg: 0.0286, mix.decode.acc_seg: 98.7330, mix.loss: 0.0286, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:08:32,111 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 1:03:27, time: 1.291, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0395, src.decode.acc_seg: 98.4837, src.loss: 0.0555, mix.decode.loss_seg: 0.0287, mix.decode.acc_seg: 98.7182, mix.loss: 0.0287, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:09:36,058 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 1:02:23, time: 1.279, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0469, src.decode.acc_seg: 98.3410, src.loss: 0.0630, mix.decode.loss_seg: 0.0402, mix.decode.acc_seg: 98.3438, mix.loss: 0.0402, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:10:39,589 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 1:01:18, time: 1.271, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0396, src.decode.acc_seg: 98.5158, src.loss: 0.0556, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.7638, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:11:43,585 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 1:00:14, time: 1.280, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0408, src.decode.acc_seg: 98.4455, src.loss: 0.0568, mix.decode.loss_seg: 0.0342, mix.decode.acc_seg: 98.5967, mix.loss: 0.0342, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:12:47,785 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:59:09, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0340, src.decode.acc_seg: 98.6901, src.loss: 0.0500, mix.decode.loss_seg: 0.0297, mix.decode.acc_seg: 98.7332, mix.loss: 0.0297, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:13:51,634 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:58:04, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0431, src.decode.acc_seg: 98.3522, src.loss: 0.0591, mix.decode.loss_seg: 0.0337, mix.decode.acc_seg: 98.4567, mix.loss: 0.0337, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:14:55,636 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:57:00, time: 1.280, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0403, src.decode.acc_seg: 98.4717, src.loss: 0.0564, mix.decode.loss_seg: 0.0265, mix.decode.acc_seg: 98.8193, mix.loss: 0.0265, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:15:59,748 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:55:55, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0423, src.decode.acc_seg: 98.3950, src.loss: 0.0584, mix.decode.loss_seg: 0.0309, mix.decode.acc_seg: 98.7128, mix.loss: 0.0309, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:17:04,416 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:54:51, time: 1.293, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0413, src.decode.acc_seg: 98.4998, src.loss: 0.0574, mix.decode.loss_seg: 0.0301, mix.decode.acc_seg: 98.6863, mix.loss: 0.0301, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:18:08,474 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:53:46, time: 1.281, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0367, src.decode.acc_seg: 98.6114, src.loss: 0.0528, mix.decode.loss_seg: 0.0303, mix.decode.acc_seg: 98.7737, mix.loss: 0.0303, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:19:12,493 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:52:42, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0383, src.decode.acc_seg: 98.5976, src.loss: 0.0543, mix.decode.loss_seg: 0.0291, mix.decode.acc_seg: 98.6921, mix.loss: 0.0291, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:20:16,787 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:51:37, time: 1.286, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0392, src.decode.acc_seg: 98.4825, src.loss: 0.0553, mix.decode.loss_seg: 0.0308, mix.decode.acc_seg: 98.6839, mix.loss: 0.0308, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:21:21,188 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:50:32, time: 1.288, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0373, src.decode.acc_seg: 98.5770, src.loss: 0.0533, mix.decode.loss_seg: 0.0285, mix.decode.acc_seg: 98.8171, mix.loss: 0.0285, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:22:25,597 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:49:28, time: 1.288, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0433, src.decode.acc_seg: 98.3574, src.loss: 0.0594, mix.decode.loss_seg: 0.0295, mix.decode.acc_seg: 98.7877, mix.loss: 0.0295, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:23:29,466 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:48:23, time: 1.277, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0400, src.decode.acc_seg: 98.5203, src.loss: 0.0560, mix.decode.loss_seg: 0.0318, mix.decode.acc_seg: 98.7388, mix.loss: 0.0318, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:24:33,753 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:47:19, time: 1.286, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0369, src.decode.acc_seg: 98.5852, src.loss: 0.0529, mix.decode.loss_seg: 0.0295, mix.decode.acc_seg: 98.8176, mix.loss: 0.0295, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:25:37,544 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:46:14, time: 1.276, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0389, src.decode.acc_seg: 98.4634, src.loss: 0.0549, mix.decode.loss_seg: 0.0310, mix.decode.acc_seg: 98.6505, mix.loss: 0.0310, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:26:41,260 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:45:10, time: 1.274, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0375, src.decode.acc_seg: 98.6205, src.loss: 0.0535, mix.decode.loss_seg: 0.0293, mix.decode.acc_seg: 98.7241, mix.loss: 0.0293, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:27:45,815 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:44:05, time: 1.291, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0367, src.decode.acc_seg: 98.6464, src.loss: 0.0528, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.5893, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:28:50,684 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 22:28:50,684 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:43:01, time: 1.297, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0420, src.decode.acc_seg: 98.4304, src.loss: 0.0580, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.8123, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:29:54,359 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:41:56, time: 1.273, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0385, src.decode.acc_seg: 98.5192, src.loss: 0.0545, mix.decode.loss_seg: 0.0361, mix.decode.acc_seg: 98.5551, mix.loss: 0.0361, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:30:58,852 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:40:52, time: 1.290, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0389, src.decode.acc_seg: 98.5211, src.loss: 0.0549, mix.decode.loss_seg: 0.0297, mix.decode.acc_seg: 98.6529, mix.loss: 0.0297, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:32:03,073 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:39:47, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0384, src.decode.acc_seg: 98.5287, src.loss: 0.0544, mix.decode.loss_seg: 0.0323, mix.decode.acc_seg: 98.6938, mix.loss: 0.0323, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:33:06,704 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:38:42, time: 1.273, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0382, src.decode.acc_seg: 98.5793, src.loss: 0.0542, mix.decode.loss_seg: 0.0299, mix.decode.acc_seg: 98.6815, mix.loss: 0.0299, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:34:10,959 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:37:38, time: 1.285, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0371, src.decode.acc_seg: 98.6058, src.loss: 0.0531, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6318, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:35:15,343 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:36:33, time: 1.288, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0381, src.decode.acc_seg: 98.5309, src.loss: 0.0541, mix.decode.loss_seg: 0.0280, mix.decode.acc_seg: 98.8083, mix.loss: 0.0280, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:36:19,540 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:35:29, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0391, src.decode.acc_seg: 98.5020, src.loss: 0.0551, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.6754, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:37:23,711 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:34:24, time: 1.283, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0428, src.decode.acc_seg: 98.4379, src.loss: 0.0588, mix.decode.loss_seg: 0.0376, mix.decode.acc_seg: 98.3813, mix.loss: 0.0376, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:38:27,747 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:33:20, time: 1.281, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0427, src.decode.acc_seg: 98.3405, src.loss: 0.0587, mix.decode.loss_seg: 0.0306, mix.decode.acc_seg: 98.7285, mix.loss: 0.0306, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:39:32,104 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:32:15, time: 1.287, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0381, src.decode.acc_seg: 98.5728, src.loss: 0.0541, mix.decode.loss_seg: 0.0343, mix.decode.acc_seg: 98.5501, mix.loss: 0.0343, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:40:36,376 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:31:11, time: 1.285, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0413, src.decode.acc_seg: 98.4730, src.loss: 0.0573, mix.decode.loss_seg: 0.0309, mix.decode.acc_seg: 98.7055, mix.loss: 0.0309, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:41:40,262 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:30:06, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0427, src.decode.acc_seg: 98.4642, src.loss: 0.0587, mix.decode.loss_seg: 0.0314, mix.decode.acc_seg: 98.8012, mix.loss: 0.0314, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:42:44,700 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:29:02, time: 1.289, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0345, src.decode.acc_seg: 98.7012, src.loss: 0.0505, mix.decode.loss_seg: 0.0279, mix.decode.acc_seg: 98.7367, mix.loss: 0.0279, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:43:48,605 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:27:57, time: 1.278, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0373, src.decode.acc_seg: 98.5324, src.loss: 0.0533, mix.decode.loss_seg: 0.0315, mix.decode.acc_seg: 98.7061, mix.loss: 0.0315, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:44:52,526 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:26:53, time: 1.278, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0451, src.decode.acc_seg: 98.3359, src.loss: 0.0612, mix.decode.loss_seg: 0.0341, mix.decode.acc_seg: 98.5735, mix.loss: 0.0341, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:45:56,292 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:25:48, time: 1.275, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0387, src.decode.acc_seg: 98.5153, src.loss: 0.0547, mix.decode.loss_seg: 0.0382, mix.decode.acc_seg: 98.3093, mix.loss: 0.0382, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:47:00,080 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:24:43, time: 1.276, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0353, src.decode.acc_seg: 98.6280, src.loss: 0.0513, mix.decode.loss_seg: 0.0283, mix.decode.acc_seg: 98.7243, mix.loss: 0.0283, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:48:04,260 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:23:39, time: 1.284, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0450, src.decode.acc_seg: 98.3672, src.loss: 0.0610, mix.decode.loss_seg: 0.0319, mix.decode.acc_seg: 98.6191, mix.loss: 0.0319, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:49:09,537 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:22:34, time: 1.306, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0377, src.decode.acc_seg: 98.5117, src.loss: 0.0538, mix.decode.loss_seg: 0.0285, mix.decode.acc_seg: 98.6137, mix.loss: 0.0285, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:50:13,938 - mmseg - INFO - Exp name: 221010_0851_daformer_sepaspp_proj_mitb5_dacs_sepico_DistCL-reg-w1e-05-start-iter3000-tau100.0-l[0, 1, 2, 3]-w0.01_cpl_self_adamw_6e-05_pmT_poly10warm_1x2_40k_zerov12zerov2_seed65535_183e42022-10-10 22:50:13,938 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:21:30, time: 1.288, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0397, src.decode.acc_seg: 98.5586, src.loss: 0.0557, mix.decode.loss_seg: 0.0345, mix.decode.acc_seg: 98.5304, mix.loss: 0.0345, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:51:18,591 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:20:25, time: 1.293, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0365, src.decode.acc_seg: 98.6338, src.loss: 0.0525, mix.decode.loss_seg: 0.0284, mix.decode.acc_seg: 98.8250, mix.loss: 0.0284, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:52:23,141 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:19:21, time: 1.291, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0351, src.decode.acc_seg: 98.6786, src.loss: 0.0511, mix.decode.loss_seg: 0.0275, mix.decode.acc_seg: 98.8848, mix.loss: 0.0275, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:53:27,146 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:18:16, time: 1.280, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0490, src.decode.acc_seg: 98.1999, src.loss: 0.0650, mix.decode.loss_seg: 0.0391, mix.decode.acc_seg: 98.5389, mix.loss: 0.0391, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:54:31,507 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:17:12, time: 1.287, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0393, src.decode.acc_seg: 98.4959, src.loss: 0.0553, mix.decode.loss_seg: 0.0290, mix.decode.acc_seg: 98.7685, mix.loss: 0.0290, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:55:35,583 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:16:07, time: 1.281, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0354, src.decode.acc_seg: 98.6597, src.loss: 0.0514, mix.decode.loss_seg: 0.0278, mix.decode.acc_seg: 98.8758, mix.loss: 0.0278, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:56:39,785 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:15:03, time: 1.284, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0430, src.decode.acc_seg: 98.3315, src.loss: 0.0590, mix.decode.loss_seg: 0.0310, mix.decode.acc_seg: 98.6818, mix.loss: 0.0310, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:57:45,169 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:13:58, time: 1.308, data_time: 0.016, memory: 67494, src.decode.loss_seg: 0.0404, src.decode.acc_seg: 98.5664, src.loss: 0.0565, mix.decode.loss_seg: 0.0298, mix.decode.acc_seg: 98.7448, mix.loss: 0.0298, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:58:48,522 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:12:54, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0379, src.decode.acc_seg: 98.5161, src.loss: 0.0539, mix.decode.loss_seg: 0.0293, mix.decode.acc_seg: 98.7520, mix.loss: 0.0293, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 22:59:51,882 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:11:49, time: 1.267, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0391, src.decode.acc_seg: 98.5422, src.loss: 0.0551, mix.decode.loss_seg: 0.0355, mix.decode.acc_seg: 98.5274, mix.loss: 0.0355, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:00:55,979 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:10:45, time: 1.282, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0383, src.decode.acc_seg: 98.5767, src.loss: 0.0543, mix.decode.loss_seg: 0.0340, mix.decode.acc_seg: 98.6138, mix.loss: 0.0340, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:02:02,757 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:09:40, time: 1.336, data_time: 0.017, memory: 67494, src.decode.loss_seg: 0.0361, src.decode.acc_seg: 98.6256, src.loss: 0.0522, mix.decode.loss_seg: 0.0249, mix.decode.acc_seg: 98.9024, mix.loss: 0.0249, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:03:11,976 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:08:36, time: 1.384, data_time: 0.018, memory: 67494, src.decode.loss_seg: 0.0366, src.decode.acc_seg: 98.6464, src.loss: 0.0526, mix.decode.loss_seg: 0.0304, mix.decode.acc_seg: 98.6997, mix.loss: 0.0304, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:04:15,567 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:07:31, time: 1.272, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0374, src.decode.acc_seg: 98.5529, src.loss: 0.0534, mix.decode.loss_seg: 0.0281, mix.decode.acc_seg: 98.7886, mix.loss: 0.0281, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:05:18,007 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:06:27, time: 1.249, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0394, src.decode.acc_seg: 98.4710, src.loss: 0.0555, mix.decode.loss_seg: 0.0276, mix.decode.acc_seg: 98.7967, mix.loss: 0.0276, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:06:20,734 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:05:22, time: 1.255, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0368, src.decode.acc_seg: 98.6082, src.loss: 0.0528, mix.decode.loss_seg: 0.0294, mix.decode.acc_seg: 98.7948, mix.loss: 0.0294, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:07:23,520 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:04:18, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0379, src.decode.acc_seg: 98.5894, src.loss: 0.0539, mix.decode.loss_seg: 0.0321, mix.decode.acc_seg: 98.6839, mix.loss: 0.0321, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:08:26,811 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:03:13, time: 1.266, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0416, src.decode.acc_seg: 98.4437, src.loss: 0.0576, mix.decode.loss_seg: 0.0320, mix.decode.acc_seg: 98.6823, mix.loss: 0.0320, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:09:29,633 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:02:09, time: 1.256, data_time: 0.014, memory: 67494, src.decode.loss_seg: 0.0456, src.decode.acc_seg: 98.4940, src.loss: 0.0616, mix.decode.loss_seg: 0.0377, mix.decode.acc_seg: 98.6104, mix.loss: 0.0377, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160/mnt/data/bit/miniconda3/envs/sepico/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],2022-10-10 23:10:32,576 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:01:04, time: 1.259, data_time: 0.015, memory: 67494, src.decode.loss_seg: 0.0345, src.decode.acc_seg: 98.6472, src.loss: 0.0506, mix.decode.loss_seg: 0.0271, mix.decode.acc_seg: 98.8475, mix.loss: 0.0271, src.aux.loss_cl: 0.0160, tgt.aux.loss_cl: 0.0160, tgt.loss: 0.0160[                                                  ] 0/929, elapsed: 0s, ETA:[                                 ] 1/929, 0.7 task/s, elapsed: 1s, ETA:  1269s[                                 ] 2/929, 1.4 task/s, elapsed: 1s, ETA:   684s[                                 ] 3/929, 1.9 task/s, elapsed: 2s, ETA:   489s[                                 ] 4/929, 2.4 task/s, elapsed: 2s, ETA:   391s[                                 ] 5/929, 2.8 task/s, elapsed: 2s, ETA:   332s[                                 ] 6/929, 3.1 task/s, elapsed: 2s, ETA:   296s[                                 ] 7/929, 3.4 task/s, elapsed: 2s, ETA:   268s[                                 ] 8/929, 3.7 task/s, elapsed: 2s, ETA:   246s[                                 ] 9/929, 4.0 task/s, elapsed: 2s, ETA:   229s[                                ] 10/929, 4.2 task/s, elapsed: 2s, ETA:   218s[                                ] 11/929, 4.4 task/s, elapsed: 2s, ETA:   206s[                                ] 12/929, 4.7 task/s, elapsed: 3s, ETA:   197s[                                ] 13/929, 4.8 task/s, elapsed: 3s, ETA:   189s[                                ] 14/929, 5.0 task/s, elapsed: 3s, ETA:   184s[                                ] 15/929, 5.1 task/s, elapsed: 3s, ETA:   178s[                                ] 16/929, 5.3 task/s, elapsed: 3s, ETA:   173s[                                ] 17/929, 5.4 task/s, elapsed: 3s, ETA:   168s[                                ] 18/929, 5.6 task/s, elapsed: 3s, ETA:   164s[                                ] 19/929, 5.7 task/s, elapsed: 3s, ETA:   160s[                                ] 20/929, 5.8 task/s, elapsed: 3s, ETA:   157s[                                ] 21/929, 5.9 task/s, elapsed: 4s, ETA:   154s[                                ] 22/929, 6.0 task/s, elapsed: 4s, ETA:   151s[                                ] 23/929, 6.1 task/s, elapsed: 4s, ETA:   149s[                                ] 24/929, 6.2 task/s, elapsed: 4s, ETA:   146s[                                ] 25/929, 6.3 task/s, elapsed: 4s, ETA:   144s[                                ] 26/929, 6.4 task/s, elapsed: 4s, ETA:   142s[                                ] 27/929, 6.4 task/s, elapsed: 4s, ETA:   140s[                                ] 28/929, 6.5 task/s, elapsed: 4s, ETA:   138s[                                ] 29/929, 6.6 task/s, elapsed: 4s, ETA:   136s[>                               ] 30/929, 6.7 task/s, elapsed: 5s, ETA:   135s[>                               ] 31/929, 6.7 task/s, elapsed: 5s, ETA:   133s[>                               ] 32/929, 6.8 task/s, elapsed: 5s, ETA:   132s[>                               ] 33/929, 6.9 task/s, elapsed: 5s, ETA:   131s[>                               ] 34/929, 6.9 task/s, elapsed: 5s, ETA:   129s[>                               ] 35/929, 7.0 task/s, elapsed: 5s, ETA:   128s[>                               ] 36/929, 7.0 task/s, elapsed: 5s, ETA:   127s[>                               ] 37/929, 7.1 task/s, elapsed: 5s, ETA:   126s[>                               ] 38/929, 7.1 task/s, elapsed: 5s, ETA:   125s[>                               ] 39/929, 7.2 task/s, elapsed: 5s, ETA:   124s[>                               ] 40/929, 7.2 task/s, elapsed: 6s, ETA:   123s[>                               ] 41/929, 7.3 task/s, elapsed: 6s, ETA:   122s[>                               ] 42/929, 7.3 task/s, elapsed: 6s, ETA:   121s[>                               ] 43/929, 7.3 task/s, elapsed: 6s, ETA:   121s[>                               ] 44/929, 7.4 task/s, elapsed: 6s, ETA:   120s[>                               ] 45/929, 7.4 task/s, elapsed: 6s, ETA:   119s[>                               ] 46/929, 7.5 task/s, elapsed: 6s, ETA:   118s[>                               ] 47/929, 7.5 task/s, elapsed: 6s, ETA:   118s[>                               ] 48/929, 7.5 task/s, elapsed: 6s, ETA:   117s[>                               ] 49/929, 7.6 task/s, elapsed: 6s, ETA:   116s[>                               ] 50/929, 7.6 task/s, elapsed: 7s, ETA:   116s[>                               ] 51/929, 7.6 task/s, elapsed: 7s, ETA:   115s[>                               ] 52/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 53/929, 7.7 task/s, elapsed: 7s, ETA:   114s[>                               ] 54/929, 7.7 task/s, elapsed: 7s, ETA:   113s[>                               ] 55/929, 7.8 task/s, elapsed: 7s, ETA:   113s[>                               ] 56/929, 7.8 task/s, elapsed: 7s, ETA:   112s[>                               ] 57/929, 7.8 task/s, elapsed: 7s, ETA:   112s[>                               ] 58/929, 7.8 task/s, elapsed: 7s, ETA:   111s[>>                              ] 59/929, 7.9 task/s, elapsed: 8s, ETA:   111s[>>                              ] 60/929, 7.9 task/s, elapsed: 8s, ETA:   110s[>>                              ] 61/929, 7.9 task/s, elapsed: 8s, ETA:   110s[>>                              ] 62/929, 7.9 task/s, elapsed: 8s, ETA:   109s[>>                              ] 63/929, 8.0 task/s, elapsed: 8s, ETA:   109s[>>                              ] 64/929, 8.0 task/s, elapsed: 8s, ETA:   109s[>>                              ] 65/929, 8.0 task/s, elapsed: 8s, ETA:   108s[>>                              ] 66/929, 8.0 task/s, elapsed: 8s, ETA:   108s[>>                              ] 67/929, 8.0 task/s, elapsed: 8s, ETA:   107s[>>                              ] 68/929, 8.0 task/s, elapsed: 8s, ETA:   107s[>>                              ] 69/929, 8.1 task/s, elapsed: 9s, ETA:   107s[>>                              ] 70/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 71/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 72/929, 8.1 task/s, elapsed: 9s, ETA:   106s[>>                              ] 73/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 74/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 75/929, 8.1 task/s, elapsed: 9s, ETA:   105s[>>                              ] 76/929, 8.2 task/s, elapsed: 9s, ETA:   104s[>>                              ] 77/929, 8.2 task/s, elapsed: 9s, ETA:   104s[>>                             ] 78/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 79/929, 8.2 task/s, elapsed: 10s, ETA:   104s[>>                             ] 80/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 81/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 82/929, 8.2 task/s, elapsed: 10s, ETA:   103s[>>                             ] 83/929, 8.3 task/s, elapsed: 10s, ETA:   102s[>>                             ] 84/929, 8.3 task/s, elapsed: 10s, ETA:   102s[>>                             ] 85/929, 8.3 task/s, elapsed: 10s, ETA:   102s[>>                             ] 86/929, 8.3 task/s, elapsed: 10s, ETA:   102s[>>                             ] 87/929, 8.3 task/s, elapsed: 10s, ETA:   101s[>>                             ] 88/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>                             ] 89/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 90/929, 8.3 task/s, elapsed: 11s, ETA:   101s[>>>                            ] 91/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 92/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 93/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 94/929, 8.4 task/s, elapsed: 11s, ETA:   100s[>>>                            ] 95/929, 8.4 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 96/929, 8.4 task/s, elapsed: 11s, ETA:    99s[>>>                            ] 97/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                            ] 98/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                            ] 99/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 100/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 101/929, 8.4 task/s, elapsed: 12s, ETA:    99s[>>>                           ] 102/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 103/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 104/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 105/929, 8.4 task/s, elapsed: 12s, ETA:    98s[>>>                           ] 106/929, 8.4 task/s, elapsed: 13s, ETA:    98s[>>>                           ] 107/929, 8.4 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 108/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 109/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 110/929, 8.5 task/s, elapsed: 13s, ETA:    97s[>>>                           ] 111/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 112/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 113/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 114/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 115/929, 8.5 task/s, elapsed: 13s, ETA:    96s[>>>                           ] 116/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 117/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 118/929, 8.5 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 119/929, 8.6 task/s, elapsed: 14s, ETA:    95s[>>>                           ] 120/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 121/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 122/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>                           ] 123/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>>                          ] 124/929, 8.6 task/s, elapsed: 14s, ETA:    94s[>>>>                          ] 125/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 126/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 127/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 128/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 129/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 130/929, 8.6 task/s, elapsed: 15s, ETA:    93s[>>>>                          ] 131/929, 8.6 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 132/929, 8.6 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 133/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 134/929, 8.7 task/s, elapsed: 15s, ETA:    92s[>>>>                          ] 135/929, 8.7 task/s, elapsed: 16s, ETA:    92s[>>>>                          ] 136/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 137/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 138/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 139/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 140/929, 8.7 task/s, elapsed: 16s, ETA:    91s[>>>>                          ] 141/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 142/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 143/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 144/929, 8.7 task/s, elapsed: 16s, ETA:    90s[>>>>                          ] 145/929, 8.7 task/s, elapsed: 17s, ETA:    90s[>>>>                          ] 146/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 147/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 148/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 149/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 150/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 151/929, 8.8 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 152/929, 8.7 task/s, elapsed: 17s, ETA:    89s[>>>>                          ] 153/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>                          ] 154/929, 8.7 task/s, elapsed: 18s, ETA:    89s[>>>>>                         ] 155/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 156/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 157/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 158/929, 8.7 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 159/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 160/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 161/929, 8.8 task/s, elapsed: 18s, ETA:    88s[>>>>>                         ] 162/929, 8.8 task/s, elapsed: 18s, ETA:    87s[>>>>>                         ] 163/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 164/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 165/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 166/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 167/929, 8.8 task/s, elapsed: 19s, ETA:    87s[>>>>>                         ] 168/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 169/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 170/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 171/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 172/929, 8.8 task/s, elapsed: 19s, ETA:    86s[>>>>>                         ] 173/929, 8.8 task/s, elapsed: 20s, ETA:    86s[>>>>>                         ] 174/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 175/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 176/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 177/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 178/929, 8.8 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 179/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 180/929, 8.9 task/s, elapsed: 20s, ETA:    85s[>>>>>                         ] 181/929, 8.9 task/s, elapsed: 20s, ETA:    84s[>>>>>                         ] 182/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 183/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 184/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>                         ] 185/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 186/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 187/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 188/929, 8.9 task/s, elapsed: 21s, ETA:    84s[>>>>>>                        ] 189/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 190/929, 8.9 task/s, elapsed: 21s, ETA:    83s[>>>>>>                        ] 191/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 192/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 193/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 194/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 195/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 196/929, 8.9 task/s, elapsed: 22s, ETA:    83s[>>>>>>                        ] 197/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 198/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 199/929, 8.9 task/s, elapsed: 22s, ETA:    82s[>>>>>>                        ] 200/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 201/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 202/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 203/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 204/929, 8.9 task/s, elapsed: 23s, ETA:    82s[>>>>>>                        ] 205/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 206/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 207/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 208/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 209/929, 8.9 task/s, elapsed: 23s, ETA:    81s[>>>>>>                        ] 210/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 211/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 212/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 213/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 214/929, 8.9 task/s, elapsed: 24s, ETA:    81s[>>>>>>                        ] 215/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>                        ] 216/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 217/929, 8.9 task/s, elapsed: 24s, ETA:    80s[>>>>>>>                       ] 218/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 219/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 220/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 221/929, 8.9 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 222/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 223/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 224/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 225/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 226/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 227/929, 8.9 task/s, elapsed: 25s, ETA:    79s[>>>>>>>                       ] 228/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 229/929, 8.9 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 230/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 231/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 232/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 233/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 234/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 235/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 236/929, 8.9 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 237/929, 8.9 task/s, elapsed: 27s, ETA:    78s[>>>>>>>                       ] 238/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 239/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 240/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 241/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 242/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 243/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 244/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 245/929, 8.9 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 246/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>                       ] 247/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 248/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 249/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 250/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 251/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 252/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 253/929, 8.9 task/s, elapsed: 28s, ETA:    76s[>>>>>>>>                      ] 254/929, 8.9 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 255/929, 8.9 task/s, elapsed: 28s, ETA:    75s[>>>>>>>>                      ] 256/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 257/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 258/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 259/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 260/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 261/929, 9.0 task/s, elapsed: 29s, ETA:    75s[>>>>>>>>                      ] 262/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 263/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 264/929, 9.0 task/s, elapsed: 29s, ETA:    74s[>>>>>>>>                      ] 265/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 266/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 267/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 268/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 269/929, 9.0 task/s, elapsed: 30s, ETA:    74s[>>>>>>>>                      ] 270/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 271/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 272/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 273/929, 9.0 task/s, elapsed: 30s, ETA:    73s[>>>>>>>>                      ] 274/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 275/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 276/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 277/929, 9.0 task/s, elapsed: 31s, ETA:    73s[>>>>>>>>                      ] 278/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 279/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 280/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 281/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 282/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 283/929, 9.0 task/s, elapsed: 31s, ETA:    72s[>>>>>>>>>                     ] 284/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 285/929, 9.0 task/s, elapsed: 32s, ETA:    72s[>>>>>>>>>                     ] 286/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 287/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 288/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 289/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 290/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 291/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 292/929, 9.0 task/s, elapsed: 32s, ETA:    71s[>>>>>>>>>                     ] 293/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 294/929, 9.0 task/s, elapsed: 33s, ETA:    71s[>>>>>>>>>                     ] 295/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 296/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 297/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 298/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 299/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 300/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 301/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 302/929, 9.0 task/s, elapsed: 33s, ETA:    70s[>>>>>>>>>                     ] 303/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 304/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 305/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 306/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 307/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 308/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>                     ] 309/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 310/929, 9.0 task/s, elapsed: 34s, ETA:    69s[>>>>>>>>>>                    ] 311/929, 9.0 task/s, elapsed: 34s, ETA:    68s[>>>>>>>>>>                    ] 312/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 313/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 314/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 315/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 316/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 317/929, 9.0 task/s, elapsed: 35s, ETA:    68s[>>>>>>>>>>                    ] 318/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 319/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 320/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 321/929, 9.1 task/s, elapsed: 35s, ETA:    67s[>>>>>>>>>>                    ] 322/929, 9.1 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 323/929, 9.1 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 324/929, 9.1 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 325/929, 9.1 task/s, elapsed: 36s, ETA:    67s[>>>>>>>>>>                    ] 326/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 327/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 328/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 329/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 330/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 331/929, 9.1 task/s, elapsed: 36s, ETA:    66s[>>>>>>>>>>                    ] 332/929, 9.1 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 333/929, 9.1 task/s, elapsed: 37s, ETA:    66s[>>>>>>>>>>                    ] 334/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 335/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 336/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 337/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 338/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 339/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>                    ] 340/929, 9.1 task/s, elapsed: 37s, ETA:    65s[>>>>>>>>>>>                   ] 341/929, 9.1 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 342/929, 9.1 task/s, elapsed: 38s, ETA:    65s[>>>>>>>>>>>                   ] 343/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 344/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 345/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 346/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 347/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 348/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 349/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 350/929, 9.1 task/s, elapsed: 38s, ETA:    64s[>>>>>>>>>>>                   ] 351/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 352/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 353/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 354/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 355/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 356/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 357/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 358/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 359/929, 9.1 task/s, elapsed: 39s, ETA:    63s[>>>>>>>>>>>                   ] 360/929, 9.1 task/s, elapsed: 39s, ETA:    62s[>>>>>>>>>>>                   ] 361/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 362/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 363/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 364/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 365/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 366/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 367/929, 9.1 task/s, elapsed: 40s, ETA:    62s[>>>>>>>>>>>                   ] 368/929, 9.1 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 369/929, 9.1 task/s, elapsed: 40s, ETA:    61s[>>>>>>>>>>>                   ] 370/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>                   ] 371/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 372/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 373/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 374/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 375/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 376/929, 9.1 task/s, elapsed: 41s, ETA:    61s[>>>>>>>>>>>>                  ] 377/929, 9.1 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 378/929, 9.1 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 379/929, 9.1 task/s, elapsed: 41s, ETA:    60s[>>>>>>>>>>>>                  ] 380/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 381/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 382/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 383/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 384/929, 9.1 task/s, elapsed: 42s, ETA:    60s[>>>>>>>>>>>>                  ] 385/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 386/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 387/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 388/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 389/929, 9.2 task/s, elapsed: 42s, ETA:    59s[>>>>>>>>>>>>                  ] 390/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 391/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 392/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 393/929, 9.2 task/s, elapsed: 43s, ETA:    59s[>>>>>>>>>>>>                  ] 394/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 395/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 396/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 397/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 398/929, 9.2 task/s, elapsed: 43s, ETA:    58s[>>>>>>>>>>>>                  ] 399/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 400/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 401/929, 9.2 task/s, elapsed: 44s, ETA:    58s[>>>>>>>>>>>>                  ] 402/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 403/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 404/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 405/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 406/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 407/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 408/929, 9.2 task/s, elapsed: 44s, ETA:    57s[>>>>>>>>>>>>>                 ] 409/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 410/929, 9.2 task/s, elapsed: 45s, ETA:    57s[>>>>>>>>>>>>>                 ] 411/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 412/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 413/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 414/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 415/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 416/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 417/929, 9.2 task/s, elapsed: 45s, ETA:    56s[>>>>>>>>>>>>>                 ] 418/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 419/929, 9.2 task/s, elapsed: 46s, ETA:    56s[>>>>>>>>>>>>>                 ] 420/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 421/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 422/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 423/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 424/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 425/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 426/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 427/929, 9.2 task/s, elapsed: 46s, ETA:    55s[>>>>>>>>>>>>>                 ] 428/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 429/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 430/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 431/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 432/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>                 ] 433/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 434/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 435/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 436/929, 9.2 task/s, elapsed: 47s, ETA:    54s[>>>>>>>>>>>>>>                ] 437/929, 9.2 task/s, elapsed: 47s, ETA:    53s[>>>>>>>>>>>>>>                ] 438/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 439/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 440/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 441/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 442/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 443/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 444/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 445/929, 9.2 task/s, elapsed: 48s, ETA:    53s[>>>>>>>>>>>>>>                ] 446/929, 9.2 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 447/929, 9.2 task/s, elapsed: 48s, ETA:    52s[>>>>>>>>>>>>>>                ] 448/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 449/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 450/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 451/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 452/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 453/929, 9.2 task/s, elapsed: 49s, ETA:    52s[>>>>>>>>>>>>>>                ] 454/929, 9.2 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 455/929, 9.2 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 456/929, 9.2 task/s, elapsed: 49s, ETA:    51s[>>>>>>>>>>>>>>                ] 457/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 458/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 459/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 460/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 461/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 462/929, 9.2 task/s, elapsed: 50s, ETA:    51s[>>>>>>>>>>>>>>                ] 463/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>                ] 464/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 465/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 466/929, 9.2 task/s, elapsed: 50s, ETA:    50s[>>>>>>>>>>>>>>>               ] 467/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 468/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 469/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 470/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 471/929, 9.2 task/s, elapsed: 51s, ETA:    50s[>>>>>>>>>>>>>>>               ] 472/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 473/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 474/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 475/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 476/929, 9.2 task/s, elapsed: 51s, ETA:    49s[>>>>>>>>>>>>>>>               ] 477/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 478/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 479/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 480/929, 9.2 task/s, elapsed: 52s, ETA:    49s[>>>>>>>>>>>>>>>               ] 481/929, 9.2 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 482/929, 9.2 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 483/929, 9.2 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 484/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 485/929, 9.3 task/s, elapsed: 52s, ETA:    48s[>>>>>>>>>>>>>>>               ] 486/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 487/929, 9.3 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 488/929, 9.2 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 489/929, 9.3 task/s, elapsed: 53s, ETA:    48s[>>>>>>>>>>>>>>>               ] 490/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 491/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 492/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 493/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 494/929, 9.3 task/s, elapsed: 53s, ETA:    47s[>>>>>>>>>>>>>>>               ] 495/929, 9.3 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 496/929, 9.3 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 497/929, 9.3 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 498/929, 9.3 task/s, elapsed: 54s, ETA:    47s[>>>>>>>>>>>>>>>>              ] 499/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 500/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 501/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 502/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 503/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 504/929, 9.3 task/s, elapsed: 54s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 505/929, 9.3 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 506/929, 9.3 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 507/929, 9.3 task/s, elapsed: 55s, ETA:    46s[>>>>>>>>>>>>>>>>              ] 508/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 509/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 510/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 511/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 512/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 513/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 514/929, 9.3 task/s, elapsed: 55s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 515/929, 9.3 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 516/929, 9.3 task/s, elapsed: 56s, ETA:    45s[>>>>>>>>>>>>>>>>              ] 517/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 518/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 519/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 520/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 521/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 522/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 523/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 524/929, 9.3 task/s, elapsed: 56s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 525/929, 9.3 task/s, elapsed: 57s, ETA:    44s[>>>>>>>>>>>>>>>>              ] 526/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 527/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 528/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 529/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 530/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 531/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 532/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 533/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 534/929, 9.3 task/s, elapsed: 57s, ETA:    43s[>>>>>>>>>>>>>>>>>             ] 535/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 536/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 537/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 538/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 539/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 540/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 541/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 542/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 543/929, 9.3 task/s, elapsed: 58s, ETA:    42s[>>>>>>>>>>>>>>>>>             ] 544/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 545/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 546/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 547/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 548/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 549/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 550/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 551/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 552/929, 9.3 task/s, elapsed: 59s, ETA:    41s[>>>>>>>>>>>>>>>>>             ] 553/929, 9.3 task/s, elapsed: 59s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 554/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 555/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 556/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>             ] 557/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 558/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 559/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 560/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 561/929, 9.3 task/s, elapsed: 60s, ETA:    40s[>>>>>>>>>>>>>>>>>>            ] 562/929, 9.3 task/s, elapsed: 60s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 563/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 564/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 565/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 566/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 567/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 568/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 569/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 570/929, 9.3 task/s, elapsed: 61s, ETA:    39s[>>>>>>>>>>>>>>>>>>            ] 571/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 572/929, 9.3 task/s, elapsed: 61s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 573/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 574/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 575/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 576/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 577/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 578/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 579/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 580/929, 9.3 task/s, elapsed: 62s, ETA:    38s[>>>>>>>>>>>>>>>>>>            ] 581/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 582/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 583/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 584/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 585/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 586/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 587/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>            ] 588/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 589/929, 9.3 task/s, elapsed: 63s, ETA:    37s[>>>>>>>>>>>>>>>>>>>           ] 590/929, 9.3 task/s, elapsed: 63s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 591/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 592/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 593/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 594/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 595/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 596/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 597/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 598/929, 9.3 task/s, elapsed: 64s, ETA:    36s[>>>>>>>>>>>>>>>>>>>           ] 599/929, 9.3 task/s, elapsed: 64s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 600/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 601/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 602/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 603/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 604/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 605/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 606/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 607/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 608/929, 9.3 task/s, elapsed: 65s, ETA:    35s[>>>>>>>>>>>>>>>>>>>           ] 609/929, 9.3 task/s, elapsed: 65s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 610/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 611/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 612/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 613/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 614/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 615/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 616/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 617/929, 9.3 task/s, elapsed: 66s, ETA:    34s[>>>>>>>>>>>>>>>>>>>           ] 618/929, 9.3 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>           ] 619/929, 9.3 task/s, elapsed: 66s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 620/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 621/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 622/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 623/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 624/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 625/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 626/929, 9.3 task/s, elapsed: 67s, ETA:    33s[>>>>>>>>>>>>>>>>>>>>          ] 627/929, 9.3 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 628/929, 9.3 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 629/929, 9.3 task/s, elapsed: 67s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 630/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 631/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 632/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 633/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 634/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 635/929, 9.3 task/s, elapsed: 68s, ETA:    32s[>>>>>>>>>>>>>>>>>>>>          ] 636/929, 9.3 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 637/929, 9.3 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 638/929, 9.3 task/s, elapsed: 68s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 639/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 640/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 641/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 642/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 643/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 644/929, 9.3 task/s, elapsed: 69s, ETA:    31s[>>>>>>>>>>>>>>>>>>>>          ] 645/929, 9.3 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 646/929, 9.3 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 647/929, 9.3 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 648/929, 9.3 task/s, elapsed: 69s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 649/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>          ] 650/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 651/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 652/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 653/929, 9.3 task/s, elapsed: 70s, ETA:    30s[>>>>>>>>>>>>>>>>>>>>>         ] 654/929, 9.3 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 655/929, 9.3 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 656/929, 9.3 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 657/929, 9.3 task/s, elapsed: 70s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 658/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 659/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 660/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 661/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 662/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 663/929, 9.3 task/s, elapsed: 71s, ETA:    29s[>>>>>>>>>>>>>>>>>>>>>         ] 664/929, 9.3 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 665/929, 9.3 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 666/929, 9.3 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 667/929, 9.3 task/s, elapsed: 71s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 668/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 669/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 670/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 671/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 672/929, 9.3 task/s, elapsed: 72s, ETA:    28s[>>>>>>>>>>>>>>>>>>>>>         ] 673/929, 9.3 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 674/929, 9.3 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 675/929, 9.3 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 676/929, 9.3 task/s, elapsed: 72s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 677/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 678/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 679/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 680/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>         ] 681/929, 9.3 task/s, elapsed: 73s, ETA:    27s[>>>>>>>>>>>>>>>>>>>>>>        ] 682/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 683/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 684/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 685/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 686/929, 9.3 task/s, elapsed: 73s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 687/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 688/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 689/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 690/929, 9.3 task/s, elapsed: 74s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>>>        ] 691/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 692/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 693/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 694/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 695/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 696/929, 9.3 task/s, elapsed: 74s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 697/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 698/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 699/929, 9.3 task/s, elapsed: 75s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>>>        ] 700/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 701/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 702/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 703/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 704/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 705/929, 9.3 task/s, elapsed: 75s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 706/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 707/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 708/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 709/929, 9.3 task/s, elapsed: 76s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>>        ] 710/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 711/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>        ] 712/929, 9.4 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 713/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 714/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 715/929, 9.3 task/s, elapsed: 76s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 716/929, 9.4 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 717/929, 9.4 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 718/929, 9.4 task/s, elapsed: 77s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>>>       ] 719/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 720/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 721/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 722/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 723/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 724/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 725/929, 9.4 task/s, elapsed: 77s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 726/929, 9.4 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 727/929, 9.4 task/s, elapsed: 78s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>>>       ] 728/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 729/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 730/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 731/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 732/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 733/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 734/929, 9.4 task/s, elapsed: 78s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 735/929, 9.4 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 736/929, 9.4 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 737/929, 9.4 task/s, elapsed: 79s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>>       ] 738/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 739/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 740/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 741/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 742/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>       ] 743/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 744/929, 9.4 task/s, elapsed: 79s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 745/929, 9.4 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 746/929, 9.4 task/s, elapsed: 80s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 747/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 748/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 749/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 750/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 751/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 752/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 753/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 754/929, 9.4 task/s, elapsed: 80s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 755/929, 9.4 task/s, elapsed: 81s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 756/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 757/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 758/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 759/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 760/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 761/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 762/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 763/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 764/929, 9.4 task/s, elapsed: 81s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 765/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 766/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 767/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 768/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 769/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 770/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 771/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 772/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 773/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 774/929, 9.4 task/s, elapsed: 82s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 775/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 776/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 777/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 778/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 779/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 780/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 781/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 782/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 783/929, 9.4 task/s, elapsed: 83s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 784/929, 9.4 task/s, elapsed: 83s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 785/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 786/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 787/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 788/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 789/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 790/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 791/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 792/929, 9.4 task/s, elapsed: 84s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 793/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 794/929, 9.4 task/s, elapsed: 84s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 795/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 796/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 797/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 798/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 799/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 800/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 801/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 802/929, 9.4 task/s, elapsed: 85s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 803/929, 9.4 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 804/929, 9.4 task/s, elapsed: 85s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 805/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 806/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 807/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 808/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 809/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 810/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 811/929, 9.4 task/s, elapsed: 86s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 812/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 813/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 814/929, 9.4 task/s, elapsed: 86s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 815/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 816/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 817/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 818/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 819/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 820/929, 9.4 task/s, elapsed: 87s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 821/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 822/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 823/929, 9.4 task/s, elapsed: 87s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 824/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 825/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 826/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 827/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 828/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 829/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 830/929, 9.4 task/s, elapsed: 88s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 831/929, 9.4 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 832/929, 9.4 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 833/929, 9.4 task/s, elapsed: 88s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 834/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 835/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 836/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 837/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 838/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 839/929, 9.4 task/s, elapsed: 89s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 840/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 841/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 842/929, 9.4 task/s, elapsed: 89s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 843/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 844/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 845/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 846/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 847/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 848/929, 9.4 task/s, elapsed: 90s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 849/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 850/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 851/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 852/929, 9.4 task/s, elapsed: 90s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 853/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 854/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 855/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 856/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 857/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 858/929, 9.4 task/s, elapsed: 91s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 859/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 860/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 861/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 862/929, 9.4 task/s, elapsed: 91s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 863/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 864/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 865/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 866/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 867/929, 9.4 task/s, elapsed: 92s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 868/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 869/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 870/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 871/929, 9.4 task/s, elapsed: 92s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 872/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 873/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 874/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 875/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 876/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 877/929, 9.4 task/s, elapsed: 93s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 878/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 879/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 880/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 881/929, 9.4 task/s, elapsed: 93s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 882/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 883/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 884/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 885/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 886/929, 9.4 task/s, elapsed: 94s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 887/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 888/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 889/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 890/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 891/929, 9.4 task/s, elapsed: 94s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 892/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 893/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 894/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 895/929, 9.4 task/s, elapsed: 95s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 896/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 897/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 898/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 899/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 900/929, 9.4 task/s, elapsed: 95s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 901/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 902/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 903/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 904/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 905/929, 9.4 task/s, elapsed: 96s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 906/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 907/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 908/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 909/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 910/929, 9.4 task/s, elapsed: 96s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 911/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 912/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 913/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 914/929, 9.4 task/s, elapsed: 97s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 915/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 916/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 917/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 918/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 919/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 920/929, 9.4 task/s, elapsed: 97s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 921/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 922/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 923/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 924/929, 9.4 task/s, elapsed: 98s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 925/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 926/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 927/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 928/929, 9.4 task/s, elapsed: 98s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 929/929, 9.4 task/s, elapsed: 98s, ETA:     0s2022-10-10 23:14:08,357 - mmseg - INFO - per class results:2022-10-10 23:14:08,358 - mmseg - INFO - +---------------+-------+-------+|     Class     |  IoU  |  Acc  |+---------------+-------+-------+|   background  | 91.29 |  96.3 || rigid_plastic | 37.51 | 43.25 ||   cardboard   | 58.68 | 73.27 ||     metal     | 31.47 | 40.38 ||  soft_plastic | 64.59 | 72.32 |+---------------+-------+-------+2022-10-10 23:14:08,358 - mmseg - INFO - Summary:2022-10-10 23:14:08,358 - mmseg - INFO - +-------+-------+------+|  aAcc |  mIoU | mAcc |+-------+-------+------+| 91.85 | 56.71 | 65.1 |+-------+-------+------+2022-10-10 23:14:08,360 - mmseg - INFO - Saving checkpoint at 40000 iterations